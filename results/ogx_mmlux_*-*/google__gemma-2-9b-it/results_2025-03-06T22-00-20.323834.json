{
  "results": {
    "ogx_mmlux_sv-world_religions": {
      "acc,none": 0.7777777777777778,
      "acc_stderr,none": 0.03188578017686398,
      "alias": "ogx_mmlux_sv-world_religions"
    },
    "ogx_mmlux_sv-virology": {
      "acc,none": 0.5481927710843374,
      "acc_stderr,none": 0.038743715565879536,
      "alias": "ogx_mmlux_sv-virology"
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "acc,none": 0.84,
      "acc_stderr,none": 0.03684529491774708,
      "alias": "ogx_mmlux_sv-us_foreign_policy"
    },
    "ogx_mmlux_sv-sociology": {
      "acc,none": 0.845771144278607,
      "acc_stderr,none": 0.02553843336857833,
      "alias": "ogx_mmlux_sv-sociology"
    },
    "ogx_mmlux_sv-security_studies": {
      "acc,none": 0.7673469387755102,
      "acc_stderr,none": 0.02704925791589618,
      "alias": "ogx_mmlux_sv-security_studies"
    },
    "ogx_mmlux_sv-public_relations": {
      "acc,none": 0.6818181818181818,
      "acc_stderr,none": 0.04461272175910509,
      "alias": "ogx_mmlux_sv-public_relations"
    },
    "ogx_mmlux_sv-professional_psychology": {
      "acc,none": 0.684640522875817,
      "acc_stderr,none": 0.018798086284886887,
      "alias": "ogx_mmlux_sv-professional_psychology"
    },
    "ogx_mmlux_sv-professional_medicine": {
      "acc,none": 0.6911764705882353,
      "acc_stderr,none": 0.028064998167040094,
      "alias": "ogx_mmlux_sv-professional_medicine"
    },
    "ogx_mmlux_sv-professional_law": {
      "acc,none": 0.4680573663624511,
      "acc_stderr,none": 0.012744149704869645,
      "alias": "ogx_mmlux_sv-professional_law"
    },
    "ogx_mmlux_sv-professional_accounting": {
      "acc,none": 0.4858156028368794,
      "acc_stderr,none": 0.02981549448368206,
      "alias": "ogx_mmlux_sv-professional_accounting"
    },
    "ogx_mmlux_sv-prehistory": {
      "acc,none": 0.7314814814814815,
      "acc_stderr,none": 0.02465968518596729,
      "alias": "ogx_mmlux_sv-prehistory"
    },
    "ogx_mmlux_sv-philosophy": {
      "acc,none": 0.6977491961414791,
      "acc_stderr,none": 0.02608270069539965,
      "alias": "ogx_mmlux_sv-philosophy"
    },
    "ogx_mmlux_sv-nutrition": {
      "acc,none": 0.6928104575163399,
      "acc_stderr,none": 0.026415601914388995,
      "alias": "ogx_mmlux_sv-nutrition"
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "acc,none": 0.36312849162011174,
      "acc_stderr,none": 0.0160837499868537,
      "alias": "ogx_mmlux_sv-moral_scenarios"
    },
    "ogx_mmlux_sv-moral_disputes": {
      "acc,none": 0.6907514450867052,
      "acc_stderr,none": 0.024883140570071748,
      "alias": "ogx_mmlux_sv-moral_disputes"
    },
    "ogx_mmlux_sv-miscellaneous": {
      "acc,none": 0.8186462324393359,
      "acc_stderr,none": 0.013778693778464078,
      "alias": "ogx_mmlux_sv-miscellaneous"
    },
    "ogx_mmlux_sv-medical_genetics": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_sv-medical_genetics"
    },
    "ogx_mmlux_sv-marketing": {
      "acc,none": 0.8589743589743589,
      "acc_stderr,none": 0.022801382534597535,
      "alias": "ogx_mmlux_sv-marketing"
    },
    "ogx_mmlux_sv-management": {
      "acc,none": 0.7961165048543689,
      "acc_stderr,none": 0.0398913985953177,
      "alias": "ogx_mmlux_sv-management"
    },
    "ogx_mmlux_sv-machine_learning": {
      "acc,none": 0.45535714285714285,
      "acc_stderr,none": 0.04726835553719099,
      "alias": "ogx_mmlux_sv-machine_learning"
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "acc,none": 0.7116564417177914,
      "acc_stderr,none": 0.03559039531617342,
      "alias": "ogx_mmlux_sv-logical_fallacies"
    },
    "ogx_mmlux_sv-jurisprudence": {
      "acc,none": 0.7407407407407407,
      "acc_stderr,none": 0.04236511258094633,
      "alias": "ogx_mmlux_sv-jurisprudence"
    },
    "ogx_mmlux_sv-international_law": {
      "acc,none": 0.7933884297520661,
      "acc_stderr,none": 0.03695980128098822,
      "alias": "ogx_mmlux_sv-international_law"
    },
    "ogx_mmlux_sv-human_sexuality": {
      "acc,none": 0.7786259541984732,
      "acc_stderr,none": 0.03641297081313728,
      "alias": "ogx_mmlux_sv-human_sexuality"
    },
    "ogx_mmlux_sv-human_aging": {
      "acc,none": 0.7174887892376681,
      "acc_stderr,none": 0.030216831011508762,
      "alias": "ogx_mmlux_sv-human_aging"
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "acc,none": 0.8227848101265823,
      "acc_stderr,none": 0.024856364184503234,
      "alias": "ogx_mmlux_sv-high_school_world_history"
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "acc,none": 0.8627450980392157,
      "acc_stderr,none": 0.024152225962801577,
      "alias": "ogx_mmlux_sv-high_school_us_history"
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "acc,none": 0.5879629629629629,
      "acc_stderr,none": 0.03356787758160831,
      "alias": "ogx_mmlux_sv-high_school_statistics"
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "acc,none": 0.8623853211009175,
      "acc_stderr,none": 0.014770105878649442,
      "alias": "ogx_mmlux_sv-high_school_psychology"
    },
    "ogx_mmlux_sv-high_school_physics": {
      "acc,none": 0.5231788079470199,
      "acc_stderr,none": 0.04078093859163084,
      "alias": "ogx_mmlux_sv-high_school_physics"
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "acc,none": 0.7563025210084033,
      "acc_stderr,none": 0.027886828078380572,
      "alias": "ogx_mmlux_sv-high_school_microeconomics"
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "acc,none": 0.3962962962962963,
      "acc_stderr,none": 0.029822619458534,
      "alias": "ogx_mmlux_sv-high_school_mathematics"
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "acc,none": 0.7128205128205128,
      "acc_stderr,none": 0.02293992541853062,
      "alias": "ogx_mmlux_sv-high_school_macroeconomics"
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "acc,none": 0.8497409326424871,
      "acc_stderr,none": 0.025787723180723882,
      "alias": "ogx_mmlux_sv-high_school_government_and_politics"
    },
    "ogx_mmlux_sv-high_school_geography": {
      "acc,none": 0.8181818181818182,
      "acc_stderr,none": 0.027479603010538787,
      "alias": "ogx_mmlux_sv-high_school_geography"
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "acc,none": 0.806060606060606,
      "acc_stderr,none": 0.0308741451365621,
      "alias": "ogx_mmlux_sv-high_school_european_history"
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.04408440022768079,
      "alias": "ogx_mmlux_sv-high_school_computer_science"
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "acc,none": 0.6896551724137931,
      "acc_stderr,none": 0.03255086769970103,
      "alias": "ogx_mmlux_sv-high_school_chemistry"
    },
    "ogx_mmlux_sv-high_school_biology": {
      "acc,none": 0.8548387096774194,
      "acc_stderr,none": 0.02003956362805331,
      "alias": "ogx_mmlux_sv-high_school_biology"
    },
    "ogx_mmlux_sv-global_facts": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.04999999999999999,
      "alias": "ogx_mmlux_sv-global_facts"
    },
    "ogx_mmlux_sv-formal_logic": {
      "acc,none": 0.42857142857142855,
      "acc_stderr,none": 0.0442626668137991,
      "alias": "ogx_mmlux_sv-formal_logic"
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "acc,none": 0.5132275132275133,
      "acc_stderr,none": 0.025742297289575142,
      "alias": "ogx_mmlux_sv-elementary_mathematics"
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "acc,none": 0.6275862068965518,
      "acc_stderr,none": 0.04028731532947558,
      "alias": "ogx_mmlux_sv-electrical_engineering"
    },
    "ogx_mmlux_sv-econometrics": {
      "acc,none": 0.5877192982456141,
      "acc_stderr,none": 0.046306532033665956,
      "alias": "ogx_mmlux_sv-econometrics"
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "acc,none": 0.6936170212765957,
      "acc_stderr,none": 0.03013590647851756,
      "alias": "ogx_mmlux_sv-conceptual_physics"
    },
    "ogx_mmlux_sv-computer_security": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.04408440022768079,
      "alias": "ogx_mmlux_sv-computer_security"
    },
    "ogx_mmlux_sv-college_physics": {
      "acc,none": 0.46078431372549017,
      "acc_stderr,none": 0.04959859966384181,
      "alias": "ogx_mmlux_sv-college_physics"
    },
    "ogx_mmlux_sv-college_medicine": {
      "acc,none": 0.653179190751445,
      "acc_stderr,none": 0.03629146670159663,
      "alias": "ogx_mmlux_sv-college_medicine"
    },
    "ogx_mmlux_sv-college_mathematics": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252604,
      "alias": "ogx_mmlux_sv-college_mathematics"
    },
    "ogx_mmlux_sv-college_computer_science": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620333,
      "alias": "ogx_mmlux_sv-college_computer_science"
    },
    "ogx_mmlux_sv-college_chemistry": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_sv-college_chemistry"
    },
    "ogx_mmlux_sv-college_biology": {
      "acc,none": 0.7638888888888888,
      "acc_stderr,none": 0.03551446610810826,
      "alias": "ogx_mmlux_sv-college_biology"
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "acc,none": 0.6981132075471698,
      "acc_stderr,none": 0.02825420034443866,
      "alias": "ogx_mmlux_sv-clinical_knowledge"
    },
    "ogx_mmlux_sv-business_ethics": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_sv-business_ethics"
    },
    "ogx_mmlux_sv-astronomy": {
      "acc,none": 0.7763157894736842,
      "acc_stderr,none": 0.03391160934343604,
      "alias": "ogx_mmlux_sv-astronomy"
    },
    "ogx_mmlux_sv-anatomy": {
      "acc,none": 0.6592592592592592,
      "acc_stderr,none": 0.040943762699967946,
      "alias": "ogx_mmlux_sv-anatomy"
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_sv-abstract_algebra"
    },
    "ogx_mmlux_sl-world_religions": {
      "acc,none": 0.8304093567251462,
      "acc_stderr,none": 0.02878210810540171,
      "alias": "ogx_mmlux_sl-world_religions"
    },
    "ogx_mmlux_sl-virology": {
      "acc,none": 0.5060240963855421,
      "acc_stderr,none": 0.03892212195333045,
      "alias": "ogx_mmlux_sl-virology"
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "acc,none": 0.78,
      "acc_stderr,none": 0.041633319989322605,
      "alias": "ogx_mmlux_sl-us_foreign_policy"
    },
    "ogx_mmlux_sl-sociology": {
      "acc,none": 0.8009950248756219,
      "acc_stderr,none": 0.028231365092758406,
      "alias": "ogx_mmlux_sl-sociology"
    },
    "ogx_mmlux_sl-security_studies": {
      "acc,none": 0.710204081632653,
      "acc_stderr,none": 0.029043088683304345,
      "alias": "ogx_mmlux_sl-security_studies"
    },
    "ogx_mmlux_sl-public_relations": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.0469237132203465,
      "alias": "ogx_mmlux_sl-public_relations"
    },
    "ogx_mmlux_sl-professional_psychology": {
      "acc,none": 0.6339869281045751,
      "acc_stderr,none": 0.01948802574552967,
      "alias": "ogx_mmlux_sl-professional_psychology"
    },
    "ogx_mmlux_sl-professional_medicine": {
      "acc,none": 0.6397058823529411,
      "acc_stderr,none": 0.029163128570670733,
      "alias": "ogx_mmlux_sl-professional_medicine"
    },
    "ogx_mmlux_sl-professional_law": {
      "acc,none": 0.4471968709256845,
      "acc_stderr,none": 0.012698825252435111,
      "alias": "ogx_mmlux_sl-professional_law"
    },
    "ogx_mmlux_sl-professional_accounting": {
      "acc,none": 0.4574468085106383,
      "acc_stderr,none": 0.029719281272236834,
      "alias": "ogx_mmlux_sl-professional_accounting"
    },
    "ogx_mmlux_sl-prehistory": {
      "acc,none": 0.7438271604938271,
      "acc_stderr,none": 0.0242885336377261,
      "alias": "ogx_mmlux_sl-prehistory"
    },
    "ogx_mmlux_sl-philosophy": {
      "acc,none": 0.6881028938906752,
      "acc_stderr,none": 0.02631185807185416,
      "alias": "ogx_mmlux_sl-philosophy"
    },
    "ogx_mmlux_sl-nutrition": {
      "acc,none": 0.6895424836601307,
      "acc_stderr,none": 0.026493033225145905,
      "alias": "ogx_mmlux_sl-nutrition"
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "acc,none": 0.18435754189944134,
      "acc_stderr,none": 0.012969152811883461,
      "alias": "ogx_mmlux_sl-moral_scenarios"
    },
    "ogx_mmlux_sl-moral_disputes": {
      "acc,none": 0.6763005780346821,
      "acc_stderr,none": 0.025190181327608415,
      "alias": "ogx_mmlux_sl-moral_disputes"
    },
    "ogx_mmlux_sl-miscellaneous": {
      "acc,none": 0.7496807151979565,
      "acc_stderr,none": 0.015491088951494605,
      "alias": "ogx_mmlux_sl-miscellaneous"
    },
    "ogx_mmlux_sl-medical_genetics": {
      "acc,none": 0.72,
      "acc_stderr,none": 0.04512608598542127,
      "alias": "ogx_mmlux_sl-medical_genetics"
    },
    "ogx_mmlux_sl-marketing": {
      "acc,none": 0.8504273504273504,
      "acc_stderr,none": 0.023365051491753715,
      "alias": "ogx_mmlux_sl-marketing"
    },
    "ogx_mmlux_sl-management": {
      "acc,none": 0.7669902912621359,
      "acc_stderr,none": 0.04185832598928315,
      "alias": "ogx_mmlux_sl-management"
    },
    "ogx_mmlux_sl-machine_learning": {
      "acc,none": 0.44642857142857145,
      "acc_stderr,none": 0.04718471485219588,
      "alias": "ogx_mmlux_sl-machine_learning"
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "acc,none": 0.7055214723926381,
      "acc_stderr,none": 0.03581165790474082,
      "alias": "ogx_mmlux_sl-logical_fallacies"
    },
    "ogx_mmlux_sl-jurisprudence": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.04186091791394607,
      "alias": "ogx_mmlux_sl-jurisprudence"
    },
    "ogx_mmlux_sl-international_law": {
      "acc,none": 0.7851239669421488,
      "acc_stderr,none": 0.03749492448709695,
      "alias": "ogx_mmlux_sl-international_law"
    },
    "ogx_mmlux_sl-human_sexuality": {
      "acc,none": 0.7404580152671756,
      "acc_stderr,none": 0.03844876139785271,
      "alias": "ogx_mmlux_sl-human_sexuality"
    },
    "ogx_mmlux_sl-human_aging": {
      "acc,none": 0.6905829596412556,
      "acc_stderr,none": 0.03102441174057221,
      "alias": "ogx_mmlux_sl-human_aging"
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "acc,none": 0.7974683544303798,
      "acc_stderr,none": 0.026160568246601453,
      "alias": "ogx_mmlux_sl-high_school_world_history"
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "acc,none": 0.7990196078431373,
      "acc_stderr,none": 0.028125972265654366,
      "alias": "ogx_mmlux_sl-high_school_us_history"
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "acc,none": 0.5879629629629629,
      "acc_stderr,none": 0.03356787758160831,
      "alias": "ogx_mmlux_sl-high_school_statistics"
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "acc,none": 0.8091743119266055,
      "acc_stderr,none": 0.0168476764000911,
      "alias": "ogx_mmlux_sl-high_school_psychology"
    },
    "ogx_mmlux_sl-high_school_physics": {
      "acc,none": 0.5231788079470199,
      "acc_stderr,none": 0.04078093859163084,
      "alias": "ogx_mmlux_sl-high_school_physics"
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "acc,none": 0.7226890756302521,
      "acc_stderr,none": 0.02907937453948001,
      "alias": "ogx_mmlux_sl-high_school_microeconomics"
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "acc,none": 0.3925925925925926,
      "acc_stderr,none": 0.02977384701253297,
      "alias": "ogx_mmlux_sl-high_school_mathematics"
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.02323458108842849,
      "alias": "ogx_mmlux_sl-high_school_macroeconomics"
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "acc,none": 0.7772020725388601,
      "acc_stderr,none": 0.03003114797764154,
      "alias": "ogx_mmlux_sl-high_school_government_and_politics"
    },
    "ogx_mmlux_sl-high_school_geography": {
      "acc,none": 0.7676767676767676,
      "acc_stderr,none": 0.030088629490217487,
      "alias": "ogx_mmlux_sl-high_school_geography"
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "acc,none": 0.8181818181818182,
      "acc_stderr,none": 0.030117688929503582,
      "alias": "ogx_mmlux_sl-high_school_european_history"
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_sl-high_school_computer_science"
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "acc,none": 0.6108374384236454,
      "acc_stderr,none": 0.034304624161038716,
      "alias": "ogx_mmlux_sl-high_school_chemistry"
    },
    "ogx_mmlux_sl-high_school_biology": {
      "acc,none": 0.8032258064516129,
      "acc_stderr,none": 0.022616409420742018,
      "alias": "ogx_mmlux_sl-high_school_biology"
    },
    "ogx_mmlux_sl-global_facts": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_sl-global_facts"
    },
    "ogx_mmlux_sl-formal_logic": {
      "acc,none": 0.4126984126984127,
      "acc_stderr,none": 0.04403438954768176,
      "alias": "ogx_mmlux_sl-formal_logic"
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "acc,none": 0.5052910052910053,
      "acc_stderr,none": 0.02574986828855657,
      "alias": "ogx_mmlux_sl-elementary_mathematics"
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "acc,none": 0.5655172413793104,
      "acc_stderr,none": 0.04130740879555498,
      "alias": "ogx_mmlux_sl-electrical_engineering"
    },
    "ogx_mmlux_sl-econometrics": {
      "acc,none": 0.5350877192982456,
      "acc_stderr,none": 0.04692008381368909,
      "alias": "ogx_mmlux_sl-econometrics"
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "acc,none": 0.6212765957446809,
      "acc_stderr,none": 0.03170995606040655,
      "alias": "ogx_mmlux_sl-conceptual_physics"
    },
    "ogx_mmlux_sl-computer_security": {
      "acc,none": 0.69,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_sl-computer_security"
    },
    "ogx_mmlux_sl-college_physics": {
      "acc,none": 0.47058823529411764,
      "acc_stderr,none": 0.049665709039785295,
      "alias": "ogx_mmlux_sl-college_physics"
    },
    "ogx_mmlux_sl-college_medicine": {
      "acc,none": 0.6473988439306358,
      "acc_stderr,none": 0.036430371689585475,
      "alias": "ogx_mmlux_sl-college_medicine"
    },
    "ogx_mmlux_sl-college_mathematics": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695236,
      "alias": "ogx_mmlux_sl-college_mathematics"
    },
    "ogx_mmlux_sl-college_computer_science": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_sl-college_computer_science"
    },
    "ogx_mmlux_sl-college_chemistry": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_sl-college_chemistry"
    },
    "ogx_mmlux_sl-college_biology": {
      "acc,none": 0.6944444444444444,
      "acc_stderr,none": 0.03852084696008534,
      "alias": "ogx_mmlux_sl-college_biology"
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "acc,none": 0.6452830188679245,
      "acc_stderr,none": 0.029445175328199583,
      "alias": "ogx_mmlux_sl-clinical_knowledge"
    },
    "ogx_mmlux_sl-business_ethics": {
      "acc,none": 0.69,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_sl-business_ethics"
    },
    "ogx_mmlux_sl-astronomy": {
      "acc,none": 0.7631578947368421,
      "acc_stderr,none": 0.03459777606810536,
      "alias": "ogx_mmlux_sl-astronomy"
    },
    "ogx_mmlux_sl-anatomy": {
      "acc,none": 0.5925925925925926,
      "acc_stderr,none": 0.04244633238353228,
      "alias": "ogx_mmlux_sl-anatomy"
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_sl-abstract_algebra"
    },
    "ogx_mmlux_sk-world_religions": {
      "acc,none": 0.783625730994152,
      "acc_stderr,none": 0.031581495393387324,
      "alias": "ogx_mmlux_sk-world_religions"
    },
    "ogx_mmlux_sk-virology": {
      "acc,none": 0.4939759036144578,
      "acc_stderr,none": 0.03892212195333045,
      "alias": "ogx_mmlux_sk-virology"
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "acc,none": 0.83,
      "acc_stderr,none": 0.0377525168068637,
      "alias": "ogx_mmlux_sk-us_foreign_policy"
    },
    "ogx_mmlux_sk-sociology": {
      "acc,none": 0.8208955223880597,
      "acc_stderr,none": 0.027113286753111837,
      "alias": "ogx_mmlux_sk-sociology"
    },
    "ogx_mmlux_sk-security_studies": {
      "acc,none": 0.7795918367346939,
      "acc_stderr,none": 0.026537045312145274,
      "alias": "ogx_mmlux_sk-security_studies"
    },
    "ogx_mmlux_sk-public_relations": {
      "acc,none": 0.6363636363636364,
      "acc_stderr,none": 0.04607582090719976,
      "alias": "ogx_mmlux_sk-public_relations"
    },
    "ogx_mmlux_sk-professional_psychology": {
      "acc,none": 0.6454248366013072,
      "acc_stderr,none": 0.019353360547553704,
      "alias": "ogx_mmlux_sk-professional_psychology"
    },
    "ogx_mmlux_sk-professional_medicine": {
      "acc,none": 0.6176470588235294,
      "acc_stderr,none": 0.02952009569768776,
      "alias": "ogx_mmlux_sk-professional_medicine"
    },
    "ogx_mmlux_sk-professional_law": {
      "acc,none": 0.45697522816166886,
      "acc_stderr,none": 0.01272286950161142,
      "alias": "ogx_mmlux_sk-professional_law"
    },
    "ogx_mmlux_sk-professional_accounting": {
      "acc,none": 0.42907801418439717,
      "acc_stderr,none": 0.029525914302558562,
      "alias": "ogx_mmlux_sk-professional_accounting"
    },
    "ogx_mmlux_sk-prehistory": {
      "acc,none": 0.7746913580246914,
      "acc_stderr,none": 0.02324620264781975,
      "alias": "ogx_mmlux_sk-prehistory"
    },
    "ogx_mmlux_sk-philosophy": {
      "acc,none": 0.6881028938906752,
      "acc_stderr,none": 0.02631185807185416,
      "alias": "ogx_mmlux_sk-philosophy"
    },
    "ogx_mmlux_sk-nutrition": {
      "acc,none": 0.7091503267973857,
      "acc_stderr,none": 0.02600480036395213,
      "alias": "ogx_mmlux_sk-nutrition"
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "acc,none": 0.2770949720670391,
      "acc_stderr,none": 0.014968772435812145,
      "alias": "ogx_mmlux_sk-moral_scenarios"
    },
    "ogx_mmlux_sk-moral_disputes": {
      "acc,none": 0.6676300578034682,
      "acc_stderr,none": 0.025361168749688225,
      "alias": "ogx_mmlux_sk-moral_disputes"
    },
    "ogx_mmlux_sk-miscellaneous": {
      "acc,none": 0.7662835249042146,
      "acc_stderr,none": 0.015133383278988829,
      "alias": "ogx_mmlux_sk-miscellaneous"
    },
    "ogx_mmlux_sk-medical_genetics": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_sk-medical_genetics"
    },
    "ogx_mmlux_sk-marketing": {
      "acc,none": 0.8504273504273504,
      "acc_stderr,none": 0.02336505149175372,
      "alias": "ogx_mmlux_sk-marketing"
    },
    "ogx_mmlux_sk-management": {
      "acc,none": 0.7669902912621359,
      "acc_stderr,none": 0.04185832598928315,
      "alias": "ogx_mmlux_sk-management"
    },
    "ogx_mmlux_sk-machine_learning": {
      "acc,none": 0.45535714285714285,
      "acc_stderr,none": 0.04726835553719099,
      "alias": "ogx_mmlux_sk-machine_learning"
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "acc,none": 0.7177914110429447,
      "acc_stderr,none": 0.03536117886664742,
      "alias": "ogx_mmlux_sk-logical_fallacies"
    },
    "ogx_mmlux_sk-jurisprudence": {
      "acc,none": 0.7314814814814815,
      "acc_stderr,none": 0.042844679680521934,
      "alias": "ogx_mmlux_sk-jurisprudence"
    },
    "ogx_mmlux_sk-international_law": {
      "acc,none": 0.7933884297520661,
      "acc_stderr,none": 0.03695980128098823,
      "alias": "ogx_mmlux_sk-international_law"
    },
    "ogx_mmlux_sk-human_sexuality": {
      "acc,none": 0.7175572519083969,
      "acc_stderr,none": 0.03948406125768362,
      "alias": "ogx_mmlux_sk-human_sexuality"
    },
    "ogx_mmlux_sk-human_aging": {
      "acc,none": 0.7085201793721974,
      "acc_stderr,none": 0.030500283176545847,
      "alias": "ogx_mmlux_sk-human_aging"
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "acc,none": 0.8016877637130801,
      "acc_stderr,none": 0.025955020841621098,
      "alias": "ogx_mmlux_sk-high_school_world_history"
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "acc,none": 0.7990196078431373,
      "acc_stderr,none": 0.028125972265654362,
      "alias": "ogx_mmlux_sk-high_school_us_history"
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "acc,none": 0.5879629629629629,
      "acc_stderr,none": 0.03356787758160831,
      "alias": "ogx_mmlux_sk-high_school_statistics"
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "acc,none": 0.8128440366972477,
      "acc_stderr,none": 0.016722684526200154,
      "alias": "ogx_mmlux_sk-high_school_psychology"
    },
    "ogx_mmlux_sk-high_school_physics": {
      "acc,none": 0.543046357615894,
      "acc_stderr,none": 0.04067325174247442,
      "alias": "ogx_mmlux_sk-high_school_physics"
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "acc,none": 0.7184873949579832,
      "acc_stderr,none": 0.02921354941437216,
      "alias": "ogx_mmlux_sk-high_school_microeconomics"
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "acc,none": 0.40370370370370373,
      "acc_stderr,none": 0.02991481234222762,
      "alias": "ogx_mmlux_sk-high_school_mathematics"
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "acc,none": 0.7153846153846154,
      "acc_stderr,none": 0.022878322799706283,
      "alias": "ogx_mmlux_sk-high_school_macroeconomics"
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "acc,none": 0.7668393782383419,
      "acc_stderr,none": 0.03051611137147601,
      "alias": "ogx_mmlux_sk-high_school_government_and_politics"
    },
    "ogx_mmlux_sk-high_school_geography": {
      "acc,none": 0.8181818181818182,
      "acc_stderr,none": 0.0274796030105388,
      "alias": "ogx_mmlux_sk-high_school_geography"
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "acc,none": 0.8303030303030303,
      "acc_stderr,none": 0.02931118867498312,
      "alias": "ogx_mmlux_sk-high_school_european_history"
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_sk-high_school_computer_science"
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "acc,none": 0.6354679802955665,
      "acc_stderr,none": 0.0338640574606209,
      "alias": "ogx_mmlux_sk-high_school_chemistry"
    },
    "ogx_mmlux_sk-high_school_biology": {
      "acc,none": 0.8483870967741935,
      "acc_stderr,none": 0.020402616654416745,
      "alias": "ogx_mmlux_sk-high_school_biology"
    },
    "ogx_mmlux_sk-global_facts": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_sk-global_facts"
    },
    "ogx_mmlux_sk-formal_logic": {
      "acc,none": 0.4365079365079365,
      "acc_stderr,none": 0.04435932892851466,
      "alias": "ogx_mmlux_sk-formal_logic"
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "acc,none": 0.5423280423280423,
      "acc_stderr,none": 0.02565886886205833,
      "alias": "ogx_mmlux_sk-elementary_mathematics"
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "acc,none": 0.6137931034482759,
      "acc_stderr,none": 0.04057324734419035,
      "alias": "ogx_mmlux_sk-electrical_engineering"
    },
    "ogx_mmlux_sk-econometrics": {
      "acc,none": 0.5350877192982456,
      "acc_stderr,none": 0.046920083813689104,
      "alias": "ogx_mmlux_sk-econometrics"
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "acc,none": 0.6723404255319149,
      "acc_stderr,none": 0.030683020843231,
      "alias": "ogx_mmlux_sk-conceptual_physics"
    },
    "ogx_mmlux_sk-computer_security": {
      "acc,none": 0.67,
      "acc_stderr,none": 0.04725815626252609,
      "alias": "ogx_mmlux_sk-computer_security"
    },
    "ogx_mmlux_sk-college_physics": {
      "acc,none": 0.4215686274509804,
      "acc_stderr,none": 0.04913595201274498,
      "alias": "ogx_mmlux_sk-college_physics"
    },
    "ogx_mmlux_sk-college_medicine": {
      "acc,none": 0.6878612716763006,
      "acc_stderr,none": 0.03533133389323657,
      "alias": "ogx_mmlux_sk-college_medicine"
    },
    "ogx_mmlux_sk-college_mathematics": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_sk-college_mathematics"
    },
    "ogx_mmlux_sk-college_computer_science": {
      "acc,none": 0.53,
      "acc_stderr,none": 0.050161355804659205,
      "alias": "ogx_mmlux_sk-college_computer_science"
    },
    "ogx_mmlux_sk-college_chemistry": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956911,
      "alias": "ogx_mmlux_sk-college_chemistry"
    },
    "ogx_mmlux_sk-college_biology": {
      "acc,none": 0.7569444444444444,
      "acc_stderr,none": 0.03586879280080342,
      "alias": "ogx_mmlux_sk-college_biology"
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "acc,none": 0.6830188679245283,
      "acc_stderr,none": 0.028637235639800893,
      "alias": "ogx_mmlux_sk-clinical_knowledge"
    },
    "ogx_mmlux_sk-business_ethics": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.04461960433384739,
      "alias": "ogx_mmlux_sk-business_ethics"
    },
    "ogx_mmlux_sk-astronomy": {
      "acc,none": 0.7631578947368421,
      "acc_stderr,none": 0.03459777606810536,
      "alias": "ogx_mmlux_sk-astronomy"
    },
    "ogx_mmlux_sk-anatomy": {
      "acc,none": 0.6222222222222222,
      "acc_stderr,none": 0.04188307537595853,
      "alias": "ogx_mmlux_sk-anatomy"
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_sk-abstract_algebra"
    },
    "ogx_mmlux_ro-world_religions": {
      "acc,none": 0.8304093567251462,
      "acc_stderr,none": 0.02878210810540171,
      "alias": "ogx_mmlux_ro-world_religions"
    },
    "ogx_mmlux_ro-virology": {
      "acc,none": 0.5180722891566265,
      "acc_stderr,none": 0.038899512528272166,
      "alias": "ogx_mmlux_ro-virology"
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "acc,none": 0.84,
      "acc_stderr,none": 0.03684529491774709,
      "alias": "ogx_mmlux_ro-us_foreign_policy"
    },
    "ogx_mmlux_ro-sociology": {
      "acc,none": 0.8109452736318408,
      "acc_stderr,none": 0.027686913588013028,
      "alias": "ogx_mmlux_ro-sociology"
    },
    "ogx_mmlux_ro-security_studies": {
      "acc,none": 0.7836734693877551,
      "acc_stderr,none": 0.02635891633490402,
      "alias": "ogx_mmlux_ro-security_studies"
    },
    "ogx_mmlux_ro-public_relations": {
      "acc,none": 0.6545454545454545,
      "acc_stderr,none": 0.04554619617541054,
      "alias": "ogx_mmlux_ro-public_relations"
    },
    "ogx_mmlux_ro-professional_psychology": {
      "acc,none": 0.6748366013071896,
      "acc_stderr,none": 0.018950886770806297,
      "alias": "ogx_mmlux_ro-professional_psychology"
    },
    "ogx_mmlux_ro-professional_medicine": {
      "acc,none": 0.6727941176470589,
      "acc_stderr,none": 0.028501452860396563,
      "alias": "ogx_mmlux_ro-professional_medicine"
    },
    "ogx_mmlux_ro-professional_law": {
      "acc,none": 0.4589308996088657,
      "acc_stderr,none": 0.012727084826799798,
      "alias": "ogx_mmlux_ro-professional_law"
    },
    "ogx_mmlux_ro-professional_accounting": {
      "acc,none": 0.475177304964539,
      "acc_stderr,none": 0.029790719243829714,
      "alias": "ogx_mmlux_ro-professional_accounting"
    },
    "ogx_mmlux_ro-prehistory": {
      "acc,none": 0.7530864197530864,
      "acc_stderr,none": 0.023993501709042103,
      "alias": "ogx_mmlux_ro-prehistory"
    },
    "ogx_mmlux_ro-philosophy": {
      "acc,none": 0.7041800643086816,
      "acc_stderr,none": 0.025922371788818788,
      "alias": "ogx_mmlux_ro-philosophy"
    },
    "ogx_mmlux_ro-nutrition": {
      "acc,none": 0.7091503267973857,
      "acc_stderr,none": 0.02600480036395213,
      "alias": "ogx_mmlux_ro-nutrition"
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "acc,none": 0.4245810055865922,
      "acc_stderr,none": 0.01653117099327888,
      "alias": "ogx_mmlux_ro-moral_scenarios"
    },
    "ogx_mmlux_ro-moral_disputes": {
      "acc,none": 0.6936416184971098,
      "acc_stderr,none": 0.0248183501294366,
      "alias": "ogx_mmlux_ro-moral_disputes"
    },
    "ogx_mmlux_ro-miscellaneous": {
      "acc,none": 0.7854406130268199,
      "acc_stderr,none": 0.014680033956893346,
      "alias": "ogx_mmlux_ro-miscellaneous"
    },
    "ogx_mmlux_ro-medical_genetics": {
      "acc,none": 0.81,
      "acc_stderr,none": 0.03942772444036624,
      "alias": "ogx_mmlux_ro-medical_genetics"
    },
    "ogx_mmlux_ro-marketing": {
      "acc,none": 0.8675213675213675,
      "acc_stderr,none": 0.02220930907316562,
      "alias": "ogx_mmlux_ro-marketing"
    },
    "ogx_mmlux_ro-management": {
      "acc,none": 0.8252427184466019,
      "acc_stderr,none": 0.0376017800602662,
      "alias": "ogx_mmlux_ro-management"
    },
    "ogx_mmlux_ro-machine_learning": {
      "acc,none": 0.45535714285714285,
      "acc_stderr,none": 0.04726835553719099,
      "alias": "ogx_mmlux_ro-machine_learning"
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "acc,none": 0.7116564417177914,
      "acc_stderr,none": 0.03559039531617342,
      "alias": "ogx_mmlux_ro-logical_fallacies"
    },
    "ogx_mmlux_ro-jurisprudence": {
      "acc,none": 0.7685185185185185,
      "acc_stderr,none": 0.04077494709252627,
      "alias": "ogx_mmlux_ro-jurisprudence"
    },
    "ogx_mmlux_ro-international_law": {
      "acc,none": 0.7851239669421488,
      "acc_stderr,none": 0.03749492448709699,
      "alias": "ogx_mmlux_ro-international_law"
    },
    "ogx_mmlux_ro-human_sexuality": {
      "acc,none": 0.7557251908396947,
      "acc_stderr,none": 0.03768335959728743,
      "alias": "ogx_mmlux_ro-human_sexuality"
    },
    "ogx_mmlux_ro-human_aging": {
      "acc,none": 0.7219730941704036,
      "acc_stderr,none": 0.030069584874494033,
      "alias": "ogx_mmlux_ro-human_aging"
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "acc,none": 0.8312236286919831,
      "acc_stderr,none": 0.02438140683258623,
      "alias": "ogx_mmlux_ro-high_school_world_history"
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "acc,none": 0.8480392156862745,
      "acc_stderr,none": 0.0251956584289318,
      "alias": "ogx_mmlux_ro-high_school_us_history"
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "acc,none": 0.5416666666666666,
      "acc_stderr,none": 0.03398110890294636,
      "alias": "ogx_mmlux_ro-high_school_statistics"
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "acc,none": 0.8330275229357799,
      "acc_stderr,none": 0.015990154885073413,
      "alias": "ogx_mmlux_ro-high_school_psychology"
    },
    "ogx_mmlux_ro-high_school_physics": {
      "acc,none": 0.5364238410596026,
      "acc_stderr,none": 0.04071636065944216,
      "alias": "ogx_mmlux_ro-high_school_physics"
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "acc,none": 0.7310924369747899,
      "acc_stderr,none": 0.028801392193631273,
      "alias": "ogx_mmlux_ro-high_school_microeconomics"
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "acc,none": 0.4111111111111111,
      "acc_stderr,none": 0.02999992350870668,
      "alias": "ogx_mmlux_ro-high_school_mathematics"
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "acc,none": 0.7076923076923077,
      "acc_stderr,none": 0.02306043838085774,
      "alias": "ogx_mmlux_ro-high_school_macroeconomics"
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "acc,none": 0.8290155440414507,
      "acc_stderr,none": 0.027171213683164542,
      "alias": "ogx_mmlux_ro-high_school_government_and_politics"
    },
    "ogx_mmlux_ro-high_school_geography": {
      "acc,none": 0.8181818181818182,
      "acc_stderr,none": 0.0274796030105388,
      "alias": "ogx_mmlux_ro-high_school_geography"
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "acc,none": 0.8121212121212121,
      "acc_stderr,none": 0.03050193405942914,
      "alias": "ogx_mmlux_ro-high_school_european_history"
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.04560480215720684,
      "alias": "ogx_mmlux_ro-high_school_computer_science"
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "acc,none": 0.6551724137931034,
      "acc_stderr,none": 0.03344283744280458,
      "alias": "ogx_mmlux_ro-high_school_chemistry"
    },
    "ogx_mmlux_ro-high_school_biology": {
      "acc,none": 0.8580645161290322,
      "acc_stderr,none": 0.019853003676559764,
      "alias": "ogx_mmlux_ro-high_school_biology"
    },
    "ogx_mmlux_ro-global_facts": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_ro-global_facts"
    },
    "ogx_mmlux_ro-formal_logic": {
      "acc,none": 0.47619047619047616,
      "acc_stderr,none": 0.04467062628403273,
      "alias": "ogx_mmlux_ro-formal_logic"
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "acc,none": 0.5370370370370371,
      "acc_stderr,none": 0.025680564640056882,
      "alias": "ogx_mmlux_ro-elementary_mathematics"
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "acc,none": 0.593103448275862,
      "acc_stderr,none": 0.04093793981266236,
      "alias": "ogx_mmlux_ro-electrical_engineering"
    },
    "ogx_mmlux_ro-econometrics": {
      "acc,none": 0.5526315789473685,
      "acc_stderr,none": 0.04677473004491199,
      "alias": "ogx_mmlux_ro-econometrics"
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "acc,none": 0.6851063829787234,
      "acc_stderr,none": 0.030363582197238156,
      "alias": "ogx_mmlux_ro-conceptual_physics"
    },
    "ogx_mmlux_ro-computer_security": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_ro-computer_security"
    },
    "ogx_mmlux_ro-college_physics": {
      "acc,none": 0.47058823529411764,
      "acc_stderr,none": 0.049665709039785295,
      "alias": "ogx_mmlux_ro-college_physics"
    },
    "ogx_mmlux_ro-college_medicine": {
      "acc,none": 0.6473988439306358,
      "acc_stderr,none": 0.036430371689585475,
      "alias": "ogx_mmlux_ro-college_medicine"
    },
    "ogx_mmlux_ro-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_ro-college_mathematics"
    },
    "ogx_mmlux_ro-college_computer_science": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_ro-college_computer_science"
    },
    "ogx_mmlux_ro-college_chemistry": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_ro-college_chemistry"
    },
    "ogx_mmlux_ro-college_biology": {
      "acc,none": 0.7986111111111112,
      "acc_stderr,none": 0.0335364746971384,
      "alias": "ogx_mmlux_ro-college_biology"
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "acc,none": 0.6981132075471698,
      "acc_stderr,none": 0.02825420034443866,
      "alias": "ogx_mmlux_ro-clinical_knowledge"
    },
    "ogx_mmlux_ro-business_ethics": {
      "acc,none": 0.72,
      "acc_stderr,none": 0.04512608598542128,
      "alias": "ogx_mmlux_ro-business_ethics"
    },
    "ogx_mmlux_ro-astronomy": {
      "acc,none": 0.743421052631579,
      "acc_stderr,none": 0.0355418036802569,
      "alias": "ogx_mmlux_ro-astronomy"
    },
    "ogx_mmlux_ro-anatomy": {
      "acc,none": 0.5925925925925926,
      "acc_stderr,none": 0.04244633238353229,
      "alias": "ogx_mmlux_ro-anatomy"
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_ro-abstract_algebra"
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "acc,none": 0.847953216374269,
      "acc_stderr,none": 0.027539122889061445,
      "alias": "ogx_mmlux_pt-pt-world_religions"
    },
    "ogx_mmlux_pt-pt-virology": {
      "acc,none": 0.4819277108433735,
      "acc_stderr,none": 0.03889951252827216,
      "alias": "ogx_mmlux_pt-pt-virology"
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "acc,none": 0.81,
      "acc_stderr,none": 0.039427724440366255,
      "alias": "ogx_mmlux_pt-pt-us_foreign_policy"
    },
    "ogx_mmlux_pt-pt-sociology": {
      "acc,none": 0.8059701492537313,
      "acc_stderr,none": 0.0279626776047689,
      "alias": "ogx_mmlux_pt-pt-sociology"
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "acc,none": 0.7551020408163265,
      "acc_stderr,none": 0.027529637440174917,
      "alias": "ogx_mmlux_pt-pt-security_studies"
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "acc,none": 0.6636363636363637,
      "acc_stderr,none": 0.04525393596302506,
      "alias": "ogx_mmlux_pt-pt-public_relations"
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "acc,none": 0.6862745098039216,
      "acc_stderr,none": 0.018771683893528176,
      "alias": "ogx_mmlux_pt-pt-professional_psychology"
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "acc,none": 0.6139705882352942,
      "acc_stderr,none": 0.029573269134411124,
      "alias": "ogx_mmlux_pt-pt-professional_medicine"
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "acc,none": 0.3200782268578879,
      "acc_stderr,none": 0.011914791947638514,
      "alias": "ogx_mmlux_pt-pt-professional_law"
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "acc,none": 0.4432624113475177,
      "acc_stderr,none": 0.029634838473766006,
      "alias": "ogx_mmlux_pt-pt-professional_accounting"
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "acc,none": 0.7407407407407407,
      "acc_stderr,none": 0.02438366553103545,
      "alias": "ogx_mmlux_pt-pt-prehistory"
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "acc,none": 0.7170418006430869,
      "acc_stderr,none": 0.02558306248998483,
      "alias": "ogx_mmlux_pt-pt-philosophy"
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "acc,none": 0.7058823529411765,
      "acc_stderr,none": 0.02609016250427905,
      "alias": "ogx_mmlux_pt-pt-nutrition"
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "acc,none": 0.41675977653631285,
      "acc_stderr,none": 0.016489134962438954,
      "alias": "ogx_mmlux_pt-pt-moral_scenarios"
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "acc,none": 0.7427745664739884,
      "acc_stderr,none": 0.02353292543104428,
      "alias": "ogx_mmlux_pt-pt-moral_disputes"
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "acc,none": 0.7905491698595147,
      "acc_stderr,none": 0.014551310568143697,
      "alias": "ogx_mmlux_pt-pt-miscellaneous"
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "acc,none": 0.78,
      "acc_stderr,none": 0.04163331998932261,
      "alias": "ogx_mmlux_pt-pt-medical_genetics"
    },
    "ogx_mmlux_pt-pt-marketing": {
      "acc,none": 0.8589743589743589,
      "acc_stderr,none": 0.022801382534597528,
      "alias": "ogx_mmlux_pt-pt-marketing"
    },
    "ogx_mmlux_pt-pt-management": {
      "acc,none": 0.7864077669902912,
      "acc_stderr,none": 0.04058042015646034,
      "alias": "ogx_mmlux_pt-pt-management"
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "acc,none": 0.5089285714285714,
      "acc_stderr,none": 0.04745033255489123,
      "alias": "ogx_mmlux_pt-pt-machine_learning"
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "acc,none": 0.7361963190184049,
      "acc_stderr,none": 0.03462419931615624,
      "alias": "ogx_mmlux_pt-pt-logical_fallacies"
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "acc,none": 0.7777777777777778,
      "acc_stderr,none": 0.0401910747255735,
      "alias": "ogx_mmlux_pt-pt-jurisprudence"
    },
    "ogx_mmlux_pt-pt-international_law": {
      "acc,none": 0.8099173553719008,
      "acc_stderr,none": 0.035817969517092825,
      "alias": "ogx_mmlux_pt-pt-international_law"
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "acc,none": 0.7480916030534351,
      "acc_stderr,none": 0.03807387116306086,
      "alias": "ogx_mmlux_pt-pt-human_sexuality"
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "acc,none": 0.7130044843049327,
      "acc_stderr,none": 0.030360379710291967,
      "alias": "ogx_mmlux_pt-pt-human_aging"
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "acc,none": 0.7890295358649789,
      "acc_stderr,none": 0.02655837250266192,
      "alias": "ogx_mmlux_pt-pt-high_school_world_history"
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "acc,none": 0.7205882352941176,
      "acc_stderr,none": 0.03149328104507957,
      "alias": "ogx_mmlux_pt-pt-high_school_us_history"
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "acc,none": 0.42592592592592593,
      "acc_stderr,none": 0.033723432716530624,
      "alias": "ogx_mmlux_pt-pt-high_school_statistics"
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "acc,none": 0.8550458715596331,
      "acc_stderr,none": 0.015094215699700445,
      "alias": "ogx_mmlux_pt-pt-high_school_psychology"
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "acc,none": 0.4503311258278146,
      "acc_stderr,none": 0.04062290018683775,
      "alias": "ogx_mmlux_pt-pt-high_school_physics"
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "acc,none": 0.7142857142857143,
      "acc_stderr,none": 0.02934457250063434,
      "alias": "ogx_mmlux_pt-pt-high_school_microeconomics"
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "acc,none": 0.3148148148148148,
      "acc_stderr,none": 0.028317533496066468,
      "alias": "ogx_mmlux_pt-pt-high_school_mathematics"
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "acc,none": 0.6897435897435897,
      "acc_stderr,none": 0.023454674889404288,
      "alias": "ogx_mmlux_pt-pt-high_school_macroeconomics"
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "acc,none": 0.8497409326424871,
      "acc_stderr,none": 0.025787723180723882,
      "alias": "ogx_mmlux_pt-pt-high_school_government_and_politics"
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "acc,none": 0.8383838383838383,
      "acc_stderr,none": 0.02622591986362929,
      "alias": "ogx_mmlux_pt-pt-high_school_geography"
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "acc,none": 0.47878787878787876,
      "acc_stderr,none": 0.03900828913737302,
      "alias": "ogx_mmlux_pt-pt-high_school_european_history"
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_pt-pt-high_school_computer_science"
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "acc,none": 0.5270935960591133,
      "acc_stderr,none": 0.03512819077876106,
      "alias": "ogx_mmlux_pt-pt-high_school_chemistry"
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "acc,none": 0.8290322580645161,
      "acc_stderr,none": 0.02141724293632157,
      "alias": "ogx_mmlux_pt-pt-high_school_biology"
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_pt-pt-global_facts"
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "acc,none": 0.48412698412698413,
      "acc_stderr,none": 0.04469881854072606,
      "alias": "ogx_mmlux_pt-pt-formal_logic"
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "acc,none": 0.5185185185185185,
      "acc_stderr,none": 0.02573364199183898,
      "alias": "ogx_mmlux_pt-pt-elementary_mathematics"
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "acc,none": 0.6137931034482759,
      "acc_stderr,none": 0.04057324734419034,
      "alias": "ogx_mmlux_pt-pt-electrical_engineering"
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "acc,none": 0.5701754385964912,
      "acc_stderr,none": 0.04657047260594963,
      "alias": "ogx_mmlux_pt-pt-econometrics"
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "acc,none": 0.6851063829787234,
      "acc_stderr,none": 0.03036358219723816,
      "alias": "ogx_mmlux_pt-pt-conceptual_physics"
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_pt-pt-computer_security"
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "acc,none": 0.38235294117647056,
      "acc_stderr,none": 0.04835503696107223,
      "alias": "ogx_mmlux_pt-pt-college_physics"
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "acc,none": 0.630057803468208,
      "acc_stderr,none": 0.0368122963339432,
      "alias": "ogx_mmlux_pt-pt-college_medicine"
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.0446196043338474,
      "alias": "ogx_mmlux_pt-pt-college_mathematics"
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_pt-pt-college_computer_science"
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_pt-pt-college_chemistry"
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "acc,none": 0.8125,
      "acc_stderr,none": 0.032639560491693344,
      "alias": "ogx_mmlux_pt-pt-college_biology"
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "acc,none": 0.6754716981132075,
      "acc_stderr,none": 0.028815615713432118,
      "alias": "ogx_mmlux_pt-pt-clinical_knowledge"
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_pt-pt-business_ethics"
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "acc,none": 0.7105263157894737,
      "acc_stderr,none": 0.036906779861372814,
      "alias": "ogx_mmlux_pt-pt-astronomy"
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.04232073695151589,
      "alias": "ogx_mmlux_pt-pt-anatomy"
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_pt-pt-abstract_algebra"
    },
    "ogx_mmlux_pl-world_religions": {
      "acc,none": 0.8362573099415205,
      "acc_stderr,none": 0.028380919596145866,
      "alias": "ogx_mmlux_pl-world_religions"
    },
    "ogx_mmlux_pl-virology": {
      "acc,none": 0.4759036144578313,
      "acc_stderr,none": 0.03887971849597264,
      "alias": "ogx_mmlux_pl-virology"
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "acc,none": 0.84,
      "acc_stderr,none": 0.03684529491774708,
      "alias": "ogx_mmlux_pl-us_foreign_policy"
    },
    "ogx_mmlux_pl-sociology": {
      "acc,none": 0.7960199004975125,
      "acc_stderr,none": 0.028493176245326088,
      "alias": "ogx_mmlux_pl-sociology"
    },
    "ogx_mmlux_pl-security_studies": {
      "acc,none": 0.7591836734693878,
      "acc_stderr,none": 0.02737294220178817,
      "alias": "ogx_mmlux_pl-security_studies"
    },
    "ogx_mmlux_pl-public_relations": {
      "acc,none": 0.6909090909090909,
      "acc_stderr,none": 0.044262946482000985,
      "alias": "ogx_mmlux_pl-public_relations"
    },
    "ogx_mmlux_pl-professional_psychology": {
      "acc,none": 0.6519607843137255,
      "acc_stderr,none": 0.019270998708223974,
      "alias": "ogx_mmlux_pl-professional_psychology"
    },
    "ogx_mmlux_pl-professional_medicine": {
      "acc,none": 0.5955882352941176,
      "acc_stderr,none": 0.029812630701569736,
      "alias": "ogx_mmlux_pl-professional_medicine"
    },
    "ogx_mmlux_pl-professional_law": {
      "acc,none": 0.45241199478487615,
      "acc_stderr,none": 0.012712265105889136,
      "alias": "ogx_mmlux_pl-professional_law"
    },
    "ogx_mmlux_pl-professional_accounting": {
      "acc,none": 0.4219858156028369,
      "acc_stderr,none": 0.02946218923337059,
      "alias": "ogx_mmlux_pl-professional_accounting"
    },
    "ogx_mmlux_pl-prehistory": {
      "acc,none": 0.7283950617283951,
      "acc_stderr,none": 0.02474862449053737,
      "alias": "ogx_mmlux_pl-prehistory"
    },
    "ogx_mmlux_pl-philosophy": {
      "acc,none": 0.6816720257234726,
      "acc_stderr,none": 0.02645722506781103,
      "alias": "ogx_mmlux_pl-philosophy"
    },
    "ogx_mmlux_pl-nutrition": {
      "acc,none": 0.7091503267973857,
      "acc_stderr,none": 0.02600480036395213,
      "alias": "ogx_mmlux_pl-nutrition"
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "acc,none": 0.358659217877095,
      "acc_stderr,none": 0.016040454426164474,
      "alias": "ogx_mmlux_pl-moral_scenarios"
    },
    "ogx_mmlux_pl-moral_disputes": {
      "acc,none": 0.7052023121387283,
      "acc_stderr,none": 0.02454761779480384,
      "alias": "ogx_mmlux_pl-moral_disputes"
    },
    "ogx_mmlux_pl-miscellaneous": {
      "acc,none": 0.7790549169859514,
      "acc_stderr,none": 0.014836205167333562,
      "alias": "ogx_mmlux_pl-miscellaneous"
    },
    "ogx_mmlux_pl-medical_genetics": {
      "acc,none": 0.76,
      "acc_stderr,none": 0.04292346959909281,
      "alias": "ogx_mmlux_pl-medical_genetics"
    },
    "ogx_mmlux_pl-marketing": {
      "acc,none": 0.8333333333333334,
      "acc_stderr,none": 0.024414947304543674,
      "alias": "ogx_mmlux_pl-marketing"
    },
    "ogx_mmlux_pl-management": {
      "acc,none": 0.8543689320388349,
      "acc_stderr,none": 0.0349260647662379,
      "alias": "ogx_mmlux_pl-management"
    },
    "ogx_mmlux_pl-machine_learning": {
      "acc,none": 0.45535714285714285,
      "acc_stderr,none": 0.04726835553719099,
      "alias": "ogx_mmlux_pl-machine_learning"
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "acc,none": 0.7423312883435583,
      "acc_stderr,none": 0.03436150827846917,
      "alias": "ogx_mmlux_pl-logical_fallacies"
    },
    "ogx_mmlux_pl-jurisprudence": {
      "acc,none": 0.7777777777777778,
      "acc_stderr,none": 0.040191074725573483,
      "alias": "ogx_mmlux_pl-jurisprudence"
    },
    "ogx_mmlux_pl-international_law": {
      "acc,none": 0.768595041322314,
      "acc_stderr,none": 0.03849856098794088,
      "alias": "ogx_mmlux_pl-international_law"
    },
    "ogx_mmlux_pl-human_sexuality": {
      "acc,none": 0.7557251908396947,
      "acc_stderr,none": 0.03768335959728743,
      "alias": "ogx_mmlux_pl-human_sexuality"
    },
    "ogx_mmlux_pl-human_aging": {
      "acc,none": 0.6860986547085202,
      "acc_stderr,none": 0.031146796482972465,
      "alias": "ogx_mmlux_pl-human_aging"
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "acc,none": 0.810126582278481,
      "acc_stderr,none": 0.025530100460233508,
      "alias": "ogx_mmlux_pl-high_school_world_history"
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "acc,none": 0.7990196078431373,
      "acc_stderr,none": 0.028125972265654352,
      "alias": "ogx_mmlux_pl-high_school_us_history"
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "acc,none": 0.5879629629629629,
      "acc_stderr,none": 0.03356787758160831,
      "alias": "ogx_mmlux_pl-high_school_statistics"
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "acc,none": 0.8055045871559633,
      "acc_stderr,none": 0.01697028909045805,
      "alias": "ogx_mmlux_pl-high_school_psychology"
    },
    "ogx_mmlux_pl-high_school_physics": {
      "acc,none": 0.5099337748344371,
      "acc_stderr,none": 0.04081677107248437,
      "alias": "ogx_mmlux_pl-high_school_physics"
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "acc,none": 0.7100840336134454,
      "acc_stderr,none": 0.0294724858331361,
      "alias": "ogx_mmlux_pl-high_school_microeconomics"
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "acc,none": 0.3814814814814815,
      "acc_stderr,none": 0.029616718927497593,
      "alias": "ogx_mmlux_pl-high_school_mathematics"
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "acc,none": 0.7076923076923077,
      "acc_stderr,none": 0.02306043838085775,
      "alias": "ogx_mmlux_pl-high_school_macroeconomics"
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "acc,none": 0.8549222797927462,
      "acc_stderr,none": 0.025416343096306433,
      "alias": "ogx_mmlux_pl-high_school_government_and_politics"
    },
    "ogx_mmlux_pl-high_school_geography": {
      "acc,none": 0.7929292929292929,
      "acc_stderr,none": 0.02886977846026705,
      "alias": "ogx_mmlux_pl-high_school_geography"
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "acc,none": 0.7818181818181819,
      "acc_stderr,none": 0.03225078108306289,
      "alias": "ogx_mmlux_pl-high_school_european_history"
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "acc,none": 0.72,
      "acc_stderr,none": 0.04512608598542127,
      "alias": "ogx_mmlux_pl-high_school_computer_science"
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "acc,none": 0.6403940886699507,
      "acc_stderr,none": 0.03376458246509567,
      "alias": "ogx_mmlux_pl-high_school_chemistry"
    },
    "ogx_mmlux_pl-high_school_biology": {
      "acc,none": 0.8129032258064516,
      "acc_stderr,none": 0.022185710092252245,
      "alias": "ogx_mmlux_pl-high_school_biology"
    },
    "ogx_mmlux_pl-global_facts": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_pl-global_facts"
    },
    "ogx_mmlux_pl-formal_logic": {
      "acc,none": 0.4523809523809524,
      "acc_stderr,none": 0.044518079590553275,
      "alias": "ogx_mmlux_pl-formal_logic"
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "acc,none": 0.5264550264550265,
      "acc_stderr,none": 0.025715239811346758,
      "alias": "ogx_mmlux_pl-elementary_mathematics"
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "acc,none": 0.5724137931034483,
      "acc_stderr,none": 0.04122737111370332,
      "alias": "ogx_mmlux_pl-electrical_engineering"
    },
    "ogx_mmlux_pl-econometrics": {
      "acc,none": 0.4824561403508772,
      "acc_stderr,none": 0.047007080335510376,
      "alias": "ogx_mmlux_pl-econometrics"
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "acc,none": 0.6851063829787234,
      "acc_stderr,none": 0.03036358219723816,
      "alias": "ogx_mmlux_pl-conceptual_physics"
    },
    "ogx_mmlux_pl-computer_security": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_pl-computer_security"
    },
    "ogx_mmlux_pl-college_physics": {
      "acc,none": 0.46078431372549017,
      "acc_stderr,none": 0.049598599663841815,
      "alias": "ogx_mmlux_pl-college_physics"
    },
    "ogx_mmlux_pl-college_medicine": {
      "acc,none": 0.6878612716763006,
      "acc_stderr,none": 0.035331333893236574,
      "alias": "ogx_mmlux_pl-college_medicine"
    },
    "ogx_mmlux_pl-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_pl-college_mathematics"
    },
    "ogx_mmlux_pl-college_computer_science": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_pl-college_computer_science"
    },
    "ogx_mmlux_pl-college_chemistry": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_pl-college_chemistry"
    },
    "ogx_mmlux_pl-college_biology": {
      "acc,none": 0.7291666666666666,
      "acc_stderr,none": 0.03716177437566017,
      "alias": "ogx_mmlux_pl-college_biology"
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "acc,none": 0.6981132075471698,
      "acc_stderr,none": 0.028254200344438665,
      "alias": "ogx_mmlux_pl-clinical_knowledge"
    },
    "ogx_mmlux_pl-business_ethics": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_pl-business_ethics"
    },
    "ogx_mmlux_pl-astronomy": {
      "acc,none": 0.7302631578947368,
      "acc_stderr,none": 0.03611780560284898,
      "alias": "ogx_mmlux_pl-astronomy"
    },
    "ogx_mmlux_pl-anatomy": {
      "acc,none": 0.6148148148148148,
      "acc_stderr,none": 0.042039210401562783,
      "alias": "ogx_mmlux_pl-anatomy"
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_pl-abstract_algebra"
    },
    "ogx_mmlux_nl-world_religions": {
      "acc,none": 0.8128654970760234,
      "acc_stderr,none": 0.029913127232368032,
      "alias": "ogx_mmlux_nl-world_religions"
    },
    "ogx_mmlux_nl-virology": {
      "acc,none": 0.5481927710843374,
      "acc_stderr,none": 0.03874371556587953,
      "alias": "ogx_mmlux_nl-virology"
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "acc,none": 0.85,
      "acc_stderr,none": 0.03588702812826369,
      "alias": "ogx_mmlux_nl-us_foreign_policy"
    },
    "ogx_mmlux_nl-sociology": {
      "acc,none": 0.845771144278607,
      "acc_stderr,none": 0.02553843336857833,
      "alias": "ogx_mmlux_nl-sociology"
    },
    "ogx_mmlux_nl-security_studies": {
      "acc,none": 0.763265306122449,
      "acc_stderr,none": 0.02721283588407315,
      "alias": "ogx_mmlux_nl-security_studies"
    },
    "ogx_mmlux_nl-public_relations": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.04389311454644286,
      "alias": "ogx_mmlux_nl-public_relations"
    },
    "ogx_mmlux_nl-professional_psychology": {
      "acc,none": 0.6748366013071896,
      "acc_stderr,none": 0.018950886770806304,
      "alias": "ogx_mmlux_nl-professional_psychology"
    },
    "ogx_mmlux_nl-professional_medicine": {
      "acc,none": 0.6911764705882353,
      "acc_stderr,none": 0.028064998167040094,
      "alias": "ogx_mmlux_nl-professional_medicine"
    },
    "ogx_mmlux_nl-professional_law": {
      "acc,none": 0.46936114732724904,
      "acc_stderr,none": 0.012746237711716634,
      "alias": "ogx_mmlux_nl-professional_law"
    },
    "ogx_mmlux_nl-professional_accounting": {
      "acc,none": 0.450354609929078,
      "acc_stderr,none": 0.029680105565029036,
      "alias": "ogx_mmlux_nl-professional_accounting"
    },
    "ogx_mmlux_nl-prehistory": {
      "acc,none": 0.7469135802469136,
      "acc_stderr,none": 0.024191808600713,
      "alias": "ogx_mmlux_nl-prehistory"
    },
    "ogx_mmlux_nl-philosophy": {
      "acc,none": 0.6977491961414791,
      "acc_stderr,none": 0.026082700695399655,
      "alias": "ogx_mmlux_nl-philosophy"
    },
    "ogx_mmlux_nl-nutrition": {
      "acc,none": 0.7124183006535948,
      "acc_stderr,none": 0.02591780611714716,
      "alias": "ogx_mmlux_nl-nutrition"
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "acc,none": 0.40893854748603353,
      "acc_stderr,none": 0.01644283065471554,
      "alias": "ogx_mmlux_nl-moral_scenarios"
    },
    "ogx_mmlux_nl-moral_disputes": {
      "acc,none": 0.7138728323699421,
      "acc_stderr,none": 0.024332146779134128,
      "alias": "ogx_mmlux_nl-moral_disputes"
    },
    "ogx_mmlux_nl-miscellaneous": {
      "acc,none": 0.80970625798212,
      "acc_stderr,none": 0.014036945850381392,
      "alias": "ogx_mmlux_nl-miscellaneous"
    },
    "ogx_mmlux_nl-medical_genetics": {
      "acc,none": 0.81,
      "acc_stderr,none": 0.03942772444036624,
      "alias": "ogx_mmlux_nl-medical_genetics"
    },
    "ogx_mmlux_nl-marketing": {
      "acc,none": 0.8547008547008547,
      "acc_stderr,none": 0.0230866350868414,
      "alias": "ogx_mmlux_nl-marketing"
    },
    "ogx_mmlux_nl-management": {
      "acc,none": 0.8155339805825242,
      "acc_stderr,none": 0.03840423627288276,
      "alias": "ogx_mmlux_nl-management"
    },
    "ogx_mmlux_nl-machine_learning": {
      "acc,none": 0.48214285714285715,
      "acc_stderr,none": 0.047427623612430116,
      "alias": "ogx_mmlux_nl-machine_learning"
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "acc,none": 0.7607361963190185,
      "acc_stderr,none": 0.033519538795212696,
      "alias": "ogx_mmlux_nl-logical_fallacies"
    },
    "ogx_mmlux_nl-jurisprudence": {
      "acc,none": 0.7685185185185185,
      "acc_stderr,none": 0.04077494709252626,
      "alias": "ogx_mmlux_nl-jurisprudence"
    },
    "ogx_mmlux_nl-international_law": {
      "acc,none": 0.768595041322314,
      "acc_stderr,none": 0.038498560987940904,
      "alias": "ogx_mmlux_nl-international_law"
    },
    "ogx_mmlux_nl-human_sexuality": {
      "acc,none": 0.7633587786259542,
      "acc_stderr,none": 0.03727673575596914,
      "alias": "ogx_mmlux_nl-human_sexuality"
    },
    "ogx_mmlux_nl-human_aging": {
      "acc,none": 0.7219730941704036,
      "acc_stderr,none": 0.030069584874494057,
      "alias": "ogx_mmlux_nl-human_aging"
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "acc,none": 0.8270042194092827,
      "acc_stderr,none": 0.024621562866768445,
      "alias": "ogx_mmlux_nl-high_school_world_history"
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "acc,none": 0.8480392156862745,
      "acc_stderr,none": 0.0251956584289318,
      "alias": "ogx_mmlux_nl-high_school_us_history"
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "acc,none": 0.5740740740740741,
      "acc_stderr,none": 0.03372343271653063,
      "alias": "ogx_mmlux_nl-high_school_statistics"
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "acc,none": 0.8697247706422019,
      "acc_stderr,none": 0.014431862852473238,
      "alias": "ogx_mmlux_nl-high_school_psychology"
    },
    "ogx_mmlux_nl-high_school_physics": {
      "acc,none": 0.5298013245033113,
      "acc_stderr,none": 0.04075224992216979,
      "alias": "ogx_mmlux_nl-high_school_physics"
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "acc,none": 0.7436974789915967,
      "acc_stderr,none": 0.02835962087053395,
      "alias": "ogx_mmlux_nl-high_school_microeconomics"
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "acc,none": 0.3851851851851852,
      "acc_stderr,none": 0.029670906124630875,
      "alias": "ogx_mmlux_nl-high_school_mathematics"
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "acc,none": 0.7410256410256411,
      "acc_stderr,none": 0.022211106810061658,
      "alias": "ogx_mmlux_nl-high_school_macroeconomics"
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "acc,none": 0.844559585492228,
      "acc_stderr,none": 0.026148483469153314,
      "alias": "ogx_mmlux_nl-high_school_government_and_politics"
    },
    "ogx_mmlux_nl-high_school_geography": {
      "acc,none": 0.8282828282828283,
      "acc_stderr,none": 0.02686971618742992,
      "alias": "ogx_mmlux_nl-high_school_geography"
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "acc,none": 0.8303030303030303,
      "acc_stderr,none": 0.029311188674983116,
      "alias": "ogx_mmlux_nl-high_school_european_history"
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_nl-high_school_computer_science"
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "acc,none": 0.6305418719211823,
      "acc_stderr,none": 0.03395970381998574,
      "alias": "ogx_mmlux_nl-high_school_chemistry"
    },
    "ogx_mmlux_nl-high_school_biology": {
      "acc,none": 0.867741935483871,
      "acc_stderr,none": 0.01927201543484649,
      "alias": "ogx_mmlux_nl-high_school_biology"
    },
    "ogx_mmlux_nl-global_facts": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_nl-global_facts"
    },
    "ogx_mmlux_nl-formal_logic": {
      "acc,none": 0.4523809523809524,
      "acc_stderr,none": 0.044518079590553275,
      "alias": "ogx_mmlux_nl-formal_logic"
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "acc,none": 0.5396825396825397,
      "acc_stderr,none": 0.025670080636909322,
      "alias": "ogx_mmlux_nl-elementary_mathematics"
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "acc,none": 0.6413793103448275,
      "acc_stderr,none": 0.039966295748767186,
      "alias": "ogx_mmlux_nl-electrical_engineering"
    },
    "ogx_mmlux_nl-econometrics": {
      "acc,none": 0.5701754385964912,
      "acc_stderr,none": 0.04657047260594963,
      "alias": "ogx_mmlux_nl-econometrics"
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "acc,none": 0.6851063829787234,
      "acc_stderr,none": 0.030363582197238156,
      "alias": "ogx_mmlux_nl-conceptual_physics"
    },
    "ogx_mmlux_nl-computer_security": {
      "acc,none": 0.68,
      "acc_stderr,none": 0.04688261722621503,
      "alias": "ogx_mmlux_nl-computer_security"
    },
    "ogx_mmlux_nl-college_physics": {
      "acc,none": 0.4803921568627451,
      "acc_stderr,none": 0.04971358884367406,
      "alias": "ogx_mmlux_nl-college_physics"
    },
    "ogx_mmlux_nl-college_medicine": {
      "acc,none": 0.6705202312138728,
      "acc_stderr,none": 0.03583901754736411,
      "alias": "ogx_mmlux_nl-college_medicine"
    },
    "ogx_mmlux_nl-college_mathematics": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.04793724854411018,
      "alias": "ogx_mmlux_nl-college_mathematics"
    },
    "ogx_mmlux_nl-college_computer_science": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620333,
      "alias": "ogx_mmlux_nl-college_computer_science"
    },
    "ogx_mmlux_nl-college_chemistry": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_nl-college_chemistry"
    },
    "ogx_mmlux_nl-college_biology": {
      "acc,none": 0.7916666666666666,
      "acc_stderr,none": 0.033961162058453336,
      "alias": "ogx_mmlux_nl-college_biology"
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "acc,none": 0.7169811320754716,
      "acc_stderr,none": 0.027724236492700918,
      "alias": "ogx_mmlux_nl-clinical_knowledge"
    },
    "ogx_mmlux_nl-business_ethics": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.044084400227680794,
      "alias": "ogx_mmlux_nl-business_ethics"
    },
    "ogx_mmlux_nl-astronomy": {
      "acc,none": 0.756578947368421,
      "acc_stderr,none": 0.034923496688842384,
      "alias": "ogx_mmlux_nl-astronomy"
    },
    "ogx_mmlux_nl-anatomy": {
      "acc,none": 0.6222222222222222,
      "acc_stderr,none": 0.04188307537595853,
      "alias": "ogx_mmlux_nl-anatomy"
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_nl-abstract_algebra"
    },
    "ogx_mmlux_lv-world_religions": {
      "acc,none": 0.7485380116959064,
      "acc_stderr,none": 0.033275044238468436,
      "alias": "ogx_mmlux_lv-world_religions"
    },
    "ogx_mmlux_lv-virology": {
      "acc,none": 0.5180722891566265,
      "acc_stderr,none": 0.03889951252827216,
      "alias": "ogx_mmlux_lv-virology"
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "acc,none": 0.76,
      "acc_stderr,none": 0.04292346959909282,
      "alias": "ogx_mmlux_lv-us_foreign_policy"
    },
    "ogx_mmlux_lv-sociology": {
      "acc,none": 0.7313432835820896,
      "acc_stderr,none": 0.03134328358208954,
      "alias": "ogx_mmlux_lv-sociology"
    },
    "ogx_mmlux_lv-security_studies": {
      "acc,none": 0.710204081632653,
      "acc_stderr,none": 0.029043088683304345,
      "alias": "ogx_mmlux_lv-security_studies"
    },
    "ogx_mmlux_lv-public_relations": {
      "acc,none": 0.5545454545454546,
      "acc_stderr,none": 0.047605488214603246,
      "alias": "ogx_mmlux_lv-public_relations"
    },
    "ogx_mmlux_lv-professional_psychology": {
      "acc,none": 0.5996732026143791,
      "acc_stderr,none": 0.019821843688271775,
      "alias": "ogx_mmlux_lv-professional_psychology"
    },
    "ogx_mmlux_lv-professional_medicine": {
      "acc,none": 0.5772058823529411,
      "acc_stderr,none": 0.030008562845003486,
      "alias": "ogx_mmlux_lv-professional_medicine"
    },
    "ogx_mmlux_lv-professional_law": {
      "acc,none": 0.4302477183833116,
      "acc_stderr,none": 0.012645361435115219,
      "alias": "ogx_mmlux_lv-professional_law"
    },
    "ogx_mmlux_lv-professional_accounting": {
      "acc,none": 0.40425531914893614,
      "acc_stderr,none": 0.029275532159704725,
      "alias": "ogx_mmlux_lv-professional_accounting"
    },
    "ogx_mmlux_lv-prehistory": {
      "acc,none": 0.6820987654320988,
      "acc_stderr,none": 0.02591006352824088,
      "alias": "ogx_mmlux_lv-prehistory"
    },
    "ogx_mmlux_lv-philosophy": {
      "acc,none": 0.6784565916398714,
      "acc_stderr,none": 0.026527724079528872,
      "alias": "ogx_mmlux_lv-philosophy"
    },
    "ogx_mmlux_lv-nutrition": {
      "acc,none": 0.6437908496732027,
      "acc_stderr,none": 0.02742047766262925,
      "alias": "ogx_mmlux_lv-nutrition"
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "acc,none": 0.23128491620111732,
      "acc_stderr,none": 0.014102223623152586,
      "alias": "ogx_mmlux_lv-moral_scenarios"
    },
    "ogx_mmlux_lv-moral_disputes": {
      "acc,none": 0.6127167630057804,
      "acc_stderr,none": 0.026226158605124655,
      "alias": "ogx_mmlux_lv-moral_disputes"
    },
    "ogx_mmlux_lv-miscellaneous": {
      "acc,none": 0.6947637292464879,
      "acc_stderr,none": 0.01646771194763513,
      "alias": "ogx_mmlux_lv-miscellaneous"
    },
    "ogx_mmlux_lv-medical_genetics": {
      "acc,none": 0.67,
      "acc_stderr,none": 0.047258156262526094,
      "alias": "ogx_mmlux_lv-medical_genetics"
    },
    "ogx_mmlux_lv-marketing": {
      "acc,none": 0.811965811965812,
      "acc_stderr,none": 0.025598193686652244,
      "alias": "ogx_mmlux_lv-marketing"
    },
    "ogx_mmlux_lv-management": {
      "acc,none": 0.7572815533980582,
      "acc_stderr,none": 0.04245022486384495,
      "alias": "ogx_mmlux_lv-management"
    },
    "ogx_mmlux_lv-machine_learning": {
      "acc,none": 0.39285714285714285,
      "acc_stderr,none": 0.046355501356099754,
      "alias": "ogx_mmlux_lv-machine_learning"
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "acc,none": 0.6809815950920245,
      "acc_stderr,none": 0.03661997551073836,
      "alias": "ogx_mmlux_lv-logical_fallacies"
    },
    "ogx_mmlux_lv-jurisprudence": {
      "acc,none": 0.6851851851851852,
      "acc_stderr,none": 0.04489931073591312,
      "alias": "ogx_mmlux_lv-jurisprudence"
    },
    "ogx_mmlux_lv-international_law": {
      "acc,none": 0.7603305785123967,
      "acc_stderr,none": 0.038968789850704164,
      "alias": "ogx_mmlux_lv-international_law"
    },
    "ogx_mmlux_lv-human_sexuality": {
      "acc,none": 0.6793893129770993,
      "acc_stderr,none": 0.04093329229834278,
      "alias": "ogx_mmlux_lv-human_sexuality"
    },
    "ogx_mmlux_lv-human_aging": {
      "acc,none": 0.6681614349775785,
      "acc_stderr,none": 0.031602951437766785,
      "alias": "ogx_mmlux_lv-human_aging"
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "acc,none": 0.7552742616033755,
      "acc_stderr,none": 0.027985699387036416,
      "alias": "ogx_mmlux_lv-high_school_world_history"
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "acc,none": 0.7450980392156863,
      "acc_stderr,none": 0.03058759135160426,
      "alias": "ogx_mmlux_lv-high_school_us_history"
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "acc,none": 0.47685185185185186,
      "acc_stderr,none": 0.03406315360711507,
      "alias": "ogx_mmlux_lv-high_school_statistics"
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "acc,none": 0.7596330275229358,
      "acc_stderr,none": 0.01832060732096407,
      "alias": "ogx_mmlux_lv-high_school_psychology"
    },
    "ogx_mmlux_lv-high_school_physics": {
      "acc,none": 0.48344370860927155,
      "acc_stderr,none": 0.040802441856289715,
      "alias": "ogx_mmlux_lv-high_school_physics"
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "acc,none": 0.6722689075630253,
      "acc_stderr,none": 0.03048991141767323,
      "alias": "ogx_mmlux_lv-high_school_microeconomics"
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "acc,none": 0.37777777777777777,
      "acc_stderr,none": 0.029560707392465718,
      "alias": "ogx_mmlux_lv-high_school_mathematics"
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "acc,none": 0.6461538461538462,
      "acc_stderr,none": 0.024243783994062164,
      "alias": "ogx_mmlux_lv-high_school_macroeconomics"
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "acc,none": 0.7357512953367875,
      "acc_stderr,none": 0.03182155050916647,
      "alias": "ogx_mmlux_lv-high_school_government_and_politics"
    },
    "ogx_mmlux_lv-high_school_geography": {
      "acc,none": 0.7525252525252525,
      "acc_stderr,none": 0.030746300742124498,
      "alias": "ogx_mmlux_lv-high_school_geography"
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "acc,none": 0.7454545454545455,
      "acc_stderr,none": 0.03401506715249039,
      "alias": "ogx_mmlux_lv-high_school_european_history"
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "acc,none": 0.76,
      "acc_stderr,none": 0.04292346959909283,
      "alias": "ogx_mmlux_lv-high_school_computer_science"
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "acc,none": 0.6305418719211823,
      "acc_stderr,none": 0.033959703819985726,
      "alias": "ogx_mmlux_lv-high_school_chemistry"
    },
    "ogx_mmlux_lv-high_school_biology": {
      "acc,none": 0.7709677419354839,
      "acc_stderr,none": 0.02390491431178264,
      "alias": "ogx_mmlux_lv-high_school_biology"
    },
    "ogx_mmlux_lv-global_facts": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956913,
      "alias": "ogx_mmlux_lv-global_facts"
    },
    "ogx_mmlux_lv-formal_logic": {
      "acc,none": 0.4523809523809524,
      "acc_stderr,none": 0.044518079590553275,
      "alias": "ogx_mmlux_lv-formal_logic"
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "acc,none": 0.47354497354497355,
      "acc_stderr,none": 0.025715239811346755,
      "alias": "ogx_mmlux_lv-elementary_mathematics"
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "acc,none": 0.5448275862068965,
      "acc_stderr,none": 0.04149886942192118,
      "alias": "ogx_mmlux_lv-electrical_engineering"
    },
    "ogx_mmlux_lv-econometrics": {
      "acc,none": 0.5087719298245614,
      "acc_stderr,none": 0.04702880432049615,
      "alias": "ogx_mmlux_lv-econometrics"
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "acc,none": 0.6042553191489362,
      "acc_stderr,none": 0.03196758697835361,
      "alias": "ogx_mmlux_lv-conceptual_physics"
    },
    "ogx_mmlux_lv-computer_security": {
      "acc,none": 0.69,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_lv-computer_security"
    },
    "ogx_mmlux_lv-college_physics": {
      "acc,none": 0.4411764705882353,
      "acc_stderr,none": 0.049406356306056595,
      "alias": "ogx_mmlux_lv-college_physics"
    },
    "ogx_mmlux_lv-college_medicine": {
      "acc,none": 0.653179190751445,
      "acc_stderr,none": 0.03629146670159663,
      "alias": "ogx_mmlux_lv-college_medicine"
    },
    "ogx_mmlux_lv-college_mathematics": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_lv-college_mathematics"
    },
    "ogx_mmlux_lv-college_computer_science": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_lv-college_computer_science"
    },
    "ogx_mmlux_lv-college_chemistry": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.04999999999999999,
      "alias": "ogx_mmlux_lv-college_chemistry"
    },
    "ogx_mmlux_lv-college_biology": {
      "acc,none": 0.6319444444444444,
      "acc_stderr,none": 0.040329990539607195,
      "alias": "ogx_mmlux_lv-college_biology"
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "acc,none": 0.6415094339622641,
      "acc_stderr,none": 0.02951470358398177,
      "alias": "ogx_mmlux_lv-clinical_knowledge"
    },
    "ogx_mmlux_lv-business_ethics": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_lv-business_ethics"
    },
    "ogx_mmlux_lv-astronomy": {
      "acc,none": 0.7171052631578947,
      "acc_stderr,none": 0.03665349695640767,
      "alias": "ogx_mmlux_lv-astronomy"
    },
    "ogx_mmlux_lv-anatomy": {
      "acc,none": 0.5185185185185185,
      "acc_stderr,none": 0.043163785995113245,
      "alias": "ogx_mmlux_lv-anatomy"
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.047937248544110196,
      "alias": "ogx_mmlux_lv-abstract_algebra"
    },
    "ogx_mmlux_lt-world_religions": {
      "acc,none": 0.7894736842105263,
      "acc_stderr,none": 0.031267817146631786,
      "alias": "ogx_mmlux_lt-world_religions"
    },
    "ogx_mmlux_lt-virology": {
      "acc,none": 0.4819277108433735,
      "acc_stderr,none": 0.03889951252827216,
      "alias": "ogx_mmlux_lt-virology"
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "acc,none": 0.76,
      "acc_stderr,none": 0.04292346959909282,
      "alias": "ogx_mmlux_lt-us_foreign_policy"
    },
    "ogx_mmlux_lt-sociology": {
      "acc,none": 0.7661691542288557,
      "acc_stderr,none": 0.029929415408348384,
      "alias": "ogx_mmlux_lt-sociology"
    },
    "ogx_mmlux_lt-security_studies": {
      "acc,none": 0.7020408163265306,
      "acc_stderr,none": 0.029279567411065677,
      "alias": "ogx_mmlux_lt-security_studies"
    },
    "ogx_mmlux_lt-public_relations": {
      "acc,none": 0.6090909090909091,
      "acc_stderr,none": 0.04673752333670237,
      "alias": "ogx_mmlux_lt-public_relations"
    },
    "ogx_mmlux_lt-professional_psychology": {
      "acc,none": 0.6029411764705882,
      "acc_stderr,none": 0.01979448890002411,
      "alias": "ogx_mmlux_lt-professional_psychology"
    },
    "ogx_mmlux_lt-professional_medicine": {
      "acc,none": 0.5845588235294118,
      "acc_stderr,none": 0.02993534270787774,
      "alias": "ogx_mmlux_lt-professional_medicine"
    },
    "ogx_mmlux_lt-professional_law": {
      "acc,none": 0.4315514993481095,
      "acc_stderr,none": 0.012650007999463893,
      "alias": "ogx_mmlux_lt-professional_law"
    },
    "ogx_mmlux_lt-professional_accounting": {
      "acc,none": 0.4432624113475177,
      "acc_stderr,none": 0.029634838473766006,
      "alias": "ogx_mmlux_lt-professional_accounting"
    },
    "ogx_mmlux_lt-prehistory": {
      "acc,none": 0.6882716049382716,
      "acc_stderr,none": 0.02577311116963045,
      "alias": "ogx_mmlux_lt-prehistory"
    },
    "ogx_mmlux_lt-philosophy": {
      "acc,none": 0.6752411575562701,
      "acc_stderr,none": 0.026596782287697046,
      "alias": "ogx_mmlux_lt-philosophy"
    },
    "ogx_mmlux_lt-nutrition": {
      "acc,none": 0.6372549019607843,
      "acc_stderr,none": 0.027530078447110303,
      "alias": "ogx_mmlux_lt-nutrition"
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "acc,none": 0.2782122905027933,
      "acc_stderr,none": 0.014987325439963556,
      "alias": "ogx_mmlux_lt-moral_scenarios"
    },
    "ogx_mmlux_lt-moral_disputes": {
      "acc,none": 0.6358381502890174,
      "acc_stderr,none": 0.025906632631016124,
      "alias": "ogx_mmlux_lt-moral_disputes"
    },
    "ogx_mmlux_lt-miscellaneous": {
      "acc,none": 0.7113665389527458,
      "acc_stderr,none": 0.016203792703197797,
      "alias": "ogx_mmlux_lt-miscellaneous"
    },
    "ogx_mmlux_lt-medical_genetics": {
      "acc,none": 0.66,
      "acc_stderr,none": 0.04760952285695237,
      "alias": "ogx_mmlux_lt-medical_genetics"
    },
    "ogx_mmlux_lt-marketing": {
      "acc,none": 0.8376068376068376,
      "acc_stderr,none": 0.024161618127987745,
      "alias": "ogx_mmlux_lt-marketing"
    },
    "ogx_mmlux_lt-management": {
      "acc,none": 0.7378640776699029,
      "acc_stderr,none": 0.043546310772605956,
      "alias": "ogx_mmlux_lt-management"
    },
    "ogx_mmlux_lt-machine_learning": {
      "acc,none": 0.41964285714285715,
      "acc_stderr,none": 0.04684099321077106,
      "alias": "ogx_mmlux_lt-machine_learning"
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "acc,none": 0.6932515337423313,
      "acc_stderr,none": 0.036230899157241474,
      "alias": "ogx_mmlux_lt-logical_fallacies"
    },
    "ogx_mmlux_lt-jurisprudence": {
      "acc,none": 0.7777777777777778,
      "acc_stderr,none": 0.040191074725573483,
      "alias": "ogx_mmlux_lt-jurisprudence"
    },
    "ogx_mmlux_lt-international_law": {
      "acc,none": 0.7768595041322314,
      "acc_stderr,none": 0.03800754475228733,
      "alias": "ogx_mmlux_lt-international_law"
    },
    "ogx_mmlux_lt-human_sexuality": {
      "acc,none": 0.7022900763358778,
      "acc_stderr,none": 0.04010358942462203,
      "alias": "ogx_mmlux_lt-human_sexuality"
    },
    "ogx_mmlux_lt-human_aging": {
      "acc,none": 0.6860986547085202,
      "acc_stderr,none": 0.031146796482972465,
      "alias": "ogx_mmlux_lt-human_aging"
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "acc,none": 0.7679324894514767,
      "acc_stderr,none": 0.027479744550808514,
      "alias": "ogx_mmlux_lt-high_school_world_history"
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.03039153369274154,
      "alias": "ogx_mmlux_lt-high_school_us_history"
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "acc,none": 0.49537037037037035,
      "acc_stderr,none": 0.03409825519163572,
      "alias": "ogx_mmlux_lt-high_school_statistics"
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "acc,none": 0.7761467889908257,
      "acc_stderr,none": 0.017871217767790222,
      "alias": "ogx_mmlux_lt-high_school_psychology"
    },
    "ogx_mmlux_lt-high_school_physics": {
      "acc,none": 0.5364238410596026,
      "acc_stderr,none": 0.04071636065944216,
      "alias": "ogx_mmlux_lt-high_school_physics"
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "acc,none": 0.6428571428571429,
      "acc_stderr,none": 0.031124619309328177,
      "alias": "ogx_mmlux_lt-high_school_microeconomics"
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "acc,none": 0.3925925925925926,
      "acc_stderr,none": 0.02977384701253297,
      "alias": "ogx_mmlux_lt-high_school_mathematics"
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "acc,none": 0.6615384615384615,
      "acc_stderr,none": 0.023991500500313036,
      "alias": "ogx_mmlux_lt-high_school_macroeconomics"
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "acc,none": 0.7512953367875648,
      "acc_stderr,none": 0.03119584087770029,
      "alias": "ogx_mmlux_lt-high_school_government_and_politics"
    },
    "ogx_mmlux_lt-high_school_geography": {
      "acc,none": 0.7272727272727273,
      "acc_stderr,none": 0.03173071239071724,
      "alias": "ogx_mmlux_lt-high_school_geography"
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "acc,none": 0.7757575757575758,
      "acc_stderr,none": 0.03256866661681102,
      "alias": "ogx_mmlux_lt-high_school_european_history"
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "acc,none": 0.72,
      "acc_stderr,none": 0.04512608598542129,
      "alias": "ogx_mmlux_lt-high_school_computer_science"
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "acc,none": 0.6206896551724138,
      "acc_stderr,none": 0.03413963805906235,
      "alias": "ogx_mmlux_lt-high_school_chemistry"
    },
    "ogx_mmlux_lt-high_school_biology": {
      "acc,none": 0.8161290322580645,
      "acc_stderr,none": 0.02203721734026785,
      "alias": "ogx_mmlux_lt-high_school_biology"
    },
    "ogx_mmlux_lt-global_facts": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_lt-global_facts"
    },
    "ogx_mmlux_lt-formal_logic": {
      "acc,none": 0.4365079365079365,
      "acc_stderr,none": 0.04435932892851466,
      "alias": "ogx_mmlux_lt-formal_logic"
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "acc,none": 0.5026455026455027,
      "acc_stderr,none": 0.025750949678130387,
      "alias": "ogx_mmlux_lt-elementary_mathematics"
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "acc,none": 0.5586206896551724,
      "acc_stderr,none": 0.04137931034482758,
      "alias": "ogx_mmlux_lt-electrical_engineering"
    },
    "ogx_mmlux_lt-econometrics": {
      "acc,none": 0.5087719298245614,
      "acc_stderr,none": 0.04702880432049615,
      "alias": "ogx_mmlux_lt-econometrics"
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "acc,none": 0.6468085106382979,
      "acc_stderr,none": 0.031245325202761923,
      "alias": "ogx_mmlux_lt-conceptual_physics"
    },
    "ogx_mmlux_lt-computer_security": {
      "acc,none": 0.64,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_lt-computer_security"
    },
    "ogx_mmlux_lt-college_physics": {
      "acc,none": 0.4019607843137255,
      "acc_stderr,none": 0.048786087144669955,
      "alias": "ogx_mmlux_lt-college_physics"
    },
    "ogx_mmlux_lt-college_medicine": {
      "acc,none": 0.6647398843930635,
      "acc_stderr,none": 0.03599586301247078,
      "alias": "ogx_mmlux_lt-college_medicine"
    },
    "ogx_mmlux_lt-college_mathematics": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_lt-college_mathematics"
    },
    "ogx_mmlux_lt-college_computer_science": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620333,
      "alias": "ogx_mmlux_lt-college_computer_science"
    },
    "ogx_mmlux_lt-college_chemistry": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_lt-college_chemistry"
    },
    "ogx_mmlux_lt-college_biology": {
      "acc,none": 0.7013888888888888,
      "acc_stderr,none": 0.03827052357950756,
      "alias": "ogx_mmlux_lt-college_biology"
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "acc,none": 0.6641509433962264,
      "acc_stderr,none": 0.029067220146644823,
      "alias": "ogx_mmlux_lt-clinical_knowledge"
    },
    "ogx_mmlux_lt-business_ethics": {
      "acc,none": 0.66,
      "acc_stderr,none": 0.04760952285695237,
      "alias": "ogx_mmlux_lt-business_ethics"
    },
    "ogx_mmlux_lt-astronomy": {
      "acc,none": 0.756578947368421,
      "acc_stderr,none": 0.034923496688842384,
      "alias": "ogx_mmlux_lt-astronomy"
    },
    "ogx_mmlux_lt-anatomy": {
      "acc,none": 0.5407407407407407,
      "acc_stderr,none": 0.04304979692464243,
      "alias": "ogx_mmlux_lt-anatomy"
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_lt-abstract_algebra"
    },
    "ogx_mmlux_it-world_religions": {
      "acc,none": 0.847953216374269,
      "acc_stderr,none": 0.02753912288906145,
      "alias": "ogx_mmlux_it-world_religions"
    },
    "ogx_mmlux_it-virology": {
      "acc,none": 0.5481927710843374,
      "acc_stderr,none": 0.03874371556587953,
      "alias": "ogx_mmlux_it-virology"
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "acc,none": 0.88,
      "acc_stderr,none": 0.03265986323710905,
      "alias": "ogx_mmlux_it-us_foreign_policy"
    },
    "ogx_mmlux_it-sociology": {
      "acc,none": 0.8308457711442786,
      "acc_stderr,none": 0.026508590656233268,
      "alias": "ogx_mmlux_it-sociology"
    },
    "ogx_mmlux_it-security_studies": {
      "acc,none": 0.763265306122449,
      "acc_stderr,none": 0.027212835884073142,
      "alias": "ogx_mmlux_it-security_studies"
    },
    "ogx_mmlux_it-public_relations": {
      "acc,none": 0.6818181818181818,
      "acc_stderr,none": 0.044612721759105085,
      "alias": "ogx_mmlux_it-public_relations"
    },
    "ogx_mmlux_it-professional_psychology": {
      "acc,none": 0.6830065359477124,
      "acc_stderr,none": 0.018824219512706217,
      "alias": "ogx_mmlux_it-professional_psychology"
    },
    "ogx_mmlux_it-professional_medicine": {
      "acc,none": 0.7022058823529411,
      "acc_stderr,none": 0.027778298701545443,
      "alias": "ogx_mmlux_it-professional_medicine"
    },
    "ogx_mmlux_it-professional_law": {
      "acc,none": 0.4869621903520209,
      "acc_stderr,none": 0.012765893883835332,
      "alias": "ogx_mmlux_it-professional_law"
    },
    "ogx_mmlux_it-professional_accounting": {
      "acc,none": 0.4574468085106383,
      "acc_stderr,none": 0.029719281272236837,
      "alias": "ogx_mmlux_it-professional_accounting"
    },
    "ogx_mmlux_it-prehistory": {
      "acc,none": 0.7438271604938271,
      "acc_stderr,none": 0.0242885336377261,
      "alias": "ogx_mmlux_it-prehistory"
    },
    "ogx_mmlux_it-philosophy": {
      "acc,none": 0.7266881028938906,
      "acc_stderr,none": 0.02531176597542611,
      "alias": "ogx_mmlux_it-philosophy"
    },
    "ogx_mmlux_it-nutrition": {
      "acc,none": 0.7026143790849673,
      "acc_stderr,none": 0.02617390850671858,
      "alias": "ogx_mmlux_it-nutrition"
    },
    "ogx_mmlux_it-moral_scenarios": {
      "acc,none": 0.38994413407821227,
      "acc_stderr,none": 0.016312376629213067,
      "alias": "ogx_mmlux_it-moral_scenarios"
    },
    "ogx_mmlux_it-moral_disputes": {
      "acc,none": 0.7225433526011561,
      "acc_stderr,none": 0.024105712607754307,
      "alias": "ogx_mmlux_it-moral_disputes"
    },
    "ogx_mmlux_it-miscellaneous": {
      "acc,none": 0.8148148148148148,
      "acc_stderr,none": 0.013890862162876164,
      "alias": "ogx_mmlux_it-miscellaneous"
    },
    "ogx_mmlux_it-medical_genetics": {
      "acc,none": 0.81,
      "acc_stderr,none": 0.03942772444036624,
      "alias": "ogx_mmlux_it-medical_genetics"
    },
    "ogx_mmlux_it-marketing": {
      "acc,none": 0.8803418803418803,
      "acc_stderr,none": 0.021262719400406953,
      "alias": "ogx_mmlux_it-marketing"
    },
    "ogx_mmlux_it-management": {
      "acc,none": 0.8155339805825242,
      "acc_stderr,none": 0.03840423627288276,
      "alias": "ogx_mmlux_it-management"
    },
    "ogx_mmlux_it-machine_learning": {
      "acc,none": 0.49107142857142855,
      "acc_stderr,none": 0.04745033255489123,
      "alias": "ogx_mmlux_it-machine_learning"
    },
    "ogx_mmlux_it-logical_fallacies": {
      "acc,none": 0.7791411042944786,
      "acc_stderr,none": 0.032591773927421776,
      "alias": "ogx_mmlux_it-logical_fallacies"
    },
    "ogx_mmlux_it-jurisprudence": {
      "acc,none": 0.7870370370370371,
      "acc_stderr,none": 0.03957835471980979,
      "alias": "ogx_mmlux_it-jurisprudence"
    },
    "ogx_mmlux_it-international_law": {
      "acc,none": 0.7851239669421488,
      "acc_stderr,none": 0.03749492448709699,
      "alias": "ogx_mmlux_it-international_law"
    },
    "ogx_mmlux_it-human_sexuality": {
      "acc,none": 0.7938931297709924,
      "acc_stderr,none": 0.03547771004159465,
      "alias": "ogx_mmlux_it-human_sexuality"
    },
    "ogx_mmlux_it-human_aging": {
      "acc,none": 0.7309417040358744,
      "acc_stderr,none": 0.029763779406874972,
      "alias": "ogx_mmlux_it-human_aging"
    },
    "ogx_mmlux_it-high_school_world_history": {
      "acc,none": 0.8227848101265823,
      "acc_stderr,none": 0.024856364184503234,
      "alias": "ogx_mmlux_it-high_school_world_history"
    },
    "ogx_mmlux_it-high_school_us_history": {
      "acc,none": 0.8284313725490197,
      "acc_stderr,none": 0.026460569561240658,
      "alias": "ogx_mmlux_it-high_school_us_history"
    },
    "ogx_mmlux_it-high_school_statistics": {
      "acc,none": 0.5879629629629629,
      "acc_stderr,none": 0.03356787758160831,
      "alias": "ogx_mmlux_it-high_school_statistics"
    },
    "ogx_mmlux_it-high_school_psychology": {
      "acc,none": 0.8697247706422019,
      "acc_stderr,none": 0.014431862852473233,
      "alias": "ogx_mmlux_it-high_school_psychology"
    },
    "ogx_mmlux_it-high_school_physics": {
      "acc,none": 0.5629139072847682,
      "acc_stderr,none": 0.04050035722230636,
      "alias": "ogx_mmlux_it-high_school_physics"
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "acc,none": 0.7394957983193278,
      "acc_stderr,none": 0.028510251512341937,
      "alias": "ogx_mmlux_it-high_school_microeconomics"
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "acc,none": 0.4074074074074074,
      "acc_stderr,none": 0.029958249250082124,
      "alias": "ogx_mmlux_it-high_school_mathematics"
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "acc,none": 0.7512820512820513,
      "acc_stderr,none": 0.021916957709213796,
      "alias": "ogx_mmlux_it-high_school_macroeconomics"
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "acc,none": 0.8290155440414507,
      "acc_stderr,none": 0.02717121368316455,
      "alias": "ogx_mmlux_it-high_school_government_and_politics"
    },
    "ogx_mmlux_it-high_school_geography": {
      "acc,none": 0.8484848484848485,
      "acc_stderr,none": 0.025545650426603617,
      "alias": "ogx_mmlux_it-high_school_geography"
    },
    "ogx_mmlux_it-high_school_european_history": {
      "acc,none": 0.8303030303030303,
      "acc_stderr,none": 0.029311188674983127,
      "alias": "ogx_mmlux_it-high_school_european_history"
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.0446196043338474,
      "alias": "ogx_mmlux_it-high_school_computer_science"
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "acc,none": 0.6650246305418719,
      "acc_stderr,none": 0.033208527423483104,
      "alias": "ogx_mmlux_it-high_school_chemistry"
    },
    "ogx_mmlux_it-high_school_biology": {
      "acc,none": 0.8838709677419355,
      "acc_stderr,none": 0.018225757949432306,
      "alias": "ogx_mmlux_it-high_school_biology"
    },
    "ogx_mmlux_it-global_facts": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_it-global_facts"
    },
    "ogx_mmlux_it-formal_logic": {
      "acc,none": 0.5158730158730159,
      "acc_stderr,none": 0.044698818540726076,
      "alias": "ogx_mmlux_it-formal_logic"
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "acc,none": 0.5132275132275133,
      "acc_stderr,none": 0.025742297289575142,
      "alias": "ogx_mmlux_it-elementary_mathematics"
    },
    "ogx_mmlux_it-electrical_engineering": {
      "acc,none": 0.6620689655172414,
      "acc_stderr,none": 0.039417076320648906,
      "alias": "ogx_mmlux_it-electrical_engineering"
    },
    "ogx_mmlux_it-econometrics": {
      "acc,none": 0.6228070175438597,
      "acc_stderr,none": 0.045595221419582166,
      "alias": "ogx_mmlux_it-econometrics"
    },
    "ogx_mmlux_it-conceptual_physics": {
      "acc,none": 0.6936170212765957,
      "acc_stderr,none": 0.03013590647851756,
      "alias": "ogx_mmlux_it-conceptual_physics"
    },
    "ogx_mmlux_it-computer_security": {
      "acc,none": 0.72,
      "acc_stderr,none": 0.045126085985421276,
      "alias": "ogx_mmlux_it-computer_security"
    },
    "ogx_mmlux_it-college_physics": {
      "acc,none": 0.43137254901960786,
      "acc_stderr,none": 0.04928099597287534,
      "alias": "ogx_mmlux_it-college_physics"
    },
    "ogx_mmlux_it-college_medicine": {
      "acc,none": 0.6820809248554913,
      "acc_stderr,none": 0.03550683989165582,
      "alias": "ogx_mmlux_it-college_medicine"
    },
    "ogx_mmlux_it-college_mathematics": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_it-college_mathematics"
    },
    "ogx_mmlux_it-college_computer_science": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_it-college_computer_science"
    },
    "ogx_mmlux_it-college_chemistry": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_it-college_chemistry"
    },
    "ogx_mmlux_it-college_biology": {
      "acc,none": 0.8333333333333334,
      "acc_stderr,none": 0.031164899666948603,
      "alias": "ogx_mmlux_it-college_biology"
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "acc,none": 0.7283018867924528,
      "acc_stderr,none": 0.027377706624670713,
      "alias": "ogx_mmlux_it-clinical_knowledge"
    },
    "ogx_mmlux_it-business_ethics": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_it-business_ethics"
    },
    "ogx_mmlux_it-astronomy": {
      "acc,none": 0.7697368421052632,
      "acc_stderr,none": 0.03426059424403165,
      "alias": "ogx_mmlux_it-astronomy"
    },
    "ogx_mmlux_it-anatomy": {
      "acc,none": 0.6074074074074074,
      "acc_stderr,none": 0.04218506215368879,
      "alias": "ogx_mmlux_it-anatomy"
    },
    "ogx_mmlux_it-abstract_algebra": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_it-abstract_algebra"
    },
    "ogx_mmlux_hu-world_religions": {
      "acc,none": 0.7953216374269005,
      "acc_stderr,none": 0.030944459778533204,
      "alias": "ogx_mmlux_hu-world_religions"
    },
    "ogx_mmlux_hu-virology": {
      "acc,none": 0.463855421686747,
      "acc_stderr,none": 0.03882310850890594,
      "alias": "ogx_mmlux_hu-virology"
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "acc,none": 0.81,
      "acc_stderr,none": 0.039427724440366234,
      "alias": "ogx_mmlux_hu-us_foreign_policy"
    },
    "ogx_mmlux_hu-sociology": {
      "acc,none": 0.8059701492537313,
      "acc_stderr,none": 0.02796267760476892,
      "alias": "ogx_mmlux_hu-sociology"
    },
    "ogx_mmlux_hu-security_studies": {
      "acc,none": 0.710204081632653,
      "acc_stderr,none": 0.02904308868330434,
      "alias": "ogx_mmlux_hu-security_studies"
    },
    "ogx_mmlux_hu-public_relations": {
      "acc,none": 0.6363636363636364,
      "acc_stderr,none": 0.04607582090719976,
      "alias": "ogx_mmlux_hu-public_relations"
    },
    "ogx_mmlux_hu-professional_psychology": {
      "acc,none": 0.5866013071895425,
      "acc_stderr,none": 0.01992211568278668,
      "alias": "ogx_mmlux_hu-professional_psychology"
    },
    "ogx_mmlux_hu-professional_medicine": {
      "acc,none": 0.5551470588235294,
      "acc_stderr,none": 0.030187532060329387,
      "alias": "ogx_mmlux_hu-professional_medicine"
    },
    "ogx_mmlux_hu-professional_law": {
      "acc,none": 0.27183833116036504,
      "acc_stderr,none": 0.011363135278651418,
      "alias": "ogx_mmlux_hu-professional_law"
    },
    "ogx_mmlux_hu-professional_accounting": {
      "acc,none": 0.32978723404255317,
      "acc_stderr,none": 0.0280459469420424,
      "alias": "ogx_mmlux_hu-professional_accounting"
    },
    "ogx_mmlux_hu-prehistory": {
      "acc,none": 0.7006172839506173,
      "acc_stderr,none": 0.025483115601195462,
      "alias": "ogx_mmlux_hu-prehistory"
    },
    "ogx_mmlux_hu-philosophy": {
      "acc,none": 0.6559485530546624,
      "acc_stderr,none": 0.026981478043648026,
      "alias": "ogx_mmlux_hu-philosophy"
    },
    "ogx_mmlux_hu-nutrition": {
      "acc,none": 0.6339869281045751,
      "acc_stderr,none": 0.027582811415159628,
      "alias": "ogx_mmlux_hu-nutrition"
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "acc,none": 0.4212290502793296,
      "acc_stderr,none": 0.016513676031179595,
      "alias": "ogx_mmlux_hu-moral_scenarios"
    },
    "ogx_mmlux_hu-moral_disputes": {
      "acc,none": 0.6647398843930635,
      "acc_stderr,none": 0.025416003773165555,
      "alias": "ogx_mmlux_hu-moral_disputes"
    },
    "ogx_mmlux_hu-miscellaneous": {
      "acc,none": 0.7203065134099617,
      "acc_stderr,none": 0.016050792148036546,
      "alias": "ogx_mmlux_hu-miscellaneous"
    },
    "ogx_mmlux_hu-medical_genetics": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_hu-medical_genetics"
    },
    "ogx_mmlux_hu-marketing": {
      "acc,none": 0.8504273504273504,
      "acc_stderr,none": 0.02336505149175372,
      "alias": "ogx_mmlux_hu-marketing"
    },
    "ogx_mmlux_hu-management": {
      "acc,none": 0.7572815533980582,
      "acc_stderr,none": 0.04245022486384495,
      "alias": "ogx_mmlux_hu-management"
    },
    "ogx_mmlux_hu-machine_learning": {
      "acc,none": 0.45535714285714285,
      "acc_stderr,none": 0.04726835553719099,
      "alias": "ogx_mmlux_hu-machine_learning"
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "acc,none": 0.6441717791411042,
      "acc_stderr,none": 0.03761521380046734,
      "alias": "ogx_mmlux_hu-logical_fallacies"
    },
    "ogx_mmlux_hu-jurisprudence": {
      "acc,none": 0.6851851851851852,
      "acc_stderr,none": 0.04489931073591311,
      "alias": "ogx_mmlux_hu-jurisprudence"
    },
    "ogx_mmlux_hu-international_law": {
      "acc,none": 0.7768595041322314,
      "acc_stderr,none": 0.03800754475228732,
      "alias": "ogx_mmlux_hu-international_law"
    },
    "ogx_mmlux_hu-human_sexuality": {
      "acc,none": 0.7251908396946565,
      "acc_stderr,none": 0.039153454088478354,
      "alias": "ogx_mmlux_hu-human_sexuality"
    },
    "ogx_mmlux_hu-human_aging": {
      "acc,none": 0.6995515695067265,
      "acc_stderr,none": 0.030769352008229136,
      "alias": "ogx_mmlux_hu-human_aging"
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "acc,none": 0.70042194092827,
      "acc_stderr,none": 0.029818024749753095,
      "alias": "ogx_mmlux_hu-high_school_world_history"
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "acc,none": 0.3382352941176471,
      "acc_stderr,none": 0.03320574612945431,
      "alias": "ogx_mmlux_hu-high_school_us_history"
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "acc,none": 0.37037037037037035,
      "acc_stderr,none": 0.03293377139415191,
      "alias": "ogx_mmlux_hu-high_school_statistics"
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "acc,none": 0.7963302752293578,
      "acc_stderr,none": 0.0172667420876308,
      "alias": "ogx_mmlux_hu-high_school_psychology"
    },
    "ogx_mmlux_hu-high_school_physics": {
      "acc,none": 0.44370860927152317,
      "acc_stderr,none": 0.04056527902281732,
      "alias": "ogx_mmlux_hu-high_school_physics"
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "acc,none": 0.6638655462184874,
      "acc_stderr,none": 0.030684737115135363,
      "alias": "ogx_mmlux_hu-high_school_microeconomics"
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "acc,none": 0.24444444444444444,
      "acc_stderr,none": 0.02620276653465215,
      "alias": "ogx_mmlux_hu-high_school_mathematics"
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "acc,none": 0.6307692307692307,
      "acc_stderr,none": 0.024468615241478912,
      "alias": "ogx_mmlux_hu-high_school_macroeconomics"
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "acc,none": 0.7668393782383419,
      "acc_stderr,none": 0.03051611137147601,
      "alias": "ogx_mmlux_hu-high_school_government_and_politics"
    },
    "ogx_mmlux_hu-high_school_geography": {
      "acc,none": 0.7828282828282829,
      "acc_stderr,none": 0.029376616484945637,
      "alias": "ogx_mmlux_hu-high_school_geography"
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "acc,none": 0.26666666666666666,
      "acc_stderr,none": 0.03453131801885416,
      "alias": "ogx_mmlux_hu-high_school_european_history"
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_hu-high_school_computer_science"
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "acc,none": 0.43349753694581283,
      "acc_stderr,none": 0.03486731727419872,
      "alias": "ogx_mmlux_hu-high_school_chemistry"
    },
    "ogx_mmlux_hu-high_school_biology": {
      "acc,none": 0.7322580645161291,
      "acc_stderr,none": 0.025189006660212374,
      "alias": "ogx_mmlux_hu-high_school_biology"
    },
    "ogx_mmlux_hu-global_facts": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_hu-global_facts"
    },
    "ogx_mmlux_hu-formal_logic": {
      "acc,none": 0.3968253968253968,
      "acc_stderr,none": 0.0437588849272706,
      "alias": "ogx_mmlux_hu-formal_logic"
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "acc,none": 0.42063492063492064,
      "acc_stderr,none": 0.025424835086924006,
      "alias": "ogx_mmlux_hu-elementary_mathematics"
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "acc,none": 0.5586206896551724,
      "acc_stderr,none": 0.04137931034482758,
      "alias": "ogx_mmlux_hu-electrical_engineering"
    },
    "ogx_mmlux_hu-econometrics": {
      "acc,none": 0.45614035087719296,
      "acc_stderr,none": 0.046854730419077895,
      "alias": "ogx_mmlux_hu-econometrics"
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "acc,none": 0.6510638297872341,
      "acc_stderr,none": 0.031158522131357808,
      "alias": "ogx_mmlux_hu-conceptual_physics"
    },
    "ogx_mmlux_hu-computer_security": {
      "acc,none": 0.69,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_hu-computer_security"
    },
    "ogx_mmlux_hu-college_physics": {
      "acc,none": 0.37254901960784315,
      "acc_stderr,none": 0.048108401480826346,
      "alias": "ogx_mmlux_hu-college_physics"
    },
    "ogx_mmlux_hu-college_medicine": {
      "acc,none": 0.5780346820809249,
      "acc_stderr,none": 0.0376574669386515,
      "alias": "ogx_mmlux_hu-college_medicine"
    },
    "ogx_mmlux_hu-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_hu-college_mathematics"
    },
    "ogx_mmlux_hu-college_computer_science": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.04878317312145633,
      "alias": "ogx_mmlux_hu-college_computer_science"
    },
    "ogx_mmlux_hu-college_chemistry": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_hu-college_chemistry"
    },
    "ogx_mmlux_hu-college_biology": {
      "acc,none": 0.7430555555555556,
      "acc_stderr,none": 0.036539469694421,
      "alias": "ogx_mmlux_hu-college_biology"
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "acc,none": 0.6415094339622641,
      "acc_stderr,none": 0.02951470358398177,
      "alias": "ogx_mmlux_hu-clinical_knowledge"
    },
    "ogx_mmlux_hu-business_ethics": {
      "acc,none": 0.67,
      "acc_stderr,none": 0.047258156262526094,
      "alias": "ogx_mmlux_hu-business_ethics"
    },
    "ogx_mmlux_hu-astronomy": {
      "acc,none": 0.7039473684210527,
      "acc_stderr,none": 0.03715062154998905,
      "alias": "ogx_mmlux_hu-astronomy"
    },
    "ogx_mmlux_hu-anatomy": {
      "acc,none": 0.5481481481481482,
      "acc_stderr,none": 0.04299268905480864,
      "alias": "ogx_mmlux_hu-anatomy"
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "acc,none": 0.26,
      "acc_stderr,none": 0.044084400227680794,
      "alias": "ogx_mmlux_hu-abstract_algebra"
    },
    "ogx_mmlux_fr-world_religions": {
      "acc,none": 0.8888888888888888,
      "acc_stderr,none": 0.024103384202072854,
      "alias": "ogx_mmlux_fr-world_religions"
    },
    "ogx_mmlux_fr-virology": {
      "acc,none": 0.5301204819277109,
      "acc_stderr,none": 0.03885425420866767,
      "alias": "ogx_mmlux_fr-virology"
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "acc,none": 0.82,
      "acc_stderr,none": 0.038612291966536934,
      "alias": "ogx_mmlux_fr-us_foreign_policy"
    },
    "ogx_mmlux_fr-sociology": {
      "acc,none": 0.8208955223880597,
      "acc_stderr,none": 0.027113286753111848,
      "alias": "ogx_mmlux_fr-sociology"
    },
    "ogx_mmlux_fr-security_studies": {
      "acc,none": 0.7673469387755102,
      "acc_stderr,none": 0.02704925791589618,
      "alias": "ogx_mmlux_fr-security_studies"
    },
    "ogx_mmlux_fr-public_relations": {
      "acc,none": 0.7090909090909091,
      "acc_stderr,none": 0.04350271442923243,
      "alias": "ogx_mmlux_fr-public_relations"
    },
    "ogx_mmlux_fr-professional_psychology": {
      "acc,none": 0.6830065359477124,
      "acc_stderr,none": 0.018824219512706214,
      "alias": "ogx_mmlux_fr-professional_psychology"
    },
    "ogx_mmlux_fr-professional_medicine": {
      "acc,none": 0.6985294117647058,
      "acc_stderr,none": 0.027875982114273168,
      "alias": "ogx_mmlux_fr-professional_medicine"
    },
    "ogx_mmlux_fr-professional_law": {
      "acc,none": 0.49478487614080835,
      "acc_stderr,none": 0.012769541449652547,
      "alias": "ogx_mmlux_fr-professional_law"
    },
    "ogx_mmlux_fr-professional_accounting": {
      "acc,none": 0.48226950354609927,
      "acc_stderr,none": 0.02980873964223777,
      "alias": "ogx_mmlux_fr-professional_accounting"
    },
    "ogx_mmlux_fr-prehistory": {
      "acc,none": 0.7716049382716049,
      "acc_stderr,none": 0.023358211840626267,
      "alias": "ogx_mmlux_fr-prehistory"
    },
    "ogx_mmlux_fr-philosophy": {
      "acc,none": 0.6881028938906752,
      "acc_stderr,none": 0.026311858071854155,
      "alias": "ogx_mmlux_fr-philosophy"
    },
    "ogx_mmlux_fr-nutrition": {
      "acc,none": 0.7156862745098039,
      "acc_stderr,none": 0.02582916327275747,
      "alias": "ogx_mmlux_fr-nutrition"
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "acc,none": 0.3005586592178771,
      "acc_stderr,none": 0.015334566806251166,
      "alias": "ogx_mmlux_fr-moral_scenarios"
    },
    "ogx_mmlux_fr-moral_disputes": {
      "acc,none": 0.7052023121387283,
      "acc_stderr,none": 0.02454761779480384,
      "alias": "ogx_mmlux_fr-moral_disputes"
    },
    "ogx_mmlux_fr-miscellaneous": {
      "acc,none": 0.8122605363984674,
      "acc_stderr,none": 0.01396439376989914,
      "alias": "ogx_mmlux_fr-miscellaneous"
    },
    "ogx_mmlux_fr-medical_genetics": {
      "acc,none": 0.79,
      "acc_stderr,none": 0.040936018074033256,
      "alias": "ogx_mmlux_fr-medical_genetics"
    },
    "ogx_mmlux_fr-marketing": {
      "acc,none": 0.8589743589743589,
      "acc_stderr,none": 0.022801382534597518,
      "alias": "ogx_mmlux_fr-marketing"
    },
    "ogx_mmlux_fr-management": {
      "acc,none": 0.8252427184466019,
      "acc_stderr,none": 0.0376017800602662,
      "alias": "ogx_mmlux_fr-management"
    },
    "ogx_mmlux_fr-machine_learning": {
      "acc,none": 0.49107142857142855,
      "acc_stderr,none": 0.04745033255489123,
      "alias": "ogx_mmlux_fr-machine_learning"
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "acc,none": 0.7484662576687117,
      "acc_stderr,none": 0.034089978868575295,
      "alias": "ogx_mmlux_fr-logical_fallacies"
    },
    "ogx_mmlux_fr-jurisprudence": {
      "acc,none": 0.7962962962962963,
      "acc_stderr,none": 0.03893542518824847,
      "alias": "ogx_mmlux_fr-jurisprudence"
    },
    "ogx_mmlux_fr-international_law": {
      "acc,none": 0.8181818181818182,
      "acc_stderr,none": 0.03520893951097654,
      "alias": "ogx_mmlux_fr-international_law"
    },
    "ogx_mmlux_fr-human_sexuality": {
      "acc,none": 0.7938931297709924,
      "acc_stderr,none": 0.03547771004159463,
      "alias": "ogx_mmlux_fr-human_sexuality"
    },
    "ogx_mmlux_fr-human_aging": {
      "acc,none": 0.7533632286995515,
      "acc_stderr,none": 0.028930413120910874,
      "alias": "ogx_mmlux_fr-human_aging"
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "acc,none": 0.8312236286919831,
      "acc_stderr,none": 0.02438140683258623,
      "alias": "ogx_mmlux_fr-high_school_world_history"
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "acc,none": 0.8431372549019608,
      "acc_stderr,none": 0.025524722324553332,
      "alias": "ogx_mmlux_fr-high_school_us_history"
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "acc,none": 0.6111111111111112,
      "acc_stderr,none": 0.033247089118091176,
      "alias": "ogx_mmlux_fr-high_school_statistics"
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "acc,none": 0.8568807339449541,
      "acc_stderr,none": 0.015014462497168583,
      "alias": "ogx_mmlux_fr-high_school_psychology"
    },
    "ogx_mmlux_fr-high_school_physics": {
      "acc,none": 0.5298013245033113,
      "acc_stderr,none": 0.040752249922169775,
      "alias": "ogx_mmlux_fr-high_school_physics"
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "acc,none": 0.7478991596638656,
      "acc_stderr,none": 0.02820554503327772,
      "alias": "ogx_mmlux_fr-high_school_microeconomics"
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "acc,none": 0.42962962962962964,
      "acc_stderr,none": 0.030182099804387262,
      "alias": "ogx_mmlux_fr-high_school_mathematics"
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "acc,none": 0.7384615384615385,
      "acc_stderr,none": 0.022282141204204395,
      "alias": "ogx_mmlux_fr-high_school_macroeconomics"
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "acc,none": 0.8860103626943006,
      "acc_stderr,none": 0.02293514405391942,
      "alias": "ogx_mmlux_fr-high_school_government_and_politics"
    },
    "ogx_mmlux_fr-high_school_geography": {
      "acc,none": 0.8434343434343434,
      "acc_stderr,none": 0.025890520358141454,
      "alias": "ogx_mmlux_fr-high_school_geography"
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "acc,none": 0.8121212121212121,
      "acc_stderr,none": 0.03050193405942914,
      "alias": "ogx_mmlux_fr-high_school_european_history"
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.0446196043338474,
      "alias": "ogx_mmlux_fr-high_school_computer_science"
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "acc,none": 0.6502463054187192,
      "acc_stderr,none": 0.03355400904969566,
      "alias": "ogx_mmlux_fr-high_school_chemistry"
    },
    "ogx_mmlux_fr-high_school_biology": {
      "acc,none": 0.8903225806451613,
      "acc_stderr,none": 0.01777677870048516,
      "alias": "ogx_mmlux_fr-high_school_biology"
    },
    "ogx_mmlux_fr-global_facts": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_fr-global_facts"
    },
    "ogx_mmlux_fr-formal_logic": {
      "acc,none": 0.5158730158730159,
      "acc_stderr,none": 0.044698818540726076,
      "alias": "ogx_mmlux_fr-formal_logic"
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "acc,none": 0.5343915343915344,
      "acc_stderr,none": 0.02569032176249384,
      "alias": "ogx_mmlux_fr-elementary_mathematics"
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "acc,none": 0.6137931034482759,
      "acc_stderr,none": 0.04057324734419035,
      "alias": "ogx_mmlux_fr-electrical_engineering"
    },
    "ogx_mmlux_fr-econometrics": {
      "acc,none": 0.5701754385964912,
      "acc_stderr,none": 0.04657047260594963,
      "alias": "ogx_mmlux_fr-econometrics"
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "acc,none": 0.6936170212765957,
      "acc_stderr,none": 0.03013590647851756,
      "alias": "ogx_mmlux_fr-conceptual_physics"
    },
    "ogx_mmlux_fr-computer_security": {
      "acc,none": 0.72,
      "acc_stderr,none": 0.045126085985421276,
      "alias": "ogx_mmlux_fr-computer_security"
    },
    "ogx_mmlux_fr-college_physics": {
      "acc,none": 0.4411764705882353,
      "acc_stderr,none": 0.04940635630605659,
      "alias": "ogx_mmlux_fr-college_physics"
    },
    "ogx_mmlux_fr-college_medicine": {
      "acc,none": 0.6416184971098265,
      "acc_stderr,none": 0.03656343653353158,
      "alias": "ogx_mmlux_fr-college_medicine"
    },
    "ogx_mmlux_fr-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_fr-college_mathematics"
    },
    "ogx_mmlux_fr-college_computer_science": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_fr-college_computer_science"
    },
    "ogx_mmlux_fr-college_chemistry": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956911,
      "alias": "ogx_mmlux_fr-college_chemistry"
    },
    "ogx_mmlux_fr-college_biology": {
      "acc,none": 0.7986111111111112,
      "acc_stderr,none": 0.033536474697138406,
      "alias": "ogx_mmlux_fr-college_biology"
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "acc,none": 0.7245283018867924,
      "acc_stderr,none": 0.027495663683724057,
      "alias": "ogx_mmlux_fr-clinical_knowledge"
    },
    "ogx_mmlux_fr-business_ethics": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_fr-business_ethics"
    },
    "ogx_mmlux_fr-astronomy": {
      "acc,none": 0.7763157894736842,
      "acc_stderr,none": 0.033911609343436025,
      "alias": "ogx_mmlux_fr-astronomy"
    },
    "ogx_mmlux_fr-anatomy": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.04232073695151589,
      "alias": "ogx_mmlux_fr-anatomy"
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_fr-abstract_algebra"
    },
    "ogx_mmlux_fi-world_religions": {
      "acc,none": 0.8070175438596491,
      "acc_stderr,none": 0.030267457554898465,
      "alias": "ogx_mmlux_fi-world_religions"
    },
    "ogx_mmlux_fi-virology": {
      "acc,none": 0.5301204819277109,
      "acc_stderr,none": 0.03885425420866766,
      "alias": "ogx_mmlux_fi-virology"
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "acc,none": 0.81,
      "acc_stderr,none": 0.03942772444036625,
      "alias": "ogx_mmlux_fi-us_foreign_policy"
    },
    "ogx_mmlux_fi-sociology": {
      "acc,none": 0.8109452736318408,
      "acc_stderr,none": 0.02768691358801301,
      "alias": "ogx_mmlux_fi-sociology"
    },
    "ogx_mmlux_fi-security_studies": {
      "acc,none": 0.7224489795918367,
      "acc_stderr,none": 0.028666857790274648,
      "alias": "ogx_mmlux_fi-security_studies"
    },
    "ogx_mmlux_fi-public_relations": {
      "acc,none": 0.7090909090909091,
      "acc_stderr,none": 0.04350271442923243,
      "alias": "ogx_mmlux_fi-public_relations"
    },
    "ogx_mmlux_fi-professional_psychology": {
      "acc,none": 0.6209150326797386,
      "acc_stderr,none": 0.019627444748412243,
      "alias": "ogx_mmlux_fi-professional_psychology"
    },
    "ogx_mmlux_fi-professional_medicine": {
      "acc,none": 0.5808823529411765,
      "acc_stderr,none": 0.02997280717046462,
      "alias": "ogx_mmlux_fi-professional_medicine"
    },
    "ogx_mmlux_fi-professional_law": {
      "acc,none": 0.4452411994784876,
      "acc_stderr,none": 0.012693421303973296,
      "alias": "ogx_mmlux_fi-professional_law"
    },
    "ogx_mmlux_fi-professional_accounting": {
      "acc,none": 0.40070921985815605,
      "acc_stderr,none": 0.029233465745573093,
      "alias": "ogx_mmlux_fi-professional_accounting"
    },
    "ogx_mmlux_fi-prehistory": {
      "acc,none": 0.6851851851851852,
      "acc_stderr,none": 0.025842248700902168,
      "alias": "ogx_mmlux_fi-prehistory"
    },
    "ogx_mmlux_fi-philosophy": {
      "acc,none": 0.6463022508038585,
      "acc_stderr,none": 0.02715520810320088,
      "alias": "ogx_mmlux_fi-philosophy"
    },
    "ogx_mmlux_fi-nutrition": {
      "acc,none": 0.6601307189542484,
      "acc_stderr,none": 0.027121956071388856,
      "alias": "ogx_mmlux_fi-nutrition"
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "acc,none": 0.3854748603351955,
      "acc_stderr,none": 0.016277927039638193,
      "alias": "ogx_mmlux_fi-moral_scenarios"
    },
    "ogx_mmlux_fi-moral_disputes": {
      "acc,none": 0.6358381502890174,
      "acc_stderr,none": 0.025906632631016127,
      "alias": "ogx_mmlux_fi-moral_disputes"
    },
    "ogx_mmlux_fi-miscellaneous": {
      "acc,none": 0.756066411238825,
      "acc_stderr,none": 0.015357212665829489,
      "alias": "ogx_mmlux_fi-miscellaneous"
    },
    "ogx_mmlux_fi-medical_genetics": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_fi-medical_genetics"
    },
    "ogx_mmlux_fi-marketing": {
      "acc,none": 0.8034188034188035,
      "acc_stderr,none": 0.02603538609895129,
      "alias": "ogx_mmlux_fi-marketing"
    },
    "ogx_mmlux_fi-management": {
      "acc,none": 0.7378640776699029,
      "acc_stderr,none": 0.04354631077260597,
      "alias": "ogx_mmlux_fi-management"
    },
    "ogx_mmlux_fi-machine_learning": {
      "acc,none": 0.44642857142857145,
      "acc_stderr,none": 0.04718471485219588,
      "alias": "ogx_mmlux_fi-machine_learning"
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "acc,none": 0.6809815950920245,
      "acc_stderr,none": 0.03661997551073836,
      "alias": "ogx_mmlux_fi-logical_fallacies"
    },
    "ogx_mmlux_fi-jurisprudence": {
      "acc,none": 0.7314814814814815,
      "acc_stderr,none": 0.042844679680521934,
      "alias": "ogx_mmlux_fi-jurisprudence"
    },
    "ogx_mmlux_fi-international_law": {
      "acc,none": 0.7603305785123967,
      "acc_stderr,none": 0.03896878985070416,
      "alias": "ogx_mmlux_fi-international_law"
    },
    "ogx_mmlux_fi-human_sexuality": {
      "acc,none": 0.7099236641221374,
      "acc_stderr,none": 0.03980066246467765,
      "alias": "ogx_mmlux_fi-human_sexuality"
    },
    "ogx_mmlux_fi-human_aging": {
      "acc,none": 0.7219730941704036,
      "acc_stderr,none": 0.030069584874494053,
      "alias": "ogx_mmlux_fi-human_aging"
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "acc,none": 0.7848101265822784,
      "acc_stderr,none": 0.026750826994676163,
      "alias": "ogx_mmlux_fi-high_school_world_history"
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "acc,none": 0.7843137254901961,
      "acc_stderr,none": 0.028867431449849313,
      "alias": "ogx_mmlux_fi-high_school_us_history"
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "acc,none": 0.5185185185185185,
      "acc_stderr,none": 0.034076320938540516,
      "alias": "ogx_mmlux_fi-high_school_statistics"
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "acc,none": 0.7669724770642202,
      "acc_stderr,none": 0.0181256691808615,
      "alias": "ogx_mmlux_fi-high_school_psychology"
    },
    "ogx_mmlux_fi-high_school_physics": {
      "acc,none": 0.5033112582781457,
      "acc_stderr,none": 0.04082393379449654,
      "alias": "ogx_mmlux_fi-high_school_physics"
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "acc,none": 0.6596638655462185,
      "acc_stderr,none": 0.03077805742293167,
      "alias": "ogx_mmlux_fi-high_school_microeconomics"
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "acc,none": 0.4185185185185185,
      "acc_stderr,none": 0.030078013075022062,
      "alias": "ogx_mmlux_fi-high_school_mathematics"
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "acc,none": 0.6358974358974359,
      "acc_stderr,none": 0.02439667298509476,
      "alias": "ogx_mmlux_fi-high_school_macroeconomics"
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "acc,none": 0.7772020725388601,
      "acc_stderr,none": 0.03003114797764154,
      "alias": "ogx_mmlux_fi-high_school_government_and_politics"
    },
    "ogx_mmlux_fi-high_school_geography": {
      "acc,none": 0.7727272727272727,
      "acc_stderr,none": 0.02985751567338641,
      "alias": "ogx_mmlux_fi-high_school_geography"
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "acc,none": 0.793939393939394,
      "acc_stderr,none": 0.03158415324047708,
      "alias": "ogx_mmlux_fi-high_school_european_history"
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_fi-high_school_computer_science"
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "acc,none": 0.6699507389162561,
      "acc_stderr,none": 0.03308530426228259,
      "alias": "ogx_mmlux_fi-high_school_chemistry"
    },
    "ogx_mmlux_fi-high_school_biology": {
      "acc,none": 0.8129032258064516,
      "acc_stderr,none": 0.022185710092252245,
      "alias": "ogx_mmlux_fi-high_school_biology"
    },
    "ogx_mmlux_fi-global_facts": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_fi-global_facts"
    },
    "ogx_mmlux_fi-formal_logic": {
      "acc,none": 0.49206349206349204,
      "acc_stderr,none": 0.044715725362943486,
      "alias": "ogx_mmlux_fi-formal_logic"
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "acc,none": 0.5343915343915344,
      "acc_stderr,none": 0.025690321762493838,
      "alias": "ogx_mmlux_fi-elementary_mathematics"
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "acc,none": 0.5655172413793104,
      "acc_stderr,none": 0.04130740879555497,
      "alias": "ogx_mmlux_fi-electrical_engineering"
    },
    "ogx_mmlux_fi-econometrics": {
      "acc,none": 0.5175438596491229,
      "acc_stderr,none": 0.0470070803355104,
      "alias": "ogx_mmlux_fi-econometrics"
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "acc,none": 0.625531914893617,
      "acc_stderr,none": 0.03163910665367291,
      "alias": "ogx_mmlux_fi-conceptual_physics"
    },
    "ogx_mmlux_fi-computer_security": {
      "acc,none": 0.69,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_fi-computer_security"
    },
    "ogx_mmlux_fi-college_physics": {
      "acc,none": 0.46078431372549017,
      "acc_stderr,none": 0.04959859966384181,
      "alias": "ogx_mmlux_fi-college_physics"
    },
    "ogx_mmlux_fi-college_medicine": {
      "acc,none": 0.653179190751445,
      "acc_stderr,none": 0.03629146670159663,
      "alias": "ogx_mmlux_fi-college_medicine"
    },
    "ogx_mmlux_fi-college_mathematics": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.046882617226215034,
      "alias": "ogx_mmlux_fi-college_mathematics"
    },
    "ogx_mmlux_fi-college_computer_science": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_fi-college_computer_science"
    },
    "ogx_mmlux_fi-college_chemistry": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_fi-college_chemistry"
    },
    "ogx_mmlux_fi-college_biology": {
      "acc,none": 0.7083333333333334,
      "acc_stderr,none": 0.03800968060554858,
      "alias": "ogx_mmlux_fi-college_biology"
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "acc,none": 0.660377358490566,
      "acc_stderr,none": 0.029146904747798335,
      "alias": "ogx_mmlux_fi-clinical_knowledge"
    },
    "ogx_mmlux_fi-business_ethics": {
      "acc,none": 0.69,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_fi-business_ethics"
    },
    "ogx_mmlux_fi-astronomy": {
      "acc,none": 0.7039473684210527,
      "acc_stderr,none": 0.037150621549989056,
      "alias": "ogx_mmlux_fi-astronomy"
    },
    "ogx_mmlux_fi-anatomy": {
      "acc,none": 0.5555555555555556,
      "acc_stderr,none": 0.04292596718256981,
      "alias": "ogx_mmlux_fi-anatomy"
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_fi-abstract_algebra"
    },
    "ogx_mmlux_et-world_religions": {
      "acc,none": 0.7953216374269005,
      "acc_stderr,none": 0.030944459778533193,
      "alias": "ogx_mmlux_et-world_religions"
    },
    "ogx_mmlux_et-virology": {
      "acc,none": 0.4939759036144578,
      "acc_stderr,none": 0.03892212195333047,
      "alias": "ogx_mmlux_et-virology"
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "acc,none": 0.8,
      "acc_stderr,none": 0.04020151261036846,
      "alias": "ogx_mmlux_et-us_foreign_policy"
    },
    "ogx_mmlux_et-sociology": {
      "acc,none": 0.8009950248756219,
      "acc_stderr,none": 0.028231365092758406,
      "alias": "ogx_mmlux_et-sociology"
    },
    "ogx_mmlux_et-security_studies": {
      "acc,none": 0.7183673469387755,
      "acc_stderr,none": 0.028795185574291286,
      "alias": "ogx_mmlux_et-security_studies"
    },
    "ogx_mmlux_et-public_relations": {
      "acc,none": 0.6545454545454545,
      "acc_stderr,none": 0.04554619617541054,
      "alias": "ogx_mmlux_et-public_relations"
    },
    "ogx_mmlux_et-professional_psychology": {
      "acc,none": 0.6029411764705882,
      "acc_stderr,none": 0.019794488900024106,
      "alias": "ogx_mmlux_et-professional_psychology"
    },
    "ogx_mmlux_et-professional_medicine": {
      "acc,none": 0.5588235294117647,
      "acc_stderr,none": 0.030161911930767105,
      "alias": "ogx_mmlux_et-professional_medicine"
    },
    "ogx_mmlux_et-professional_law": {
      "acc,none": 0.42242503259452413,
      "acc_stderr,none": 0.012615600475734921,
      "alias": "ogx_mmlux_et-professional_law"
    },
    "ogx_mmlux_et-professional_accounting": {
      "acc,none": 0.4397163120567376,
      "acc_stderr,none": 0.029609912075594106,
      "alias": "ogx_mmlux_et-professional_accounting"
    },
    "ogx_mmlux_et-prehistory": {
      "acc,none": 0.6635802469135802,
      "acc_stderr,none": 0.02628973494595293,
      "alias": "ogx_mmlux_et-prehistory"
    },
    "ogx_mmlux_et-philosophy": {
      "acc,none": 0.6430868167202572,
      "acc_stderr,none": 0.027210420375934016,
      "alias": "ogx_mmlux_et-philosophy"
    },
    "ogx_mmlux_et-nutrition": {
      "acc,none": 0.6503267973856209,
      "acc_stderr,none": 0.027305308076274695,
      "alias": "ogx_mmlux_et-nutrition"
    },
    "ogx_mmlux_et-moral_scenarios": {
      "acc,none": 0.3407821229050279,
      "acc_stderr,none": 0.01585200244986211,
      "alias": "ogx_mmlux_et-moral_scenarios"
    },
    "ogx_mmlux_et-moral_disputes": {
      "acc,none": 0.615606936416185,
      "acc_stderr,none": 0.026189666966272028,
      "alias": "ogx_mmlux_et-moral_disputes"
    },
    "ogx_mmlux_et-miscellaneous": {
      "acc,none": 0.7458492975734355,
      "acc_stderr,none": 0.015569254692045793,
      "alias": "ogx_mmlux_et-miscellaneous"
    },
    "ogx_mmlux_et-medical_genetics": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_et-medical_genetics"
    },
    "ogx_mmlux_et-marketing": {
      "acc,none": 0.7735042735042735,
      "acc_stderr,none": 0.027421007295392902,
      "alias": "ogx_mmlux_et-marketing"
    },
    "ogx_mmlux_et-management": {
      "acc,none": 0.7184466019417476,
      "acc_stderr,none": 0.04453254836326469,
      "alias": "ogx_mmlux_et-management"
    },
    "ogx_mmlux_et-machine_learning": {
      "acc,none": 0.44642857142857145,
      "acc_stderr,none": 0.04718471485219588,
      "alias": "ogx_mmlux_et-machine_learning"
    },
    "ogx_mmlux_et-logical_fallacies": {
      "acc,none": 0.6748466257668712,
      "acc_stderr,none": 0.036803503712864616,
      "alias": "ogx_mmlux_et-logical_fallacies"
    },
    "ogx_mmlux_et-jurisprudence": {
      "acc,none": 0.7314814814814815,
      "acc_stderr,none": 0.042844679680521934,
      "alias": "ogx_mmlux_et-jurisprudence"
    },
    "ogx_mmlux_et-international_law": {
      "acc,none": 0.7272727272727273,
      "acc_stderr,none": 0.04065578140908705,
      "alias": "ogx_mmlux_et-international_law"
    },
    "ogx_mmlux_et-human_sexuality": {
      "acc,none": 0.6793893129770993,
      "acc_stderr,none": 0.04093329229834278,
      "alias": "ogx_mmlux_et-human_sexuality"
    },
    "ogx_mmlux_et-human_aging": {
      "acc,none": 0.6636771300448431,
      "acc_stderr,none": 0.031708824268455005,
      "alias": "ogx_mmlux_et-human_aging"
    },
    "ogx_mmlux_et-high_school_world_history": {
      "acc,none": 0.7552742616033755,
      "acc_stderr,none": 0.027985699387036416,
      "alias": "ogx_mmlux_et-high_school_world_history"
    },
    "ogx_mmlux_et-high_school_us_history": {
      "acc,none": 0.7696078431372549,
      "acc_stderr,none": 0.029554292605695053,
      "alias": "ogx_mmlux_et-high_school_us_history"
    },
    "ogx_mmlux_et-high_school_statistics": {
      "acc,none": 0.49537037037037035,
      "acc_stderr,none": 0.03409825519163572,
      "alias": "ogx_mmlux_et-high_school_statistics"
    },
    "ogx_mmlux_et-high_school_psychology": {
      "acc,none": 0.781651376146789,
      "acc_stderr,none": 0.017712600528722738,
      "alias": "ogx_mmlux_et-high_school_psychology"
    },
    "ogx_mmlux_et-high_school_physics": {
      "acc,none": 0.44370860927152317,
      "acc_stderr,none": 0.04056527902281732,
      "alias": "ogx_mmlux_et-high_school_physics"
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "acc,none": 0.6008403361344538,
      "acc_stderr,none": 0.03181110032413925,
      "alias": "ogx_mmlux_et-high_school_microeconomics"
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "acc,none": 0.37407407407407406,
      "acc_stderr,none": 0.02950286112895529,
      "alias": "ogx_mmlux_et-high_school_mathematics"
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "acc,none": 0.6512820512820513,
      "acc_stderr,none": 0.02416278028401772,
      "alias": "ogx_mmlux_et-high_school_macroeconomics"
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "acc,none": 0.7461139896373057,
      "acc_stderr,none": 0.03141024780565319,
      "alias": "ogx_mmlux_et-high_school_government_and_politics"
    },
    "ogx_mmlux_et-high_school_geography": {
      "acc,none": 0.696969696969697,
      "acc_stderr,none": 0.032742879140268674,
      "alias": "ogx_mmlux_et-high_school_geography"
    },
    "ogx_mmlux_et-high_school_european_history": {
      "acc,none": 0.7757575757575758,
      "acc_stderr,none": 0.03256866661681102,
      "alias": "ogx_mmlux_et-high_school_european_history"
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.0446196043338474,
      "alias": "ogx_mmlux_et-high_school_computer_science"
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "acc,none": 0.6206896551724138,
      "acc_stderr,none": 0.03413963805906235,
      "alias": "ogx_mmlux_et-high_school_chemistry"
    },
    "ogx_mmlux_et-high_school_biology": {
      "acc,none": 0.7741935483870968,
      "acc_stderr,none": 0.023785577884181012,
      "alias": "ogx_mmlux_et-high_school_biology"
    },
    "ogx_mmlux_et-global_facts": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.04999999999999999,
      "alias": "ogx_mmlux_et-global_facts"
    },
    "ogx_mmlux_et-formal_logic": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.04360314860077459,
      "alias": "ogx_mmlux_et-formal_logic"
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "acc,none": 0.5158730158730159,
      "acc_stderr,none": 0.025738330639412152,
      "alias": "ogx_mmlux_et-elementary_mathematics"
    },
    "ogx_mmlux_et-electrical_engineering": {
      "acc,none": 0.5862068965517241,
      "acc_stderr,none": 0.04104269211806232,
      "alias": "ogx_mmlux_et-electrical_engineering"
    },
    "ogx_mmlux_et-econometrics": {
      "acc,none": 0.5087719298245614,
      "acc_stderr,none": 0.04702880432049615,
      "alias": "ogx_mmlux_et-econometrics"
    },
    "ogx_mmlux_et-conceptual_physics": {
      "acc,none": 0.6127659574468085,
      "acc_stderr,none": 0.03184389265339526,
      "alias": "ogx_mmlux_et-conceptual_physics"
    },
    "ogx_mmlux_et-computer_security": {
      "acc,none": 0.68,
      "acc_stderr,none": 0.04688261722621505,
      "alias": "ogx_mmlux_et-computer_security"
    },
    "ogx_mmlux_et-college_physics": {
      "acc,none": 0.3627450980392157,
      "acc_stderr,none": 0.04784060704105654,
      "alias": "ogx_mmlux_et-college_physics"
    },
    "ogx_mmlux_et-college_medicine": {
      "acc,none": 0.6473988439306358,
      "acc_stderr,none": 0.036430371689585475,
      "alias": "ogx_mmlux_et-college_medicine"
    },
    "ogx_mmlux_et-college_mathematics": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.046882617226215034,
      "alias": "ogx_mmlux_et-college_mathematics"
    },
    "ogx_mmlux_et-college_computer_science": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_et-college_computer_science"
    },
    "ogx_mmlux_et-college_chemistry": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_et-college_chemistry"
    },
    "ogx_mmlux_et-college_biology": {
      "acc,none": 0.7291666666666666,
      "acc_stderr,none": 0.03716177437566016,
      "alias": "ogx_mmlux_et-college_biology"
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "acc,none": 0.660377358490566,
      "acc_stderr,none": 0.02914690474779833,
      "alias": "ogx_mmlux_et-clinical_knowledge"
    },
    "ogx_mmlux_et-business_ethics": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.049431107042371025,
      "alias": "ogx_mmlux_et-business_ethics"
    },
    "ogx_mmlux_et-astronomy": {
      "acc,none": 0.7763157894736842,
      "acc_stderr,none": 0.033911609343436025,
      "alias": "ogx_mmlux_et-astronomy"
    },
    "ogx_mmlux_et-anatomy": {
      "acc,none": 0.5037037037037037,
      "acc_stderr,none": 0.04319223625811331,
      "alias": "ogx_mmlux_et-anatomy"
    },
    "ogx_mmlux_et-abstract_algebra": {
      "acc,none": 0.41,
      "acc_stderr,none": 0.049431107042371025,
      "alias": "ogx_mmlux_et-abstract_algebra"
    },
    "ogx_mmlux_es-world_religions": {
      "acc,none": 0.8362573099415205,
      "acc_stderr,none": 0.028380919596145866,
      "alias": "ogx_mmlux_es-world_religions"
    },
    "ogx_mmlux_es-virology": {
      "acc,none": 0.5240963855421686,
      "acc_stderr,none": 0.03887971849597264,
      "alias": "ogx_mmlux_es-virology"
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "acc,none": 0.83,
      "acc_stderr,none": 0.0377525168068637,
      "alias": "ogx_mmlux_es-us_foreign_policy"
    },
    "ogx_mmlux_es-sociology": {
      "acc,none": 0.8258706467661692,
      "acc_stderr,none": 0.026814951200421606,
      "alias": "ogx_mmlux_es-sociology"
    },
    "ogx_mmlux_es-security_studies": {
      "acc,none": 0.763265306122449,
      "acc_stderr,none": 0.02721283588407315,
      "alias": "ogx_mmlux_es-security_studies"
    },
    "ogx_mmlux_es-public_relations": {
      "acc,none": 0.6727272727272727,
      "acc_stderr,none": 0.044942908662520896,
      "alias": "ogx_mmlux_es-public_relations"
    },
    "ogx_mmlux_es-professional_psychology": {
      "acc,none": 0.6928104575163399,
      "acc_stderr,none": 0.01866335967146366,
      "alias": "ogx_mmlux_es-professional_psychology"
    },
    "ogx_mmlux_es-professional_medicine": {
      "acc,none": 0.7022058823529411,
      "acc_stderr,none": 0.027778298701545443,
      "alias": "ogx_mmlux_es-professional_medicine"
    },
    "ogx_mmlux_es-professional_law": {
      "acc,none": 0.500651890482399,
      "acc_stderr,none": 0.01277022525225556,
      "alias": "ogx_mmlux_es-professional_law"
    },
    "ogx_mmlux_es-professional_accounting": {
      "acc,none": 0.4397163120567376,
      "acc_stderr,none": 0.029609912075594106,
      "alias": "ogx_mmlux_es-professional_accounting"
    },
    "ogx_mmlux_es-prehistory": {
      "acc,none": 0.7685185185185185,
      "acc_stderr,none": 0.023468429832451163,
      "alias": "ogx_mmlux_es-prehistory"
    },
    "ogx_mmlux_es-philosophy": {
      "acc,none": 0.7266881028938906,
      "acc_stderr,none": 0.02531176597542612,
      "alias": "ogx_mmlux_es-philosophy"
    },
    "ogx_mmlux_es-nutrition": {
      "acc,none": 0.6993464052287581,
      "acc_stderr,none": 0.02625605383571896,
      "alias": "ogx_mmlux_es-nutrition"
    },
    "ogx_mmlux_es-moral_scenarios": {
      "acc,none": 0.36201117318435755,
      "acc_stderr,none": 0.016073067350153087,
      "alias": "ogx_mmlux_es-moral_scenarios"
    },
    "ogx_mmlux_es-moral_disputes": {
      "acc,none": 0.7427745664739884,
      "acc_stderr,none": 0.023532925431044276,
      "alias": "ogx_mmlux_es-moral_disputes"
    },
    "ogx_mmlux_es-miscellaneous": {
      "acc,none": 0.822477650063857,
      "acc_stderr,none": 0.01366423099583483,
      "alias": "ogx_mmlux_es-miscellaneous"
    },
    "ogx_mmlux_es-medical_genetics": {
      "acc,none": 0.82,
      "acc_stderr,none": 0.038612291966536934,
      "alias": "ogx_mmlux_es-medical_genetics"
    },
    "ogx_mmlux_es-marketing": {
      "acc,none": 0.8717948717948718,
      "acc_stderr,none": 0.02190190511507333,
      "alias": "ogx_mmlux_es-marketing"
    },
    "ogx_mmlux_es-management": {
      "acc,none": 0.8058252427184466,
      "acc_stderr,none": 0.039166677628225836,
      "alias": "ogx_mmlux_es-management"
    },
    "ogx_mmlux_es-machine_learning": {
      "acc,none": 0.4732142857142857,
      "acc_stderr,none": 0.047389751192741546,
      "alias": "ogx_mmlux_es-machine_learning"
    },
    "ogx_mmlux_es-logical_fallacies": {
      "acc,none": 0.7730061349693251,
      "acc_stderr,none": 0.03291099578615769,
      "alias": "ogx_mmlux_es-logical_fallacies"
    },
    "ogx_mmlux_es-jurisprudence": {
      "acc,none": 0.7870370370370371,
      "acc_stderr,none": 0.0395783547198098,
      "alias": "ogx_mmlux_es-jurisprudence"
    },
    "ogx_mmlux_es-international_law": {
      "acc,none": 0.768595041322314,
      "acc_stderr,none": 0.038498560987940904,
      "alias": "ogx_mmlux_es-international_law"
    },
    "ogx_mmlux_es-human_sexuality": {
      "acc,none": 0.7633587786259542,
      "acc_stderr,none": 0.03727673575596915,
      "alias": "ogx_mmlux_es-human_sexuality"
    },
    "ogx_mmlux_es-human_aging": {
      "acc,none": 0.7309417040358744,
      "acc_stderr,none": 0.029763779406874965,
      "alias": "ogx_mmlux_es-human_aging"
    },
    "ogx_mmlux_es-high_school_world_history": {
      "acc,none": 0.8059071729957806,
      "acc_stderr,none": 0.02574490253229093,
      "alias": "ogx_mmlux_es-high_school_world_history"
    },
    "ogx_mmlux_es-high_school_us_history": {
      "acc,none": 0.8431372549019608,
      "acc_stderr,none": 0.025524722324553318,
      "alias": "ogx_mmlux_es-high_school_us_history"
    },
    "ogx_mmlux_es-high_school_statistics": {
      "acc,none": 0.5879629629629629,
      "acc_stderr,none": 0.03356787758160831,
      "alias": "ogx_mmlux_es-high_school_statistics"
    },
    "ogx_mmlux_es-high_school_psychology": {
      "acc,none": 0.8788990825688073,
      "acc_stderr,none": 0.013987618292389712,
      "alias": "ogx_mmlux_es-high_school_psychology"
    },
    "ogx_mmlux_es-high_school_physics": {
      "acc,none": 0.5099337748344371,
      "acc_stderr,none": 0.04081677107248437,
      "alias": "ogx_mmlux_es-high_school_physics"
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "acc,none": 0.7647058823529411,
      "acc_stderr,none": 0.027553614467863804,
      "alias": "ogx_mmlux_es-high_school_microeconomics"
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "acc,none": 0.42592592592592593,
      "acc_stderr,none": 0.03014913560136594,
      "alias": "ogx_mmlux_es-high_school_mathematics"
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "acc,none": 0.7384615384615385,
      "acc_stderr,none": 0.022282141204204395,
      "alias": "ogx_mmlux_es-high_school_macroeconomics"
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "acc,none": 0.8911917098445595,
      "acc_stderr,none": 0.022473253332768763,
      "alias": "ogx_mmlux_es-high_school_government_and_politics"
    },
    "ogx_mmlux_es-high_school_geography": {
      "acc,none": 0.8282828282828283,
      "acc_stderr,none": 0.026869716187429914,
      "alias": "ogx_mmlux_es-high_school_geography"
    },
    "ogx_mmlux_es-high_school_european_history": {
      "acc,none": 0.8181818181818182,
      "acc_stderr,none": 0.030117688929503585,
      "alias": "ogx_mmlux_es-high_school_european_history"
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_es-high_school_computer_science"
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "acc,none": 0.6748768472906403,
      "acc_stderr,none": 0.03295797566311271,
      "alias": "ogx_mmlux_es-high_school_chemistry"
    },
    "ogx_mmlux_es-high_school_biology": {
      "acc,none": 0.8741935483870967,
      "acc_stderr,none": 0.018865834288029997,
      "alias": "ogx_mmlux_es-high_school_biology"
    },
    "ogx_mmlux_es-global_facts": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_es-global_facts"
    },
    "ogx_mmlux_es-formal_logic": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.04472135954999579,
      "alias": "ogx_mmlux_es-formal_logic"
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "acc,none": 0.5423280423280423,
      "acc_stderr,none": 0.025658868862058325,
      "alias": "ogx_mmlux_es-elementary_mathematics"
    },
    "ogx_mmlux_es-electrical_engineering": {
      "acc,none": 0.6413793103448275,
      "acc_stderr,none": 0.03996629574876719,
      "alias": "ogx_mmlux_es-electrical_engineering"
    },
    "ogx_mmlux_es-econometrics": {
      "acc,none": 0.5877192982456141,
      "acc_stderr,none": 0.046306532033665956,
      "alias": "ogx_mmlux_es-econometrics"
    },
    "ogx_mmlux_es-conceptual_physics": {
      "acc,none": 0.7106382978723405,
      "acc_stderr,none": 0.02964400657700962,
      "alias": "ogx_mmlux_es-conceptual_physics"
    },
    "ogx_mmlux_es-computer_security": {
      "acc,none": 0.72,
      "acc_stderr,none": 0.04512608598542128,
      "alias": "ogx_mmlux_es-computer_security"
    },
    "ogx_mmlux_es-college_physics": {
      "acc,none": 0.4803921568627451,
      "acc_stderr,none": 0.04971358884367406,
      "alias": "ogx_mmlux_es-college_physics"
    },
    "ogx_mmlux_es-college_medicine": {
      "acc,none": 0.6589595375722543,
      "acc_stderr,none": 0.036146654241808254,
      "alias": "ogx_mmlux_es-college_medicine"
    },
    "ogx_mmlux_es-college_mathematics": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252604,
      "alias": "ogx_mmlux_es-college_mathematics"
    },
    "ogx_mmlux_es-college_computer_science": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_es-college_computer_science"
    },
    "ogx_mmlux_es-college_chemistry": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_es-college_chemistry"
    },
    "ogx_mmlux_es-college_biology": {
      "acc,none": 0.8055555555555556,
      "acc_stderr,none": 0.03309615177059006,
      "alias": "ogx_mmlux_es-college_biology"
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "acc,none": 0.7283018867924528,
      "acc_stderr,none": 0.027377706624670713,
      "alias": "ogx_mmlux_es-clinical_knowledge"
    },
    "ogx_mmlux_es-business_ethics": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_es-business_ethics"
    },
    "ogx_mmlux_es-astronomy": {
      "acc,none": 0.7828947368421053,
      "acc_stderr,none": 0.033550453048829226,
      "alias": "ogx_mmlux_es-astronomy"
    },
    "ogx_mmlux_es-anatomy": {
      "acc,none": 0.6518518518518519,
      "acc_stderr,none": 0.041153246103369526,
      "alias": "ogx_mmlux_es-anatomy"
    },
    "ogx_mmlux_es-abstract_algebra": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_es-abstract_algebra"
    },
    "ogx_mmlux_el-world_religions": {
      "acc,none": 0.7368421052631579,
      "acc_stderr,none": 0.03377310252209205,
      "alias": "ogx_mmlux_el-world_religions"
    },
    "ogx_mmlux_el-virology": {
      "acc,none": 0.4759036144578313,
      "acc_stderr,none": 0.03887971849597264,
      "alias": "ogx_mmlux_el-virology"
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "acc,none": 0.77,
      "acc_stderr,none": 0.04229525846816505,
      "alias": "ogx_mmlux_el-us_foreign_policy"
    },
    "ogx_mmlux_el-sociology": {
      "acc,none": 0.7960199004975125,
      "acc_stderr,none": 0.028493176245326088,
      "alias": "ogx_mmlux_el-sociology"
    },
    "ogx_mmlux_el-security_studies": {
      "acc,none": 0.7142857142857143,
      "acc_stderr,none": 0.0289205832206756,
      "alias": "ogx_mmlux_el-security_studies"
    },
    "ogx_mmlux_el-public_relations": {
      "acc,none": 0.6363636363636364,
      "acc_stderr,none": 0.04607582090719976,
      "alias": "ogx_mmlux_el-public_relations"
    },
    "ogx_mmlux_el-professional_psychology": {
      "acc,none": 0.6241830065359477,
      "acc_stderr,none": 0.01959402113657745,
      "alias": "ogx_mmlux_el-professional_psychology"
    },
    "ogx_mmlux_el-professional_medicine": {
      "acc,none": 0.5257352941176471,
      "acc_stderr,none": 0.03033257809455504,
      "alias": "ogx_mmlux_el-professional_medicine"
    },
    "ogx_mmlux_el-professional_law": {
      "acc,none": 0.4556714471968709,
      "acc_stderr,none": 0.012719949543032204,
      "alias": "ogx_mmlux_el-professional_law"
    },
    "ogx_mmlux_el-professional_accounting": {
      "acc,none": 0.4078014184397163,
      "acc_stderr,none": 0.029316011776343562,
      "alias": "ogx_mmlux_el-professional_accounting"
    },
    "ogx_mmlux_el-prehistory": {
      "acc,none": 0.691358024691358,
      "acc_stderr,none": 0.02570264026060375,
      "alias": "ogx_mmlux_el-prehistory"
    },
    "ogx_mmlux_el-philosophy": {
      "acc,none": 0.639871382636656,
      "acc_stderr,none": 0.027264297599804015,
      "alias": "ogx_mmlux_el-philosophy"
    },
    "ogx_mmlux_el-nutrition": {
      "acc,none": 0.630718954248366,
      "acc_stderr,none": 0.02763417668960266,
      "alias": "ogx_mmlux_el-nutrition"
    },
    "ogx_mmlux_el-moral_scenarios": {
      "acc,none": 0.3340782122905028,
      "acc_stderr,none": 0.015774911422381636,
      "alias": "ogx_mmlux_el-moral_scenarios"
    },
    "ogx_mmlux_el-moral_disputes": {
      "acc,none": 0.6676300578034682,
      "acc_stderr,none": 0.025361168749688218,
      "alias": "ogx_mmlux_el-moral_disputes"
    },
    "ogx_mmlux_el-miscellaneous": {
      "acc,none": 0.7151979565772669,
      "acc_stderr,none": 0.01613917409652258,
      "alias": "ogx_mmlux_el-miscellaneous"
    },
    "ogx_mmlux_el-medical_genetics": {
      "acc,none": 0.66,
      "acc_stderr,none": 0.04760952285695238,
      "alias": "ogx_mmlux_el-medical_genetics"
    },
    "ogx_mmlux_el-marketing": {
      "acc,none": 0.8290598290598291,
      "acc_stderr,none": 0.024662496845209818,
      "alias": "ogx_mmlux_el-marketing"
    },
    "ogx_mmlux_el-management": {
      "acc,none": 0.7572815533980582,
      "acc_stderr,none": 0.042450224863844935,
      "alias": "ogx_mmlux_el-management"
    },
    "ogx_mmlux_el-machine_learning": {
      "acc,none": 0.44642857142857145,
      "acc_stderr,none": 0.047184714852195886,
      "alias": "ogx_mmlux_el-machine_learning"
    },
    "ogx_mmlux_el-logical_fallacies": {
      "acc,none": 0.6993865030674846,
      "acc_stderr,none": 0.03602511318806771,
      "alias": "ogx_mmlux_el-logical_fallacies"
    },
    "ogx_mmlux_el-jurisprudence": {
      "acc,none": 0.7037037037037037,
      "acc_stderr,none": 0.044143436668549335,
      "alias": "ogx_mmlux_el-jurisprudence"
    },
    "ogx_mmlux_el-international_law": {
      "acc,none": 0.7768595041322314,
      "acc_stderr,none": 0.03800754475228733,
      "alias": "ogx_mmlux_el-international_law"
    },
    "ogx_mmlux_el-human_sexuality": {
      "acc,none": 0.7022900763358778,
      "acc_stderr,none": 0.04010358942462203,
      "alias": "ogx_mmlux_el-human_sexuality"
    },
    "ogx_mmlux_el-human_aging": {
      "acc,none": 0.6367713004484304,
      "acc_stderr,none": 0.032277904428505,
      "alias": "ogx_mmlux_el-human_aging"
    },
    "ogx_mmlux_el-high_school_world_history": {
      "acc,none": 0.8016877637130801,
      "acc_stderr,none": 0.025955020841621105,
      "alias": "ogx_mmlux_el-high_school_world_history"
    },
    "ogx_mmlux_el-high_school_us_history": {
      "acc,none": 0.7549019607843137,
      "acc_stderr,none": 0.030190282453501933,
      "alias": "ogx_mmlux_el-high_school_us_history"
    },
    "ogx_mmlux_el-high_school_statistics": {
      "acc,none": 0.5694444444444444,
      "acc_stderr,none": 0.03376922151252336,
      "alias": "ogx_mmlux_el-high_school_statistics"
    },
    "ogx_mmlux_el-high_school_psychology": {
      "acc,none": 0.7431192660550459,
      "acc_stderr,none": 0.01873249292834246,
      "alias": "ogx_mmlux_el-high_school_psychology"
    },
    "ogx_mmlux_el-high_school_physics": {
      "acc,none": 0.4900662251655629,
      "acc_stderr,none": 0.04081677107248436,
      "alias": "ogx_mmlux_el-high_school_physics"
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "acc,none": 0.6512605042016807,
      "acc_stderr,none": 0.030956636328566548,
      "alias": "ogx_mmlux_el-high_school_microeconomics"
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "acc,none": 0.4111111111111111,
      "acc_stderr,none": 0.029999923508706675,
      "alias": "ogx_mmlux_el-high_school_mathematics"
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "acc,none": 0.6461538461538462,
      "acc_stderr,none": 0.02424378399406217,
      "alias": "ogx_mmlux_el-high_school_macroeconomics"
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "acc,none": 0.7357512953367875,
      "acc_stderr,none": 0.03182155050916646,
      "alias": "ogx_mmlux_el-high_school_government_and_politics"
    },
    "ogx_mmlux_el-high_school_geography": {
      "acc,none": 0.7424242424242424,
      "acc_stderr,none": 0.031156269519646836,
      "alias": "ogx_mmlux_el-high_school_geography"
    },
    "ogx_mmlux_el-high_school_european_history": {
      "acc,none": 0.793939393939394,
      "acc_stderr,none": 0.03158415324047709,
      "alias": "ogx_mmlux_el-high_school_european_history"
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.0446196043338474,
      "alias": "ogx_mmlux_el-high_school_computer_science"
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "acc,none": 0.6403940886699507,
      "acc_stderr,none": 0.033764582465095665,
      "alias": "ogx_mmlux_el-high_school_chemistry"
    },
    "ogx_mmlux_el-high_school_biology": {
      "acc,none": 0.7677419354838709,
      "acc_stderr,none": 0.02402225613030824,
      "alias": "ogx_mmlux_el-high_school_biology"
    },
    "ogx_mmlux_el-global_facts": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_el-global_facts"
    },
    "ogx_mmlux_el-formal_logic": {
      "acc,none": 0.42857142857142855,
      "acc_stderr,none": 0.04426266681379909,
      "alias": "ogx_mmlux_el-formal_logic"
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "acc,none": 0.5396825396825397,
      "acc_stderr,none": 0.025670080636909322,
      "alias": "ogx_mmlux_el-elementary_mathematics"
    },
    "ogx_mmlux_el-electrical_engineering": {
      "acc,none": 0.5517241379310345,
      "acc_stderr,none": 0.04144311810878152,
      "alias": "ogx_mmlux_el-electrical_engineering"
    },
    "ogx_mmlux_el-econometrics": {
      "acc,none": 0.543859649122807,
      "acc_stderr,none": 0.046854730419077895,
      "alias": "ogx_mmlux_el-econometrics"
    },
    "ogx_mmlux_el-conceptual_physics": {
      "acc,none": 0.6468085106382979,
      "acc_stderr,none": 0.031245325202761923,
      "alias": "ogx_mmlux_el-conceptual_physics"
    },
    "ogx_mmlux_el-computer_security": {
      "acc,none": 0.72,
      "acc_stderr,none": 0.04512608598542129,
      "alias": "ogx_mmlux_el-computer_security"
    },
    "ogx_mmlux_el-college_physics": {
      "acc,none": 0.4803921568627451,
      "acc_stderr,none": 0.04971358884367406,
      "alias": "ogx_mmlux_el-college_physics"
    },
    "ogx_mmlux_el-college_medicine": {
      "acc,none": 0.6184971098265896,
      "acc_stderr,none": 0.0370385119309952,
      "alias": "ogx_mmlux_el-college_medicine"
    },
    "ogx_mmlux_el-college_mathematics": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_el-college_mathematics"
    },
    "ogx_mmlux_el-college_computer_science": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_el-college_computer_science"
    },
    "ogx_mmlux_el-college_chemistry": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_el-college_chemistry"
    },
    "ogx_mmlux_el-college_biology": {
      "acc,none": 0.6527777777777778,
      "acc_stderr,none": 0.039812405437178615,
      "alias": "ogx_mmlux_el-college_biology"
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "acc,none": 0.6075471698113207,
      "acc_stderr,none": 0.030052580579557845,
      "alias": "ogx_mmlux_el-clinical_knowledge"
    },
    "ogx_mmlux_el-business_ethics": {
      "acc,none": 0.72,
      "acc_stderr,none": 0.045126085985421276,
      "alias": "ogx_mmlux_el-business_ethics"
    },
    "ogx_mmlux_el-astronomy": {
      "acc,none": 0.7368421052631579,
      "acc_stderr,none": 0.03583496176361073,
      "alias": "ogx_mmlux_el-astronomy"
    },
    "ogx_mmlux_el-anatomy": {
      "acc,none": 0.5407407407407407,
      "acc_stderr,none": 0.04304979692464242,
      "alias": "ogx_mmlux_el-anatomy"
    },
    "ogx_mmlux_el-abstract_algebra": {
      "acc,none": 0.41,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_el-abstract_algebra"
    },
    "ogx_mmlux_de-world_religions": {
      "acc,none": 0.8304093567251462,
      "acc_stderr,none": 0.02878210810540171,
      "alias": "ogx_mmlux_de-world_religions"
    },
    "ogx_mmlux_de-virology": {
      "acc,none": 0.4879518072289157,
      "acc_stderr,none": 0.03891364495835819,
      "alias": "ogx_mmlux_de-virology"
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "acc,none": 0.84,
      "acc_stderr,none": 0.036845294917747094,
      "alias": "ogx_mmlux_de-us_foreign_policy"
    },
    "ogx_mmlux_de-sociology": {
      "acc,none": 0.8507462686567164,
      "acc_stderr,none": 0.02519692987482707,
      "alias": "ogx_mmlux_de-sociology"
    },
    "ogx_mmlux_de-security_studies": {
      "acc,none": 0.7591836734693878,
      "acc_stderr,none": 0.02737294220178817,
      "alias": "ogx_mmlux_de-security_studies"
    },
    "ogx_mmlux_de-public_relations": {
      "acc,none": 0.6909090909090909,
      "acc_stderr,none": 0.044262946482000985,
      "alias": "ogx_mmlux_de-public_relations"
    },
    "ogx_mmlux_de-professional_psychology": {
      "acc,none": 0.6764705882352942,
      "acc_stderr,none": 0.018926082916083383,
      "alias": "ogx_mmlux_de-professional_psychology"
    },
    "ogx_mmlux_de-professional_medicine": {
      "acc,none": 0.6948529411764706,
      "acc_stderr,none": 0.027971541370170598,
      "alias": "ogx_mmlux_de-professional_medicine"
    },
    "ogx_mmlux_de-professional_law": {
      "acc,none": 0.44328552803129073,
      "acc_stderr,none": 0.012687818419599924,
      "alias": "ogx_mmlux_de-professional_law"
    },
    "ogx_mmlux_de-professional_accounting": {
      "acc,none": 0.4787234042553192,
      "acc_stderr,none": 0.029800481645628693,
      "alias": "ogx_mmlux_de-professional_accounting"
    },
    "ogx_mmlux_de-prehistory": {
      "acc,none": 0.7623456790123457,
      "acc_stderr,none": 0.02368359183700856,
      "alias": "ogx_mmlux_de-prehistory"
    },
    "ogx_mmlux_de-philosophy": {
      "acc,none": 0.6945337620578779,
      "acc_stderr,none": 0.026160584450140453,
      "alias": "ogx_mmlux_de-philosophy"
    },
    "ogx_mmlux_de-nutrition": {
      "acc,none": 0.7156862745098039,
      "acc_stderr,none": 0.025829163272757475,
      "alias": "ogx_mmlux_de-nutrition"
    },
    "ogx_mmlux_de-moral_scenarios": {
      "acc,none": 0.32625698324022345,
      "acc_stderr,none": 0.01568044151888918,
      "alias": "ogx_mmlux_de-moral_scenarios"
    },
    "ogx_mmlux_de-moral_disputes": {
      "acc,none": 0.7196531791907514,
      "acc_stderr,none": 0.024182427496577612,
      "alias": "ogx_mmlux_de-moral_disputes"
    },
    "ogx_mmlux_de-miscellaneous": {
      "acc,none": 0.8045977011494253,
      "acc_stderr,none": 0.014179171373424384,
      "alias": "ogx_mmlux_de-miscellaneous"
    },
    "ogx_mmlux_de-medical_genetics": {
      "acc,none": 0.78,
      "acc_stderr,none": 0.04163331998932262,
      "alias": "ogx_mmlux_de-medical_genetics"
    },
    "ogx_mmlux_de-marketing": {
      "acc,none": 0.8547008547008547,
      "acc_stderr,none": 0.023086635086841407,
      "alias": "ogx_mmlux_de-marketing"
    },
    "ogx_mmlux_de-management": {
      "acc,none": 0.7864077669902912,
      "acc_stderr,none": 0.040580420156460344,
      "alias": "ogx_mmlux_de-management"
    },
    "ogx_mmlux_de-machine_learning": {
      "acc,none": 0.4642857142857143,
      "acc_stderr,none": 0.04733667890053756,
      "alias": "ogx_mmlux_de-machine_learning"
    },
    "ogx_mmlux_de-logical_fallacies": {
      "acc,none": 0.7484662576687117,
      "acc_stderr,none": 0.034089978868575295,
      "alias": "ogx_mmlux_de-logical_fallacies"
    },
    "ogx_mmlux_de-jurisprudence": {
      "acc,none": 0.7870370370370371,
      "acc_stderr,none": 0.0395783547198098,
      "alias": "ogx_mmlux_de-jurisprudence"
    },
    "ogx_mmlux_de-international_law": {
      "acc,none": 0.7933884297520661,
      "acc_stderr,none": 0.03695980128098824,
      "alias": "ogx_mmlux_de-international_law"
    },
    "ogx_mmlux_de-human_sexuality": {
      "acc,none": 0.7633587786259542,
      "acc_stderr,none": 0.03727673575596914,
      "alias": "ogx_mmlux_de-human_sexuality"
    },
    "ogx_mmlux_de-human_aging": {
      "acc,none": 0.7130044843049327,
      "acc_stderr,none": 0.030360379710291964,
      "alias": "ogx_mmlux_de-human_aging"
    },
    "ogx_mmlux_de-high_school_world_history": {
      "acc,none": 0.8396624472573839,
      "acc_stderr,none": 0.023884380925965676,
      "alias": "ogx_mmlux_de-high_school_world_history"
    },
    "ogx_mmlux_de-high_school_us_history": {
      "acc,none": 0.8333333333333334,
      "acc_stderr,none": 0.026156867523931038,
      "alias": "ogx_mmlux_de-high_school_us_history"
    },
    "ogx_mmlux_de-high_school_statistics": {
      "acc,none": 0.5648148148148148,
      "acc_stderr,none": 0.033812000056435254,
      "alias": "ogx_mmlux_de-high_school_statistics"
    },
    "ogx_mmlux_de-high_school_psychology": {
      "acc,none": 0.8532110091743119,
      "acc_stderr,none": 0.015173141845126279,
      "alias": "ogx_mmlux_de-high_school_psychology"
    },
    "ogx_mmlux_de-high_school_physics": {
      "acc,none": 0.543046357615894,
      "acc_stderr,none": 0.04067325174247442,
      "alias": "ogx_mmlux_de-high_school_physics"
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "acc,none": 0.6974789915966386,
      "acc_stderr,none": 0.02983796238829193,
      "alias": "ogx_mmlux_de-high_school_microeconomics"
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "acc,none": 0.4148148148148148,
      "acc_stderr,none": 0.030039842454069286,
      "alias": "ogx_mmlux_de-high_school_mathematics"
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "acc,none": 0.7333333333333333,
      "acc_stderr,none": 0.02242127361292372,
      "alias": "ogx_mmlux_de-high_school_macroeconomics"
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "acc,none": 0.8393782383419689,
      "acc_stderr,none": 0.026499057701397443,
      "alias": "ogx_mmlux_de-high_school_government_and_politics"
    },
    "ogx_mmlux_de-high_school_geography": {
      "acc,none": 0.8585858585858586,
      "acc_stderr,none": 0.024825909793343343,
      "alias": "ogx_mmlux_de-high_school_geography"
    },
    "ogx_mmlux_de-high_school_european_history": {
      "acc,none": 0.8424242424242424,
      "acc_stderr,none": 0.028450388805284343,
      "alias": "ogx_mmlux_de-high_school_european_history"
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.0440844002276808,
      "alias": "ogx_mmlux_de-high_school_computer_science"
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "acc,none": 0.6551724137931034,
      "acc_stderr,none": 0.03344283744280458,
      "alias": "ogx_mmlux_de-high_school_chemistry"
    },
    "ogx_mmlux_de-high_school_biology": {
      "acc,none": 0.8483870967741935,
      "acc_stderr,none": 0.02040261665441674,
      "alias": "ogx_mmlux_de-high_school_biology"
    },
    "ogx_mmlux_de-global_facts": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_de-global_facts"
    },
    "ogx_mmlux_de-formal_logic": {
      "acc,none": 0.47619047619047616,
      "acc_stderr,none": 0.04467062628403273,
      "alias": "ogx_mmlux_de-formal_logic"
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "acc,none": 0.5052910052910053,
      "acc_stderr,none": 0.02574986828855657,
      "alias": "ogx_mmlux_de-elementary_mathematics"
    },
    "ogx_mmlux_de-electrical_engineering": {
      "acc,none": 0.6137931034482759,
      "acc_stderr,none": 0.04057324734419035,
      "alias": "ogx_mmlux_de-electrical_engineering"
    },
    "ogx_mmlux_de-econometrics": {
      "acc,none": 0.5263157894736842,
      "acc_stderr,none": 0.046970851366478626,
      "alias": "ogx_mmlux_de-econometrics"
    },
    "ogx_mmlux_de-conceptual_physics": {
      "acc,none": 0.6723404255319149,
      "acc_stderr,none": 0.030683020843231,
      "alias": "ogx_mmlux_de-conceptual_physics"
    },
    "ogx_mmlux_de-computer_security": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.04408440022768079,
      "alias": "ogx_mmlux_de-computer_security"
    },
    "ogx_mmlux_de-college_physics": {
      "acc,none": 0.47058823529411764,
      "acc_stderr,none": 0.049665709039785295,
      "alias": "ogx_mmlux_de-college_physics"
    },
    "ogx_mmlux_de-college_medicine": {
      "acc,none": 0.6936416184971098,
      "acc_stderr,none": 0.03514942551267437,
      "alias": "ogx_mmlux_de-college_medicine"
    },
    "ogx_mmlux_de-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_de-college_mathematics"
    },
    "ogx_mmlux_de-college_computer_science": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_de-college_computer_science"
    },
    "ogx_mmlux_de-college_chemistry": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_de-college_chemistry"
    },
    "ogx_mmlux_de-college_biology": {
      "acc,none": 0.7777777777777778,
      "acc_stderr,none": 0.03476590104304134,
      "alias": "ogx_mmlux_de-college_biology"
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "acc,none": 0.7320754716981132,
      "acc_stderr,none": 0.027257260322494845,
      "alias": "ogx_mmlux_de-clinical_knowledge"
    },
    "ogx_mmlux_de-business_ethics": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_de-business_ethics"
    },
    "ogx_mmlux_de-astronomy": {
      "acc,none": 0.7960526315789473,
      "acc_stderr,none": 0.03279000406310051,
      "alias": "ogx_mmlux_de-astronomy"
    },
    "ogx_mmlux_de-anatomy": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.04232073695151589,
      "alias": "ogx_mmlux_de-anatomy"
    },
    "ogx_mmlux_de-abstract_algebra": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_de-abstract_algebra"
    },
    "ogx_mmlux_da-world_religions": {
      "acc,none": 0.8187134502923976,
      "acc_stderr,none": 0.029547741687640038,
      "alias": "ogx_mmlux_da-world_religions"
    },
    "ogx_mmlux_da-virology": {
      "acc,none": 0.536144578313253,
      "acc_stderr,none": 0.03882310850890593,
      "alias": "ogx_mmlux_da-virology"
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "acc,none": 0.82,
      "acc_stderr,none": 0.038612291966536934,
      "alias": "ogx_mmlux_da-us_foreign_policy"
    },
    "ogx_mmlux_da-sociology": {
      "acc,none": 0.8208955223880597,
      "acc_stderr,none": 0.027113286753111837,
      "alias": "ogx_mmlux_da-sociology"
    },
    "ogx_mmlux_da-security_studies": {
      "acc,none": 0.7795918367346939,
      "acc_stderr,none": 0.02653704531214528,
      "alias": "ogx_mmlux_da-security_studies"
    },
    "ogx_mmlux_da-public_relations": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.04389311454644286,
      "alias": "ogx_mmlux_da-public_relations"
    },
    "ogx_mmlux_da-professional_psychology": {
      "acc,none": 0.6862745098039216,
      "acc_stderr,none": 0.018771683893528183,
      "alias": "ogx_mmlux_da-professional_psychology"
    },
    "ogx_mmlux_da-professional_medicine": {
      "acc,none": 0.6764705882352942,
      "acc_stderr,none": 0.028418208619406752,
      "alias": "ogx_mmlux_da-professional_medicine"
    },
    "ogx_mmlux_da-professional_law": {
      "acc,none": 0.4634941329856584,
      "acc_stderr,none": 0.012736153390214961,
      "alias": "ogx_mmlux_da-professional_law"
    },
    "ogx_mmlux_da-professional_accounting": {
      "acc,none": 0.450354609929078,
      "acc_stderr,none": 0.029680105565029036,
      "alias": "ogx_mmlux_da-professional_accounting"
    },
    "ogx_mmlux_da-prehistory": {
      "acc,none": 0.7314814814814815,
      "acc_stderr,none": 0.02465968518596729,
      "alias": "ogx_mmlux_da-prehistory"
    },
    "ogx_mmlux_da-philosophy": {
      "acc,none": 0.6945337620578779,
      "acc_stderr,none": 0.026160584450140453,
      "alias": "ogx_mmlux_da-philosophy"
    },
    "ogx_mmlux_da-nutrition": {
      "acc,none": 0.7026143790849673,
      "acc_stderr,none": 0.026173908506718576,
      "alias": "ogx_mmlux_da-nutrition"
    },
    "ogx_mmlux_da-moral_scenarios": {
      "acc,none": 0.26145251396648045,
      "acc_stderr,none": 0.014696599650364546,
      "alias": "ogx_mmlux_da-moral_scenarios"
    },
    "ogx_mmlux_da-moral_disputes": {
      "acc,none": 0.7052023121387283,
      "acc_stderr,none": 0.02454761779480384,
      "alias": "ogx_mmlux_da-moral_disputes"
    },
    "ogx_mmlux_da-miscellaneous": {
      "acc,none": 0.8135376756066411,
      "acc_stderr,none": 0.013927751372001501,
      "alias": "ogx_mmlux_da-miscellaneous"
    },
    "ogx_mmlux_da-medical_genetics": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_da-medical_genetics"
    },
    "ogx_mmlux_da-marketing": {
      "acc,none": 0.8888888888888888,
      "acc_stderr,none": 0.02058849131609238,
      "alias": "ogx_mmlux_da-marketing"
    },
    "ogx_mmlux_da-management": {
      "acc,none": 0.7961165048543689,
      "acc_stderr,none": 0.0398913985953177,
      "alias": "ogx_mmlux_da-management"
    },
    "ogx_mmlux_da-machine_learning": {
      "acc,none": 0.45535714285714285,
      "acc_stderr,none": 0.04726835553719099,
      "alias": "ogx_mmlux_da-machine_learning"
    },
    "ogx_mmlux_da-logical_fallacies": {
      "acc,none": 0.7484662576687117,
      "acc_stderr,none": 0.034089978868575295,
      "alias": "ogx_mmlux_da-logical_fallacies"
    },
    "ogx_mmlux_da-jurisprudence": {
      "acc,none": 0.8148148148148148,
      "acc_stderr,none": 0.03755265865037181,
      "alias": "ogx_mmlux_da-jurisprudence"
    },
    "ogx_mmlux_da-international_law": {
      "acc,none": 0.768595041322314,
      "acc_stderr,none": 0.03849856098794088,
      "alias": "ogx_mmlux_da-international_law"
    },
    "ogx_mmlux_da-human_sexuality": {
      "acc,none": 0.7786259541984732,
      "acc_stderr,none": 0.03641297081313729,
      "alias": "ogx_mmlux_da-human_sexuality"
    },
    "ogx_mmlux_da-human_aging": {
      "acc,none": 0.7443946188340808,
      "acc_stderr,none": 0.029275891003969923,
      "alias": "ogx_mmlux_da-human_aging"
    },
    "ogx_mmlux_da-high_school_world_history": {
      "acc,none": 0.8312236286919831,
      "acc_stderr,none": 0.02438140683258623,
      "alias": "ogx_mmlux_da-high_school_world_history"
    },
    "ogx_mmlux_da-high_school_us_history": {
      "acc,none": 0.8382352941176471,
      "acc_stderr,none": 0.025845017986926913,
      "alias": "ogx_mmlux_da-high_school_us_history"
    },
    "ogx_mmlux_da-high_school_statistics": {
      "acc,none": 0.6064814814814815,
      "acc_stderr,none": 0.03331747876370312,
      "alias": "ogx_mmlux_da-high_school_statistics"
    },
    "ogx_mmlux_da-high_school_psychology": {
      "acc,none": 0.8550458715596331,
      "acc_stderr,none": 0.015094215699700457,
      "alias": "ogx_mmlux_da-high_school_psychology"
    },
    "ogx_mmlux_da-high_school_physics": {
      "acc,none": 0.5629139072847682,
      "acc_stderr,none": 0.04050035722230636,
      "alias": "ogx_mmlux_da-high_school_physics"
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "acc,none": 0.7563025210084033,
      "acc_stderr,none": 0.027886828078380565,
      "alias": "ogx_mmlux_da-high_school_microeconomics"
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "acc,none": 0.4185185185185185,
      "acc_stderr,none": 0.030078013075022066,
      "alias": "ogx_mmlux_da-high_school_mathematics"
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "acc,none": 0.7205128205128205,
      "acc_stderr,none": 0.02275238883977683,
      "alias": "ogx_mmlux_da-high_school_macroeconomics"
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "acc,none": 0.8549222797927462,
      "acc_stderr,none": 0.025416343096306422,
      "alias": "ogx_mmlux_da-high_school_government_and_politics"
    },
    "ogx_mmlux_da-high_school_geography": {
      "acc,none": 0.8383838383838383,
      "acc_stderr,none": 0.026225919863629293,
      "alias": "ogx_mmlux_da-high_school_geography"
    },
    "ogx_mmlux_da-high_school_european_history": {
      "acc,none": 0.7818181818181819,
      "acc_stderr,none": 0.03225078108306289,
      "alias": "ogx_mmlux_da-high_school_european_history"
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_da-high_school_computer_science"
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "acc,none": 0.645320197044335,
      "acc_stderr,none": 0.033661244890514495,
      "alias": "ogx_mmlux_da-high_school_chemistry"
    },
    "ogx_mmlux_da-high_school_biology": {
      "acc,none": 0.8548387096774194,
      "acc_stderr,none": 0.020039563628053314,
      "alias": "ogx_mmlux_da-high_school_biology"
    },
    "ogx_mmlux_da-global_facts": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_da-global_facts"
    },
    "ogx_mmlux_da-formal_logic": {
      "acc,none": 0.5079365079365079,
      "acc_stderr,none": 0.044715725362943486,
      "alias": "ogx_mmlux_da-formal_logic"
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "acc,none": 0.5396825396825397,
      "acc_stderr,none": 0.025670080636909322,
      "alias": "ogx_mmlux_da-elementary_mathematics"
    },
    "ogx_mmlux_da-electrical_engineering": {
      "acc,none": 0.6344827586206897,
      "acc_stderr,none": 0.04013124195424385,
      "alias": "ogx_mmlux_da-electrical_engineering"
    },
    "ogx_mmlux_da-econometrics": {
      "acc,none": 0.5789473684210527,
      "acc_stderr,none": 0.046446020912223177,
      "alias": "ogx_mmlux_da-econometrics"
    },
    "ogx_mmlux_da-conceptual_physics": {
      "acc,none": 0.6851063829787234,
      "acc_stderr,none": 0.030363582197238156,
      "alias": "ogx_mmlux_da-conceptual_physics"
    },
    "ogx_mmlux_da-computer_security": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.04461960433384739,
      "alias": "ogx_mmlux_da-computer_security"
    },
    "ogx_mmlux_da-college_physics": {
      "acc,none": 0.45098039215686275,
      "acc_stderr,none": 0.049512182523962625,
      "alias": "ogx_mmlux_da-college_physics"
    },
    "ogx_mmlux_da-college_medicine": {
      "acc,none": 0.6647398843930635,
      "acc_stderr,none": 0.03599586301247077,
      "alias": "ogx_mmlux_da-college_medicine"
    },
    "ogx_mmlux_da-college_mathematics": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.046882617226215034,
      "alias": "ogx_mmlux_da-college_mathematics"
    },
    "ogx_mmlux_da-college_computer_science": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_da-college_computer_science"
    },
    "ogx_mmlux_da-college_chemistry": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_da-college_chemistry"
    },
    "ogx_mmlux_da-college_biology": {
      "acc,none": 0.7638888888888888,
      "acc_stderr,none": 0.03551446610810826,
      "alias": "ogx_mmlux_da-college_biology"
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "acc,none": 0.720754716981132,
      "acc_stderr,none": 0.027611163402399715,
      "alias": "ogx_mmlux_da-clinical_knowledge"
    },
    "ogx_mmlux_da-business_ethics": {
      "acc,none": 0.68,
      "acc_stderr,none": 0.04688261722621505,
      "alias": "ogx_mmlux_da-business_ethics"
    },
    "ogx_mmlux_da-astronomy": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.03523807393012047,
      "alias": "ogx_mmlux_da-astronomy"
    },
    "ogx_mmlux_da-anatomy": {
      "acc,none": 0.6444444444444445,
      "acc_stderr,none": 0.04135176749720386,
      "alias": "ogx_mmlux_da-anatomy"
    },
    "ogx_mmlux_da-abstract_algebra": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_da-abstract_algebra"
    },
    "ogx_mmlux_cs-world_religions": {
      "acc,none": 0.7953216374269005,
      "acc_stderr,none": 0.030944459778533197,
      "alias": "ogx_mmlux_cs-world_religions"
    },
    "ogx_mmlux_cs-virology": {
      "acc,none": 0.4819277108433735,
      "acc_stderr,none": 0.03889951252827216,
      "alias": "ogx_mmlux_cs-virology"
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "acc,none": 0.83,
      "acc_stderr,none": 0.0377525168068637,
      "alias": "ogx_mmlux_cs-us_foreign_policy"
    },
    "ogx_mmlux_cs-sociology": {
      "acc,none": 0.7960199004975125,
      "acc_stderr,none": 0.028493176245326088,
      "alias": "ogx_mmlux_cs-sociology"
    },
    "ogx_mmlux_cs-security_studies": {
      "acc,none": 0.746938775510204,
      "acc_stderr,none": 0.027833023871399704,
      "alias": "ogx_mmlux_cs-security_studies"
    },
    "ogx_mmlux_cs-public_relations": {
      "acc,none": 0.6818181818181818,
      "acc_stderr,none": 0.044612721759105085,
      "alias": "ogx_mmlux_cs-public_relations"
    },
    "ogx_mmlux_cs-professional_psychology": {
      "acc,none": 0.6535947712418301,
      "acc_stderr,none": 0.019249785691717217,
      "alias": "ogx_mmlux_cs-professional_psychology"
    },
    "ogx_mmlux_cs-professional_medicine": {
      "acc,none": 0.6323529411764706,
      "acc_stderr,none": 0.029289413409403196,
      "alias": "ogx_mmlux_cs-professional_medicine"
    },
    "ogx_mmlux_cs-professional_law": {
      "acc,none": 0.4654498044328553,
      "acc_stderr,none": 0.012739711554045708,
      "alias": "ogx_mmlux_cs-professional_law"
    },
    "ogx_mmlux_cs-professional_accounting": {
      "acc,none": 0.4326241134751773,
      "acc_stderr,none": 0.029555454236778845,
      "alias": "ogx_mmlux_cs-professional_accounting"
    },
    "ogx_mmlux_cs-prehistory": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.02409347123262133,
      "alias": "ogx_mmlux_cs-prehistory"
    },
    "ogx_mmlux_cs-philosophy": {
      "acc,none": 0.662379421221865,
      "acc_stderr,none": 0.026858825879488554,
      "alias": "ogx_mmlux_cs-philosophy"
    },
    "ogx_mmlux_cs-nutrition": {
      "acc,none": 0.6862745098039216,
      "acc_stderr,none": 0.026568921015457162,
      "alias": "ogx_mmlux_cs-nutrition"
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "acc,none": 0.38100558659217876,
      "acc_stderr,none": 0.01624202883405361,
      "alias": "ogx_mmlux_cs-moral_scenarios"
    },
    "ogx_mmlux_cs-moral_disputes": {
      "acc,none": 0.6994219653179191,
      "acc_stderr,none": 0.0246853168672578,
      "alias": "ogx_mmlux_cs-moral_disputes"
    },
    "ogx_mmlux_cs-miscellaneous": {
      "acc,none": 0.7803320561941252,
      "acc_stderr,none": 0.014805384478371169,
      "alias": "ogx_mmlux_cs-miscellaneous"
    },
    "ogx_mmlux_cs-medical_genetics": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_cs-medical_genetics"
    },
    "ogx_mmlux_cs-marketing": {
      "acc,none": 0.8376068376068376,
      "acc_stderr,none": 0.02416161812798774,
      "alias": "ogx_mmlux_cs-marketing"
    },
    "ogx_mmlux_cs-management": {
      "acc,none": 0.7961165048543689,
      "acc_stderr,none": 0.0398913985953177,
      "alias": "ogx_mmlux_cs-management"
    },
    "ogx_mmlux_cs-machine_learning": {
      "acc,none": 0.4642857142857143,
      "acc_stderr,none": 0.04733667890053756,
      "alias": "ogx_mmlux_cs-machine_learning"
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "acc,none": 0.7177914110429447,
      "acc_stderr,none": 0.03536117886664743,
      "alias": "ogx_mmlux_cs-logical_fallacies"
    },
    "ogx_mmlux_cs-jurisprudence": {
      "acc,none": 0.7592592592592593,
      "acc_stderr,none": 0.04133119440243839,
      "alias": "ogx_mmlux_cs-jurisprudence"
    },
    "ogx_mmlux_cs-international_law": {
      "acc,none": 0.7851239669421488,
      "acc_stderr,none": 0.03749492448709695,
      "alias": "ogx_mmlux_cs-international_law"
    },
    "ogx_mmlux_cs-human_sexuality": {
      "acc,none": 0.7709923664122137,
      "acc_stderr,none": 0.036853466317118506,
      "alias": "ogx_mmlux_cs-human_sexuality"
    },
    "ogx_mmlux_cs-human_aging": {
      "acc,none": 0.7130044843049327,
      "acc_stderr,none": 0.030360379710291964,
      "alias": "ogx_mmlux_cs-human_aging"
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "acc,none": 0.8270042194092827,
      "acc_stderr,none": 0.024621562866768445,
      "alias": "ogx_mmlux_cs-high_school_world_history"
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "acc,none": 0.7598039215686274,
      "acc_stderr,none": 0.02998373305591361,
      "alias": "ogx_mmlux_cs-high_school_us_history"
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "acc,none": 0.5648148148148148,
      "acc_stderr,none": 0.033812000056435254,
      "alias": "ogx_mmlux_cs-high_school_statistics"
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "acc,none": 0.8238532110091743,
      "acc_stderr,none": 0.016332882393431395,
      "alias": "ogx_mmlux_cs-high_school_psychology"
    },
    "ogx_mmlux_cs-high_school_physics": {
      "acc,none": 0.543046357615894,
      "acc_stderr,none": 0.04067325174247442,
      "alias": "ogx_mmlux_cs-high_school_physics"
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "acc,none": 0.7142857142857143,
      "acc_stderr,none": 0.02934457250063436,
      "alias": "ogx_mmlux_cs-high_school_microeconomics"
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.029723278961476664,
      "alias": "ogx_mmlux_cs-high_school_mathematics"
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "acc,none": 0.7153846153846154,
      "acc_stderr,none": 0.022878322799706294,
      "alias": "ogx_mmlux_cs-high_school_macroeconomics"
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "acc,none": 0.844559585492228,
      "acc_stderr,none": 0.02614848346915331,
      "alias": "ogx_mmlux_cs-high_school_government_and_politics"
    },
    "ogx_mmlux_cs-high_school_geography": {
      "acc,none": 0.8232323232323232,
      "acc_stderr,none": 0.027178752639044915,
      "alias": "ogx_mmlux_cs-high_school_geography"
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "acc,none": 0.8121212121212121,
      "acc_stderr,none": 0.03050193405942914,
      "alias": "ogx_mmlux_cs-high_school_european_history"
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_cs-high_school_computer_science"
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "acc,none": 0.645320197044335,
      "acc_stderr,none": 0.03366124489051449,
      "alias": "ogx_mmlux_cs-high_school_chemistry"
    },
    "ogx_mmlux_cs-high_school_biology": {
      "acc,none": 0.8451612903225807,
      "acc_stderr,none": 0.020579287326583227,
      "alias": "ogx_mmlux_cs-high_school_biology"
    },
    "ogx_mmlux_cs-global_facts": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.04923659639173309,
      "alias": "ogx_mmlux_cs-global_facts"
    },
    "ogx_mmlux_cs-formal_logic": {
      "acc,none": 0.3968253968253968,
      "acc_stderr,none": 0.0437588849272706,
      "alias": "ogx_mmlux_cs-formal_logic"
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "acc,none": 0.5211640211640212,
      "acc_stderr,none": 0.025728230952130733,
      "alias": "ogx_mmlux_cs-elementary_mathematics"
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "acc,none": 0.593103448275862,
      "acc_stderr,none": 0.04093793981266236,
      "alias": "ogx_mmlux_cs-electrical_engineering"
    },
    "ogx_mmlux_cs-econometrics": {
      "acc,none": 0.5263157894736842,
      "acc_stderr,none": 0.046970851366478626,
      "alias": "ogx_mmlux_cs-econometrics"
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "acc,none": 0.6553191489361702,
      "acc_stderr,none": 0.03106898596312214,
      "alias": "ogx_mmlux_cs-conceptual_physics"
    },
    "ogx_mmlux_cs-computer_security": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_cs-computer_security"
    },
    "ogx_mmlux_cs-college_physics": {
      "acc,none": 0.4803921568627451,
      "acc_stderr,none": 0.04971358884367405,
      "alias": "ogx_mmlux_cs-college_physics"
    },
    "ogx_mmlux_cs-college_medicine": {
      "acc,none": 0.6878612716763006,
      "acc_stderr,none": 0.035331333893236574,
      "alias": "ogx_mmlux_cs-college_medicine"
    },
    "ogx_mmlux_cs-college_mathematics": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_cs-college_mathematics"
    },
    "ogx_mmlux_cs-college_computer_science": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956911,
      "alias": "ogx_mmlux_cs-college_computer_science"
    },
    "ogx_mmlux_cs-college_chemistry": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956911,
      "alias": "ogx_mmlux_cs-college_chemistry"
    },
    "ogx_mmlux_cs-college_biology": {
      "acc,none": 0.7708333333333334,
      "acc_stderr,none": 0.035146974678623884,
      "alias": "ogx_mmlux_cs-college_biology"
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "acc,none": 0.7056603773584905,
      "acc_stderr,none": 0.028049186315695245,
      "alias": "ogx_mmlux_cs-clinical_knowledge"
    },
    "ogx_mmlux_cs-business_ethics": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.04461960433384739,
      "alias": "ogx_mmlux_cs-business_ethics"
    },
    "ogx_mmlux_cs-astronomy": {
      "acc,none": 0.756578947368421,
      "acc_stderr,none": 0.034923496688842384,
      "alias": "ogx_mmlux_cs-astronomy"
    },
    "ogx_mmlux_cs-anatomy": {
      "acc,none": 0.6592592592592592,
      "acc_stderr,none": 0.04094376269996794,
      "alias": "ogx_mmlux_cs-anatomy"
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_cs-abstract_algebra"
    },
    "ogx_mmlux_bg-world_religions": {
      "acc,none": 0.8128654970760234,
      "acc_stderr,none": 0.029913127232368032,
      "alias": "ogx_mmlux_bg-world_religions"
    },
    "ogx_mmlux_bg-virology": {
      "acc,none": 0.4939759036144578,
      "acc_stderr,none": 0.03892212195333045,
      "alias": "ogx_mmlux_bg-virology"
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "acc,none": 0.83,
      "acc_stderr,none": 0.0377525168068637,
      "alias": "ogx_mmlux_bg-us_foreign_policy"
    },
    "ogx_mmlux_bg-sociology": {
      "acc,none": 0.7761194029850746,
      "acc_stderr,none": 0.029475250236017197,
      "alias": "ogx_mmlux_bg-sociology"
    },
    "ogx_mmlux_bg-security_studies": {
      "acc,none": 0.7673469387755102,
      "acc_stderr,none": 0.02704925791589618,
      "alias": "ogx_mmlux_bg-security_studies"
    },
    "ogx_mmlux_bg-public_relations": {
      "acc,none": 0.6545454545454545,
      "acc_stderr,none": 0.04554619617541054,
      "alias": "ogx_mmlux_bg-public_relations"
    },
    "ogx_mmlux_bg-professional_psychology": {
      "acc,none": 0.6356209150326797,
      "acc_stderr,none": 0.01946951822157369,
      "alias": "ogx_mmlux_bg-professional_psychology"
    },
    "ogx_mmlux_bg-professional_medicine": {
      "acc,none": 0.5992647058823529,
      "acc_stderr,none": 0.029768263528933112,
      "alias": "ogx_mmlux_bg-professional_medicine"
    },
    "ogx_mmlux_bg-professional_law": {
      "acc,none": 0.4667535853976532,
      "acc_stderr,none": 0.012741974333897226,
      "alias": "ogx_mmlux_bg-professional_law"
    },
    "ogx_mmlux_bg-professional_accounting": {
      "acc,none": 0.46099290780141844,
      "acc_stderr,none": 0.029736592526424438,
      "alias": "ogx_mmlux_bg-professional_accounting"
    },
    "ogx_mmlux_bg-prehistory": {
      "acc,none": 0.7067901234567902,
      "acc_stderr,none": 0.025329888171900922,
      "alias": "ogx_mmlux_bg-prehistory"
    },
    "ogx_mmlux_bg-philosophy": {
      "acc,none": 0.6913183279742765,
      "acc_stderr,none": 0.02623696588115326,
      "alias": "ogx_mmlux_bg-philosophy"
    },
    "ogx_mmlux_bg-nutrition": {
      "acc,none": 0.6601307189542484,
      "acc_stderr,none": 0.027121956071388866,
      "alias": "ogx_mmlux_bg-nutrition"
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "acc,none": 0.3541899441340782,
      "acc_stderr,none": 0.015995644947299232,
      "alias": "ogx_mmlux_bg-moral_scenarios"
    },
    "ogx_mmlux_bg-moral_disputes": {
      "acc,none": 0.6445086705202312,
      "acc_stderr,none": 0.025770292082977247,
      "alias": "ogx_mmlux_bg-moral_disputes"
    },
    "ogx_mmlux_bg-miscellaneous": {
      "acc,none": 0.7471264367816092,
      "acc_stderr,none": 0.01554337731371968,
      "alias": "ogx_mmlux_bg-miscellaneous"
    },
    "ogx_mmlux_bg-medical_genetics": {
      "acc,none": 0.66,
      "acc_stderr,none": 0.04760952285695237,
      "alias": "ogx_mmlux_bg-medical_genetics"
    },
    "ogx_mmlux_bg-marketing": {
      "acc,none": 0.8333333333333334,
      "acc_stderr,none": 0.024414947304543674,
      "alias": "ogx_mmlux_bg-marketing"
    },
    "ogx_mmlux_bg-management": {
      "acc,none": 0.7378640776699029,
      "acc_stderr,none": 0.04354631077260595,
      "alias": "ogx_mmlux_bg-management"
    },
    "ogx_mmlux_bg-machine_learning": {
      "acc,none": 0.4375,
      "acc_stderr,none": 0.04708567521880525,
      "alias": "ogx_mmlux_bg-machine_learning"
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "acc,none": 0.7484662576687117,
      "acc_stderr,none": 0.03408997886857529,
      "alias": "ogx_mmlux_bg-logical_fallacies"
    },
    "ogx_mmlux_bg-jurisprudence": {
      "acc,none": 0.7777777777777778,
      "acc_stderr,none": 0.040191074725573483,
      "alias": "ogx_mmlux_bg-jurisprudence"
    },
    "ogx_mmlux_bg-international_law": {
      "acc,none": 0.7933884297520661,
      "acc_stderr,none": 0.03695980128098823,
      "alias": "ogx_mmlux_bg-international_law"
    },
    "ogx_mmlux_bg-human_sexuality": {
      "acc,none": 0.7099236641221374,
      "acc_stderr,none": 0.03980066246467765,
      "alias": "ogx_mmlux_bg-human_sexuality"
    },
    "ogx_mmlux_bg-human_aging": {
      "acc,none": 0.672645739910314,
      "acc_stderr,none": 0.03149384670994131,
      "alias": "ogx_mmlux_bg-human_aging"
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "acc,none": 0.7932489451476793,
      "acc_stderr,none": 0.0263616516683891,
      "alias": "ogx_mmlux_bg-high_school_world_history"
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "acc,none": 0.7598039215686274,
      "acc_stderr,none": 0.02998373305591361,
      "alias": "ogx_mmlux_bg-high_school_us_history"
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "acc,none": 0.6111111111111112,
      "acc_stderr,none": 0.03324708911809117,
      "alias": "ogx_mmlux_bg-high_school_statistics"
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "acc,none": 0.8348623853211009,
      "acc_stderr,none": 0.015919557829976068,
      "alias": "ogx_mmlux_bg-high_school_psychology"
    },
    "ogx_mmlux_bg-high_school_physics": {
      "acc,none": 0.5364238410596026,
      "acc_stderr,none": 0.04071636065944216,
      "alias": "ogx_mmlux_bg-high_school_physics"
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "acc,none": 0.7058823529411765,
      "acc_stderr,none": 0.0295973297309781,
      "alias": "ogx_mmlux_bg-high_school_microeconomics"
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "acc,none": 0.4074074074074074,
      "acc_stderr,none": 0.02995824925008212,
      "alias": "ogx_mmlux_bg-high_school_mathematics"
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "acc,none": 0.7102564102564103,
      "acc_stderr,none": 0.02300062824368797,
      "alias": "ogx_mmlux_bg-high_school_macroeconomics"
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "acc,none": 0.7979274611398963,
      "acc_stderr,none": 0.02897908979429673,
      "alias": "ogx_mmlux_bg-high_school_government_and_politics"
    },
    "ogx_mmlux_bg-high_school_geography": {
      "acc,none": 0.797979797979798,
      "acc_stderr,none": 0.028606204289229893,
      "alias": "ogx_mmlux_bg-high_school_geography"
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "acc,none": 0.8,
      "acc_stderr,none": 0.031234752377721175,
      "alias": "ogx_mmlux_bg-high_school_european_history"
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.0446196043338474,
      "alias": "ogx_mmlux_bg-high_school_computer_science"
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "acc,none": 0.6650246305418719,
      "acc_stderr,none": 0.033208527423483104,
      "alias": "ogx_mmlux_bg-high_school_chemistry"
    },
    "ogx_mmlux_bg-high_school_biology": {
      "acc,none": 0.8419354838709677,
      "acc_stderr,none": 0.02075283151187526,
      "alias": "ogx_mmlux_bg-high_school_biology"
    },
    "ogx_mmlux_bg-global_facts": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.04999999999999999,
      "alias": "ogx_mmlux_bg-global_facts"
    },
    "ogx_mmlux_bg-formal_logic": {
      "acc,none": 0.46825396825396826,
      "acc_stderr,none": 0.04463112720677172,
      "alias": "ogx_mmlux_bg-formal_logic"
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "acc,none": 0.5317460317460317,
      "acc_stderr,none": 0.0256993528321318,
      "alias": "ogx_mmlux_bg-elementary_mathematics"
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "acc,none": 0.5793103448275863,
      "acc_stderr,none": 0.0411391498118926,
      "alias": "ogx_mmlux_bg-electrical_engineering"
    },
    "ogx_mmlux_bg-econometrics": {
      "acc,none": 0.5701754385964912,
      "acc_stderr,none": 0.04657047260594964,
      "alias": "ogx_mmlux_bg-econometrics"
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "acc,none": 0.6553191489361702,
      "acc_stderr,none": 0.031068985963122145,
      "alias": "ogx_mmlux_bg-conceptual_physics"
    },
    "ogx_mmlux_bg-computer_security": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.044084400227680794,
      "alias": "ogx_mmlux_bg-computer_security"
    },
    "ogx_mmlux_bg-college_physics": {
      "acc,none": 0.4411764705882353,
      "acc_stderr,none": 0.04940635630605659,
      "alias": "ogx_mmlux_bg-college_physics"
    },
    "ogx_mmlux_bg-college_medicine": {
      "acc,none": 0.6647398843930635,
      "acc_stderr,none": 0.03599586301247077,
      "alias": "ogx_mmlux_bg-college_medicine"
    },
    "ogx_mmlux_bg-college_mathematics": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_bg-college_mathematics"
    },
    "ogx_mmlux_bg-college_computer_science": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956911,
      "alias": "ogx_mmlux_bg-college_computer_science"
    },
    "ogx_mmlux_bg-college_chemistry": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956913,
      "alias": "ogx_mmlux_bg-college_chemistry"
    },
    "ogx_mmlux_bg-college_biology": {
      "acc,none": 0.7291666666666666,
      "acc_stderr,none": 0.03716177437566016,
      "alias": "ogx_mmlux_bg-college_biology"
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "acc,none": 0.6490566037735849,
      "acc_stderr,none": 0.02937364625323469,
      "alias": "ogx_mmlux_bg-clinical_knowledge"
    },
    "ogx_mmlux_bg-business_ethics": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.04605661864718381,
      "alias": "ogx_mmlux_bg-business_ethics"
    },
    "ogx_mmlux_bg-astronomy": {
      "acc,none": 0.7763157894736842,
      "acc_stderr,none": 0.033911609343436025,
      "alias": "ogx_mmlux_bg-astronomy"
    },
    "ogx_mmlux_bg-anatomy": {
      "acc,none": 0.5777777777777777,
      "acc_stderr,none": 0.04266763404099582,
      "alias": "ogx_mmlux_bg-anatomy"
    },
    "ogx_mmlux_bg-abstract_algebra": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_bg-abstract_algebra"
    }
  },
  "group_subtasks": {
    "ogx_mmlux_bg-abstract_algebra": [],
    "ogx_mmlux_bg-anatomy": [],
    "ogx_mmlux_bg-astronomy": [],
    "ogx_mmlux_bg-business_ethics": [],
    "ogx_mmlux_bg-clinical_knowledge": [],
    "ogx_mmlux_bg-college_biology": [],
    "ogx_mmlux_bg-college_chemistry": [],
    "ogx_mmlux_bg-college_computer_science": [],
    "ogx_mmlux_bg-college_mathematics": [],
    "ogx_mmlux_bg-college_medicine": [],
    "ogx_mmlux_bg-college_physics": [],
    "ogx_mmlux_bg-computer_security": [],
    "ogx_mmlux_bg-conceptual_physics": [],
    "ogx_mmlux_bg-econometrics": [],
    "ogx_mmlux_bg-electrical_engineering": [],
    "ogx_mmlux_bg-elementary_mathematics": [],
    "ogx_mmlux_bg-formal_logic": [],
    "ogx_mmlux_bg-global_facts": [],
    "ogx_mmlux_bg-high_school_biology": [],
    "ogx_mmlux_bg-high_school_chemistry": [],
    "ogx_mmlux_bg-high_school_computer_science": [],
    "ogx_mmlux_bg-high_school_european_history": [],
    "ogx_mmlux_bg-high_school_geography": [],
    "ogx_mmlux_bg-high_school_government_and_politics": [],
    "ogx_mmlux_bg-high_school_macroeconomics": [],
    "ogx_mmlux_bg-high_school_mathematics": [],
    "ogx_mmlux_bg-high_school_microeconomics": [],
    "ogx_mmlux_bg-high_school_physics": [],
    "ogx_mmlux_bg-high_school_psychology": [],
    "ogx_mmlux_bg-high_school_statistics": [],
    "ogx_mmlux_bg-high_school_us_history": [],
    "ogx_mmlux_bg-high_school_world_history": [],
    "ogx_mmlux_bg-human_aging": [],
    "ogx_mmlux_bg-human_sexuality": [],
    "ogx_mmlux_bg-international_law": [],
    "ogx_mmlux_bg-jurisprudence": [],
    "ogx_mmlux_bg-logical_fallacies": [],
    "ogx_mmlux_bg-machine_learning": [],
    "ogx_mmlux_bg-management": [],
    "ogx_mmlux_bg-marketing": [],
    "ogx_mmlux_bg-medical_genetics": [],
    "ogx_mmlux_bg-miscellaneous": [],
    "ogx_mmlux_bg-moral_disputes": [],
    "ogx_mmlux_bg-moral_scenarios": [],
    "ogx_mmlux_bg-nutrition": [],
    "ogx_mmlux_bg-philosophy": [],
    "ogx_mmlux_bg-prehistory": [],
    "ogx_mmlux_bg-professional_accounting": [],
    "ogx_mmlux_bg-professional_law": [],
    "ogx_mmlux_bg-professional_medicine": [],
    "ogx_mmlux_bg-professional_psychology": [],
    "ogx_mmlux_bg-public_relations": [],
    "ogx_mmlux_bg-security_studies": [],
    "ogx_mmlux_bg-sociology": [],
    "ogx_mmlux_bg-us_foreign_policy": [],
    "ogx_mmlux_bg-virology": [],
    "ogx_mmlux_bg-world_religions": [],
    "ogx_mmlux_cs-abstract_algebra": [],
    "ogx_mmlux_cs-anatomy": [],
    "ogx_mmlux_cs-astronomy": [],
    "ogx_mmlux_cs-business_ethics": [],
    "ogx_mmlux_cs-clinical_knowledge": [],
    "ogx_mmlux_cs-college_biology": [],
    "ogx_mmlux_cs-college_chemistry": [],
    "ogx_mmlux_cs-college_computer_science": [],
    "ogx_mmlux_cs-college_mathematics": [],
    "ogx_mmlux_cs-college_medicine": [],
    "ogx_mmlux_cs-college_physics": [],
    "ogx_mmlux_cs-computer_security": [],
    "ogx_mmlux_cs-conceptual_physics": [],
    "ogx_mmlux_cs-econometrics": [],
    "ogx_mmlux_cs-electrical_engineering": [],
    "ogx_mmlux_cs-elementary_mathematics": [],
    "ogx_mmlux_cs-formal_logic": [],
    "ogx_mmlux_cs-global_facts": [],
    "ogx_mmlux_cs-high_school_biology": [],
    "ogx_mmlux_cs-high_school_chemistry": [],
    "ogx_mmlux_cs-high_school_computer_science": [],
    "ogx_mmlux_cs-high_school_european_history": [],
    "ogx_mmlux_cs-high_school_geography": [],
    "ogx_mmlux_cs-high_school_government_and_politics": [],
    "ogx_mmlux_cs-high_school_macroeconomics": [],
    "ogx_mmlux_cs-high_school_mathematics": [],
    "ogx_mmlux_cs-high_school_microeconomics": [],
    "ogx_mmlux_cs-high_school_physics": [],
    "ogx_mmlux_cs-high_school_psychology": [],
    "ogx_mmlux_cs-high_school_statistics": [],
    "ogx_mmlux_cs-high_school_us_history": [],
    "ogx_mmlux_cs-high_school_world_history": [],
    "ogx_mmlux_cs-human_aging": [],
    "ogx_mmlux_cs-human_sexuality": [],
    "ogx_mmlux_cs-international_law": [],
    "ogx_mmlux_cs-jurisprudence": [],
    "ogx_mmlux_cs-logical_fallacies": [],
    "ogx_mmlux_cs-machine_learning": [],
    "ogx_mmlux_cs-management": [],
    "ogx_mmlux_cs-marketing": [],
    "ogx_mmlux_cs-medical_genetics": [],
    "ogx_mmlux_cs-miscellaneous": [],
    "ogx_mmlux_cs-moral_disputes": [],
    "ogx_mmlux_cs-moral_scenarios": [],
    "ogx_mmlux_cs-nutrition": [],
    "ogx_mmlux_cs-philosophy": [],
    "ogx_mmlux_cs-prehistory": [],
    "ogx_mmlux_cs-professional_accounting": [],
    "ogx_mmlux_cs-professional_law": [],
    "ogx_mmlux_cs-professional_medicine": [],
    "ogx_mmlux_cs-professional_psychology": [],
    "ogx_mmlux_cs-public_relations": [],
    "ogx_mmlux_cs-security_studies": [],
    "ogx_mmlux_cs-sociology": [],
    "ogx_mmlux_cs-us_foreign_policy": [],
    "ogx_mmlux_cs-virology": [],
    "ogx_mmlux_cs-world_religions": [],
    "ogx_mmlux_da-abstract_algebra": [],
    "ogx_mmlux_da-anatomy": [],
    "ogx_mmlux_da-astronomy": [],
    "ogx_mmlux_da-business_ethics": [],
    "ogx_mmlux_da-clinical_knowledge": [],
    "ogx_mmlux_da-college_biology": [],
    "ogx_mmlux_da-college_chemistry": [],
    "ogx_mmlux_da-college_computer_science": [],
    "ogx_mmlux_da-college_mathematics": [],
    "ogx_mmlux_da-college_medicine": [],
    "ogx_mmlux_da-college_physics": [],
    "ogx_mmlux_da-computer_security": [],
    "ogx_mmlux_da-conceptual_physics": [],
    "ogx_mmlux_da-econometrics": [],
    "ogx_mmlux_da-electrical_engineering": [],
    "ogx_mmlux_da-elementary_mathematics": [],
    "ogx_mmlux_da-formal_logic": [],
    "ogx_mmlux_da-global_facts": [],
    "ogx_mmlux_da-high_school_biology": [],
    "ogx_mmlux_da-high_school_chemistry": [],
    "ogx_mmlux_da-high_school_computer_science": [],
    "ogx_mmlux_da-high_school_european_history": [],
    "ogx_mmlux_da-high_school_geography": [],
    "ogx_mmlux_da-high_school_government_and_politics": [],
    "ogx_mmlux_da-high_school_macroeconomics": [],
    "ogx_mmlux_da-high_school_mathematics": [],
    "ogx_mmlux_da-high_school_microeconomics": [],
    "ogx_mmlux_da-high_school_physics": [],
    "ogx_mmlux_da-high_school_psychology": [],
    "ogx_mmlux_da-high_school_statistics": [],
    "ogx_mmlux_da-high_school_us_history": [],
    "ogx_mmlux_da-high_school_world_history": [],
    "ogx_mmlux_da-human_aging": [],
    "ogx_mmlux_da-human_sexuality": [],
    "ogx_mmlux_da-international_law": [],
    "ogx_mmlux_da-jurisprudence": [],
    "ogx_mmlux_da-logical_fallacies": [],
    "ogx_mmlux_da-machine_learning": [],
    "ogx_mmlux_da-management": [],
    "ogx_mmlux_da-marketing": [],
    "ogx_mmlux_da-medical_genetics": [],
    "ogx_mmlux_da-miscellaneous": [],
    "ogx_mmlux_da-moral_disputes": [],
    "ogx_mmlux_da-moral_scenarios": [],
    "ogx_mmlux_da-nutrition": [],
    "ogx_mmlux_da-philosophy": [],
    "ogx_mmlux_da-prehistory": [],
    "ogx_mmlux_da-professional_accounting": [],
    "ogx_mmlux_da-professional_law": [],
    "ogx_mmlux_da-professional_medicine": [],
    "ogx_mmlux_da-professional_psychology": [],
    "ogx_mmlux_da-public_relations": [],
    "ogx_mmlux_da-security_studies": [],
    "ogx_mmlux_da-sociology": [],
    "ogx_mmlux_da-us_foreign_policy": [],
    "ogx_mmlux_da-virology": [],
    "ogx_mmlux_da-world_religions": [],
    "ogx_mmlux_de-abstract_algebra": [],
    "ogx_mmlux_de-anatomy": [],
    "ogx_mmlux_de-astronomy": [],
    "ogx_mmlux_de-business_ethics": [],
    "ogx_mmlux_de-clinical_knowledge": [],
    "ogx_mmlux_de-college_biology": [],
    "ogx_mmlux_de-college_chemistry": [],
    "ogx_mmlux_de-college_computer_science": [],
    "ogx_mmlux_de-college_mathematics": [],
    "ogx_mmlux_de-college_medicine": [],
    "ogx_mmlux_de-college_physics": [],
    "ogx_mmlux_de-computer_security": [],
    "ogx_mmlux_de-conceptual_physics": [],
    "ogx_mmlux_de-econometrics": [],
    "ogx_mmlux_de-electrical_engineering": [],
    "ogx_mmlux_de-elementary_mathematics": [],
    "ogx_mmlux_de-formal_logic": [],
    "ogx_mmlux_de-global_facts": [],
    "ogx_mmlux_de-high_school_biology": [],
    "ogx_mmlux_de-high_school_chemistry": [],
    "ogx_mmlux_de-high_school_computer_science": [],
    "ogx_mmlux_de-high_school_european_history": [],
    "ogx_mmlux_de-high_school_geography": [],
    "ogx_mmlux_de-high_school_government_and_politics": [],
    "ogx_mmlux_de-high_school_macroeconomics": [],
    "ogx_mmlux_de-high_school_mathematics": [],
    "ogx_mmlux_de-high_school_microeconomics": [],
    "ogx_mmlux_de-high_school_physics": [],
    "ogx_mmlux_de-high_school_psychology": [],
    "ogx_mmlux_de-high_school_statistics": [],
    "ogx_mmlux_de-high_school_us_history": [],
    "ogx_mmlux_de-high_school_world_history": [],
    "ogx_mmlux_de-human_aging": [],
    "ogx_mmlux_de-human_sexuality": [],
    "ogx_mmlux_de-international_law": [],
    "ogx_mmlux_de-jurisprudence": [],
    "ogx_mmlux_de-logical_fallacies": [],
    "ogx_mmlux_de-machine_learning": [],
    "ogx_mmlux_de-management": [],
    "ogx_mmlux_de-marketing": [],
    "ogx_mmlux_de-medical_genetics": [],
    "ogx_mmlux_de-miscellaneous": [],
    "ogx_mmlux_de-moral_disputes": [],
    "ogx_mmlux_de-moral_scenarios": [],
    "ogx_mmlux_de-nutrition": [],
    "ogx_mmlux_de-philosophy": [],
    "ogx_mmlux_de-prehistory": [],
    "ogx_mmlux_de-professional_accounting": [],
    "ogx_mmlux_de-professional_law": [],
    "ogx_mmlux_de-professional_medicine": [],
    "ogx_mmlux_de-professional_psychology": [],
    "ogx_mmlux_de-public_relations": [],
    "ogx_mmlux_de-security_studies": [],
    "ogx_mmlux_de-sociology": [],
    "ogx_mmlux_de-us_foreign_policy": [],
    "ogx_mmlux_de-virology": [],
    "ogx_mmlux_de-world_religions": [],
    "ogx_mmlux_el-abstract_algebra": [],
    "ogx_mmlux_el-anatomy": [],
    "ogx_mmlux_el-astronomy": [],
    "ogx_mmlux_el-business_ethics": [],
    "ogx_mmlux_el-clinical_knowledge": [],
    "ogx_mmlux_el-college_biology": [],
    "ogx_mmlux_el-college_chemistry": [],
    "ogx_mmlux_el-college_computer_science": [],
    "ogx_mmlux_el-college_mathematics": [],
    "ogx_mmlux_el-college_medicine": [],
    "ogx_mmlux_el-college_physics": [],
    "ogx_mmlux_el-computer_security": [],
    "ogx_mmlux_el-conceptual_physics": [],
    "ogx_mmlux_el-econometrics": [],
    "ogx_mmlux_el-electrical_engineering": [],
    "ogx_mmlux_el-elementary_mathematics": [],
    "ogx_mmlux_el-formal_logic": [],
    "ogx_mmlux_el-global_facts": [],
    "ogx_mmlux_el-high_school_biology": [],
    "ogx_mmlux_el-high_school_chemistry": [],
    "ogx_mmlux_el-high_school_computer_science": [],
    "ogx_mmlux_el-high_school_european_history": [],
    "ogx_mmlux_el-high_school_geography": [],
    "ogx_mmlux_el-high_school_government_and_politics": [],
    "ogx_mmlux_el-high_school_macroeconomics": [],
    "ogx_mmlux_el-high_school_mathematics": [],
    "ogx_mmlux_el-high_school_microeconomics": [],
    "ogx_mmlux_el-high_school_physics": [],
    "ogx_mmlux_el-high_school_psychology": [],
    "ogx_mmlux_el-high_school_statistics": [],
    "ogx_mmlux_el-high_school_us_history": [],
    "ogx_mmlux_el-high_school_world_history": [],
    "ogx_mmlux_el-human_aging": [],
    "ogx_mmlux_el-human_sexuality": [],
    "ogx_mmlux_el-international_law": [],
    "ogx_mmlux_el-jurisprudence": [],
    "ogx_mmlux_el-logical_fallacies": [],
    "ogx_mmlux_el-machine_learning": [],
    "ogx_mmlux_el-management": [],
    "ogx_mmlux_el-marketing": [],
    "ogx_mmlux_el-medical_genetics": [],
    "ogx_mmlux_el-miscellaneous": [],
    "ogx_mmlux_el-moral_disputes": [],
    "ogx_mmlux_el-moral_scenarios": [],
    "ogx_mmlux_el-nutrition": [],
    "ogx_mmlux_el-philosophy": [],
    "ogx_mmlux_el-prehistory": [],
    "ogx_mmlux_el-professional_accounting": [],
    "ogx_mmlux_el-professional_law": [],
    "ogx_mmlux_el-professional_medicine": [],
    "ogx_mmlux_el-professional_psychology": [],
    "ogx_mmlux_el-public_relations": [],
    "ogx_mmlux_el-security_studies": [],
    "ogx_mmlux_el-sociology": [],
    "ogx_mmlux_el-us_foreign_policy": [],
    "ogx_mmlux_el-virology": [],
    "ogx_mmlux_el-world_religions": [],
    "ogx_mmlux_es-abstract_algebra": [],
    "ogx_mmlux_es-anatomy": [],
    "ogx_mmlux_es-astronomy": [],
    "ogx_mmlux_es-business_ethics": [],
    "ogx_mmlux_es-clinical_knowledge": [],
    "ogx_mmlux_es-college_biology": [],
    "ogx_mmlux_es-college_chemistry": [],
    "ogx_mmlux_es-college_computer_science": [],
    "ogx_mmlux_es-college_mathematics": [],
    "ogx_mmlux_es-college_medicine": [],
    "ogx_mmlux_es-college_physics": [],
    "ogx_mmlux_es-computer_security": [],
    "ogx_mmlux_es-conceptual_physics": [],
    "ogx_mmlux_es-econometrics": [],
    "ogx_mmlux_es-electrical_engineering": [],
    "ogx_mmlux_es-elementary_mathematics": [],
    "ogx_mmlux_es-formal_logic": [],
    "ogx_mmlux_es-global_facts": [],
    "ogx_mmlux_es-high_school_biology": [],
    "ogx_mmlux_es-high_school_chemistry": [],
    "ogx_mmlux_es-high_school_computer_science": [],
    "ogx_mmlux_es-high_school_european_history": [],
    "ogx_mmlux_es-high_school_geography": [],
    "ogx_mmlux_es-high_school_government_and_politics": [],
    "ogx_mmlux_es-high_school_macroeconomics": [],
    "ogx_mmlux_es-high_school_mathematics": [],
    "ogx_mmlux_es-high_school_microeconomics": [],
    "ogx_mmlux_es-high_school_physics": [],
    "ogx_mmlux_es-high_school_psychology": [],
    "ogx_mmlux_es-high_school_statistics": [],
    "ogx_mmlux_es-high_school_us_history": [],
    "ogx_mmlux_es-high_school_world_history": [],
    "ogx_mmlux_es-human_aging": [],
    "ogx_mmlux_es-human_sexuality": [],
    "ogx_mmlux_es-international_law": [],
    "ogx_mmlux_es-jurisprudence": [],
    "ogx_mmlux_es-logical_fallacies": [],
    "ogx_mmlux_es-machine_learning": [],
    "ogx_mmlux_es-management": [],
    "ogx_mmlux_es-marketing": [],
    "ogx_mmlux_es-medical_genetics": [],
    "ogx_mmlux_es-miscellaneous": [],
    "ogx_mmlux_es-moral_disputes": [],
    "ogx_mmlux_es-moral_scenarios": [],
    "ogx_mmlux_es-nutrition": [],
    "ogx_mmlux_es-philosophy": [],
    "ogx_mmlux_es-prehistory": [],
    "ogx_mmlux_es-professional_accounting": [],
    "ogx_mmlux_es-professional_law": [],
    "ogx_mmlux_es-professional_medicine": [],
    "ogx_mmlux_es-professional_psychology": [],
    "ogx_mmlux_es-public_relations": [],
    "ogx_mmlux_es-security_studies": [],
    "ogx_mmlux_es-sociology": [],
    "ogx_mmlux_es-us_foreign_policy": [],
    "ogx_mmlux_es-virology": [],
    "ogx_mmlux_es-world_religions": [],
    "ogx_mmlux_et-abstract_algebra": [],
    "ogx_mmlux_et-anatomy": [],
    "ogx_mmlux_et-astronomy": [],
    "ogx_mmlux_et-business_ethics": [],
    "ogx_mmlux_et-clinical_knowledge": [],
    "ogx_mmlux_et-college_biology": [],
    "ogx_mmlux_et-college_chemistry": [],
    "ogx_mmlux_et-college_computer_science": [],
    "ogx_mmlux_et-college_mathematics": [],
    "ogx_mmlux_et-college_medicine": [],
    "ogx_mmlux_et-college_physics": [],
    "ogx_mmlux_et-computer_security": [],
    "ogx_mmlux_et-conceptual_physics": [],
    "ogx_mmlux_et-econometrics": [],
    "ogx_mmlux_et-electrical_engineering": [],
    "ogx_mmlux_et-elementary_mathematics": [],
    "ogx_mmlux_et-formal_logic": [],
    "ogx_mmlux_et-global_facts": [],
    "ogx_mmlux_et-high_school_biology": [],
    "ogx_mmlux_et-high_school_chemistry": [],
    "ogx_mmlux_et-high_school_computer_science": [],
    "ogx_mmlux_et-high_school_european_history": [],
    "ogx_mmlux_et-high_school_geography": [],
    "ogx_mmlux_et-high_school_government_and_politics": [],
    "ogx_mmlux_et-high_school_macroeconomics": [],
    "ogx_mmlux_et-high_school_mathematics": [],
    "ogx_mmlux_et-high_school_microeconomics": [],
    "ogx_mmlux_et-high_school_physics": [],
    "ogx_mmlux_et-high_school_psychology": [],
    "ogx_mmlux_et-high_school_statistics": [],
    "ogx_mmlux_et-high_school_us_history": [],
    "ogx_mmlux_et-high_school_world_history": [],
    "ogx_mmlux_et-human_aging": [],
    "ogx_mmlux_et-human_sexuality": [],
    "ogx_mmlux_et-international_law": [],
    "ogx_mmlux_et-jurisprudence": [],
    "ogx_mmlux_et-logical_fallacies": [],
    "ogx_mmlux_et-machine_learning": [],
    "ogx_mmlux_et-management": [],
    "ogx_mmlux_et-marketing": [],
    "ogx_mmlux_et-medical_genetics": [],
    "ogx_mmlux_et-miscellaneous": [],
    "ogx_mmlux_et-moral_disputes": [],
    "ogx_mmlux_et-moral_scenarios": [],
    "ogx_mmlux_et-nutrition": [],
    "ogx_mmlux_et-philosophy": [],
    "ogx_mmlux_et-prehistory": [],
    "ogx_mmlux_et-professional_accounting": [],
    "ogx_mmlux_et-professional_law": [],
    "ogx_mmlux_et-professional_medicine": [],
    "ogx_mmlux_et-professional_psychology": [],
    "ogx_mmlux_et-public_relations": [],
    "ogx_mmlux_et-security_studies": [],
    "ogx_mmlux_et-sociology": [],
    "ogx_mmlux_et-us_foreign_policy": [],
    "ogx_mmlux_et-virology": [],
    "ogx_mmlux_et-world_religions": [],
    "ogx_mmlux_fi-abstract_algebra": [],
    "ogx_mmlux_fi-anatomy": [],
    "ogx_mmlux_fi-astronomy": [],
    "ogx_mmlux_fi-business_ethics": [],
    "ogx_mmlux_fi-clinical_knowledge": [],
    "ogx_mmlux_fi-college_biology": [],
    "ogx_mmlux_fi-college_chemistry": [],
    "ogx_mmlux_fi-college_computer_science": [],
    "ogx_mmlux_fi-college_mathematics": [],
    "ogx_mmlux_fi-college_medicine": [],
    "ogx_mmlux_fi-college_physics": [],
    "ogx_mmlux_fi-computer_security": [],
    "ogx_mmlux_fi-conceptual_physics": [],
    "ogx_mmlux_fi-econometrics": [],
    "ogx_mmlux_fi-electrical_engineering": [],
    "ogx_mmlux_fi-elementary_mathematics": [],
    "ogx_mmlux_fi-formal_logic": [],
    "ogx_mmlux_fi-global_facts": [],
    "ogx_mmlux_fi-high_school_biology": [],
    "ogx_mmlux_fi-high_school_chemistry": [],
    "ogx_mmlux_fi-high_school_computer_science": [],
    "ogx_mmlux_fi-high_school_european_history": [],
    "ogx_mmlux_fi-high_school_geography": [],
    "ogx_mmlux_fi-high_school_government_and_politics": [],
    "ogx_mmlux_fi-high_school_macroeconomics": [],
    "ogx_mmlux_fi-high_school_mathematics": [],
    "ogx_mmlux_fi-high_school_microeconomics": [],
    "ogx_mmlux_fi-high_school_physics": [],
    "ogx_mmlux_fi-high_school_psychology": [],
    "ogx_mmlux_fi-high_school_statistics": [],
    "ogx_mmlux_fi-high_school_us_history": [],
    "ogx_mmlux_fi-high_school_world_history": [],
    "ogx_mmlux_fi-human_aging": [],
    "ogx_mmlux_fi-human_sexuality": [],
    "ogx_mmlux_fi-international_law": [],
    "ogx_mmlux_fi-jurisprudence": [],
    "ogx_mmlux_fi-logical_fallacies": [],
    "ogx_mmlux_fi-machine_learning": [],
    "ogx_mmlux_fi-management": [],
    "ogx_mmlux_fi-marketing": [],
    "ogx_mmlux_fi-medical_genetics": [],
    "ogx_mmlux_fi-miscellaneous": [],
    "ogx_mmlux_fi-moral_disputes": [],
    "ogx_mmlux_fi-moral_scenarios": [],
    "ogx_mmlux_fi-nutrition": [],
    "ogx_mmlux_fi-philosophy": [],
    "ogx_mmlux_fi-prehistory": [],
    "ogx_mmlux_fi-professional_accounting": [],
    "ogx_mmlux_fi-professional_law": [],
    "ogx_mmlux_fi-professional_medicine": [],
    "ogx_mmlux_fi-professional_psychology": [],
    "ogx_mmlux_fi-public_relations": [],
    "ogx_mmlux_fi-security_studies": [],
    "ogx_mmlux_fi-sociology": [],
    "ogx_mmlux_fi-us_foreign_policy": [],
    "ogx_mmlux_fi-virology": [],
    "ogx_mmlux_fi-world_religions": [],
    "ogx_mmlux_fr-abstract_algebra": [],
    "ogx_mmlux_fr-anatomy": [],
    "ogx_mmlux_fr-astronomy": [],
    "ogx_mmlux_fr-business_ethics": [],
    "ogx_mmlux_fr-clinical_knowledge": [],
    "ogx_mmlux_fr-college_biology": [],
    "ogx_mmlux_fr-college_chemistry": [],
    "ogx_mmlux_fr-college_computer_science": [],
    "ogx_mmlux_fr-college_mathematics": [],
    "ogx_mmlux_fr-college_medicine": [],
    "ogx_mmlux_fr-college_physics": [],
    "ogx_mmlux_fr-computer_security": [],
    "ogx_mmlux_fr-conceptual_physics": [],
    "ogx_mmlux_fr-econometrics": [],
    "ogx_mmlux_fr-electrical_engineering": [],
    "ogx_mmlux_fr-elementary_mathematics": [],
    "ogx_mmlux_fr-formal_logic": [],
    "ogx_mmlux_fr-global_facts": [],
    "ogx_mmlux_fr-high_school_biology": [],
    "ogx_mmlux_fr-high_school_chemistry": [],
    "ogx_mmlux_fr-high_school_computer_science": [],
    "ogx_mmlux_fr-high_school_european_history": [],
    "ogx_mmlux_fr-high_school_geography": [],
    "ogx_mmlux_fr-high_school_government_and_politics": [],
    "ogx_mmlux_fr-high_school_macroeconomics": [],
    "ogx_mmlux_fr-high_school_mathematics": [],
    "ogx_mmlux_fr-high_school_microeconomics": [],
    "ogx_mmlux_fr-high_school_physics": [],
    "ogx_mmlux_fr-high_school_psychology": [],
    "ogx_mmlux_fr-high_school_statistics": [],
    "ogx_mmlux_fr-high_school_us_history": [],
    "ogx_mmlux_fr-high_school_world_history": [],
    "ogx_mmlux_fr-human_aging": [],
    "ogx_mmlux_fr-human_sexuality": [],
    "ogx_mmlux_fr-international_law": [],
    "ogx_mmlux_fr-jurisprudence": [],
    "ogx_mmlux_fr-logical_fallacies": [],
    "ogx_mmlux_fr-machine_learning": [],
    "ogx_mmlux_fr-management": [],
    "ogx_mmlux_fr-marketing": [],
    "ogx_mmlux_fr-medical_genetics": [],
    "ogx_mmlux_fr-miscellaneous": [],
    "ogx_mmlux_fr-moral_disputes": [],
    "ogx_mmlux_fr-moral_scenarios": [],
    "ogx_mmlux_fr-nutrition": [],
    "ogx_mmlux_fr-philosophy": [],
    "ogx_mmlux_fr-prehistory": [],
    "ogx_mmlux_fr-professional_accounting": [],
    "ogx_mmlux_fr-professional_law": [],
    "ogx_mmlux_fr-professional_medicine": [],
    "ogx_mmlux_fr-professional_psychology": [],
    "ogx_mmlux_fr-public_relations": [],
    "ogx_mmlux_fr-security_studies": [],
    "ogx_mmlux_fr-sociology": [],
    "ogx_mmlux_fr-us_foreign_policy": [],
    "ogx_mmlux_fr-virology": [],
    "ogx_mmlux_fr-world_religions": [],
    "ogx_mmlux_hu-abstract_algebra": [],
    "ogx_mmlux_hu-anatomy": [],
    "ogx_mmlux_hu-astronomy": [],
    "ogx_mmlux_hu-business_ethics": [],
    "ogx_mmlux_hu-clinical_knowledge": [],
    "ogx_mmlux_hu-college_biology": [],
    "ogx_mmlux_hu-college_chemistry": [],
    "ogx_mmlux_hu-college_computer_science": [],
    "ogx_mmlux_hu-college_mathematics": [],
    "ogx_mmlux_hu-college_medicine": [],
    "ogx_mmlux_hu-college_physics": [],
    "ogx_mmlux_hu-computer_security": [],
    "ogx_mmlux_hu-conceptual_physics": [],
    "ogx_mmlux_hu-econometrics": [],
    "ogx_mmlux_hu-electrical_engineering": [],
    "ogx_mmlux_hu-elementary_mathematics": [],
    "ogx_mmlux_hu-formal_logic": [],
    "ogx_mmlux_hu-global_facts": [],
    "ogx_mmlux_hu-high_school_biology": [],
    "ogx_mmlux_hu-high_school_chemistry": [],
    "ogx_mmlux_hu-high_school_computer_science": [],
    "ogx_mmlux_hu-high_school_european_history": [],
    "ogx_mmlux_hu-high_school_geography": [],
    "ogx_mmlux_hu-high_school_government_and_politics": [],
    "ogx_mmlux_hu-high_school_macroeconomics": [],
    "ogx_mmlux_hu-high_school_mathematics": [],
    "ogx_mmlux_hu-high_school_microeconomics": [],
    "ogx_mmlux_hu-high_school_physics": [],
    "ogx_mmlux_hu-high_school_psychology": [],
    "ogx_mmlux_hu-high_school_statistics": [],
    "ogx_mmlux_hu-high_school_us_history": [],
    "ogx_mmlux_hu-high_school_world_history": [],
    "ogx_mmlux_hu-human_aging": [],
    "ogx_mmlux_hu-human_sexuality": [],
    "ogx_mmlux_hu-international_law": [],
    "ogx_mmlux_hu-jurisprudence": [],
    "ogx_mmlux_hu-logical_fallacies": [],
    "ogx_mmlux_hu-machine_learning": [],
    "ogx_mmlux_hu-management": [],
    "ogx_mmlux_hu-marketing": [],
    "ogx_mmlux_hu-medical_genetics": [],
    "ogx_mmlux_hu-miscellaneous": [],
    "ogx_mmlux_hu-moral_disputes": [],
    "ogx_mmlux_hu-moral_scenarios": [],
    "ogx_mmlux_hu-nutrition": [],
    "ogx_mmlux_hu-philosophy": [],
    "ogx_mmlux_hu-prehistory": [],
    "ogx_mmlux_hu-professional_accounting": [],
    "ogx_mmlux_hu-professional_law": [],
    "ogx_mmlux_hu-professional_medicine": [],
    "ogx_mmlux_hu-professional_psychology": [],
    "ogx_mmlux_hu-public_relations": [],
    "ogx_mmlux_hu-security_studies": [],
    "ogx_mmlux_hu-sociology": [],
    "ogx_mmlux_hu-us_foreign_policy": [],
    "ogx_mmlux_hu-virology": [],
    "ogx_mmlux_hu-world_religions": [],
    "ogx_mmlux_it-abstract_algebra": [],
    "ogx_mmlux_it-anatomy": [],
    "ogx_mmlux_it-astronomy": [],
    "ogx_mmlux_it-business_ethics": [],
    "ogx_mmlux_it-clinical_knowledge": [],
    "ogx_mmlux_it-college_biology": [],
    "ogx_mmlux_it-college_chemistry": [],
    "ogx_mmlux_it-college_computer_science": [],
    "ogx_mmlux_it-college_mathematics": [],
    "ogx_mmlux_it-college_medicine": [],
    "ogx_mmlux_it-college_physics": [],
    "ogx_mmlux_it-computer_security": [],
    "ogx_mmlux_it-conceptual_physics": [],
    "ogx_mmlux_it-econometrics": [],
    "ogx_mmlux_it-electrical_engineering": [],
    "ogx_mmlux_it-elementary_mathematics": [],
    "ogx_mmlux_it-formal_logic": [],
    "ogx_mmlux_it-global_facts": [],
    "ogx_mmlux_it-high_school_biology": [],
    "ogx_mmlux_it-high_school_chemistry": [],
    "ogx_mmlux_it-high_school_computer_science": [],
    "ogx_mmlux_it-high_school_european_history": [],
    "ogx_mmlux_it-high_school_geography": [],
    "ogx_mmlux_it-high_school_government_and_politics": [],
    "ogx_mmlux_it-high_school_macroeconomics": [],
    "ogx_mmlux_it-high_school_mathematics": [],
    "ogx_mmlux_it-high_school_microeconomics": [],
    "ogx_mmlux_it-high_school_physics": [],
    "ogx_mmlux_it-high_school_psychology": [],
    "ogx_mmlux_it-high_school_statistics": [],
    "ogx_mmlux_it-high_school_us_history": [],
    "ogx_mmlux_it-high_school_world_history": [],
    "ogx_mmlux_it-human_aging": [],
    "ogx_mmlux_it-human_sexuality": [],
    "ogx_mmlux_it-international_law": [],
    "ogx_mmlux_it-jurisprudence": [],
    "ogx_mmlux_it-logical_fallacies": [],
    "ogx_mmlux_it-machine_learning": [],
    "ogx_mmlux_it-management": [],
    "ogx_mmlux_it-marketing": [],
    "ogx_mmlux_it-medical_genetics": [],
    "ogx_mmlux_it-miscellaneous": [],
    "ogx_mmlux_it-moral_disputes": [],
    "ogx_mmlux_it-moral_scenarios": [],
    "ogx_mmlux_it-nutrition": [],
    "ogx_mmlux_it-philosophy": [],
    "ogx_mmlux_it-prehistory": [],
    "ogx_mmlux_it-professional_accounting": [],
    "ogx_mmlux_it-professional_law": [],
    "ogx_mmlux_it-professional_medicine": [],
    "ogx_mmlux_it-professional_psychology": [],
    "ogx_mmlux_it-public_relations": [],
    "ogx_mmlux_it-security_studies": [],
    "ogx_mmlux_it-sociology": [],
    "ogx_mmlux_it-us_foreign_policy": [],
    "ogx_mmlux_it-virology": [],
    "ogx_mmlux_it-world_religions": [],
    "ogx_mmlux_lt-abstract_algebra": [],
    "ogx_mmlux_lt-anatomy": [],
    "ogx_mmlux_lt-astronomy": [],
    "ogx_mmlux_lt-business_ethics": [],
    "ogx_mmlux_lt-clinical_knowledge": [],
    "ogx_mmlux_lt-college_biology": [],
    "ogx_mmlux_lt-college_chemistry": [],
    "ogx_mmlux_lt-college_computer_science": [],
    "ogx_mmlux_lt-college_mathematics": [],
    "ogx_mmlux_lt-college_medicine": [],
    "ogx_mmlux_lt-college_physics": [],
    "ogx_mmlux_lt-computer_security": [],
    "ogx_mmlux_lt-conceptual_physics": [],
    "ogx_mmlux_lt-econometrics": [],
    "ogx_mmlux_lt-electrical_engineering": [],
    "ogx_mmlux_lt-elementary_mathematics": [],
    "ogx_mmlux_lt-formal_logic": [],
    "ogx_mmlux_lt-global_facts": [],
    "ogx_mmlux_lt-high_school_biology": [],
    "ogx_mmlux_lt-high_school_chemistry": [],
    "ogx_mmlux_lt-high_school_computer_science": [],
    "ogx_mmlux_lt-high_school_european_history": [],
    "ogx_mmlux_lt-high_school_geography": [],
    "ogx_mmlux_lt-high_school_government_and_politics": [],
    "ogx_mmlux_lt-high_school_macroeconomics": [],
    "ogx_mmlux_lt-high_school_mathematics": [],
    "ogx_mmlux_lt-high_school_microeconomics": [],
    "ogx_mmlux_lt-high_school_physics": [],
    "ogx_mmlux_lt-high_school_psychology": [],
    "ogx_mmlux_lt-high_school_statistics": [],
    "ogx_mmlux_lt-high_school_us_history": [],
    "ogx_mmlux_lt-high_school_world_history": [],
    "ogx_mmlux_lt-human_aging": [],
    "ogx_mmlux_lt-human_sexuality": [],
    "ogx_mmlux_lt-international_law": [],
    "ogx_mmlux_lt-jurisprudence": [],
    "ogx_mmlux_lt-logical_fallacies": [],
    "ogx_mmlux_lt-machine_learning": [],
    "ogx_mmlux_lt-management": [],
    "ogx_mmlux_lt-marketing": [],
    "ogx_mmlux_lt-medical_genetics": [],
    "ogx_mmlux_lt-miscellaneous": [],
    "ogx_mmlux_lt-moral_disputes": [],
    "ogx_mmlux_lt-moral_scenarios": [],
    "ogx_mmlux_lt-nutrition": [],
    "ogx_mmlux_lt-philosophy": [],
    "ogx_mmlux_lt-prehistory": [],
    "ogx_mmlux_lt-professional_accounting": [],
    "ogx_mmlux_lt-professional_law": [],
    "ogx_mmlux_lt-professional_medicine": [],
    "ogx_mmlux_lt-professional_psychology": [],
    "ogx_mmlux_lt-public_relations": [],
    "ogx_mmlux_lt-security_studies": [],
    "ogx_mmlux_lt-sociology": [],
    "ogx_mmlux_lt-us_foreign_policy": [],
    "ogx_mmlux_lt-virology": [],
    "ogx_mmlux_lt-world_religions": [],
    "ogx_mmlux_lv-abstract_algebra": [],
    "ogx_mmlux_lv-anatomy": [],
    "ogx_mmlux_lv-astronomy": [],
    "ogx_mmlux_lv-business_ethics": [],
    "ogx_mmlux_lv-clinical_knowledge": [],
    "ogx_mmlux_lv-college_biology": [],
    "ogx_mmlux_lv-college_chemistry": [],
    "ogx_mmlux_lv-college_computer_science": [],
    "ogx_mmlux_lv-college_mathematics": [],
    "ogx_mmlux_lv-college_medicine": [],
    "ogx_mmlux_lv-college_physics": [],
    "ogx_mmlux_lv-computer_security": [],
    "ogx_mmlux_lv-conceptual_physics": [],
    "ogx_mmlux_lv-econometrics": [],
    "ogx_mmlux_lv-electrical_engineering": [],
    "ogx_mmlux_lv-elementary_mathematics": [],
    "ogx_mmlux_lv-formal_logic": [],
    "ogx_mmlux_lv-global_facts": [],
    "ogx_mmlux_lv-high_school_biology": [],
    "ogx_mmlux_lv-high_school_chemistry": [],
    "ogx_mmlux_lv-high_school_computer_science": [],
    "ogx_mmlux_lv-high_school_european_history": [],
    "ogx_mmlux_lv-high_school_geography": [],
    "ogx_mmlux_lv-high_school_government_and_politics": [],
    "ogx_mmlux_lv-high_school_macroeconomics": [],
    "ogx_mmlux_lv-high_school_mathematics": [],
    "ogx_mmlux_lv-high_school_microeconomics": [],
    "ogx_mmlux_lv-high_school_physics": [],
    "ogx_mmlux_lv-high_school_psychology": [],
    "ogx_mmlux_lv-high_school_statistics": [],
    "ogx_mmlux_lv-high_school_us_history": [],
    "ogx_mmlux_lv-high_school_world_history": [],
    "ogx_mmlux_lv-human_aging": [],
    "ogx_mmlux_lv-human_sexuality": [],
    "ogx_mmlux_lv-international_law": [],
    "ogx_mmlux_lv-jurisprudence": [],
    "ogx_mmlux_lv-logical_fallacies": [],
    "ogx_mmlux_lv-machine_learning": [],
    "ogx_mmlux_lv-management": [],
    "ogx_mmlux_lv-marketing": [],
    "ogx_mmlux_lv-medical_genetics": [],
    "ogx_mmlux_lv-miscellaneous": [],
    "ogx_mmlux_lv-moral_disputes": [],
    "ogx_mmlux_lv-moral_scenarios": [],
    "ogx_mmlux_lv-nutrition": [],
    "ogx_mmlux_lv-philosophy": [],
    "ogx_mmlux_lv-prehistory": [],
    "ogx_mmlux_lv-professional_accounting": [],
    "ogx_mmlux_lv-professional_law": [],
    "ogx_mmlux_lv-professional_medicine": [],
    "ogx_mmlux_lv-professional_psychology": [],
    "ogx_mmlux_lv-public_relations": [],
    "ogx_mmlux_lv-security_studies": [],
    "ogx_mmlux_lv-sociology": [],
    "ogx_mmlux_lv-us_foreign_policy": [],
    "ogx_mmlux_lv-virology": [],
    "ogx_mmlux_lv-world_religions": [],
    "ogx_mmlux_nl-abstract_algebra": [],
    "ogx_mmlux_nl-anatomy": [],
    "ogx_mmlux_nl-astronomy": [],
    "ogx_mmlux_nl-business_ethics": [],
    "ogx_mmlux_nl-clinical_knowledge": [],
    "ogx_mmlux_nl-college_biology": [],
    "ogx_mmlux_nl-college_chemistry": [],
    "ogx_mmlux_nl-college_computer_science": [],
    "ogx_mmlux_nl-college_mathematics": [],
    "ogx_mmlux_nl-college_medicine": [],
    "ogx_mmlux_nl-college_physics": [],
    "ogx_mmlux_nl-computer_security": [],
    "ogx_mmlux_nl-conceptual_physics": [],
    "ogx_mmlux_nl-econometrics": [],
    "ogx_mmlux_nl-electrical_engineering": [],
    "ogx_mmlux_nl-elementary_mathematics": [],
    "ogx_mmlux_nl-formal_logic": [],
    "ogx_mmlux_nl-global_facts": [],
    "ogx_mmlux_nl-high_school_biology": [],
    "ogx_mmlux_nl-high_school_chemistry": [],
    "ogx_mmlux_nl-high_school_computer_science": [],
    "ogx_mmlux_nl-high_school_european_history": [],
    "ogx_mmlux_nl-high_school_geography": [],
    "ogx_mmlux_nl-high_school_government_and_politics": [],
    "ogx_mmlux_nl-high_school_macroeconomics": [],
    "ogx_mmlux_nl-high_school_mathematics": [],
    "ogx_mmlux_nl-high_school_microeconomics": [],
    "ogx_mmlux_nl-high_school_physics": [],
    "ogx_mmlux_nl-high_school_psychology": [],
    "ogx_mmlux_nl-high_school_statistics": [],
    "ogx_mmlux_nl-high_school_us_history": [],
    "ogx_mmlux_nl-high_school_world_history": [],
    "ogx_mmlux_nl-human_aging": [],
    "ogx_mmlux_nl-human_sexuality": [],
    "ogx_mmlux_nl-international_law": [],
    "ogx_mmlux_nl-jurisprudence": [],
    "ogx_mmlux_nl-logical_fallacies": [],
    "ogx_mmlux_nl-machine_learning": [],
    "ogx_mmlux_nl-management": [],
    "ogx_mmlux_nl-marketing": [],
    "ogx_mmlux_nl-medical_genetics": [],
    "ogx_mmlux_nl-miscellaneous": [],
    "ogx_mmlux_nl-moral_disputes": [],
    "ogx_mmlux_nl-moral_scenarios": [],
    "ogx_mmlux_nl-nutrition": [],
    "ogx_mmlux_nl-philosophy": [],
    "ogx_mmlux_nl-prehistory": [],
    "ogx_mmlux_nl-professional_accounting": [],
    "ogx_mmlux_nl-professional_law": [],
    "ogx_mmlux_nl-professional_medicine": [],
    "ogx_mmlux_nl-professional_psychology": [],
    "ogx_mmlux_nl-public_relations": [],
    "ogx_mmlux_nl-security_studies": [],
    "ogx_mmlux_nl-sociology": [],
    "ogx_mmlux_nl-us_foreign_policy": [],
    "ogx_mmlux_nl-virology": [],
    "ogx_mmlux_nl-world_religions": [],
    "ogx_mmlux_pl-abstract_algebra": [],
    "ogx_mmlux_pl-anatomy": [],
    "ogx_mmlux_pl-astronomy": [],
    "ogx_mmlux_pl-business_ethics": [],
    "ogx_mmlux_pl-clinical_knowledge": [],
    "ogx_mmlux_pl-college_biology": [],
    "ogx_mmlux_pl-college_chemistry": [],
    "ogx_mmlux_pl-college_computer_science": [],
    "ogx_mmlux_pl-college_mathematics": [],
    "ogx_mmlux_pl-college_medicine": [],
    "ogx_mmlux_pl-college_physics": [],
    "ogx_mmlux_pl-computer_security": [],
    "ogx_mmlux_pl-conceptual_physics": [],
    "ogx_mmlux_pl-econometrics": [],
    "ogx_mmlux_pl-electrical_engineering": [],
    "ogx_mmlux_pl-elementary_mathematics": [],
    "ogx_mmlux_pl-formal_logic": [],
    "ogx_mmlux_pl-global_facts": [],
    "ogx_mmlux_pl-high_school_biology": [],
    "ogx_mmlux_pl-high_school_chemistry": [],
    "ogx_mmlux_pl-high_school_computer_science": [],
    "ogx_mmlux_pl-high_school_european_history": [],
    "ogx_mmlux_pl-high_school_geography": [],
    "ogx_mmlux_pl-high_school_government_and_politics": [],
    "ogx_mmlux_pl-high_school_macroeconomics": [],
    "ogx_mmlux_pl-high_school_mathematics": [],
    "ogx_mmlux_pl-high_school_microeconomics": [],
    "ogx_mmlux_pl-high_school_physics": [],
    "ogx_mmlux_pl-high_school_psychology": [],
    "ogx_mmlux_pl-high_school_statistics": [],
    "ogx_mmlux_pl-high_school_us_history": [],
    "ogx_mmlux_pl-high_school_world_history": [],
    "ogx_mmlux_pl-human_aging": [],
    "ogx_mmlux_pl-human_sexuality": [],
    "ogx_mmlux_pl-international_law": [],
    "ogx_mmlux_pl-jurisprudence": [],
    "ogx_mmlux_pl-logical_fallacies": [],
    "ogx_mmlux_pl-machine_learning": [],
    "ogx_mmlux_pl-management": [],
    "ogx_mmlux_pl-marketing": [],
    "ogx_mmlux_pl-medical_genetics": [],
    "ogx_mmlux_pl-miscellaneous": [],
    "ogx_mmlux_pl-moral_disputes": [],
    "ogx_mmlux_pl-moral_scenarios": [],
    "ogx_mmlux_pl-nutrition": [],
    "ogx_mmlux_pl-philosophy": [],
    "ogx_mmlux_pl-prehistory": [],
    "ogx_mmlux_pl-professional_accounting": [],
    "ogx_mmlux_pl-professional_law": [],
    "ogx_mmlux_pl-professional_medicine": [],
    "ogx_mmlux_pl-professional_psychology": [],
    "ogx_mmlux_pl-public_relations": [],
    "ogx_mmlux_pl-security_studies": [],
    "ogx_mmlux_pl-sociology": [],
    "ogx_mmlux_pl-us_foreign_policy": [],
    "ogx_mmlux_pl-virology": [],
    "ogx_mmlux_pl-world_religions": [],
    "ogx_mmlux_pt-pt-abstract_algebra": [],
    "ogx_mmlux_pt-pt-anatomy": [],
    "ogx_mmlux_pt-pt-astronomy": [],
    "ogx_mmlux_pt-pt-business_ethics": [],
    "ogx_mmlux_pt-pt-clinical_knowledge": [],
    "ogx_mmlux_pt-pt-college_biology": [],
    "ogx_mmlux_pt-pt-college_chemistry": [],
    "ogx_mmlux_pt-pt-college_computer_science": [],
    "ogx_mmlux_pt-pt-college_mathematics": [],
    "ogx_mmlux_pt-pt-college_medicine": [],
    "ogx_mmlux_pt-pt-college_physics": [],
    "ogx_mmlux_pt-pt-computer_security": [],
    "ogx_mmlux_pt-pt-conceptual_physics": [],
    "ogx_mmlux_pt-pt-econometrics": [],
    "ogx_mmlux_pt-pt-electrical_engineering": [],
    "ogx_mmlux_pt-pt-elementary_mathematics": [],
    "ogx_mmlux_pt-pt-formal_logic": [],
    "ogx_mmlux_pt-pt-global_facts": [],
    "ogx_mmlux_pt-pt-high_school_biology": [],
    "ogx_mmlux_pt-pt-high_school_chemistry": [],
    "ogx_mmlux_pt-pt-high_school_computer_science": [],
    "ogx_mmlux_pt-pt-high_school_european_history": [],
    "ogx_mmlux_pt-pt-high_school_geography": [],
    "ogx_mmlux_pt-pt-high_school_government_and_politics": [],
    "ogx_mmlux_pt-pt-high_school_macroeconomics": [],
    "ogx_mmlux_pt-pt-high_school_mathematics": [],
    "ogx_mmlux_pt-pt-high_school_microeconomics": [],
    "ogx_mmlux_pt-pt-high_school_physics": [],
    "ogx_mmlux_pt-pt-high_school_psychology": [],
    "ogx_mmlux_pt-pt-high_school_statistics": [],
    "ogx_mmlux_pt-pt-high_school_us_history": [],
    "ogx_mmlux_pt-pt-high_school_world_history": [],
    "ogx_mmlux_pt-pt-human_aging": [],
    "ogx_mmlux_pt-pt-human_sexuality": [],
    "ogx_mmlux_pt-pt-international_law": [],
    "ogx_mmlux_pt-pt-jurisprudence": [],
    "ogx_mmlux_pt-pt-logical_fallacies": [],
    "ogx_mmlux_pt-pt-machine_learning": [],
    "ogx_mmlux_pt-pt-management": [],
    "ogx_mmlux_pt-pt-marketing": [],
    "ogx_mmlux_pt-pt-medical_genetics": [],
    "ogx_mmlux_pt-pt-miscellaneous": [],
    "ogx_mmlux_pt-pt-moral_disputes": [],
    "ogx_mmlux_pt-pt-moral_scenarios": [],
    "ogx_mmlux_pt-pt-nutrition": [],
    "ogx_mmlux_pt-pt-philosophy": [],
    "ogx_mmlux_pt-pt-prehistory": [],
    "ogx_mmlux_pt-pt-professional_accounting": [],
    "ogx_mmlux_pt-pt-professional_law": [],
    "ogx_mmlux_pt-pt-professional_medicine": [],
    "ogx_mmlux_pt-pt-professional_psychology": [],
    "ogx_mmlux_pt-pt-public_relations": [],
    "ogx_mmlux_pt-pt-security_studies": [],
    "ogx_mmlux_pt-pt-sociology": [],
    "ogx_mmlux_pt-pt-us_foreign_policy": [],
    "ogx_mmlux_pt-pt-virology": [],
    "ogx_mmlux_pt-pt-world_religions": [],
    "ogx_mmlux_ro-abstract_algebra": [],
    "ogx_mmlux_ro-anatomy": [],
    "ogx_mmlux_ro-astronomy": [],
    "ogx_mmlux_ro-business_ethics": [],
    "ogx_mmlux_ro-clinical_knowledge": [],
    "ogx_mmlux_ro-college_biology": [],
    "ogx_mmlux_ro-college_chemistry": [],
    "ogx_mmlux_ro-college_computer_science": [],
    "ogx_mmlux_ro-college_mathematics": [],
    "ogx_mmlux_ro-college_medicine": [],
    "ogx_mmlux_ro-college_physics": [],
    "ogx_mmlux_ro-computer_security": [],
    "ogx_mmlux_ro-conceptual_physics": [],
    "ogx_mmlux_ro-econometrics": [],
    "ogx_mmlux_ro-electrical_engineering": [],
    "ogx_mmlux_ro-elementary_mathematics": [],
    "ogx_mmlux_ro-formal_logic": [],
    "ogx_mmlux_ro-global_facts": [],
    "ogx_mmlux_ro-high_school_biology": [],
    "ogx_mmlux_ro-high_school_chemistry": [],
    "ogx_mmlux_ro-high_school_computer_science": [],
    "ogx_mmlux_ro-high_school_european_history": [],
    "ogx_mmlux_ro-high_school_geography": [],
    "ogx_mmlux_ro-high_school_government_and_politics": [],
    "ogx_mmlux_ro-high_school_macroeconomics": [],
    "ogx_mmlux_ro-high_school_mathematics": [],
    "ogx_mmlux_ro-high_school_microeconomics": [],
    "ogx_mmlux_ro-high_school_physics": [],
    "ogx_mmlux_ro-high_school_psychology": [],
    "ogx_mmlux_ro-high_school_statistics": [],
    "ogx_mmlux_ro-high_school_us_history": [],
    "ogx_mmlux_ro-high_school_world_history": [],
    "ogx_mmlux_ro-human_aging": [],
    "ogx_mmlux_ro-human_sexuality": [],
    "ogx_mmlux_ro-international_law": [],
    "ogx_mmlux_ro-jurisprudence": [],
    "ogx_mmlux_ro-logical_fallacies": [],
    "ogx_mmlux_ro-machine_learning": [],
    "ogx_mmlux_ro-management": [],
    "ogx_mmlux_ro-marketing": [],
    "ogx_mmlux_ro-medical_genetics": [],
    "ogx_mmlux_ro-miscellaneous": [],
    "ogx_mmlux_ro-moral_disputes": [],
    "ogx_mmlux_ro-moral_scenarios": [],
    "ogx_mmlux_ro-nutrition": [],
    "ogx_mmlux_ro-philosophy": [],
    "ogx_mmlux_ro-prehistory": [],
    "ogx_mmlux_ro-professional_accounting": [],
    "ogx_mmlux_ro-professional_law": [],
    "ogx_mmlux_ro-professional_medicine": [],
    "ogx_mmlux_ro-professional_psychology": [],
    "ogx_mmlux_ro-public_relations": [],
    "ogx_mmlux_ro-security_studies": [],
    "ogx_mmlux_ro-sociology": [],
    "ogx_mmlux_ro-us_foreign_policy": [],
    "ogx_mmlux_ro-virology": [],
    "ogx_mmlux_ro-world_religions": [],
    "ogx_mmlux_sk-abstract_algebra": [],
    "ogx_mmlux_sk-anatomy": [],
    "ogx_mmlux_sk-astronomy": [],
    "ogx_mmlux_sk-business_ethics": [],
    "ogx_mmlux_sk-clinical_knowledge": [],
    "ogx_mmlux_sk-college_biology": [],
    "ogx_mmlux_sk-college_chemistry": [],
    "ogx_mmlux_sk-college_computer_science": [],
    "ogx_mmlux_sk-college_mathematics": [],
    "ogx_mmlux_sk-college_medicine": [],
    "ogx_mmlux_sk-college_physics": [],
    "ogx_mmlux_sk-computer_security": [],
    "ogx_mmlux_sk-conceptual_physics": [],
    "ogx_mmlux_sk-econometrics": [],
    "ogx_mmlux_sk-electrical_engineering": [],
    "ogx_mmlux_sk-elementary_mathematics": [],
    "ogx_mmlux_sk-formal_logic": [],
    "ogx_mmlux_sk-global_facts": [],
    "ogx_mmlux_sk-high_school_biology": [],
    "ogx_mmlux_sk-high_school_chemistry": [],
    "ogx_mmlux_sk-high_school_computer_science": [],
    "ogx_mmlux_sk-high_school_european_history": [],
    "ogx_mmlux_sk-high_school_geography": [],
    "ogx_mmlux_sk-high_school_government_and_politics": [],
    "ogx_mmlux_sk-high_school_macroeconomics": [],
    "ogx_mmlux_sk-high_school_mathematics": [],
    "ogx_mmlux_sk-high_school_microeconomics": [],
    "ogx_mmlux_sk-high_school_physics": [],
    "ogx_mmlux_sk-high_school_psychology": [],
    "ogx_mmlux_sk-high_school_statistics": [],
    "ogx_mmlux_sk-high_school_us_history": [],
    "ogx_mmlux_sk-high_school_world_history": [],
    "ogx_mmlux_sk-human_aging": [],
    "ogx_mmlux_sk-human_sexuality": [],
    "ogx_mmlux_sk-international_law": [],
    "ogx_mmlux_sk-jurisprudence": [],
    "ogx_mmlux_sk-logical_fallacies": [],
    "ogx_mmlux_sk-machine_learning": [],
    "ogx_mmlux_sk-management": [],
    "ogx_mmlux_sk-marketing": [],
    "ogx_mmlux_sk-medical_genetics": [],
    "ogx_mmlux_sk-miscellaneous": [],
    "ogx_mmlux_sk-moral_disputes": [],
    "ogx_mmlux_sk-moral_scenarios": [],
    "ogx_mmlux_sk-nutrition": [],
    "ogx_mmlux_sk-philosophy": [],
    "ogx_mmlux_sk-prehistory": [],
    "ogx_mmlux_sk-professional_accounting": [],
    "ogx_mmlux_sk-professional_law": [],
    "ogx_mmlux_sk-professional_medicine": [],
    "ogx_mmlux_sk-professional_psychology": [],
    "ogx_mmlux_sk-public_relations": [],
    "ogx_mmlux_sk-security_studies": [],
    "ogx_mmlux_sk-sociology": [],
    "ogx_mmlux_sk-us_foreign_policy": [],
    "ogx_mmlux_sk-virology": [],
    "ogx_mmlux_sk-world_religions": [],
    "ogx_mmlux_sl-abstract_algebra": [],
    "ogx_mmlux_sl-anatomy": [],
    "ogx_mmlux_sl-astronomy": [],
    "ogx_mmlux_sl-business_ethics": [],
    "ogx_mmlux_sl-clinical_knowledge": [],
    "ogx_mmlux_sl-college_biology": [],
    "ogx_mmlux_sl-college_chemistry": [],
    "ogx_mmlux_sl-college_computer_science": [],
    "ogx_mmlux_sl-college_mathematics": [],
    "ogx_mmlux_sl-college_medicine": [],
    "ogx_mmlux_sl-college_physics": [],
    "ogx_mmlux_sl-computer_security": [],
    "ogx_mmlux_sl-conceptual_physics": [],
    "ogx_mmlux_sl-econometrics": [],
    "ogx_mmlux_sl-electrical_engineering": [],
    "ogx_mmlux_sl-elementary_mathematics": [],
    "ogx_mmlux_sl-formal_logic": [],
    "ogx_mmlux_sl-global_facts": [],
    "ogx_mmlux_sl-high_school_biology": [],
    "ogx_mmlux_sl-high_school_chemistry": [],
    "ogx_mmlux_sl-high_school_computer_science": [],
    "ogx_mmlux_sl-high_school_european_history": [],
    "ogx_mmlux_sl-high_school_geography": [],
    "ogx_mmlux_sl-high_school_government_and_politics": [],
    "ogx_mmlux_sl-high_school_macroeconomics": [],
    "ogx_mmlux_sl-high_school_mathematics": [],
    "ogx_mmlux_sl-high_school_microeconomics": [],
    "ogx_mmlux_sl-high_school_physics": [],
    "ogx_mmlux_sl-high_school_psychology": [],
    "ogx_mmlux_sl-high_school_statistics": [],
    "ogx_mmlux_sl-high_school_us_history": [],
    "ogx_mmlux_sl-high_school_world_history": [],
    "ogx_mmlux_sl-human_aging": [],
    "ogx_mmlux_sl-human_sexuality": [],
    "ogx_mmlux_sl-international_law": [],
    "ogx_mmlux_sl-jurisprudence": [],
    "ogx_mmlux_sl-logical_fallacies": [],
    "ogx_mmlux_sl-machine_learning": [],
    "ogx_mmlux_sl-management": [],
    "ogx_mmlux_sl-marketing": [],
    "ogx_mmlux_sl-medical_genetics": [],
    "ogx_mmlux_sl-miscellaneous": [],
    "ogx_mmlux_sl-moral_disputes": [],
    "ogx_mmlux_sl-moral_scenarios": [],
    "ogx_mmlux_sl-nutrition": [],
    "ogx_mmlux_sl-philosophy": [],
    "ogx_mmlux_sl-prehistory": [],
    "ogx_mmlux_sl-professional_accounting": [],
    "ogx_mmlux_sl-professional_law": [],
    "ogx_mmlux_sl-professional_medicine": [],
    "ogx_mmlux_sl-professional_psychology": [],
    "ogx_mmlux_sl-public_relations": [],
    "ogx_mmlux_sl-security_studies": [],
    "ogx_mmlux_sl-sociology": [],
    "ogx_mmlux_sl-us_foreign_policy": [],
    "ogx_mmlux_sl-virology": [],
    "ogx_mmlux_sl-world_religions": [],
    "ogx_mmlux_sv-abstract_algebra": [],
    "ogx_mmlux_sv-anatomy": [],
    "ogx_mmlux_sv-astronomy": [],
    "ogx_mmlux_sv-business_ethics": [],
    "ogx_mmlux_sv-clinical_knowledge": [],
    "ogx_mmlux_sv-college_biology": [],
    "ogx_mmlux_sv-college_chemistry": [],
    "ogx_mmlux_sv-college_computer_science": [],
    "ogx_mmlux_sv-college_mathematics": [],
    "ogx_mmlux_sv-college_medicine": [],
    "ogx_mmlux_sv-college_physics": [],
    "ogx_mmlux_sv-computer_security": [],
    "ogx_mmlux_sv-conceptual_physics": [],
    "ogx_mmlux_sv-econometrics": [],
    "ogx_mmlux_sv-electrical_engineering": [],
    "ogx_mmlux_sv-elementary_mathematics": [],
    "ogx_mmlux_sv-formal_logic": [],
    "ogx_mmlux_sv-global_facts": [],
    "ogx_mmlux_sv-high_school_biology": [],
    "ogx_mmlux_sv-high_school_chemistry": [],
    "ogx_mmlux_sv-high_school_computer_science": [],
    "ogx_mmlux_sv-high_school_european_history": [],
    "ogx_mmlux_sv-high_school_geography": [],
    "ogx_mmlux_sv-high_school_government_and_politics": [],
    "ogx_mmlux_sv-high_school_macroeconomics": [],
    "ogx_mmlux_sv-high_school_mathematics": [],
    "ogx_mmlux_sv-high_school_microeconomics": [],
    "ogx_mmlux_sv-high_school_physics": [],
    "ogx_mmlux_sv-high_school_psychology": [],
    "ogx_mmlux_sv-high_school_statistics": [],
    "ogx_mmlux_sv-high_school_us_history": [],
    "ogx_mmlux_sv-high_school_world_history": [],
    "ogx_mmlux_sv-human_aging": [],
    "ogx_mmlux_sv-human_sexuality": [],
    "ogx_mmlux_sv-international_law": [],
    "ogx_mmlux_sv-jurisprudence": [],
    "ogx_mmlux_sv-logical_fallacies": [],
    "ogx_mmlux_sv-machine_learning": [],
    "ogx_mmlux_sv-management": [],
    "ogx_mmlux_sv-marketing": [],
    "ogx_mmlux_sv-medical_genetics": [],
    "ogx_mmlux_sv-miscellaneous": [],
    "ogx_mmlux_sv-moral_disputes": [],
    "ogx_mmlux_sv-moral_scenarios": [],
    "ogx_mmlux_sv-nutrition": [],
    "ogx_mmlux_sv-philosophy": [],
    "ogx_mmlux_sv-prehistory": [],
    "ogx_mmlux_sv-professional_accounting": [],
    "ogx_mmlux_sv-professional_law": [],
    "ogx_mmlux_sv-professional_medicine": [],
    "ogx_mmlux_sv-professional_psychology": [],
    "ogx_mmlux_sv-public_relations": [],
    "ogx_mmlux_sv-security_studies": [],
    "ogx_mmlux_sv-sociology": [],
    "ogx_mmlux_sv-us_foreign_policy": [],
    "ogx_mmlux_sv-virology": [],
    "ogx_mmlux_sv-world_religions": []
  },
  "configs": {
    "ogx_mmlux_bg-abstract_algebra": {
      "task": "ogx_mmlux_bg-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за абстрактната алгебра.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-anatomy": {
      "task": "ogx_mmlux_bg-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за анатомията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-astronomy": {
      "task": "ogx_mmlux_bg-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за астрономията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-business_ethics": {
      "task": "ogx_mmlux_bg-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за бизнес етиката.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "task": "ogx_mmlux_bg-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за клинични знания.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_biology": {
      "task": "ogx_mmlux_bg-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по биология в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_chemistry": {
      "task": "ogx_mmlux_bg-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по химия в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_computer_science": {
      "task": "ogx_mmlux_bg-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по информатика в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_mathematics": {
      "task": "ogx_mmlux_bg-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по математика в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_medicine": {
      "task": "ogx_mmlux_bg-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за университетската медицина.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_physics": {
      "task": "ogx_mmlux_bg-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по физика в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-computer_security": {
      "task": "ogx_mmlux_bg-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за компютърната сигурност.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "task": "ogx_mmlux_bg-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за концептуалната физика.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-econometrics": {
      "task": "ogx_mmlux_bg-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за иконометрията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "task": "ogx_mmlux_bg-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за електротехниката.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "task": "ogx_mmlux_bg-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по елементарна математика.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-formal_logic": {
      "task": "ogx_mmlux_bg-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за формалната логика.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-global_facts": {
      "task": "ogx_mmlux_bg-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за глобалните факти.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_biology": {
      "task": "ogx_mmlux_bg-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по биология за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "task": "ogx_mmlux_bg-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по химия за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "task": "ogx_mmlux_bg-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по информатика в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "task": "ogx_mmlux_bg-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по история на Европа в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_geography": {
      "task": "ogx_mmlux_bg-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по география за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "task": "ogx_mmlux_bg-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за управлението и политиката в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "task": "ogx_mmlux_bg-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по макроикономика за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "task": "ogx_mmlux_bg-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за математиката в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "task": "ogx_mmlux_bg-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по микроикономика за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_physics": {
      "task": "ogx_mmlux_bg-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по физика за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "task": "ogx_mmlux_bg-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по психология в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "task": "ogx_mmlux_bg-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за статистиката в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "task": "ogx_mmlux_bg-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по история на САЩ в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "task": "ogx_mmlux_bg-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по история на света в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-human_aging": {
      "task": "ogx_mmlux_bg-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за човешкото стареене.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-human_sexuality": {
      "task": "ogx_mmlux_bg-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за човешката сексуалност.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-international_law": {
      "task": "ogx_mmlux_bg-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за международното право.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-jurisprudence": {
      "task": "ogx_mmlux_bg-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за юриспруденцията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "task": "ogx_mmlux_bg-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за логическите грешки.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-machine_learning": {
      "task": "ogx_mmlux_bg-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за машинното обучение.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-management": {
      "task": "ogx_mmlux_bg-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за управлението.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-marketing": {
      "task": "ogx_mmlux_bg-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за маркетинга.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-medical_genetics": {
      "task": "ogx_mmlux_bg-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за медицинската генетика.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-miscellaneous": {
      "task": "ogx_mmlux_bg-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с въпроси с избор (с отговори) за miscellaneous.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-moral_disputes": {
      "task": "ogx_mmlux_bg-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за морални спорове.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "task": "ogx_mmlux_bg-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за морални сценарии.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-nutrition": {
      "task": "ogx_mmlux_bg-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за храненето.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-philosophy": {
      "task": "ogx_mmlux_bg-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за философията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-prehistory": {
      "task": "ogx_mmlux_bg-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за праисторията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_accounting": {
      "task": "ogx_mmlux_bg-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за професионалното счетоводство.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_law": {
      "task": "ogx_mmlux_bg-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора, свързани с професионалното право.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_medicine": {
      "task": "ogx_mmlux_bg-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за професионалната медицина.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_psychology": {
      "task": "ogx_mmlux_bg-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за професионалната психология.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-public_relations": {
      "task": "ogx_mmlux_bg-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за връзките с обществеността.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-security_studies": {
      "task": "ogx_mmlux_bg-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за проучвания в областта на сигурността.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-sociology": {
      "task": "ogx_mmlux_bg-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по социология.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "task": "ogx_mmlux_bg-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с въпроси с избор (с отговори) за външната политика на САЩ.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-virology": {
      "task": "ogx_mmlux_bg-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за вирусологията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-world_religions": {
      "task": "ogx_mmlux_bg-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за световните религии.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "task": "ogx_mmlux_cs-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o abstraktní algebře.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-anatomy": {
      "task": "ogx_mmlux_cs-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o anatomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-astronomy": {
      "task": "ogx_mmlux_cs-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o astronomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-business_ethics": {
      "task": "ogx_mmlux_cs-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o etice podnikání.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "task": "ogx_mmlux_cs-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o klinických znalostech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_biology": {
      "task": "ogx_mmlux_cs-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské biologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_chemistry": {
      "task": "ogx_mmlux_cs-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské chemii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_computer_science": {
      "task": "ogx_mmlux_cs-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské informatice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_mathematics": {
      "task": "ogx_mmlux_cs-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_medicine": {
      "task": "ogx_mmlux_cs-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské medicíně.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_physics": {
      "task": "ogx_mmlux_cs-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z vysokoškolské fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-computer_security": {
      "task": "ogx_mmlux_cs-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o počítačové bezpečnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "task": "ogx_mmlux_cs-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z konceptuální fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-econometrics": {
      "task": "ogx_mmlux_cs-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "task": "ogx_mmlux_cs-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o elektrotechnice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "task": "ogx_mmlux_cs-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o elementární matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-formal_logic": {
      "task": "ogx_mmlux_cs-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o formální logice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-global_facts": {
      "task": "ogx_mmlux_cs-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o globálních faktech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_biology": {
      "task": "ogx_mmlux_cs-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské biologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "task": "ogx_mmlux_cs-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské chemii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "task": "ogx_mmlux_cs-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské informatice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "task": "ogx_mmlux_cs-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z dějin Evropy pro střední školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_geography": {
      "task": "ogx_mmlux_cs-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolském zeměpisu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "task": "ogx_mmlux_cs-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské vládě a politice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "task": "ogx_mmlux_cs-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z makroekonomie pro střední školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "task": "ogx_mmlux_cs-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "task": "ogx_mmlux_cs-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z mikroekonomie pro střední školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_physics": {
      "task": "ogx_mmlux_cs-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí ze středoškolské fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "task": "ogx_mmlux_cs-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské psychologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "task": "ogx_mmlux_cs-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské statistice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "task": "ogx_mmlux_cs-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky s výběrem odpovědí se týkají středoškolské historie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "task": "ogx_mmlux_cs-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí ze světových dějin pro střední školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-human_aging": {
      "task": "ogx_mmlux_cs-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o stárnutí člověka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-human_sexuality": {
      "task": "ogx_mmlux_cs-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o lidské sexualitě.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-international_law": {
      "task": "ogx_mmlux_cs-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o mezinárodním právu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-jurisprudence": {
      "task": "ogx_mmlux_cs-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o právu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "task": "ogx_mmlux_cs-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o logických klamech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-machine_learning": {
      "task": "ogx_mmlux_cs-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o strojovém učení.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-management": {
      "task": "ogx_mmlux_cs-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky (s odpověďmi) se týkají managementu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-marketing": {
      "task": "ogx_mmlux_cs-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky (s odpověďmi) se týkají marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-medical_genetics": {
      "task": "ogx_mmlux_cs-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o lékařské genetice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-miscellaneous": {
      "task": "ogx_mmlux_cs-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky s výběrem odpovědi se týkají tématu miscellaneous.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-moral_disputes": {
      "task": "ogx_mmlux_cs-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky s výběrem odpovědí se týkají morálních sporů.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "task": "ogx_mmlux_cs-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o morálních scénářích.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-nutrition": {
      "task": "ogx_mmlux_cs-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o výživě.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-philosophy": {
      "task": "ogx_mmlux_cs-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-prehistory": {
      "task": "ogx_mmlux_cs-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o pravěku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_accounting": {
      "task": "ogx_mmlux_cs-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o odborném účetnictví.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_law": {
      "task": "ogx_mmlux_cs-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o profesním právu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_medicine": {
      "task": "ogx_mmlux_cs-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o profesionální medicíně.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_psychology": {
      "task": "ogx_mmlux_cs-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o odborné psychologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-public_relations": {
      "task": "ogx_mmlux_cs-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vztazích s veřejností.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-security_studies": {
      "task": "ogx_mmlux_cs-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o bezpečnostních studiích.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-sociology": {
      "task": "ogx_mmlux_cs-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o sociologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "task": "ogx_mmlux_cs-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky s výběrem odpovědí se týkají zahraniční politiky USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-virology": {
      "task": "ogx_mmlux_cs-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o virologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-world_religions": {
      "task": "ogx_mmlux_cs-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o světových náboženstvích.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-abstract_algebra": {
      "task": "ogx_mmlux_da-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om abstrakt algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-anatomy": {
      "task": "ogx_mmlux_da-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om anatomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-astronomy": {
      "task": "ogx_mmlux_da-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om astronomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-business_ethics": {
      "task": "ogx_mmlux_da-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om forretningsetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "task": "ogx_mmlux_da-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om klinisk viden.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_biology": {
      "task": "ogx_mmlux_da-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om universitetsbiologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_chemistry": {
      "task": "ogx_mmlux_da-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om kemi på college.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_computer_science": {
      "task": "ogx_mmlux_da-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om computervidenskab på college.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_mathematics": {
      "task": "ogx_mmlux_da-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om universitetsmatematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_medicine": {
      "task": "ogx_mmlux_da-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om universitetsmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_physics": {
      "task": "ogx_mmlux_da-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om universitetsfysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-computer_security": {
      "task": "ogx_mmlux_da-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om computersikkerhed.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-conceptual_physics": {
      "task": "ogx_mmlux_da-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om konceptuel fysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-econometrics": {
      "task": "ogx_mmlux_da-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om økonometri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-electrical_engineering": {
      "task": "ogx_mmlux_da-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om elektroteknik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "task": "ogx_mmlux_da-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om elementær matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-formal_logic": {
      "task": "ogx_mmlux_da-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om formel logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-global_facts": {
      "task": "ogx_mmlux_da-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om globale fakta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_biology": {
      "task": "ogx_mmlux_da-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om biologi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "task": "ogx_mmlux_da-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om kemi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "task": "ogx_mmlux_da-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om computervidenskab i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_european_history": {
      "task": "ogx_mmlux_da-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om europæisk historie i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_geography": {
      "task": "ogx_mmlux_da-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om geografi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "task": "ogx_mmlux_da-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om regering og politik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "task": "ogx_mmlux_da-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om makroøkonomi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "task": "ogx_mmlux_da-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om matematik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "task": "ogx_mmlux_da-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det følgende er multiple choice-spørgsmål (med svar) om mikroøkonomi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_physics": {
      "task": "ogx_mmlux_da-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om fysik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_psychology": {
      "task": "ogx_mmlux_da-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om psykologi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_statistics": {
      "task": "ogx_mmlux_da-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om statistik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_us_history": {
      "task": "ogx_mmlux_da-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om amerikansk historie i high school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_world_history": {
      "task": "ogx_mmlux_da-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om verdenshistorie i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-human_aging": {
      "task": "ogx_mmlux_da-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om menneskets aldring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-human_sexuality": {
      "task": "ogx_mmlux_da-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om menneskelig seksualitet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-international_law": {
      "task": "ogx_mmlux_da-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om international lov.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-jurisprudence": {
      "task": "ogx_mmlux_da-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om retsvidenskab.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-logical_fallacies": {
      "task": "ogx_mmlux_da-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om logiske fejlslutninger.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-machine_learning": {
      "task": "ogx_mmlux_da-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om maskinlæring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-management": {
      "task": "ogx_mmlux_da-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om ledelse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-marketing": {
      "task": "ogx_mmlux_da-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-medical_genetics": {
      "task": "ogx_mmlux_da-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om medicinsk genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-miscellaneous": {
      "task": "ogx_mmlux_da-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-moral_disputes": {
      "task": "ogx_mmlux_da-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om moralske tvister.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-moral_scenarios": {
      "task": "ogx_mmlux_da-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om moralske scenarier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-nutrition": {
      "task": "ogx_mmlux_da-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om ernæring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-philosophy": {
      "task": "ogx_mmlux_da-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om filosofi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-prehistory": {
      "task": "ogx_mmlux_da-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det følgende er multiple choice-spørgsmål (med svar) om forhistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_accounting": {
      "task": "ogx_mmlux_da-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om professionelt regnskab.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_law": {
      "task": "ogx_mmlux_da-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om erhvervsret.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_medicine": {
      "task": "ogx_mmlux_da-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om professionel medicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_psychology": {
      "task": "ogx_mmlux_da-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om professionel psykologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-public_relations": {
      "task": "ogx_mmlux_da-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-security_studies": {
      "task": "ogx_mmlux_da-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om sikkerhedsstudier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-sociology": {
      "task": "ogx_mmlux_da-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om sociologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "task": "ogx_mmlux_da-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om amerikansk udenrigspolitik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-virology": {
      "task": "ogx_mmlux_da-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om virologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-world_religions": {
      "task": "ogx_mmlux_da-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det følgende er multiple choice-spørgsmål (med svar) om verdensreligioner.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-abstract_algebra": {
      "task": "ogx_mmlux_de-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur abstrakten Algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-anatomy": {
      "task": "ogx_mmlux_de-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-astronomy": {
      "task": "ogx_mmlux_de-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-business_ethics": {
      "task": "ogx_mmlux_de-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Unternehmensethik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "task": "ogx_mmlux_de-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu klinischen Kenntnissen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_biology": {
      "task": "ogx_mmlux_de-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Biologie an der Universität.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_chemistry": {
      "task": "ogx_mmlux_de-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Chemie an Hochschulen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_computer_science": {
      "task": "ogx_mmlux_de-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulinformatik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_mathematics": {
      "task": "ogx_mmlux_de-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulmathematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_medicine": {
      "task": "ogx_mmlux_de-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Hochschulmedizin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_physics": {
      "task": "ogx_mmlux_de-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulphysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-computer_security": {
      "task": "ogx_mmlux_de-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Computersicherheit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-conceptual_physics": {
      "task": "ogx_mmlux_de-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur konzeptionellen Physik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-econometrics": {
      "task": "ogx_mmlux_de-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Ökonometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-electrical_engineering": {
      "task": "ogx_mmlux_de-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Elektrotechnik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "task": "ogx_mmlux_de-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur elementaren Mathematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-formal_logic": {
      "task": "ogx_mmlux_de-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur formalen Logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-global_facts": {
      "task": "ogx_mmlux_de-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu globalen Fakten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_biology": {
      "task": "ogx_mmlux_de-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Biologie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "task": "ogx_mmlux_de-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Chemie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "task": "ogx_mmlux_de-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Informatik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_european_history": {
      "task": "ogx_mmlux_de-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur europäischen Geschichte in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_geography": {
      "task": "ogx_mmlux_de-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Geografie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "task": "ogx_mmlux_de-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Regierung und Politik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "task": "ogx_mmlux_de-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Makroökonomie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "task": "ogx_mmlux_de-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Mathematik in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "task": "ogx_mmlux_de-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Mikroökonomie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_physics": {
      "task": "ogx_mmlux_de-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Physik in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_psychology": {
      "task": "ogx_mmlux_de-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Schulpsychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_statistics": {
      "task": "ogx_mmlux_de-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Statistik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_us_history": {
      "task": "ogx_mmlux_de-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Geschichte der USA in der High School.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_world_history": {
      "task": "ogx_mmlux_de-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Weltgeschichte in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-human_aging": {
      "task": "ogx_mmlux_de-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum menschlichen Altern.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-human_sexuality": {
      "task": "ogx_mmlux_de-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur menschlichen Sexualität.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-international_law": {
      "task": "ogx_mmlux_de-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum internationalen Recht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-jurisprudence": {
      "task": "ogx_mmlux_de-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Rechtswissenschaft.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-logical_fallacies": {
      "task": "ogx_mmlux_de-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu logischen Fehlschlüssen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-machine_learning": {
      "task": "ogx_mmlux_de-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum maschinellen Lernen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-management": {
      "task": "ogx_mmlux_de-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-marketing": {
      "task": "ogx_mmlux_de-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-medical_genetics": {
      "task": "ogx_mmlux_de-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur medizinischen Genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-miscellaneous": {
      "task": "ogx_mmlux_de-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Verschiedenes.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-moral_disputes": {
      "task": "ogx_mmlux_de-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu moralischen Streitigkeiten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-moral_scenarios": {
      "task": "ogx_mmlux_de-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu moralischen Szenarien.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-nutrition": {
      "task": "ogx_mmlux_de-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Ernährung.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-philosophy": {
      "task": "ogx_mmlux_de-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Philosophie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-prehistory": {
      "task": "ogx_mmlux_de-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Vorgeschichte.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_accounting": {
      "task": "ogx_mmlux_de-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema professionelle Buchhaltung.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_law": {
      "task": "ogx_mmlux_de-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Berufsrecht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_medicine": {
      "task": "ogx_mmlux_de-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Berufsmedizin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_psychology": {
      "task": "ogx_mmlux_de-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Berufspsychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-public_relations": {
      "task": "ogx_mmlux_de-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Öffentlichkeitsarbeit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-security_studies": {
      "task": "ogx_mmlux_de-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Es folgen Multiple-Choice-Fragen (mit Antworten) zu Sicherheitsstudien.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-sociology": {
      "task": "ogx_mmlux_de-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Soziologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "task": "ogx_mmlux_de-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Außenpolitik der USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-virology": {
      "task": "ogx_mmlux_de-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-world_religions": {
      "task": "ogx_mmlux_de-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu den Weltreligionen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-abstract_algebra": {
      "task": "ogx_mmlux_el-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την αφηρημένη άλγεβρα.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-anatomy": {
      "task": "ogx_mmlux_el-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ανατομία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-astronomy": {
      "task": "ogx_mmlux_el-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την αστρονομία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-business_ethics": {
      "task": "ogx_mmlux_el-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επιχειρηματική ηθική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "task": "ogx_mmlux_el-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις κλινικές γνώσεις.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_biology": {
      "task": "ogx_mmlux_el-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη βιολογία του κολεγίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_chemistry": {
      "task": "ogx_mmlux_el-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη χημεία του πανεπιστημίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_computer_science": {
      "task": "ogx_mmlux_el-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επιστήμη των υπολογιστών στο κολέγιο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_mathematics": {
      "task": "ogx_mmlux_el-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα μαθηματικά του πανεπιστημίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_medicine": {
      "task": "ogx_mmlux_el-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ιατρική στο κολέγιο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_physics": {
      "task": "ogx_mmlux_el-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη φυσική του πανεπιστημίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-computer_security": {
      "task": "ogx_mmlux_el-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ασφάλεια των υπολογιστών.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-conceptual_physics": {
      "task": "ogx_mmlux_el-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την εννοιολογική φυσική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-econometrics": {
      "task": "ogx_mmlux_el-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την οικονομετρία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-electrical_engineering": {
      "task": "ogx_mmlux_el-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ηλεκτρολογική μηχανική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "task": "ogx_mmlux_el-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα στοιχειώδη μαθηματικά.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-formal_logic": {
      "task": "ogx_mmlux_el-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την τυπική λογική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-global_facts": {
      "task": "ogx_mmlux_el-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα παγκόσμια γεγονότα.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_biology": {
      "task": "ogx_mmlux_el-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη βιολογία γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "task": "ogx_mmlux_el-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη χημεία του γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "task": "ogx_mmlux_el-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επιστήμη των υπολογιστών στο λύκειο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_european_history": {
      "task": "ogx_mmlux_el-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ευρωπαϊκή ιστορία του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_geography": {
      "task": "ogx_mmlux_el-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη γεωγραφία του γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "task": "ogx_mmlux_el-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την κυβέρνηση και την πολιτική στο λύκειο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "task": "ogx_mmlux_el-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα μακροοικονομικά του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "task": "ogx_mmlux_el-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα μαθηματικά του γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "task": "ogx_mmlux_el-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη μικροοικονομία του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_physics": {
      "task": "ogx_mmlux_el-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη φυσική γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_psychology": {
      "task": "ogx_mmlux_el-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ψυχολογία του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_statistics": {
      "task": "ogx_mmlux_el-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη στατιστική του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_us_history": {
      "task": "ogx_mmlux_el-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ιστορία μας στο λύκειο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_world_history": {
      "task": "ogx_mmlux_el-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την παγκόσμια ιστορία του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-human_aging": {
      "task": "ogx_mmlux_el-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη γήρανση του ανθρώπου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-human_sexuality": {
      "task": "ogx_mmlux_el-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ανθρώπινη σεξουαλικότητα.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-international_law": {
      "task": "ogx_mmlux_el-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με το διεθνές δίκαιο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-jurisprudence": {
      "task": "ogx_mmlux_el-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη νομική επιστήμη.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-logical_fallacies": {
      "task": "ogx_mmlux_el-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις λογικές πλάνες.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-machine_learning": {
      "task": "ogx_mmlux_el-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη μηχανική μάθηση.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-management": {
      "task": "ogx_mmlux_el-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη διαχείριση.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-marketing": {
      "task": "ogx_mmlux_el-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με το μάρκετινγκ.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-medical_genetics": {
      "task": "ogx_mmlux_el-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ιατρική γενετική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-miscellaneous": {
      "task": "ogx_mmlux_el-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα διάφορα.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-moral_disputes": {
      "task": "ogx_mmlux_el-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις ηθικές διαμάχες.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-moral_scenarios": {
      "task": "ogx_mmlux_el-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με ηθικά σενάρια.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-nutrition": {
      "task": "ogx_mmlux_el-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη διατροφή.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-philosophy": {
      "task": "ogx_mmlux_el-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη φιλοσοφία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-prehistory": {
      "task": "ogx_mmlux_el-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την προϊστορία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_accounting": {
      "task": "ogx_mmlux_el-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επαγγελματική λογιστική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_law": {
      "task": "ogx_mmlux_el-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με το επαγγελματικό δίκαιο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_medicine": {
      "task": "ogx_mmlux_el-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επαγγελματική ιατρική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_psychology": {
      "task": "ogx_mmlux_el-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επαγγελματική ψυχολογία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-public_relations": {
      "task": "ogx_mmlux_el-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις δημόσιες σχέσεις.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-security_studies": {
      "task": "ogx_mmlux_el-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις μελέτες ασφάλειας.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-sociology": {
      "task": "ogx_mmlux_el-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την κοινωνιολογία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "task": "ogx_mmlux_el-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την εξωτερική πολιτική των ΗΠΑ.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-virology": {
      "task": "ogx_mmlux_el-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ιολογία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-world_religions": {
      "task": "ogx_mmlux_el-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις παγκόσμιες θρησκείες.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-abstract_algebra": {
      "task": "ogx_mmlux_es-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre álgebra abstracta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-anatomy": {
      "task": "ogx_mmlux_es-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre anatomía.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-astronomy": {
      "task": "ogx_mmlux_es-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre astronomía.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-business_ethics": {
      "task": "ogx_mmlux_es-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre ética empresarial.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "task": "ogx_mmlux_es-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A continuación se presentan preguntas tipo test (con respuesta) sobre conocimientos clínicos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_biology": {
      "task": "ogx_mmlux_es-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre biología universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_chemistry": {
      "task": "ogx_mmlux_es-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre química universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_computer_science": {
      "task": "ogx_mmlux_es-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre informática universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_mathematics": {
      "task": "ogx_mmlux_es-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemáticas universitarias.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_medicine": {
      "task": "ogx_mmlux_es-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre medicina universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_physics": {
      "task": "ogx_mmlux_es-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre física universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-computer_security": {
      "task": "ogx_mmlux_es-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre seguridad informática.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-conceptual_physics": {
      "task": "ogx_mmlux_es-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre física conceptual.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-econometrics": {
      "task": "ogx_mmlux_es-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre econometría.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-electrical_engineering": {
      "task": "ogx_mmlux_es-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre ingeniería eléctrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "task": "ogx_mmlux_es-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemáticas elementales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-formal_logic": {
      "task": "ogx_mmlux_es-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre lógica formal.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-global_facts": {
      "task": "ogx_mmlux_es-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre hechos globales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_biology": {
      "task": "ogx_mmlux_es-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre biología de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "task": "ogx_mmlux_es-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre química de bachillerato.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "task": "ogx_mmlux_es-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre informática en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_european_history": {
      "task": "ogx_mmlux_es-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre historia europea de bachillerato.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_geography": {
      "task": "ogx_mmlux_es-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre geografía de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "task": "ogx_mmlux_es-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre el gobierno y la política en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "task": "ogx_mmlux_es-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre macroeconomía en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "task": "ogx_mmlux_es-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemáticas de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "task": "ogx_mmlux_es-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre microeconomía en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_physics": {
      "task": "ogx_mmlux_es-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre física de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_psychology": {
      "task": "ogx_mmlux_es-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre psicología en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_statistics": {
      "task": "ogx_mmlux_es-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre estadística de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_us_history": {
      "task": "ogx_mmlux_es-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre la historia de EE.UU. en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_world_history": {
      "task": "ogx_mmlux_es-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre la historia mundial de la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-human_aging": {
      "task": "ogx_mmlux_es-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre el envejecimiento humano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-human_sexuality": {
      "task": "ogx_mmlux_es-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre la sexualidad humana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-international_law": {
      "task": "ogx_mmlux_es-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre Derecho internacional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-jurisprudence": {
      "task": "ogx_mmlux_es-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre jurisprudencia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-logical_fallacies": {
      "task": "ogx_mmlux_es-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre falacias lógicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-machine_learning": {
      "task": "ogx_mmlux_es-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre aprendizaje automático.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-management": {
      "task": "ogx_mmlux_es-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre gestión.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-marketing": {
      "task": "ogx_mmlux_es-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-medical_genetics": {
      "task": "ogx_mmlux_es-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre genética médica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-miscellaneous": {
      "task": "ogx_mmlux_es-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre miscelánea.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-moral_disputes": {
      "task": "ogx_mmlux_es-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre disputas morales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-moral_scenarios": {
      "task": "ogx_mmlux_es-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre escenarios morales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-nutrition": {
      "task": "ogx_mmlux_es-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre nutrición.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-philosophy": {
      "task": "ogx_mmlux_es-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre filosofía.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-prehistory": {
      "task": "ogx_mmlux_es-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre la prehistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_accounting": {
      "task": "ogx_mmlux_es-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre contabilidad profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_law": {
      "task": "ogx_mmlux_es-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A continuación se presentan preguntas tipo test (con respuesta) sobre Derecho profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_medicine": {
      "task": "ogx_mmlux_es-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre medicina profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_psychology": {
      "task": "ogx_mmlux_es-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre psicología profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-public_relations": {
      "task": "ogx_mmlux_es-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre relaciones públicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-security_studies": {
      "task": "ogx_mmlux_es-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre estudios de seguridad.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-sociology": {
      "task": "ogx_mmlux_es-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre sociología.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "task": "ogx_mmlux_es-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre la política exterior estadounidense.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-virology": {
      "task": "ogx_mmlux_es-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre virología.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-world_religions": {
      "task": "ogx_mmlux_es-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre las religiones del mundo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-abstract_algebra": {
      "task": "ogx_mmlux_et-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) abstraktse algebra kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-anatomy": {
      "task": "ogx_mmlux_et-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) anatoomia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-astronomy": {
      "task": "ogx_mmlux_et-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) astronoomia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-business_ethics": {
      "task": "ogx_mmlux_et-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) ärieetika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "task": "ogx_mmlux_et-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kliiniliste teadmiste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_biology": {
      "task": "ogx_mmlux_et-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži bioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_chemistry": {
      "task": "ogx_mmlux_et-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži keemia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_computer_science": {
      "task": "ogx_mmlux_et-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kõrgkooli informaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_mathematics": {
      "task": "ogx_mmlux_et-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži matemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_medicine": {
      "task": "ogx_mmlux_et-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži meditsiini kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_physics": {
      "task": "ogx_mmlux_et-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži füüsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-computer_security": {
      "task": "ogx_mmlux_et-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) arvutiturbe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-conceptual_physics": {
      "task": "ogx_mmlux_et-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kontseptuaalse füüsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-econometrics": {
      "task": "ogx_mmlux_et-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) ökonomeetria kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-electrical_engineering": {
      "task": "ogx_mmlux_et-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) elektrotehnika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "task": "ogx_mmlux_et-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) elementaarmatemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-formal_logic": {
      "task": "ogx_mmlux_et-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) formaalloogika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-global_facts": {
      "task": "ogx_mmlux_et-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) globaalsete faktide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_biology": {
      "task": "ogx_mmlux_et-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli bioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "task": "ogx_mmlux_et-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli keemia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "task": "ogx_mmlux_et-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli informaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_european_history": {
      "task": "ogx_mmlux_et-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli Euroopa ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_geography": {
      "task": "ogx_mmlux_et-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli geograafia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "task": "ogx_mmlux_et-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli valitsuse ja poliitika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "task": "ogx_mmlux_et-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli makromajanduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "task": "ogx_mmlux_et-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli matemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "task": "ogx_mmlux_et-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli mikroökonoomika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_physics": {
      "task": "ogx_mmlux_et-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkoolifüüsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_psychology": {
      "task": "ogx_mmlux_et-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkoolipsühholoogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_statistics": {
      "task": "ogx_mmlux_et-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli statistika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_us_history": {
      "task": "ogx_mmlux_et-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) meie keskkooli ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_world_history": {
      "task": "ogx_mmlux_et-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli maailma ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-human_aging": {
      "task": "ogx_mmlux_et-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) inimese vananemise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-human_sexuality": {
      "task": "ogx_mmlux_et-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) inimese seksuaalsuse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-international_law": {
      "task": "ogx_mmlux_et-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) rahvusvahelise õiguse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-jurisprudence": {
      "task": "ogx_mmlux_et-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) õigusteaduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-logical_fallacies": {
      "task": "ogx_mmlux_et-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) loogiliste eksituste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-machine_learning": {
      "task": "ogx_mmlux_et-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) masinõppe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-management": {
      "task": "ogx_mmlux_et-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) juhtimise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-marketing": {
      "task": "ogx_mmlux_et-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) turunduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-medical_genetics": {
      "task": "ogx_mmlux_et-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) meditsiinigeneetika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-miscellaneous": {
      "task": "ogx_mmlux_et-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) mitmesuguste küsimuste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-moral_disputes": {
      "task": "ogx_mmlux_et-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) moraalsete vaidluste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-moral_scenarios": {
      "task": "ogx_mmlux_et-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) moraalsete stsenaariumide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-nutrition": {
      "task": "ogx_mmlux_et-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) toitumise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-philosophy": {
      "task": "ogx_mmlux_et-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) filosoofia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-prehistory": {
      "task": "ogx_mmlux_et-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) eelajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_accounting": {
      "task": "ogx_mmlux_et-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kutsealase raamatupidamise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_law": {
      "task": "ogx_mmlux_et-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kutseõiguse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_medicine": {
      "task": "ogx_mmlux_et-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) erialase meditsiini kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_psychology": {
      "task": "ogx_mmlux_et-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) erialase psühholoogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-public_relations": {
      "task": "ogx_mmlux_et-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) avalike suhete kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-security_studies": {
      "task": "ogx_mmlux_et-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) julgeolekuõppe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-sociology": {
      "task": "ogx_mmlux_et-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) sotsioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "task": "ogx_mmlux_et-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) meie välispoliitika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-virology": {
      "task": "ogx_mmlux_et-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) viroloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-world_religions": {
      "task": "ogx_mmlux_et-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) maailmareligioonide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "task": "ogx_mmlux_fi-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) abstraktista algebrasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-anatomy": {
      "task": "ogx_mmlux_fi-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) anatomiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-astronomy": {
      "task": "ogx_mmlux_fi-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) tähtitieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-business_ethics": {
      "task": "ogx_mmlux_fi-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) liike-elämän etiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "task": "ogx_mmlux_fi-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) kliinisestä tietämyksestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_biology": {
      "task": "ogx_mmlux_fi-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistobiologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_chemistry": {
      "task": "ogx_mmlux_fi-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistokemiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_computer_science": {
      "task": "ogx_mmlux_fi-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistojen tietotekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_mathematics": {
      "task": "ogx_mmlux_fi-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistomatematiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_medicine": {
      "task": "ogx_mmlux_fi-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistolääketieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_physics": {
      "task": "ogx_mmlux_fi-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistofysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-computer_security": {
      "task": "ogx_mmlux_fi-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) tietoturvasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "task": "ogx_mmlux_fi-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) käsitteellisestä fysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-econometrics": {
      "task": "ogx_mmlux_fi-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ekonometriasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "task": "ogx_mmlux_fi-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) sähkötekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "task": "ogx_mmlux_fi-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) matematiikan alkeista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-formal_logic": {
      "task": "ogx_mmlux_fi-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) muodollisesta logiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-global_facts": {
      "task": "ogx_mmlux_fi-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) globaaleista tosiasioista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_biology": {
      "task": "ogx_mmlux_fi-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion biologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "task": "ogx_mmlux_fi-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion kemiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "task": "ogx_mmlux_fi-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion tietotekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "task": "ogx_mmlux_fi-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion Euroopan historiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_geography": {
      "task": "ogx_mmlux_fi-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion maantiedosta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "task": "ogx_mmlux_fi-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion hallituksesta ja politiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "task": "ogx_mmlux_fi-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion makrotaloudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "task": "ogx_mmlux_fi-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion matematiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "task": "ogx_mmlux_fi-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion mikrotaloustieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_physics": {
      "task": "ogx_mmlux_fi-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion fysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "task": "ogx_mmlux_fi-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion psykologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "task": "ogx_mmlux_fi-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion tilastoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "task": "ogx_mmlux_fi-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion historiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "task": "ogx_mmlux_fi-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion maailmanhistoriasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-human_aging": {
      "task": "ogx_mmlux_fi-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ihmisen ikääntymisestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-human_sexuality": {
      "task": "ogx_mmlux_fi-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ihmisen seksuaalisuudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-international_law": {
      "task": "ogx_mmlux_fi-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) kansainvälisestä oikeudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-jurisprudence": {
      "task": "ogx_mmlux_fi-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) oikeustieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "task": "ogx_mmlux_fi-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) loogisista virheistä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-machine_learning": {
      "task": "ogx_mmlux_fi-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) koneoppimisesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-management": {
      "task": "ogx_mmlux_fi-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) johtamisesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-marketing": {
      "task": "ogx_mmlux_fi-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) markkinoinnista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-medical_genetics": {
      "task": "ogx_mmlux_fi-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) lääketieteellisestä genetiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-miscellaneous": {
      "task": "ogx_mmlux_fi-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) aiheesta sekalaiset.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-moral_disputes": {
      "task": "ogx_mmlux_fi-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) moraalisista kiistoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "task": "ogx_mmlux_fi-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) moraalisista skenaarioista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-nutrition": {
      "task": "ogx_mmlux_fi-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ravitsemuksesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-philosophy": {
      "task": "ogx_mmlux_fi-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) filosofiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-prehistory": {
      "task": "ogx_mmlux_fi-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on esihistoriaa koskevia monivalintakysymyksiä (vastauksineen).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_accounting": {
      "task": "ogx_mmlux_fi-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ammattimaisesta kirjanpidosta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_law": {
      "task": "ogx_mmlux_fi-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ammattioikeudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_medicine": {
      "task": "ogx_mmlux_fi-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) ammatillisesta lääketieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_psychology": {
      "task": "ogx_mmlux_fi-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ammattipsykologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-public_relations": {
      "task": "ogx_mmlux_fi-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) suhdetoiminnasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-security_studies": {
      "task": "ogx_mmlux_fi-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) turvallisuustutkimuksesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-sociology": {
      "task": "ogx_mmlux_fi-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on sosiologiaa koskevia monivalintakysymyksiä (vastauksineen).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "task": "ogx_mmlux_fi-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavat ovat monivalintakysymyksiä (vastauksineen) Yhdysvaltojen ulkopolitiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-virology": {
      "task": "ogx_mmlux_fi-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) virologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-world_religions": {
      "task": "ogx_mmlux_fi-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) maailmanuskonnoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "task": "ogx_mmlux_fr-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'algèbre abstraite.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-anatomy": {
      "task": "ogx_mmlux_fr-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-astronomy": {
      "task": "ogx_mmlux_fr-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-business_ethics": {
      "task": "ogx_mmlux_fr-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'éthique des affaires.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "task": "ogx_mmlux_fr-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les connaissances cliniques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_biology": {
      "task": "ogx_mmlux_fr-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la biologie au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_chemistry": {
      "task": "ogx_mmlux_fr-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la chimie au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_computer_science": {
      "task": "ogx_mmlux_fr-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'informatique au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_mathematics": {
      "task": "ogx_mmlux_fr-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les mathématiques au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_medicine": {
      "task": "ogx_mmlux_fr-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la médecine universitaire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_physics": {
      "task": "ogx_mmlux_fr-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la physique au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-computer_security": {
      "task": "ogx_mmlux_fr-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la sécurité informatique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "task": "ogx_mmlux_fr-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la physique conceptuelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-econometrics": {
      "task": "ogx_mmlux_fr-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'économétrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "task": "ogx_mmlux_fr-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le génie électrique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "task": "ogx_mmlux_fr-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les mathématiques élémentaires.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-formal_logic": {
      "task": "ogx_mmlux_fr-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la logique formelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-global_facts": {
      "task": "ogx_mmlux_fr-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les faits mondiaux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_biology": {
      "task": "ogx_mmlux_fr-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la biologie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "task": "ogx_mmlux_fr-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la chimie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "task": "ogx_mmlux_fr-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'informatique au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "task": "ogx_mmlux_fr-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'histoire de l'Europe au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_geography": {
      "task": "ogx_mmlux_fr-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la géographie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "task": "ogx_mmlux_fr-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le gouvernement et la politique au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "task": "ogx_mmlux_fr-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la macroéconomie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "task": "ogx_mmlux_fr-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les mathématiques au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "task": "ogx_mmlux_fr-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la microéconomie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_physics": {
      "task": "ogx_mmlux_fr-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la physique au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "task": "ogx_mmlux_fr-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la psychologie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "task": "ogx_mmlux_fr-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les statistiques de l'enseignement secondaire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "task": "ogx_mmlux_fr-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'histoire des États-Unis au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "task": "ogx_mmlux_fr-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'histoire du monde au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-human_aging": {
      "task": "ogx_mmlux_fr-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le vieillissement humain.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-human_sexuality": {
      "task": "ogx_mmlux_fr-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la sexualité humaine.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-international_law": {
      "task": "ogx_mmlux_fr-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le droit international.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-jurisprudence": {
      "task": "ogx_mmlux_fr-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la jurisprudence.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "task": "ogx_mmlux_fr-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les sophismes logiques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-machine_learning": {
      "task": "ogx_mmlux_fr-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'apprentissage automatique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-management": {
      "task": "ogx_mmlux_fr-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-marketing": {
      "task": "ogx_mmlux_fr-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-medical_genetics": {
      "task": "ogx_mmlux_fr-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la génétique médicale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-miscellaneous": {
      "task": "ogx_mmlux_fr-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les divers.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-moral_disputes": {
      "task": "ogx_mmlux_fr-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les différends moraux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "task": "ogx_mmlux_fr-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur des scénarios moraux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-nutrition": {
      "task": "ogx_mmlux_fr-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la nutrition.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-philosophy": {
      "task": "ogx_mmlux_fr-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la philosophie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-prehistory": {
      "task": "ogx_mmlux_fr-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la préhistoire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_accounting": {
      "task": "ogx_mmlux_fr-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la comptabilité professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_law": {
      "task": "ogx_mmlux_fr-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le droit professionnel.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_medicine": {
      "task": "ogx_mmlux_fr-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la médecine professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_psychology": {
      "task": "ogx_mmlux_fr-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la psychologie professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-public_relations": {
      "task": "ogx_mmlux_fr-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les relations publiques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-security_studies": {
      "task": "ogx_mmlux_fr-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les études de sécurité.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-sociology": {
      "task": "ogx_mmlux_fr-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "task": "ogx_mmlux_fr-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Voici des questions à choix multiples (avec réponses) sur la politique étrangère des États-Unis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-virology": {
      "task": "ogx_mmlux_fr-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-world_religions": {
      "task": "ogx_mmlux_fr-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Voici des questions à choix multiples (avec réponses) sur les religions du monde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "task": "ogx_mmlux_hu-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) az absztrakt algebráról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-anatomy": {
      "task": "ogx_mmlux_hu-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) az anatómiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-astronomy": {
      "task": "ogx_mmlux_hu-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a csillagászatról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-business_ethics": {
      "task": "ogx_mmlux_hu-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az üzleti etikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "task": "ogx_mmlux_hu-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban a klinikai ismeretekkel kapcsolatos feleletválasztós kérdések (válaszokkal) következnek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_biology": {
      "task": "ogx_mmlux_hu-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai biológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_chemistry": {
      "task": "ogx_mmlux_hu-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai kémiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_computer_science": {
      "task": "ogx_mmlux_hu-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai informatikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_mathematics": {
      "task": "ogx_mmlux_hu-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai matematikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_medicine": {
      "task": "ogx_mmlux_hu-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai orvostudományról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_physics": {
      "task": "ogx_mmlux_hu-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) az egyetemi fizikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-computer_security": {
      "task": "ogx_mmlux_hu-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a számítógépes biztonságról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "task": "ogx_mmlux_hu-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a fogalmi fizikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-econometrics": {
      "task": "ogx_mmlux_hu-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban az ökonometriával kapcsolatos feleletválasztós kérdések (válaszokkal) következnek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "task": "ogx_mmlux_hu-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a villamosmérnöki tudományokról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "task": "ogx_mmlux_hu-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az elemi matematikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-formal_logic": {
      "task": "ogx_mmlux_hu-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a formális logikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-global_facts": {
      "task": "ogx_mmlux_hu-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a globális tényekről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_biology": {
      "task": "ogx_mmlux_hu-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai biológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "task": "ogx_mmlux_hu-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai kémiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "task": "ogx_mmlux_hu-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai informatikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "task": "ogx_mmlux_hu-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai európai történelemről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_geography": {
      "task": "ogx_mmlux_hu-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai földrajzról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "task": "ogx_mmlux_hu-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a középiskolai kormányzatról és politikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "task": "ogx_mmlux_hu-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai makroökonómiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "task": "ogx_mmlux_hu-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai matematikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "task": "ogx_mmlux_hu-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai mikroökonómiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_physics": {
      "task": "ogx_mmlux_hu-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai fizikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "task": "ogx_mmlux_hu-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a középiskolai pszichológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "task": "ogx_mmlux_hu-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban a középiskolai statisztikával kapcsolatos feleletválasztós kérdések (válaszokkal) találhatók.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "task": "ogx_mmlux_hu-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai történelemről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "task": "ogx_mmlux_hu-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai világtörténelemről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-human_aging": {
      "task": "ogx_mmlux_hu-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az emberi öregedéssel kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-human_sexuality": {
      "task": "ogx_mmlux_hu-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az emberi szexualitásról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-international_law": {
      "task": "ogx_mmlux_hu-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a nemzetközi jogról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-jurisprudence": {
      "task": "ogx_mmlux_hu-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a jogtudományról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "task": "ogx_mmlux_hu-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban a logikai tévedésekkel kapcsolatos feleletválasztós kérdések (válaszokkal) találhatók.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-machine_learning": {
      "task": "ogx_mmlux_hu-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a gépi tanulásról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-management": {
      "task": "ogx_mmlux_hu-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a menedzsmentről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-marketing": {
      "task": "ogx_mmlux_hu-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a marketingről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-medical_genetics": {
      "task": "ogx_mmlux_hu-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az orvosi genetikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-miscellaneous": {
      "task": "ogx_mmlux_hu-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a különféle kérdésekről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-moral_disputes": {
      "task": "ogx_mmlux_hu-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az erkölcsi vitákról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "task": "ogx_mmlux_hu-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban erkölcsi forgatókönyvekkel kapcsolatos feleletválasztós kérdések (válaszokkal) következnek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-nutrition": {
      "task": "ogx_mmlux_hu-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a táplálkozással kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-philosophy": {
      "task": "ogx_mmlux_hu-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a filozófiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-prehistory": {
      "task": "ogx_mmlux_hu-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az őstörténetről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_accounting": {
      "task": "ogx_mmlux_hu-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a szakmai számvitelről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_law": {
      "task": "ogx_mmlux_hu-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a szakmai joggal kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_medicine": {
      "task": "ogx_mmlux_hu-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a hivatásos orvoslásról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_psychology": {
      "task": "ogx_mmlux_hu-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a szakpszichológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-public_relations": {
      "task": "ogx_mmlux_hu-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a public relationsről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-security_studies": {
      "task": "ogx_mmlux_hu-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a biztonsági tanulmányokról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-sociology": {
      "task": "ogx_mmlux_hu-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a szociológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "task": "ogx_mmlux_hu-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) az amerikai külpolitikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-virology": {
      "task": "ogx_mmlux_hu-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a virológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-world_religions": {
      "task": "ogx_mmlux_hu-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a világvallásokról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-abstract_algebra": {
      "task": "ogx_mmlux_it-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'algebra astratta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-anatomy": {
      "task": "ogx_mmlux_it-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'anatomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-astronomy": {
      "task": "ogx_mmlux_it-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'astronomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-business_ethics": {
      "task": "ogx_mmlux_it-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'etica aziendale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "task": "ogx_mmlux_it-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla conoscenza clinica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_biology": {
      "task": "ogx_mmlux_it-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla biologia universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_chemistry": {
      "task": "ogx_mmlux_it-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla chimica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_computer_science": {
      "task": "ogx_mmlux_it-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'informatica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_mathematics": {
      "task": "ogx_mmlux_it-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_medicine": {
      "task": "ogx_mmlux_it-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla medicina universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_physics": {
      "task": "ogx_mmlux_it-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-computer_security": {
      "task": "ogx_mmlux_it-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sicurezza informatica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-conceptual_physics": {
      "task": "ogx_mmlux_it-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica concettuale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-econometrics": {
      "task": "ogx_mmlux_it-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'econometria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-electrical_engineering": {
      "task": "ogx_mmlux_it-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'ingegneria elettrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "task": "ogx_mmlux_it-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica elementare.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-formal_logic": {
      "task": "ogx_mmlux_it-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla logica formale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-global_facts": {
      "task": "ogx_mmlux_it-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sui fatti globali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_biology": {
      "task": "ogx_mmlux_it-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla biologia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "task": "ogx_mmlux_it-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla chimica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "task": "ogx_mmlux_it-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'informatica per le scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_european_history": {
      "task": "ogx_mmlux_it-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia europea delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_geography": {
      "task": "ogx_mmlux_it-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla geografia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "task": "ogx_mmlux_it-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul governo e la politica nelle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "task": "ogx_mmlux_it-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla macroeconomia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "task": "ogx_mmlux_it-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "task": "ogx_mmlux_it-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla microeconomia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_physics": {
      "task": "ogx_mmlux_it-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_psychology": {
      "task": "ogx_mmlux_it-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla psicologia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_statistics": {
      "task": "ogx_mmlux_it-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla statistica della scuola superiore.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_us_history": {
      "task": "ogx_mmlux_it-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia degli Stati Uniti al liceo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_world_history": {
      "task": "ogx_mmlux_it-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia mondiale delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-human_aging": {
      "task": "ogx_mmlux_it-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'invecchiamento umano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-human_sexuality": {
      "task": "ogx_mmlux_it-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sessualità umana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-international_law": {
      "task": "ogx_mmlux_it-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul diritto internazionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-jurisprudence": {
      "task": "ogx_mmlux_it-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla giurisprudenza.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-logical_fallacies": {
      "task": "ogx_mmlux_it-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle fallacie logiche.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-machine_learning": {
      "task": "ogx_mmlux_it-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'apprendimento automatico.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-management": {
      "task": "ogx_mmlux_it-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla gestione.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-marketing": {
      "task": "ogx_mmlux_it-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-medical_genetics": {
      "task": "ogx_mmlux_it-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla genetica medica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-miscellaneous": {
      "task": "ogx_mmlux_it-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) su varie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-moral_disputes": {
      "task": "ogx_mmlux_it-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle controversie morali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-moral_scenarios": {
      "task": "ogx_mmlux_it-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) su scenari morali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-nutrition": {
      "task": "ogx_mmlux_it-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'alimentazione.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-philosophy": {
      "task": "ogx_mmlux_it-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla filosofia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-prehistory": {
      "task": "ogx_mmlux_it-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla preistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_accounting": {
      "task": "ogx_mmlux_it-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla contabilità professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_law": {
      "task": "ogx_mmlux_it-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul diritto professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_medicine": {
      "task": "ogx_mmlux_it-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla medicina professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_psychology": {
      "task": "ogx_mmlux_it-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla psicologia professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-public_relations": {
      "task": "ogx_mmlux_it-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle relazioni pubbliche.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-security_studies": {
      "task": "ogx_mmlux_it-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sugli studi sulla sicurezza.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-sociology": {
      "task": "ogx_mmlux_it-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sociologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "task": "ogx_mmlux_it-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla politica estera degli Stati Uniti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-virology": {
      "task": "ogx_mmlux_it-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla virologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-world_religions": {
      "task": "ogx_mmlux_it-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle religioni del mondo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "task": "ogx_mmlux_lt-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie abstrakčiąją algebrą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-anatomy": {
      "task": "ogx_mmlux_lt-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie anatomiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-astronomy": {
      "task": "ogx_mmlux_lt-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie astronomiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-business_ethics": {
      "task": "ogx_mmlux_lt-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie verslo etiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "task": "ogx_mmlux_lt-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie klinikines žinias.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_biology": {
      "task": "ogx_mmlux_lt-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos biologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_chemistry": {
      "task": "ogx_mmlux_lt-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos chemiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_computer_science": {
      "task": "ogx_mmlux_lt-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos informatiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_mathematics": {
      "task": "ogx_mmlux_lt-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos matematiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_medicine": {
      "task": "ogx_mmlux_lt-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie koledžo mediciną.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_physics": {
      "task": "ogx_mmlux_lt-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos fiziką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-computer_security": {
      "task": "ogx_mmlux_lt-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kompiuterių saugumą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "task": "ogx_mmlux_lt-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie konceptualiąją fiziką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-econometrics": {
      "task": "ogx_mmlux_lt-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie ekonometriją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "task": "ogx_mmlux_lt-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie elektrotechniką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "task": "ogx_mmlux_lt-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai su atsakymais apie elementariąją matematiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-formal_logic": {
      "task": "ogx_mmlux_lt-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie formaliąją logiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-global_facts": {
      "task": "ogx_mmlux_lt-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie visuotinius faktus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_biology": {
      "task": "ogx_mmlux_lt-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurinės mokyklos biologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "task": "ogx_mmlux_lt-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie chemiją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "task": "ogx_mmlux_lt-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie informatiką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "task": "ogx_mmlux_lt-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie Europos istoriją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_geography": {
      "task": "ogx_mmlux_lt-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie geografiją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "task": "ogx_mmlux_lt-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vyriausybę ir politiką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "task": "ogx_mmlux_lt-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie makroekonomiką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "task": "ogx_mmlux_lt-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurinės mokyklos matematiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "task": "ogx_mmlux_lt-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mikroekonomiką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_physics": {
      "task": "ogx_mmlux_lt-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie fiziką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "task": "ogx_mmlux_lt-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie psichologiją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "task": "ogx_mmlux_lt-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurinės mokyklos statistiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "task": "ogx_mmlux_lt-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie JAV vidurinės mokyklos istoriją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "task": "ogx_mmlux_lt-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie pasaulio istoriją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-human_aging": {
      "task": "ogx_mmlux_lt-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie žmogaus senėjimą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-human_sexuality": {
      "task": "ogx_mmlux_lt-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie žmogaus lytiškumą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-international_law": {
      "task": "ogx_mmlux_lt-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie tarptautinę teisę.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-jurisprudence": {
      "task": "ogx_mmlux_lt-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie jurisprudenciją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "task": "ogx_mmlux_lt-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie logines klaidas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-machine_learning": {
      "task": "ogx_mmlux_lt-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mašininį mokymąsi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-management": {
      "task": "ogx_mmlux_lt-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie valdymą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-marketing": {
      "task": "ogx_mmlux_lt-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie rinkodarą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-medical_genetics": {
      "task": "ogx_mmlux_lt-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie medicininę genetiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-miscellaneous": {
      "task": "ogx_mmlux_lt-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie įvairius dalykus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-moral_disputes": {
      "task": "ogx_mmlux_lt-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie moralinius ginčus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "task": "ogx_mmlux_lt-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie moralinius scenarijus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-nutrition": {
      "task": "ogx_mmlux_lt-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mitybą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-philosophy": {
      "task": "ogx_mmlux_lt-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie filosofiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-prehistory": {
      "task": "ogx_mmlux_lt-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie priešistorę.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_accounting": {
      "task": "ogx_mmlux_lt-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesinę apskaitą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_law": {
      "task": "ogx_mmlux_lt-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesinę teisę.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_medicine": {
      "task": "ogx_mmlux_lt-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesinę mediciną.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_psychology": {
      "task": "ogx_mmlux_lt-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesinę psichologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-public_relations": {
      "task": "ogx_mmlux_lt-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie viešuosius ryšius.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-security_studies": {
      "task": "ogx_mmlux_lt-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie saugumo studijas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-sociology": {
      "task": "ogx_mmlux_lt-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie sociologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "task": "ogx_mmlux_lt-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie JAV užsienio politiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-virology": {
      "task": "ogx_mmlux_lt-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie virusologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-world_religions": {
      "task": "ogx_mmlux_lt-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie pasaulio religijas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "task": "ogx_mmlux_lv-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par abstrakto algebru.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-anatomy": {
      "task": "ogx_mmlux_lv-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem par anatomiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-astronomy": {
      "task": "ogx_mmlux_lv-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par astronomiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-business_ethics": {
      "task": "ogx_mmlux_lv-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par uzņēmējdarbības ētiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "task": "ogx_mmlux_lv-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par klīniskajām zināšanām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_biology": {
      "task": "ogx_mmlux_lv-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas bioloģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_chemistry": {
      "task": "ogx_mmlux_lv-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas ķīmiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_computer_science": {
      "task": "ogx_mmlux_lv-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par datorzinātnēm koledžā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_mathematics": {
      "task": "ogx_mmlux_lv-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas matemātiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_medicine": {
      "task": "ogx_mmlux_lv-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas medicīnu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_physics": {
      "task": "ogx_mmlux_lv-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-computer_security": {
      "task": "ogx_mmlux_lv-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par datoru drošību.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "task": "ogx_mmlux_lv-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par konceptuālo fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-econometrics": {
      "task": "ogx_mmlux_lv-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par ekonometriju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "task": "ogx_mmlux_lv-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par elektrotehniku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "task": "ogx_mmlux_lv-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par elementāro matemātiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-formal_logic": {
      "task": "ogx_mmlux_lv-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem par formālo loģiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-global_facts": {
      "task": "ogx_mmlux_lv-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par pasaules faktiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_biology": {
      "task": "ogx_mmlux_lv-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas bioloģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "task": "ogx_mmlux_lv-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas ķīmiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "task": "ogx_mmlux_lv-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas informātiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "task": "ogx_mmlux_lv-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas Eiropas vēsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_geography": {
      "task": "ogx_mmlux_lv-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas ģeogrāfiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "task": "ogx_mmlux_lv-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par valsts pārvaldi un politiku vidusskolā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "task": "ogx_mmlux_lv-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par makroekonomiku vidusskolā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "task": "ogx_mmlux_lv-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas matemātiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "task": "ogx_mmlux_lv-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par mikroekonomiku vidusskolā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_physics": {
      "task": "ogx_mmlux_lv-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "task": "ogx_mmlux_lv-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas psiholoģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "task": "ogx_mmlux_lv-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas statistiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "task": "ogx_mmlux_lv-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par ASV vidusskolas vēsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "task": "ogx_mmlux_lv-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par pasaules vēsturi vidusskolā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-human_aging": {
      "task": "ogx_mmlux_lv-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par cilvēka novecošanu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-human_sexuality": {
      "task": "ogx_mmlux_lv-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par cilvēka seksualitāti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-international_law": {
      "task": "ogx_mmlux_lv-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par starptautiskajām tiesībām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-jurisprudence": {
      "task": "ogx_mmlux_lv-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par jurisprudenci.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "task": "ogx_mmlux_lv-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par loģiskajām kļūdām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-machine_learning": {
      "task": "ogx_mmlux_lv-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par mašīnmācīšanos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-management": {
      "task": "ogx_mmlux_lv-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par vadību.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-marketing": {
      "task": "ogx_mmlux_lv-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par mārketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-medical_genetics": {
      "task": "ogx_mmlux_lv-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par medicīnas ģenētiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-miscellaneous": {
      "task": "ogx_mmlux_lv-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par dažādiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-moral_disputes": {
      "task": "ogx_mmlux_lv-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par morāles strīdiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "task": "ogx_mmlux_lv-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par morāles scenārijiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-nutrition": {
      "task": "ogx_mmlux_lv-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par uzturu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-philosophy": {
      "task": "ogx_mmlux_lv-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par filozofiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-prehistory": {
      "task": "ogx_mmlux_lv-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par aizvēsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_accounting": {
      "task": "ogx_mmlux_lv-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par profesionālo grāmatvedību.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_law": {
      "task": "ogx_mmlux_lv-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par profesionālajām tiesībām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_medicine": {
      "task": "ogx_mmlux_lv-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par profesionālo medicīnu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_psychology": {
      "task": "ogx_mmlux_lv-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par profesionālo psiholoģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-public_relations": {
      "task": "ogx_mmlux_lv-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par sabiedriskajām attiecībām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-security_studies": {
      "task": "ogx_mmlux_lv-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par drošības studijām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-sociology": {
      "task": "ogx_mmlux_lv-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmāk ir jautājumi ar atbilžu variantiem par socioloģiju (ar atbildēm).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "task": "ogx_mmlux_lv-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem par ASV ārpolitiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-virology": {
      "task": "ogx_mmlux_lv-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem par virusoloģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-world_religions": {
      "task": "ogx_mmlux_lv-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par pasaules reliģijām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "task": "ogx_mmlux_nl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over abstracte algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-anatomy": {
      "task": "ogx_mmlux_nl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-astronomy": {
      "task": "ogx_mmlux_nl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-business_ethics": {
      "task": "ogx_mmlux_nl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over bedrijfsethiek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "task": "ogx_mmlux_nl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over klinische kennis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_biology": {
      "task": "ogx_mmlux_nl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over biologie op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_chemistry": {
      "task": "ogx_mmlux_nl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over scheikunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_computer_science": {
      "task": "ogx_mmlux_nl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over informatica op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_mathematics": {
      "task": "ogx_mmlux_nl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wiskunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_medicine": {
      "task": "ogx_mmlux_nl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over geneeskunde aan de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_physics": {
      "task": "ogx_mmlux_nl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over natuurkunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-computer_security": {
      "task": "ogx_mmlux_nl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over computerbeveiliging.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "task": "ogx_mmlux_nl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over conceptuele fysica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-econometrics": {
      "task": "ogx_mmlux_nl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over econometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "task": "ogx_mmlux_nl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over elektrotechniek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "task": "ogx_mmlux_nl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over elementaire wiskunde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-formal_logic": {
      "task": "ogx_mmlux_nl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over formele logica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-global_facts": {
      "task": "ogx_mmlux_nl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over globale feiten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_biology": {
      "task": "ogx_mmlux_nl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over biologie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "task": "ogx_mmlux_nl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over scheikunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "task": "ogx_mmlux_nl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over informatica op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "task": "ogx_mmlux_nl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over Europese geschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_geography": {
      "task": "ogx_mmlux_nl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over aardrijkskunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "task": "ogx_mmlux_nl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over bestuur en politiek op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "task": "ogx_mmlux_nl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over macro-economie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "task": "ogx_mmlux_nl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wiskunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "task": "ogx_mmlux_nl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over micro-economie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_physics": {
      "task": "ogx_mmlux_nl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over natuurkunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "task": "ogx_mmlux_nl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over psychologie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "task": "ogx_mmlux_nl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over statistiek op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "task": "ogx_mmlux_nl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over geschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "task": "ogx_mmlux_nl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wereldgeschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-human_aging": {
      "task": "ogx_mmlux_nl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over menselijke veroudering.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-human_sexuality": {
      "task": "ogx_mmlux_nl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over menselijke seksualiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-international_law": {
      "task": "ogx_mmlux_nl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over internationaal recht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-jurisprudence": {
      "task": "ogx_mmlux_nl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over jurisprudentie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "task": "ogx_mmlux_nl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over logische drogredenen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-machine_learning": {
      "task": "ogx_mmlux_nl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over machinaal leren.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-management": {
      "task": "ogx_mmlux_nl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-marketing": {
      "task": "ogx_mmlux_nl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-medical_genetics": {
      "task": "ogx_mmlux_nl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over medische genetica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-miscellaneous": {
      "task": "ogx_mmlux_nl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over diversen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-moral_disputes": {
      "task": "ogx_mmlux_nl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over morele geschillen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "task": "ogx_mmlux_nl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over morele scenario's.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-nutrition": {
      "task": "ogx_mmlux_nl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over voeding.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-philosophy": {
      "task": "ogx_mmlux_nl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over filosofie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-prehistory": {
      "task": "ogx_mmlux_nl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over de prehistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_accounting": {
      "task": "ogx_mmlux_nl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over professioneel boekhouden.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_law": {
      "task": "ogx_mmlux_nl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over het beroepsrecht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_medicine": {
      "task": "ogx_mmlux_nl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over professionele geneeskunde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_psychology": {
      "task": "ogx_mmlux_nl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over professionele psychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-public_relations": {
      "task": "ogx_mmlux_nl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-security_studies": {
      "task": "ogx_mmlux_nl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over veiligheidsstudies.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-sociology": {
      "task": "ogx_mmlux_nl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "task": "ogx_mmlux_nl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over het buitenlands beleid van de Verenigde Staten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-virology": {
      "task": "ogx_mmlux_nl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-world_religions": {
      "task": "ogx_mmlux_nl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wereldreligies.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "task": "ogx_mmlux_pl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące algebry abstrakcyjnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-anatomy": {
      "task": "ogx_mmlux_pl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące anatomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-astronomy": {
      "task": "ogx_mmlux_pl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące astronomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-business_ethics": {
      "task": "ogx_mmlux_pl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące etyki biznesu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "task": "ogx_mmlux_pl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące wiedzy klinicznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_biology": {
      "task": "ogx_mmlux_pl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące biologii na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_chemistry": {
      "task": "ogx_mmlux_pl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące chemii na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_computer_science": {
      "task": "ogx_mmlux_pl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące informatyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_mathematics": {
      "task": "ogx_mmlux_pl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące matematyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_medicine": {
      "task": "ogx_mmlux_pl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące medycyny uniwersyteckiej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_physics": {
      "task": "ogx_mmlux_pl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące fizyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-computer_security": {
      "task": "ogx_mmlux_pl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące bezpieczeństwa komputerowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "task": "ogx_mmlux_pl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące fizyki konceptualnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-econometrics": {
      "task": "ogx_mmlux_pl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "task": "ogx_mmlux_pl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące inżynierii elektrycznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "task": "ogx_mmlux_pl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące matematyki elementarnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-formal_logic": {
      "task": "ogx_mmlux_pl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące logiki formalnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-global_facts": {
      "task": "ogx_mmlux_pl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące globalnych faktów.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_biology": {
      "task": "ogx_mmlux_pl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące biologii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "task": "ogx_mmlux_pl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące chemii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "task": "ogx_mmlux_pl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące informatyki w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "task": "ogx_mmlux_pl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące historii Europy w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_geography": {
      "task": "ogx_mmlux_pl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące geografii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "task": "ogx_mmlux_pl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące rządów i polityki w szkołach średnich.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "task": "ogx_mmlux_pl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące makroekonomii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "task": "ogx_mmlux_pl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące matematyki w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "task": "ogx_mmlux_pl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące mikroekonomii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_physics": {
      "task": "ogx_mmlux_pl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące fizyki w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "task": "ogx_mmlux_pl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące psychologii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "task": "ogx_mmlux_pl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące statystyki w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "task": "ogx_mmlux_pl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące historii Stanów Zjednoczonych w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "task": "ogx_mmlux_pl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące historii świata w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-human_aging": {
      "task": "ogx_mmlux_pl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące starzenia się człowieka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-human_sexuality": {
      "task": "ogx_mmlux_pl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące ludzkiej seksualności.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-international_law": {
      "task": "ogx_mmlux_pl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące prawa międzynarodowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-jurisprudence": {
      "task": "ogx_mmlux_pl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące orzecznictwa.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "task": "ogx_mmlux_pl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące błędów logicznych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-machine_learning": {
      "task": "ogx_mmlux_pl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące uczenia maszynowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-management": {
      "task": "ogx_mmlux_pl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące zarządzania.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-marketing": {
      "task": "ogx_mmlux_pl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-medical_genetics": {
      "task": "ogx_mmlux_pl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące genetyki medycznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-miscellaneous": {
      "task": "ogx_mmlux_pl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące różnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-moral_disputes": {
      "task": "ogx_mmlux_pl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące sporów moralnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "task": "ogx_mmlux_pl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące scenariuszy moralnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-nutrition": {
      "task": "ogx_mmlux_pl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące odżywiania.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-philosophy": {
      "task": "ogx_mmlux_pl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-prehistory": {
      "task": "ogx_mmlux_pl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące prehistorii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_accounting": {
      "task": "ogx_mmlux_pl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące profesjonalnej księgowości.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_law": {
      "task": "ogx_mmlux_pl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące prawa zawodowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_medicine": {
      "task": "ogx_mmlux_pl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące medycyny profesjonalnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_psychology": {
      "task": "ogx_mmlux_pl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące psychologii zawodowej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-public_relations": {
      "task": "ogx_mmlux_pl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-security_studies": {
      "task": "ogx_mmlux_pl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące studiów nad bezpieczeństwem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-sociology": {
      "task": "ogx_mmlux_pl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące socjologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "task": "ogx_mmlux_pl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące polityki zagranicznej Stanów Zjednoczonych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-virology": {
      "task": "ogx_mmlux_pl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące wirusologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-world_religions": {
      "task": "ogx_mmlux_pl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące religii świata.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "task": "ogx_mmlux_pt-pt-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre álgebra abstrata.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "task": "ogx_mmlux_pt-pt-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre anatomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "task": "ogx_mmlux_pt-pt-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre astronomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "task": "ogx_mmlux_pt-pt-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre ética empresarial.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "task": "ogx_mmlux_pt-pt-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre conhecimentos clínicos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "task": "ogx_mmlux_pt-pt-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes são de escolha múltipla (com respostas) sobre biologia universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "task": "ogx_mmlux_pt-pt-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes são de escolha múltipla (com respostas) sobre química universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "task": "ogx_mmlux_pt-pt-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre informática universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "task": "ogx_mmlux_pt-pt-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre matemática universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "task": "ogx_mmlux_pt-pt-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre medicina universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "task": "ogx_mmlux_pt-pt-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes são de escolha múltipla (com respostas) sobre física universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "task": "ogx_mmlux_pt-pt-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre segurança informática.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "task": "ogx_mmlux_pt-pt-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre física concetual.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "task": "ogx_mmlux_pt-pt-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre econometria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "task": "ogx_mmlux_pt-pt-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre engenharia eléctrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "task": "ogx_mmlux_pt-pt-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre matemática elementar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "task": "ogx_mmlux_pt-pt-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre lógica formal.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "task": "ogx_mmlux_pt-pt-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre factos globais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "task": "ogx_mmlux_pt-pt-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre biologia do ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "task": "ogx_mmlux_pt-pt-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre química no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "task": "ogx_mmlux_pt-pt-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre informática no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "task": "ogx_mmlux_pt-pt-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre história europeia no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "task": "ogx_mmlux_pt-pt-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre geografia do ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "task": "ogx_mmlux_pt-pt-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre governo e política no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "task": "ogx_mmlux_pt-pt-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre macroeconomia no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "task": "ogx_mmlux_pt-pt-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre matemática do ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "task": "ogx_mmlux_pt-pt-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre microeconomia no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "task": "ogx_mmlux_pt-pt-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre física do ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "task": "ogx_mmlux_pt-pt-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre psicologia no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "task": "ogx_mmlux_pt-pt-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre estatística no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "task": "ogx_mmlux_pt-pt-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre História dos EUA no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "task": "ogx_mmlux_pt-pt-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre história mundial no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "task": "ogx_mmlux_pt-pt-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre o envelhecimento humano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "task": "ogx_mmlux_pt-pt-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre a sexualidade humana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-international_law": {
      "task": "ogx_mmlux_pt-pt-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre direito internacional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "task": "ogx_mmlux_pt-pt-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre jurisprudência.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "task": "ogx_mmlux_pt-pt-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre falácias lógicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "task": "ogx_mmlux_pt-pt-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre aprendizagem automática.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-management": {
      "task": "ogx_mmlux_pt-pt-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre gestão.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-marketing": {
      "task": "ogx_mmlux_pt-pt-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "task": "ogx_mmlux_pt-pt-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre genética médica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "task": "ogx_mmlux_pt-pt-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre miscelânea.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "task": "ogx_mmlux_pt-pt-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre disputas morais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "task": "ogx_mmlux_pt-pt-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre cenários morais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "task": "ogx_mmlux_pt-pt-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre nutrição.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "task": "ogx_mmlux_pt-pt-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre filosofia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "task": "ogx_mmlux_pt-pt-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre a pré-história.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "task": "ogx_mmlux_pt-pt-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre contabilidade profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "task": "ogx_mmlux_pt-pt-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre direito profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "task": "ogx_mmlux_pt-pt-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre medicina profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "task": "ogx_mmlux_pt-pt-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre psicologia profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "task": "ogx_mmlux_pt-pt-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre relações públicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "task": "ogx_mmlux_pt-pt-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre estudos de segurança.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-sociology": {
      "task": "ogx_mmlux_pt-pt-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre sociologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "task": "ogx_mmlux_pt-pt-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes são de escolha múltipla (com respostas) sobre a política externa dos EUA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-virology": {
      "task": "ogx_mmlux_pt-pt-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre virologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "task": "ogx_mmlux_pt-pt-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre as religiões do mundo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "task": "ogx_mmlux_ro-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre algebra abstractă.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-anatomy": {
      "task": "ogx_mmlux_ro-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-astronomy": {
      "task": "ogx_mmlux_ro-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu răspunsuri multiple (cu răspunsuri) despre astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-business_ethics": {
      "task": "ogx_mmlux_ro-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre etica în afaceri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "task": "ogx_mmlux_ro-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre cunoștințele clinice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_biology": {
      "task": "ogx_mmlux_ro-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre biologia universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_chemistry": {
      "task": "ogx_mmlux_ro-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre chimia universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_computer_science": {
      "task": "ogx_mmlux_ro-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre informatică universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_mathematics": {
      "task": "ogx_mmlux_ro-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre matematica universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_medicine": {
      "task": "ogx_mmlux_ro-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre medicina universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_physics": {
      "task": "ogx_mmlux_ro-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre fizica universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-computer_security": {
      "task": "ogx_mmlux_ro-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre securitatea calculatoarelor.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "task": "ogx_mmlux_ro-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre fizica conceptuală.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-econometrics": {
      "task": "ogx_mmlux_ro-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre econometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "task": "ogx_mmlux_ro-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre inginerie electrică.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "task": "ogx_mmlux_ro-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre matematică elementară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-formal_logic": {
      "task": "ogx_mmlux_ro-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre logica formală.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-global_facts": {
      "task": "ogx_mmlux_ro-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre fapte globale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_biology": {
      "task": "ogx_mmlux_ro-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre biologia de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "task": "ogx_mmlux_ro-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre chimia de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "task": "ogx_mmlux_ro-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre informatică la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "task": "ogx_mmlux_ro-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre istoria europeană la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_geography": {
      "task": "ogx_mmlux_ro-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre geografia liceului.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "task": "ogx_mmlux_ro-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre guvernare și politică în liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "task": "ogx_mmlux_ro-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre macroeconomie la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "task": "ogx_mmlux_ro-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre matematica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "task": "ogx_mmlux_ro-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre microeconomie la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_physics": {
      "task": "ogx_mmlux_ro-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre fizica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "task": "ogx_mmlux_ro-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre psihologia liceului.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "task": "ogx_mmlux_ro-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre statistica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "task": "ogx_mmlux_ro-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre istoria noastră la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "task": "ogx_mmlux_ro-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre istoria universală de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-human_aging": {
      "task": "ogx_mmlux_ro-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre îmbătrânirea umană.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-human_sexuality": {
      "task": "ogx_mmlux_ro-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre sexualitatea umană.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-international_law": {
      "task": "ogx_mmlux_ro-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre dreptul internațional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-jurisprudence": {
      "task": "ogx_mmlux_ro-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre jurisprudență.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "task": "ogx_mmlux_ro-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre erori logice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-machine_learning": {
      "task": "ogx_mmlux_ro-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre învățarea automată.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-management": {
      "task": "ogx_mmlux_ro-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-marketing": {
      "task": "ogx_mmlux_ro-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-medical_genetics": {
      "task": "ogx_mmlux_ro-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre genetica medicală.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-miscellaneous": {
      "task": "ogx_mmlux_ro-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-moral_disputes": {
      "task": "ogx_mmlux_ro-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre disputele morale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "task": "ogx_mmlux_ro-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre scenarii morale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-nutrition": {
      "task": "ogx_mmlux_ro-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre nutriție.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-philosophy": {
      "task": "ogx_mmlux_ro-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre filosofie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-prehistory": {
      "task": "ogx_mmlux_ro-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre preistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_accounting": {
      "task": "ogx_mmlux_ro-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre contabilitatea profesională.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_law": {
      "task": "ogx_mmlux_ro-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre dreptul profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_medicine": {
      "task": "ogx_mmlux_ro-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre medicina profesională.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_psychology": {
      "task": "ogx_mmlux_ro-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre psihologia profesională.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-public_relations": {
      "task": "ogx_mmlux_ro-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre relațiile publice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-security_studies": {
      "task": "ogx_mmlux_ro-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre studiile de securitate.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-sociology": {
      "task": "ogx_mmlux_ro-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "task": "ogx_mmlux_ro-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre politica externă a SUA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-virology": {
      "task": "ogx_mmlux_ro-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre virusologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-world_religions": {
      "task": "ogx_mmlux_ro-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre religiile lumii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "task": "ogx_mmlux_sk-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o abstraktnej algebre.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-anatomy": {
      "task": "ogx_mmlux_sk-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o anatómii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-astronomy": {
      "task": "ogx_mmlux_sk-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o astronómii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-business_ethics": {
      "task": "ogx_mmlux_sk-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o etike v podnikaní.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "task": "ogx_mmlux_sk-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o klinických znalostiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_biology": {
      "task": "ogx_mmlux_sk-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o vysokoškolskej biológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_chemistry": {
      "task": "ogx_mmlux_sk-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o vysokoškolskej chémii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_computer_science": {
      "task": "ogx_mmlux_sk-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o informatike na vysokej škole.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_mathematics": {
      "task": "ogx_mmlux_sk-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o vysokoškolskej matematike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_medicine": {
      "task": "ogx_mmlux_sk-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o vysokoškolskej medicíne.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_physics": {
      "task": "ogx_mmlux_sk-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o vysokoškolskej fyzike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-computer_security": {
      "task": "ogx_mmlux_sk-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o počítačovej bezpečnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "task": "ogx_mmlux_sk-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o konceptuálnej fyzike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-econometrics": {
      "task": "ogx_mmlux_sk-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "task": "ogx_mmlux_sk-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o elektrotechnike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "task": "ogx_mmlux_sk-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o elementárnej matematike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-formal_logic": {
      "task": "ogx_mmlux_sk-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o formálnej logike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-global_facts": {
      "task": "ogx_mmlux_sk-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o globálnych faktoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_biology": {
      "task": "ogx_mmlux_sk-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolskej biológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "task": "ogx_mmlux_sk-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolskej chémii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "task": "ogx_mmlux_sk-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolskej informatike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "task": "ogx_mmlux_sk-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolských európskych dejinách.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_geography": {
      "task": "ogx_mmlux_sk-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o stredoškolskom zemepise.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "task": "ogx_mmlux_sk-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú vlády a politiky na stredných školách.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "task": "ogx_mmlux_sk-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o stredoškolskej makroekonómii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "task": "ogx_mmlux_sk-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú stredoškolskej matematiky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "task": "ogx_mmlux_sk-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) z mikroekonómie pre stredné školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_physics": {
      "task": "ogx_mmlux_sk-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) zo stredoškolskej fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "task": "ogx_mmlux_sk-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o stredoškolskej psychológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "task": "ogx_mmlux_sk-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú stredoškolskej štatistiky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "task": "ogx_mmlux_sk-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolskej histórii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "task": "ogx_mmlux_sk-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) zo svetových dejín na strednej škole.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-human_aging": {
      "task": "ogx_mmlux_sk-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o starnutí človeka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-human_sexuality": {
      "task": "ogx_mmlux_sk-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o ľudskej sexualite.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-international_law": {
      "task": "ogx_mmlux_sk-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o medzinárodnom práve.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-jurisprudence": {
      "task": "ogx_mmlux_sk-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú právnej vedy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "task": "ogx_mmlux_sk-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o logických klamoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-machine_learning": {
      "task": "ogx_mmlux_sk-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o strojovom učení.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-management": {
      "task": "ogx_mmlux_sk-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o manažmente.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-marketing": {
      "task": "ogx_mmlux_sk-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-medical_genetics": {
      "task": "ogx_mmlux_sk-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o lekárskej genetike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-miscellaneous": {
      "task": "ogx_mmlux_sk-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky s výberom odpovede sa týkajú rôzneho.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-moral_disputes": {
      "task": "ogx_mmlux_sk-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o morálnych sporoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "task": "ogx_mmlux_sk-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o morálnych scenároch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-nutrition": {
      "task": "ogx_mmlux_sk-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o výžive.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-philosophy": {
      "task": "ogx_mmlux_sk-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-prehistory": {
      "task": "ogx_mmlux_sk-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o prehistórii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_accounting": {
      "task": "ogx_mmlux_sk-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o odbornom účtovníctve.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_law": {
      "task": "ogx_mmlux_sk-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú profesijného práva.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_medicine": {
      "task": "ogx_mmlux_sk-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú profesionálnej medicíny.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_psychology": {
      "task": "ogx_mmlux_sk-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o profesionálnej psychológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-public_relations": {
      "task": "ogx_mmlux_sk-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o vzťahoch s verejnosťou.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-security_studies": {
      "task": "ogx_mmlux_sk-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o bezpečnostných štúdiách.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-sociology": {
      "task": "ogx_mmlux_sk-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o sociológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "task": "ogx_mmlux_sk-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky s výberom odpovede sa týkajú zahraničnej politiky USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-virology": {
      "task": "ogx_mmlux_sk-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o virológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-world_religions": {
      "task": "ogx_mmlux_sk-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o svetových náboženstvách.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "task": "ogx_mmlux_sl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o abstraktni algebri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-anatomy": {
      "task": "ogx_mmlux_sl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o anatomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-astronomy": {
      "task": "ogx_mmlux_sl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o astronomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-business_ethics": {
      "task": "ogx_mmlux_sl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o poslovni etiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "task": "ogx_mmlux_sl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o kliničnem znanju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_biology": {
      "task": "ogx_mmlux_sl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o biologiji na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_chemistry": {
      "task": "ogx_mmlux_sl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o kemiji na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_computer_science": {
      "task": "ogx_mmlux_sl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o računalništvu na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_mathematics": {
      "task": "ogx_mmlux_sl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o matematiki na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_medicine": {
      "task": "ogx_mmlux_sl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o univerzitetni medicini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_physics": {
      "task": "ogx_mmlux_sl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o fiziki na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-computer_security": {
      "task": "ogx_mmlux_sl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o računalniški varnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "task": "ogx_mmlux_sl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o konceptualni fiziki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-econometrics": {
      "task": "ogx_mmlux_sl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o ekonometriji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "task": "ogx_mmlux_sl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o elektrotehniki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "task": "ogx_mmlux_sl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o osnovni matematiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-formal_logic": {
      "task": "ogx_mmlux_sl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o formalni logiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-global_facts": {
      "task": "ogx_mmlux_sl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o globalnih dejstvih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_biology": {
      "task": "ogx_mmlux_sl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski biologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "task": "ogx_mmlux_sl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o kemiji v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "task": "ogx_mmlux_sl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o računalništvu v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "task": "ogx_mmlux_sl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o evropski zgodovini v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_geography": {
      "task": "ogx_mmlux_sl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o geografiji v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "task": "ogx_mmlux_sl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o vladi in politiki v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "task": "ogx_mmlux_sl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski makroekonomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "task": "ogx_mmlux_sl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o matematiki v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "task": "ogx_mmlux_sl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski mikroekonomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_physics": {
      "task": "ogx_mmlux_sl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) s področja srednješolske fizike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "task": "ogx_mmlux_sl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski psihologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "task": "ogx_mmlux_sl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski statistiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "task": "ogx_mmlux_sl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski zgodovini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "task": "ogx_mmlux_sl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o svetovni zgodovini v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-human_aging": {
      "task": "ogx_mmlux_sl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o staranju človeka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-human_sexuality": {
      "task": "ogx_mmlux_sl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o človeški spolnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-international_law": {
      "task": "ogx_mmlux_sl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o mednarodnem pravu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-jurisprudence": {
      "task": "ogx_mmlux_sl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o sodni praksi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "task": "ogx_mmlux_sl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o logičnih zmotah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-machine_learning": {
      "task": "ogx_mmlux_sl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o strojnem učenju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-management": {
      "task": "ogx_mmlux_sl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o upravljanju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-marketing": {
      "task": "ogx_mmlux_sl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o trženju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-medical_genetics": {
      "task": "ogx_mmlux_sl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o medicinski genetiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-miscellaneous": {
      "task": "ogx_mmlux_sl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o raznih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-moral_disputes": {
      "task": "ogx_mmlux_sl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o moralnih sporih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "task": "ogx_mmlux_sl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o moralnih scenarijih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-nutrition": {
      "task": "ogx_mmlux_sl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o prehrani.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-philosophy": {
      "task": "ogx_mmlux_sl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o filozofiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-prehistory": {
      "task": "ogx_mmlux_sl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o prazgodovini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_accounting": {
      "task": "ogx_mmlux_sl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o strokovnem računovodstvu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_law": {
      "task": "ogx_mmlux_sl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o poklicnem pravu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_medicine": {
      "task": "ogx_mmlux_sl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o poklicni medicini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_psychology": {
      "task": "ogx_mmlux_sl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o poklicni psihologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-public_relations": {
      "task": "ogx_mmlux_sl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o odnosih z javnostmi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-security_studies": {
      "task": "ogx_mmlux_sl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o varnostnih študijah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-sociology": {
      "task": "ogx_mmlux_sl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o sociologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "task": "ogx_mmlux_sl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o zunanji politiki ZDA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-virology": {
      "task": "ogx_mmlux_sl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o virologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-world_religions": {
      "task": "ogx_mmlux_sl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o svetovnih religijah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "task": "ogx_mmlux_sv-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om abstrakt algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-anatomy": {
      "task": "ogx_mmlux_sv-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om anatomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-astronomy": {
      "task": "ogx_mmlux_sv-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om astronomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-business_ethics": {
      "task": "ogx_mmlux_sv-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om affärsetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "task": "ogx_mmlux_sv-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om klinisk kunskap.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_biology": {
      "task": "ogx_mmlux_sv-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om biologi på högskolenivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_chemistry": {
      "task": "ogx_mmlux_sv-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om kemi på högskolenivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_computer_science": {
      "task": "ogx_mmlux_sv-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om datavetenskap på högskolenivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_mathematics": {
      "task": "ogx_mmlux_sv-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om matematik på högskolenivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_medicine": {
      "task": "ogx_mmlux_sv-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om universitetsmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_physics": {
      "task": "ogx_mmlux_sv-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om högskolefysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-computer_security": {
      "task": "ogx_mmlux_sv-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om datasäkerhet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "task": "ogx_mmlux_sv-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om konceptuell fysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-econometrics": {
      "task": "ogx_mmlux_sv-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om ekonometri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "task": "ogx_mmlux_sv-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om elektroteknik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "task": "ogx_mmlux_sv-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om elementär matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-formal_logic": {
      "task": "ogx_mmlux_sv-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om formell logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-global_facts": {
      "task": "ogx_mmlux_sv-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om globala fakta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_biology": {
      "task": "ogx_mmlux_sv-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om biologi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "task": "ogx_mmlux_sv-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om kemi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "task": "ogx_mmlux_sv-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om datavetenskap på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "task": "ogx_mmlux_sv-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om europeisk historia på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_geography": {
      "task": "ogx_mmlux_sv-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om geografi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "task": "ogx_mmlux_sv-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om regering och politik på gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "task": "ogx_mmlux_sv-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om makroekonomi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "task": "ogx_mmlux_sv-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om matematik på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "task": "ogx_mmlux_sv-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om mikroekonomi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_physics": {
      "task": "ogx_mmlux_sv-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om fysik på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "task": "ogx_mmlux_sv-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om psykologi på gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "task": "ogx_mmlux_sv-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om statistik på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "task": "ogx_mmlux_sv-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om historia i USA på gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "task": "ogx_mmlux_sv-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om världshistoria på gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-human_aging": {
      "task": "ogx_mmlux_sv-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om människans åldrande.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-human_sexuality": {
      "task": "ogx_mmlux_sv-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om mänsklig sexualitet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-international_law": {
      "task": "ogx_mmlux_sv-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om internationell rätt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-jurisprudence": {
      "task": "ogx_mmlux_sv-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om rättsvetenskap.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "task": "ogx_mmlux_sv-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om logiska felslut.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-machine_learning": {
      "task": "ogx_mmlux_sv-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om maskininlärning.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-management": {
      "task": "ogx_mmlux_sv-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-marketing": {
      "task": "ogx_mmlux_sv-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om marknadsföring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-medical_genetics": {
      "task": "ogx_mmlux_sv-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om medicinsk genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-miscellaneous": {
      "task": "ogx_mmlux_sv-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-moral_disputes": {
      "task": "ogx_mmlux_sv-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om moraliska tvister.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "task": "ogx_mmlux_sv-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om moraliska scenarier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-nutrition": {
      "task": "ogx_mmlux_sv-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om näringslära.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-philosophy": {
      "task": "ogx_mmlux_sv-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om filosofi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-prehistory": {
      "task": "ogx_mmlux_sv-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om förhistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_accounting": {
      "task": "ogx_mmlux_sv-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om professionell redovisning.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_law": {
      "task": "ogx_mmlux_sv-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om yrkesrätt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_medicine": {
      "task": "ogx_mmlux_sv-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om yrkesmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_psychology": {
      "task": "ogx_mmlux_sv-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om professionell psykologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-public_relations": {
      "task": "ogx_mmlux_sv-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-security_studies": {
      "task": "ogx_mmlux_sv-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om säkerhetsstudier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-sociology": {
      "task": "ogx_mmlux_sv-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om sociologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "task": "ogx_mmlux_sv-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om USA:s utrikespolitik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-virology": {
      "task": "ogx_mmlux_sv-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om virologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-world_religions": {
      "task": "ogx_mmlux_sv-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om världsreligioner.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    }
  },
  "versions": {
    "ogx_mmlux_bg-abstract_algebra": 0,
    "ogx_mmlux_bg-anatomy": 0,
    "ogx_mmlux_bg-astronomy": 0,
    "ogx_mmlux_bg-business_ethics": 0,
    "ogx_mmlux_bg-clinical_knowledge": 0,
    "ogx_mmlux_bg-college_biology": 0,
    "ogx_mmlux_bg-college_chemistry": 0,
    "ogx_mmlux_bg-college_computer_science": 0,
    "ogx_mmlux_bg-college_mathematics": 0,
    "ogx_mmlux_bg-college_medicine": 0,
    "ogx_mmlux_bg-college_physics": 0,
    "ogx_mmlux_bg-computer_security": 0,
    "ogx_mmlux_bg-conceptual_physics": 0,
    "ogx_mmlux_bg-econometrics": 0,
    "ogx_mmlux_bg-electrical_engineering": 0,
    "ogx_mmlux_bg-elementary_mathematics": 0,
    "ogx_mmlux_bg-formal_logic": 0,
    "ogx_mmlux_bg-global_facts": 0,
    "ogx_mmlux_bg-high_school_biology": 0,
    "ogx_mmlux_bg-high_school_chemistry": 0,
    "ogx_mmlux_bg-high_school_computer_science": 0,
    "ogx_mmlux_bg-high_school_european_history": 0,
    "ogx_mmlux_bg-high_school_geography": 0,
    "ogx_mmlux_bg-high_school_government_and_politics": 0,
    "ogx_mmlux_bg-high_school_macroeconomics": 0,
    "ogx_mmlux_bg-high_school_mathematics": 0,
    "ogx_mmlux_bg-high_school_microeconomics": 0,
    "ogx_mmlux_bg-high_school_physics": 0,
    "ogx_mmlux_bg-high_school_psychology": 0,
    "ogx_mmlux_bg-high_school_statistics": 0,
    "ogx_mmlux_bg-high_school_us_history": 0,
    "ogx_mmlux_bg-high_school_world_history": 0,
    "ogx_mmlux_bg-human_aging": 0,
    "ogx_mmlux_bg-human_sexuality": 0,
    "ogx_mmlux_bg-international_law": 0,
    "ogx_mmlux_bg-jurisprudence": 0,
    "ogx_mmlux_bg-logical_fallacies": 0,
    "ogx_mmlux_bg-machine_learning": 0,
    "ogx_mmlux_bg-management": 0,
    "ogx_mmlux_bg-marketing": 0,
    "ogx_mmlux_bg-medical_genetics": 0,
    "ogx_mmlux_bg-miscellaneous": 0,
    "ogx_mmlux_bg-moral_disputes": 0,
    "ogx_mmlux_bg-moral_scenarios": 0,
    "ogx_mmlux_bg-nutrition": 0,
    "ogx_mmlux_bg-philosophy": 0,
    "ogx_mmlux_bg-prehistory": 0,
    "ogx_mmlux_bg-professional_accounting": 0,
    "ogx_mmlux_bg-professional_law": 0,
    "ogx_mmlux_bg-professional_medicine": 0,
    "ogx_mmlux_bg-professional_psychology": 0,
    "ogx_mmlux_bg-public_relations": 0,
    "ogx_mmlux_bg-security_studies": 0,
    "ogx_mmlux_bg-sociology": 0,
    "ogx_mmlux_bg-us_foreign_policy": 0,
    "ogx_mmlux_bg-virology": 0,
    "ogx_mmlux_bg-world_religions": 0,
    "ogx_mmlux_cs-abstract_algebra": 0,
    "ogx_mmlux_cs-anatomy": 0,
    "ogx_mmlux_cs-astronomy": 0,
    "ogx_mmlux_cs-business_ethics": 0,
    "ogx_mmlux_cs-clinical_knowledge": 0,
    "ogx_mmlux_cs-college_biology": 0,
    "ogx_mmlux_cs-college_chemistry": 0,
    "ogx_mmlux_cs-college_computer_science": 0,
    "ogx_mmlux_cs-college_mathematics": 0,
    "ogx_mmlux_cs-college_medicine": 0,
    "ogx_mmlux_cs-college_physics": 0,
    "ogx_mmlux_cs-computer_security": 0,
    "ogx_mmlux_cs-conceptual_physics": 0,
    "ogx_mmlux_cs-econometrics": 0,
    "ogx_mmlux_cs-electrical_engineering": 0,
    "ogx_mmlux_cs-elementary_mathematics": 0,
    "ogx_mmlux_cs-formal_logic": 0,
    "ogx_mmlux_cs-global_facts": 0,
    "ogx_mmlux_cs-high_school_biology": 0,
    "ogx_mmlux_cs-high_school_chemistry": 0,
    "ogx_mmlux_cs-high_school_computer_science": 0,
    "ogx_mmlux_cs-high_school_european_history": 0,
    "ogx_mmlux_cs-high_school_geography": 0,
    "ogx_mmlux_cs-high_school_government_and_politics": 0,
    "ogx_mmlux_cs-high_school_macroeconomics": 0,
    "ogx_mmlux_cs-high_school_mathematics": 0,
    "ogx_mmlux_cs-high_school_microeconomics": 0,
    "ogx_mmlux_cs-high_school_physics": 0,
    "ogx_mmlux_cs-high_school_psychology": 0,
    "ogx_mmlux_cs-high_school_statistics": 0,
    "ogx_mmlux_cs-high_school_us_history": 0,
    "ogx_mmlux_cs-high_school_world_history": 0,
    "ogx_mmlux_cs-human_aging": 0,
    "ogx_mmlux_cs-human_sexuality": 0,
    "ogx_mmlux_cs-international_law": 0,
    "ogx_mmlux_cs-jurisprudence": 0,
    "ogx_mmlux_cs-logical_fallacies": 0,
    "ogx_mmlux_cs-machine_learning": 0,
    "ogx_mmlux_cs-management": 0,
    "ogx_mmlux_cs-marketing": 0,
    "ogx_mmlux_cs-medical_genetics": 0,
    "ogx_mmlux_cs-miscellaneous": 0,
    "ogx_mmlux_cs-moral_disputes": 0,
    "ogx_mmlux_cs-moral_scenarios": 0,
    "ogx_mmlux_cs-nutrition": 0,
    "ogx_mmlux_cs-philosophy": 0,
    "ogx_mmlux_cs-prehistory": 0,
    "ogx_mmlux_cs-professional_accounting": 0,
    "ogx_mmlux_cs-professional_law": 0,
    "ogx_mmlux_cs-professional_medicine": 0,
    "ogx_mmlux_cs-professional_psychology": 0,
    "ogx_mmlux_cs-public_relations": 0,
    "ogx_mmlux_cs-security_studies": 0,
    "ogx_mmlux_cs-sociology": 0,
    "ogx_mmlux_cs-us_foreign_policy": 0,
    "ogx_mmlux_cs-virology": 0,
    "ogx_mmlux_cs-world_religions": 0,
    "ogx_mmlux_da-abstract_algebra": 0,
    "ogx_mmlux_da-anatomy": 0,
    "ogx_mmlux_da-astronomy": 0,
    "ogx_mmlux_da-business_ethics": 0,
    "ogx_mmlux_da-clinical_knowledge": 0,
    "ogx_mmlux_da-college_biology": 0,
    "ogx_mmlux_da-college_chemistry": 0,
    "ogx_mmlux_da-college_computer_science": 0,
    "ogx_mmlux_da-college_mathematics": 0,
    "ogx_mmlux_da-college_medicine": 0,
    "ogx_mmlux_da-college_physics": 0,
    "ogx_mmlux_da-computer_security": 0,
    "ogx_mmlux_da-conceptual_physics": 0,
    "ogx_mmlux_da-econometrics": 0,
    "ogx_mmlux_da-electrical_engineering": 0,
    "ogx_mmlux_da-elementary_mathematics": 0,
    "ogx_mmlux_da-formal_logic": 0,
    "ogx_mmlux_da-global_facts": 0,
    "ogx_mmlux_da-high_school_biology": 0,
    "ogx_mmlux_da-high_school_chemistry": 0,
    "ogx_mmlux_da-high_school_computer_science": 0,
    "ogx_mmlux_da-high_school_european_history": 0,
    "ogx_mmlux_da-high_school_geography": 0,
    "ogx_mmlux_da-high_school_government_and_politics": 0,
    "ogx_mmlux_da-high_school_macroeconomics": 0,
    "ogx_mmlux_da-high_school_mathematics": 0,
    "ogx_mmlux_da-high_school_microeconomics": 0,
    "ogx_mmlux_da-high_school_physics": 0,
    "ogx_mmlux_da-high_school_psychology": 0,
    "ogx_mmlux_da-high_school_statistics": 0,
    "ogx_mmlux_da-high_school_us_history": 0,
    "ogx_mmlux_da-high_school_world_history": 0,
    "ogx_mmlux_da-human_aging": 0,
    "ogx_mmlux_da-human_sexuality": 0,
    "ogx_mmlux_da-international_law": 0,
    "ogx_mmlux_da-jurisprudence": 0,
    "ogx_mmlux_da-logical_fallacies": 0,
    "ogx_mmlux_da-machine_learning": 0,
    "ogx_mmlux_da-management": 0,
    "ogx_mmlux_da-marketing": 0,
    "ogx_mmlux_da-medical_genetics": 0,
    "ogx_mmlux_da-miscellaneous": 0,
    "ogx_mmlux_da-moral_disputes": 0,
    "ogx_mmlux_da-moral_scenarios": 0,
    "ogx_mmlux_da-nutrition": 0,
    "ogx_mmlux_da-philosophy": 0,
    "ogx_mmlux_da-prehistory": 0,
    "ogx_mmlux_da-professional_accounting": 0,
    "ogx_mmlux_da-professional_law": 0,
    "ogx_mmlux_da-professional_medicine": 0,
    "ogx_mmlux_da-professional_psychology": 0,
    "ogx_mmlux_da-public_relations": 0,
    "ogx_mmlux_da-security_studies": 0,
    "ogx_mmlux_da-sociology": 0,
    "ogx_mmlux_da-us_foreign_policy": 0,
    "ogx_mmlux_da-virology": 0,
    "ogx_mmlux_da-world_religions": 0,
    "ogx_mmlux_de-abstract_algebra": 0,
    "ogx_mmlux_de-anatomy": 0,
    "ogx_mmlux_de-astronomy": 0,
    "ogx_mmlux_de-business_ethics": 0,
    "ogx_mmlux_de-clinical_knowledge": 0,
    "ogx_mmlux_de-college_biology": 0,
    "ogx_mmlux_de-college_chemistry": 0,
    "ogx_mmlux_de-college_computer_science": 0,
    "ogx_mmlux_de-college_mathematics": 0,
    "ogx_mmlux_de-college_medicine": 0,
    "ogx_mmlux_de-college_physics": 0,
    "ogx_mmlux_de-computer_security": 0,
    "ogx_mmlux_de-conceptual_physics": 0,
    "ogx_mmlux_de-econometrics": 0,
    "ogx_mmlux_de-electrical_engineering": 0,
    "ogx_mmlux_de-elementary_mathematics": 0,
    "ogx_mmlux_de-formal_logic": 0,
    "ogx_mmlux_de-global_facts": 0,
    "ogx_mmlux_de-high_school_biology": 0,
    "ogx_mmlux_de-high_school_chemistry": 0,
    "ogx_mmlux_de-high_school_computer_science": 0,
    "ogx_mmlux_de-high_school_european_history": 0,
    "ogx_mmlux_de-high_school_geography": 0,
    "ogx_mmlux_de-high_school_government_and_politics": 0,
    "ogx_mmlux_de-high_school_macroeconomics": 0,
    "ogx_mmlux_de-high_school_mathematics": 0,
    "ogx_mmlux_de-high_school_microeconomics": 0,
    "ogx_mmlux_de-high_school_physics": 0,
    "ogx_mmlux_de-high_school_psychology": 0,
    "ogx_mmlux_de-high_school_statistics": 0,
    "ogx_mmlux_de-high_school_us_history": 0,
    "ogx_mmlux_de-high_school_world_history": 0,
    "ogx_mmlux_de-human_aging": 0,
    "ogx_mmlux_de-human_sexuality": 0,
    "ogx_mmlux_de-international_law": 0,
    "ogx_mmlux_de-jurisprudence": 0,
    "ogx_mmlux_de-logical_fallacies": 0,
    "ogx_mmlux_de-machine_learning": 0,
    "ogx_mmlux_de-management": 0,
    "ogx_mmlux_de-marketing": 0,
    "ogx_mmlux_de-medical_genetics": 0,
    "ogx_mmlux_de-miscellaneous": 0,
    "ogx_mmlux_de-moral_disputes": 0,
    "ogx_mmlux_de-moral_scenarios": 0,
    "ogx_mmlux_de-nutrition": 0,
    "ogx_mmlux_de-philosophy": 0,
    "ogx_mmlux_de-prehistory": 0,
    "ogx_mmlux_de-professional_accounting": 0,
    "ogx_mmlux_de-professional_law": 0,
    "ogx_mmlux_de-professional_medicine": 0,
    "ogx_mmlux_de-professional_psychology": 0,
    "ogx_mmlux_de-public_relations": 0,
    "ogx_mmlux_de-security_studies": 0,
    "ogx_mmlux_de-sociology": 0,
    "ogx_mmlux_de-us_foreign_policy": 0,
    "ogx_mmlux_de-virology": 0,
    "ogx_mmlux_de-world_religions": 0,
    "ogx_mmlux_el-abstract_algebra": 0,
    "ogx_mmlux_el-anatomy": 0,
    "ogx_mmlux_el-astronomy": 0,
    "ogx_mmlux_el-business_ethics": 0,
    "ogx_mmlux_el-clinical_knowledge": 0,
    "ogx_mmlux_el-college_biology": 0,
    "ogx_mmlux_el-college_chemistry": 0,
    "ogx_mmlux_el-college_computer_science": 0,
    "ogx_mmlux_el-college_mathematics": 0,
    "ogx_mmlux_el-college_medicine": 0,
    "ogx_mmlux_el-college_physics": 0,
    "ogx_mmlux_el-computer_security": 0,
    "ogx_mmlux_el-conceptual_physics": 0,
    "ogx_mmlux_el-econometrics": 0,
    "ogx_mmlux_el-electrical_engineering": 0,
    "ogx_mmlux_el-elementary_mathematics": 0,
    "ogx_mmlux_el-formal_logic": 0,
    "ogx_mmlux_el-global_facts": 0,
    "ogx_mmlux_el-high_school_biology": 0,
    "ogx_mmlux_el-high_school_chemistry": 0,
    "ogx_mmlux_el-high_school_computer_science": 0,
    "ogx_mmlux_el-high_school_european_history": 0,
    "ogx_mmlux_el-high_school_geography": 0,
    "ogx_mmlux_el-high_school_government_and_politics": 0,
    "ogx_mmlux_el-high_school_macroeconomics": 0,
    "ogx_mmlux_el-high_school_mathematics": 0,
    "ogx_mmlux_el-high_school_microeconomics": 0,
    "ogx_mmlux_el-high_school_physics": 0,
    "ogx_mmlux_el-high_school_psychology": 0,
    "ogx_mmlux_el-high_school_statistics": 0,
    "ogx_mmlux_el-high_school_us_history": 0,
    "ogx_mmlux_el-high_school_world_history": 0,
    "ogx_mmlux_el-human_aging": 0,
    "ogx_mmlux_el-human_sexuality": 0,
    "ogx_mmlux_el-international_law": 0,
    "ogx_mmlux_el-jurisprudence": 0,
    "ogx_mmlux_el-logical_fallacies": 0,
    "ogx_mmlux_el-machine_learning": 0,
    "ogx_mmlux_el-management": 0,
    "ogx_mmlux_el-marketing": 0,
    "ogx_mmlux_el-medical_genetics": 0,
    "ogx_mmlux_el-miscellaneous": 0,
    "ogx_mmlux_el-moral_disputes": 0,
    "ogx_mmlux_el-moral_scenarios": 0,
    "ogx_mmlux_el-nutrition": 0,
    "ogx_mmlux_el-philosophy": 0,
    "ogx_mmlux_el-prehistory": 0,
    "ogx_mmlux_el-professional_accounting": 0,
    "ogx_mmlux_el-professional_law": 0,
    "ogx_mmlux_el-professional_medicine": 0,
    "ogx_mmlux_el-professional_psychology": 0,
    "ogx_mmlux_el-public_relations": 0,
    "ogx_mmlux_el-security_studies": 0,
    "ogx_mmlux_el-sociology": 0,
    "ogx_mmlux_el-us_foreign_policy": 0,
    "ogx_mmlux_el-virology": 0,
    "ogx_mmlux_el-world_religions": 0,
    "ogx_mmlux_es-abstract_algebra": 0,
    "ogx_mmlux_es-anatomy": 0,
    "ogx_mmlux_es-astronomy": 0,
    "ogx_mmlux_es-business_ethics": 0,
    "ogx_mmlux_es-clinical_knowledge": 0,
    "ogx_mmlux_es-college_biology": 0,
    "ogx_mmlux_es-college_chemistry": 0,
    "ogx_mmlux_es-college_computer_science": 0,
    "ogx_mmlux_es-college_mathematics": 0,
    "ogx_mmlux_es-college_medicine": 0,
    "ogx_mmlux_es-college_physics": 0,
    "ogx_mmlux_es-computer_security": 0,
    "ogx_mmlux_es-conceptual_physics": 0,
    "ogx_mmlux_es-econometrics": 0,
    "ogx_mmlux_es-electrical_engineering": 0,
    "ogx_mmlux_es-elementary_mathematics": 0,
    "ogx_mmlux_es-formal_logic": 0,
    "ogx_mmlux_es-global_facts": 0,
    "ogx_mmlux_es-high_school_biology": 0,
    "ogx_mmlux_es-high_school_chemistry": 0,
    "ogx_mmlux_es-high_school_computer_science": 0,
    "ogx_mmlux_es-high_school_european_history": 0,
    "ogx_mmlux_es-high_school_geography": 0,
    "ogx_mmlux_es-high_school_government_and_politics": 0,
    "ogx_mmlux_es-high_school_macroeconomics": 0,
    "ogx_mmlux_es-high_school_mathematics": 0,
    "ogx_mmlux_es-high_school_microeconomics": 0,
    "ogx_mmlux_es-high_school_physics": 0,
    "ogx_mmlux_es-high_school_psychology": 0,
    "ogx_mmlux_es-high_school_statistics": 0,
    "ogx_mmlux_es-high_school_us_history": 0,
    "ogx_mmlux_es-high_school_world_history": 0,
    "ogx_mmlux_es-human_aging": 0,
    "ogx_mmlux_es-human_sexuality": 0,
    "ogx_mmlux_es-international_law": 0,
    "ogx_mmlux_es-jurisprudence": 0,
    "ogx_mmlux_es-logical_fallacies": 0,
    "ogx_mmlux_es-machine_learning": 0,
    "ogx_mmlux_es-management": 0,
    "ogx_mmlux_es-marketing": 0,
    "ogx_mmlux_es-medical_genetics": 0,
    "ogx_mmlux_es-miscellaneous": 0,
    "ogx_mmlux_es-moral_disputes": 0,
    "ogx_mmlux_es-moral_scenarios": 0,
    "ogx_mmlux_es-nutrition": 0,
    "ogx_mmlux_es-philosophy": 0,
    "ogx_mmlux_es-prehistory": 0,
    "ogx_mmlux_es-professional_accounting": 0,
    "ogx_mmlux_es-professional_law": 0,
    "ogx_mmlux_es-professional_medicine": 0,
    "ogx_mmlux_es-professional_psychology": 0,
    "ogx_mmlux_es-public_relations": 0,
    "ogx_mmlux_es-security_studies": 0,
    "ogx_mmlux_es-sociology": 0,
    "ogx_mmlux_es-us_foreign_policy": 0,
    "ogx_mmlux_es-virology": 0,
    "ogx_mmlux_es-world_religions": 0,
    "ogx_mmlux_et-abstract_algebra": 0,
    "ogx_mmlux_et-anatomy": 0,
    "ogx_mmlux_et-astronomy": 0,
    "ogx_mmlux_et-business_ethics": 0,
    "ogx_mmlux_et-clinical_knowledge": 0,
    "ogx_mmlux_et-college_biology": 0,
    "ogx_mmlux_et-college_chemistry": 0,
    "ogx_mmlux_et-college_computer_science": 0,
    "ogx_mmlux_et-college_mathematics": 0,
    "ogx_mmlux_et-college_medicine": 0,
    "ogx_mmlux_et-college_physics": 0,
    "ogx_mmlux_et-computer_security": 0,
    "ogx_mmlux_et-conceptual_physics": 0,
    "ogx_mmlux_et-econometrics": 0,
    "ogx_mmlux_et-electrical_engineering": 0,
    "ogx_mmlux_et-elementary_mathematics": 0,
    "ogx_mmlux_et-formal_logic": 0,
    "ogx_mmlux_et-global_facts": 0,
    "ogx_mmlux_et-high_school_biology": 0,
    "ogx_mmlux_et-high_school_chemistry": 0,
    "ogx_mmlux_et-high_school_computer_science": 0,
    "ogx_mmlux_et-high_school_european_history": 0,
    "ogx_mmlux_et-high_school_geography": 0,
    "ogx_mmlux_et-high_school_government_and_politics": 0,
    "ogx_mmlux_et-high_school_macroeconomics": 0,
    "ogx_mmlux_et-high_school_mathematics": 0,
    "ogx_mmlux_et-high_school_microeconomics": 0,
    "ogx_mmlux_et-high_school_physics": 0,
    "ogx_mmlux_et-high_school_psychology": 0,
    "ogx_mmlux_et-high_school_statistics": 0,
    "ogx_mmlux_et-high_school_us_history": 0,
    "ogx_mmlux_et-high_school_world_history": 0,
    "ogx_mmlux_et-human_aging": 0,
    "ogx_mmlux_et-human_sexuality": 0,
    "ogx_mmlux_et-international_law": 0,
    "ogx_mmlux_et-jurisprudence": 0,
    "ogx_mmlux_et-logical_fallacies": 0,
    "ogx_mmlux_et-machine_learning": 0,
    "ogx_mmlux_et-management": 0,
    "ogx_mmlux_et-marketing": 0,
    "ogx_mmlux_et-medical_genetics": 0,
    "ogx_mmlux_et-miscellaneous": 0,
    "ogx_mmlux_et-moral_disputes": 0,
    "ogx_mmlux_et-moral_scenarios": 0,
    "ogx_mmlux_et-nutrition": 0,
    "ogx_mmlux_et-philosophy": 0,
    "ogx_mmlux_et-prehistory": 0,
    "ogx_mmlux_et-professional_accounting": 0,
    "ogx_mmlux_et-professional_law": 0,
    "ogx_mmlux_et-professional_medicine": 0,
    "ogx_mmlux_et-professional_psychology": 0,
    "ogx_mmlux_et-public_relations": 0,
    "ogx_mmlux_et-security_studies": 0,
    "ogx_mmlux_et-sociology": 0,
    "ogx_mmlux_et-us_foreign_policy": 0,
    "ogx_mmlux_et-virology": 0,
    "ogx_mmlux_et-world_religions": 0,
    "ogx_mmlux_fi-abstract_algebra": 0,
    "ogx_mmlux_fi-anatomy": 0,
    "ogx_mmlux_fi-astronomy": 0,
    "ogx_mmlux_fi-business_ethics": 0,
    "ogx_mmlux_fi-clinical_knowledge": 0,
    "ogx_mmlux_fi-college_biology": 0,
    "ogx_mmlux_fi-college_chemistry": 0,
    "ogx_mmlux_fi-college_computer_science": 0,
    "ogx_mmlux_fi-college_mathematics": 0,
    "ogx_mmlux_fi-college_medicine": 0,
    "ogx_mmlux_fi-college_physics": 0,
    "ogx_mmlux_fi-computer_security": 0,
    "ogx_mmlux_fi-conceptual_physics": 0,
    "ogx_mmlux_fi-econometrics": 0,
    "ogx_mmlux_fi-electrical_engineering": 0,
    "ogx_mmlux_fi-elementary_mathematics": 0,
    "ogx_mmlux_fi-formal_logic": 0,
    "ogx_mmlux_fi-global_facts": 0,
    "ogx_mmlux_fi-high_school_biology": 0,
    "ogx_mmlux_fi-high_school_chemistry": 0,
    "ogx_mmlux_fi-high_school_computer_science": 0,
    "ogx_mmlux_fi-high_school_european_history": 0,
    "ogx_mmlux_fi-high_school_geography": 0,
    "ogx_mmlux_fi-high_school_government_and_politics": 0,
    "ogx_mmlux_fi-high_school_macroeconomics": 0,
    "ogx_mmlux_fi-high_school_mathematics": 0,
    "ogx_mmlux_fi-high_school_microeconomics": 0,
    "ogx_mmlux_fi-high_school_physics": 0,
    "ogx_mmlux_fi-high_school_psychology": 0,
    "ogx_mmlux_fi-high_school_statistics": 0,
    "ogx_mmlux_fi-high_school_us_history": 0,
    "ogx_mmlux_fi-high_school_world_history": 0,
    "ogx_mmlux_fi-human_aging": 0,
    "ogx_mmlux_fi-human_sexuality": 0,
    "ogx_mmlux_fi-international_law": 0,
    "ogx_mmlux_fi-jurisprudence": 0,
    "ogx_mmlux_fi-logical_fallacies": 0,
    "ogx_mmlux_fi-machine_learning": 0,
    "ogx_mmlux_fi-management": 0,
    "ogx_mmlux_fi-marketing": 0,
    "ogx_mmlux_fi-medical_genetics": 0,
    "ogx_mmlux_fi-miscellaneous": 0,
    "ogx_mmlux_fi-moral_disputes": 0,
    "ogx_mmlux_fi-moral_scenarios": 0,
    "ogx_mmlux_fi-nutrition": 0,
    "ogx_mmlux_fi-philosophy": 0,
    "ogx_mmlux_fi-prehistory": 0,
    "ogx_mmlux_fi-professional_accounting": 0,
    "ogx_mmlux_fi-professional_law": 0,
    "ogx_mmlux_fi-professional_medicine": 0,
    "ogx_mmlux_fi-professional_psychology": 0,
    "ogx_mmlux_fi-public_relations": 0,
    "ogx_mmlux_fi-security_studies": 0,
    "ogx_mmlux_fi-sociology": 0,
    "ogx_mmlux_fi-us_foreign_policy": 0,
    "ogx_mmlux_fi-virology": 0,
    "ogx_mmlux_fi-world_religions": 0,
    "ogx_mmlux_fr-abstract_algebra": 0,
    "ogx_mmlux_fr-anatomy": 0,
    "ogx_mmlux_fr-astronomy": 0,
    "ogx_mmlux_fr-business_ethics": 0,
    "ogx_mmlux_fr-clinical_knowledge": 0,
    "ogx_mmlux_fr-college_biology": 0,
    "ogx_mmlux_fr-college_chemistry": 0,
    "ogx_mmlux_fr-college_computer_science": 0,
    "ogx_mmlux_fr-college_mathematics": 0,
    "ogx_mmlux_fr-college_medicine": 0,
    "ogx_mmlux_fr-college_physics": 0,
    "ogx_mmlux_fr-computer_security": 0,
    "ogx_mmlux_fr-conceptual_physics": 0,
    "ogx_mmlux_fr-econometrics": 0,
    "ogx_mmlux_fr-electrical_engineering": 0,
    "ogx_mmlux_fr-elementary_mathematics": 0,
    "ogx_mmlux_fr-formal_logic": 0,
    "ogx_mmlux_fr-global_facts": 0,
    "ogx_mmlux_fr-high_school_biology": 0,
    "ogx_mmlux_fr-high_school_chemistry": 0,
    "ogx_mmlux_fr-high_school_computer_science": 0,
    "ogx_mmlux_fr-high_school_european_history": 0,
    "ogx_mmlux_fr-high_school_geography": 0,
    "ogx_mmlux_fr-high_school_government_and_politics": 0,
    "ogx_mmlux_fr-high_school_macroeconomics": 0,
    "ogx_mmlux_fr-high_school_mathematics": 0,
    "ogx_mmlux_fr-high_school_microeconomics": 0,
    "ogx_mmlux_fr-high_school_physics": 0,
    "ogx_mmlux_fr-high_school_psychology": 0,
    "ogx_mmlux_fr-high_school_statistics": 0,
    "ogx_mmlux_fr-high_school_us_history": 0,
    "ogx_mmlux_fr-high_school_world_history": 0,
    "ogx_mmlux_fr-human_aging": 0,
    "ogx_mmlux_fr-human_sexuality": 0,
    "ogx_mmlux_fr-international_law": 0,
    "ogx_mmlux_fr-jurisprudence": 0,
    "ogx_mmlux_fr-logical_fallacies": 0,
    "ogx_mmlux_fr-machine_learning": 0,
    "ogx_mmlux_fr-management": 0,
    "ogx_mmlux_fr-marketing": 0,
    "ogx_mmlux_fr-medical_genetics": 0,
    "ogx_mmlux_fr-miscellaneous": 0,
    "ogx_mmlux_fr-moral_disputes": 0,
    "ogx_mmlux_fr-moral_scenarios": 0,
    "ogx_mmlux_fr-nutrition": 0,
    "ogx_mmlux_fr-philosophy": 0,
    "ogx_mmlux_fr-prehistory": 0,
    "ogx_mmlux_fr-professional_accounting": 0,
    "ogx_mmlux_fr-professional_law": 0,
    "ogx_mmlux_fr-professional_medicine": 0,
    "ogx_mmlux_fr-professional_psychology": 0,
    "ogx_mmlux_fr-public_relations": 0,
    "ogx_mmlux_fr-security_studies": 0,
    "ogx_mmlux_fr-sociology": 0,
    "ogx_mmlux_fr-us_foreign_policy": 0,
    "ogx_mmlux_fr-virology": 0,
    "ogx_mmlux_fr-world_religions": 0,
    "ogx_mmlux_hu-abstract_algebra": 0,
    "ogx_mmlux_hu-anatomy": 0,
    "ogx_mmlux_hu-astronomy": 0,
    "ogx_mmlux_hu-business_ethics": 0,
    "ogx_mmlux_hu-clinical_knowledge": 0,
    "ogx_mmlux_hu-college_biology": 0,
    "ogx_mmlux_hu-college_chemistry": 0,
    "ogx_mmlux_hu-college_computer_science": 0,
    "ogx_mmlux_hu-college_mathematics": 0,
    "ogx_mmlux_hu-college_medicine": 0,
    "ogx_mmlux_hu-college_physics": 0,
    "ogx_mmlux_hu-computer_security": 0,
    "ogx_mmlux_hu-conceptual_physics": 0,
    "ogx_mmlux_hu-econometrics": 0,
    "ogx_mmlux_hu-electrical_engineering": 0,
    "ogx_mmlux_hu-elementary_mathematics": 0,
    "ogx_mmlux_hu-formal_logic": 0,
    "ogx_mmlux_hu-global_facts": 0,
    "ogx_mmlux_hu-high_school_biology": 0,
    "ogx_mmlux_hu-high_school_chemistry": 0,
    "ogx_mmlux_hu-high_school_computer_science": 0,
    "ogx_mmlux_hu-high_school_european_history": 0,
    "ogx_mmlux_hu-high_school_geography": 0,
    "ogx_mmlux_hu-high_school_government_and_politics": 0,
    "ogx_mmlux_hu-high_school_macroeconomics": 0,
    "ogx_mmlux_hu-high_school_mathematics": 0,
    "ogx_mmlux_hu-high_school_microeconomics": 0,
    "ogx_mmlux_hu-high_school_physics": 0,
    "ogx_mmlux_hu-high_school_psychology": 0,
    "ogx_mmlux_hu-high_school_statistics": 0,
    "ogx_mmlux_hu-high_school_us_history": 0,
    "ogx_mmlux_hu-high_school_world_history": 0,
    "ogx_mmlux_hu-human_aging": 0,
    "ogx_mmlux_hu-human_sexuality": 0,
    "ogx_mmlux_hu-international_law": 0,
    "ogx_mmlux_hu-jurisprudence": 0,
    "ogx_mmlux_hu-logical_fallacies": 0,
    "ogx_mmlux_hu-machine_learning": 0,
    "ogx_mmlux_hu-management": 0,
    "ogx_mmlux_hu-marketing": 0,
    "ogx_mmlux_hu-medical_genetics": 0,
    "ogx_mmlux_hu-miscellaneous": 0,
    "ogx_mmlux_hu-moral_disputes": 0,
    "ogx_mmlux_hu-moral_scenarios": 0,
    "ogx_mmlux_hu-nutrition": 0,
    "ogx_mmlux_hu-philosophy": 0,
    "ogx_mmlux_hu-prehistory": 0,
    "ogx_mmlux_hu-professional_accounting": 0,
    "ogx_mmlux_hu-professional_law": 0,
    "ogx_mmlux_hu-professional_medicine": 0,
    "ogx_mmlux_hu-professional_psychology": 0,
    "ogx_mmlux_hu-public_relations": 0,
    "ogx_mmlux_hu-security_studies": 0,
    "ogx_mmlux_hu-sociology": 0,
    "ogx_mmlux_hu-us_foreign_policy": 0,
    "ogx_mmlux_hu-virology": 0,
    "ogx_mmlux_hu-world_religions": 0,
    "ogx_mmlux_it-abstract_algebra": 0,
    "ogx_mmlux_it-anatomy": 0,
    "ogx_mmlux_it-astronomy": 0,
    "ogx_mmlux_it-business_ethics": 0,
    "ogx_mmlux_it-clinical_knowledge": 0,
    "ogx_mmlux_it-college_biology": 0,
    "ogx_mmlux_it-college_chemistry": 0,
    "ogx_mmlux_it-college_computer_science": 0,
    "ogx_mmlux_it-college_mathematics": 0,
    "ogx_mmlux_it-college_medicine": 0,
    "ogx_mmlux_it-college_physics": 0,
    "ogx_mmlux_it-computer_security": 0,
    "ogx_mmlux_it-conceptual_physics": 0,
    "ogx_mmlux_it-econometrics": 0,
    "ogx_mmlux_it-electrical_engineering": 0,
    "ogx_mmlux_it-elementary_mathematics": 0,
    "ogx_mmlux_it-formal_logic": 0,
    "ogx_mmlux_it-global_facts": 0,
    "ogx_mmlux_it-high_school_biology": 0,
    "ogx_mmlux_it-high_school_chemistry": 0,
    "ogx_mmlux_it-high_school_computer_science": 0,
    "ogx_mmlux_it-high_school_european_history": 0,
    "ogx_mmlux_it-high_school_geography": 0,
    "ogx_mmlux_it-high_school_government_and_politics": 0,
    "ogx_mmlux_it-high_school_macroeconomics": 0,
    "ogx_mmlux_it-high_school_mathematics": 0,
    "ogx_mmlux_it-high_school_microeconomics": 0,
    "ogx_mmlux_it-high_school_physics": 0,
    "ogx_mmlux_it-high_school_psychology": 0,
    "ogx_mmlux_it-high_school_statistics": 0,
    "ogx_mmlux_it-high_school_us_history": 0,
    "ogx_mmlux_it-high_school_world_history": 0,
    "ogx_mmlux_it-human_aging": 0,
    "ogx_mmlux_it-human_sexuality": 0,
    "ogx_mmlux_it-international_law": 0,
    "ogx_mmlux_it-jurisprudence": 0,
    "ogx_mmlux_it-logical_fallacies": 0,
    "ogx_mmlux_it-machine_learning": 0,
    "ogx_mmlux_it-management": 0,
    "ogx_mmlux_it-marketing": 0,
    "ogx_mmlux_it-medical_genetics": 0,
    "ogx_mmlux_it-miscellaneous": 0,
    "ogx_mmlux_it-moral_disputes": 0,
    "ogx_mmlux_it-moral_scenarios": 0,
    "ogx_mmlux_it-nutrition": 0,
    "ogx_mmlux_it-philosophy": 0,
    "ogx_mmlux_it-prehistory": 0,
    "ogx_mmlux_it-professional_accounting": 0,
    "ogx_mmlux_it-professional_law": 0,
    "ogx_mmlux_it-professional_medicine": 0,
    "ogx_mmlux_it-professional_psychology": 0,
    "ogx_mmlux_it-public_relations": 0,
    "ogx_mmlux_it-security_studies": 0,
    "ogx_mmlux_it-sociology": 0,
    "ogx_mmlux_it-us_foreign_policy": 0,
    "ogx_mmlux_it-virology": 0,
    "ogx_mmlux_it-world_religions": 0,
    "ogx_mmlux_lt-abstract_algebra": 0,
    "ogx_mmlux_lt-anatomy": 0,
    "ogx_mmlux_lt-astronomy": 0,
    "ogx_mmlux_lt-business_ethics": 0,
    "ogx_mmlux_lt-clinical_knowledge": 0,
    "ogx_mmlux_lt-college_biology": 0,
    "ogx_mmlux_lt-college_chemistry": 0,
    "ogx_mmlux_lt-college_computer_science": 0,
    "ogx_mmlux_lt-college_mathematics": 0,
    "ogx_mmlux_lt-college_medicine": 0,
    "ogx_mmlux_lt-college_physics": 0,
    "ogx_mmlux_lt-computer_security": 0,
    "ogx_mmlux_lt-conceptual_physics": 0,
    "ogx_mmlux_lt-econometrics": 0,
    "ogx_mmlux_lt-electrical_engineering": 0,
    "ogx_mmlux_lt-elementary_mathematics": 0,
    "ogx_mmlux_lt-formal_logic": 0,
    "ogx_mmlux_lt-global_facts": 0,
    "ogx_mmlux_lt-high_school_biology": 0,
    "ogx_mmlux_lt-high_school_chemistry": 0,
    "ogx_mmlux_lt-high_school_computer_science": 0,
    "ogx_mmlux_lt-high_school_european_history": 0,
    "ogx_mmlux_lt-high_school_geography": 0,
    "ogx_mmlux_lt-high_school_government_and_politics": 0,
    "ogx_mmlux_lt-high_school_macroeconomics": 0,
    "ogx_mmlux_lt-high_school_mathematics": 0,
    "ogx_mmlux_lt-high_school_microeconomics": 0,
    "ogx_mmlux_lt-high_school_physics": 0,
    "ogx_mmlux_lt-high_school_psychology": 0,
    "ogx_mmlux_lt-high_school_statistics": 0,
    "ogx_mmlux_lt-high_school_us_history": 0,
    "ogx_mmlux_lt-high_school_world_history": 0,
    "ogx_mmlux_lt-human_aging": 0,
    "ogx_mmlux_lt-human_sexuality": 0,
    "ogx_mmlux_lt-international_law": 0,
    "ogx_mmlux_lt-jurisprudence": 0,
    "ogx_mmlux_lt-logical_fallacies": 0,
    "ogx_mmlux_lt-machine_learning": 0,
    "ogx_mmlux_lt-management": 0,
    "ogx_mmlux_lt-marketing": 0,
    "ogx_mmlux_lt-medical_genetics": 0,
    "ogx_mmlux_lt-miscellaneous": 0,
    "ogx_mmlux_lt-moral_disputes": 0,
    "ogx_mmlux_lt-moral_scenarios": 0,
    "ogx_mmlux_lt-nutrition": 0,
    "ogx_mmlux_lt-philosophy": 0,
    "ogx_mmlux_lt-prehistory": 0,
    "ogx_mmlux_lt-professional_accounting": 0,
    "ogx_mmlux_lt-professional_law": 0,
    "ogx_mmlux_lt-professional_medicine": 0,
    "ogx_mmlux_lt-professional_psychology": 0,
    "ogx_mmlux_lt-public_relations": 0,
    "ogx_mmlux_lt-security_studies": 0,
    "ogx_mmlux_lt-sociology": 0,
    "ogx_mmlux_lt-us_foreign_policy": 0,
    "ogx_mmlux_lt-virology": 0,
    "ogx_mmlux_lt-world_religions": 0,
    "ogx_mmlux_lv-abstract_algebra": 0,
    "ogx_mmlux_lv-anatomy": 0,
    "ogx_mmlux_lv-astronomy": 0,
    "ogx_mmlux_lv-business_ethics": 0,
    "ogx_mmlux_lv-clinical_knowledge": 0,
    "ogx_mmlux_lv-college_biology": 0,
    "ogx_mmlux_lv-college_chemistry": 0,
    "ogx_mmlux_lv-college_computer_science": 0,
    "ogx_mmlux_lv-college_mathematics": 0,
    "ogx_mmlux_lv-college_medicine": 0,
    "ogx_mmlux_lv-college_physics": 0,
    "ogx_mmlux_lv-computer_security": 0,
    "ogx_mmlux_lv-conceptual_physics": 0,
    "ogx_mmlux_lv-econometrics": 0,
    "ogx_mmlux_lv-electrical_engineering": 0,
    "ogx_mmlux_lv-elementary_mathematics": 0,
    "ogx_mmlux_lv-formal_logic": 0,
    "ogx_mmlux_lv-global_facts": 0,
    "ogx_mmlux_lv-high_school_biology": 0,
    "ogx_mmlux_lv-high_school_chemistry": 0,
    "ogx_mmlux_lv-high_school_computer_science": 0,
    "ogx_mmlux_lv-high_school_european_history": 0,
    "ogx_mmlux_lv-high_school_geography": 0,
    "ogx_mmlux_lv-high_school_government_and_politics": 0,
    "ogx_mmlux_lv-high_school_macroeconomics": 0,
    "ogx_mmlux_lv-high_school_mathematics": 0,
    "ogx_mmlux_lv-high_school_microeconomics": 0,
    "ogx_mmlux_lv-high_school_physics": 0,
    "ogx_mmlux_lv-high_school_psychology": 0,
    "ogx_mmlux_lv-high_school_statistics": 0,
    "ogx_mmlux_lv-high_school_us_history": 0,
    "ogx_mmlux_lv-high_school_world_history": 0,
    "ogx_mmlux_lv-human_aging": 0,
    "ogx_mmlux_lv-human_sexuality": 0,
    "ogx_mmlux_lv-international_law": 0,
    "ogx_mmlux_lv-jurisprudence": 0,
    "ogx_mmlux_lv-logical_fallacies": 0,
    "ogx_mmlux_lv-machine_learning": 0,
    "ogx_mmlux_lv-management": 0,
    "ogx_mmlux_lv-marketing": 0,
    "ogx_mmlux_lv-medical_genetics": 0,
    "ogx_mmlux_lv-miscellaneous": 0,
    "ogx_mmlux_lv-moral_disputes": 0,
    "ogx_mmlux_lv-moral_scenarios": 0,
    "ogx_mmlux_lv-nutrition": 0,
    "ogx_mmlux_lv-philosophy": 0,
    "ogx_mmlux_lv-prehistory": 0,
    "ogx_mmlux_lv-professional_accounting": 0,
    "ogx_mmlux_lv-professional_law": 0,
    "ogx_mmlux_lv-professional_medicine": 0,
    "ogx_mmlux_lv-professional_psychology": 0,
    "ogx_mmlux_lv-public_relations": 0,
    "ogx_mmlux_lv-security_studies": 0,
    "ogx_mmlux_lv-sociology": 0,
    "ogx_mmlux_lv-us_foreign_policy": 0,
    "ogx_mmlux_lv-virology": 0,
    "ogx_mmlux_lv-world_religions": 0,
    "ogx_mmlux_nl-abstract_algebra": 0,
    "ogx_mmlux_nl-anatomy": 0,
    "ogx_mmlux_nl-astronomy": 0,
    "ogx_mmlux_nl-business_ethics": 0,
    "ogx_mmlux_nl-clinical_knowledge": 0,
    "ogx_mmlux_nl-college_biology": 0,
    "ogx_mmlux_nl-college_chemistry": 0,
    "ogx_mmlux_nl-college_computer_science": 0,
    "ogx_mmlux_nl-college_mathematics": 0,
    "ogx_mmlux_nl-college_medicine": 0,
    "ogx_mmlux_nl-college_physics": 0,
    "ogx_mmlux_nl-computer_security": 0,
    "ogx_mmlux_nl-conceptual_physics": 0,
    "ogx_mmlux_nl-econometrics": 0,
    "ogx_mmlux_nl-electrical_engineering": 0,
    "ogx_mmlux_nl-elementary_mathematics": 0,
    "ogx_mmlux_nl-formal_logic": 0,
    "ogx_mmlux_nl-global_facts": 0,
    "ogx_mmlux_nl-high_school_biology": 0,
    "ogx_mmlux_nl-high_school_chemistry": 0,
    "ogx_mmlux_nl-high_school_computer_science": 0,
    "ogx_mmlux_nl-high_school_european_history": 0,
    "ogx_mmlux_nl-high_school_geography": 0,
    "ogx_mmlux_nl-high_school_government_and_politics": 0,
    "ogx_mmlux_nl-high_school_macroeconomics": 0,
    "ogx_mmlux_nl-high_school_mathematics": 0,
    "ogx_mmlux_nl-high_school_microeconomics": 0,
    "ogx_mmlux_nl-high_school_physics": 0,
    "ogx_mmlux_nl-high_school_psychology": 0,
    "ogx_mmlux_nl-high_school_statistics": 0,
    "ogx_mmlux_nl-high_school_us_history": 0,
    "ogx_mmlux_nl-high_school_world_history": 0,
    "ogx_mmlux_nl-human_aging": 0,
    "ogx_mmlux_nl-human_sexuality": 0,
    "ogx_mmlux_nl-international_law": 0,
    "ogx_mmlux_nl-jurisprudence": 0,
    "ogx_mmlux_nl-logical_fallacies": 0,
    "ogx_mmlux_nl-machine_learning": 0,
    "ogx_mmlux_nl-management": 0,
    "ogx_mmlux_nl-marketing": 0,
    "ogx_mmlux_nl-medical_genetics": 0,
    "ogx_mmlux_nl-miscellaneous": 0,
    "ogx_mmlux_nl-moral_disputes": 0,
    "ogx_mmlux_nl-moral_scenarios": 0,
    "ogx_mmlux_nl-nutrition": 0,
    "ogx_mmlux_nl-philosophy": 0,
    "ogx_mmlux_nl-prehistory": 0,
    "ogx_mmlux_nl-professional_accounting": 0,
    "ogx_mmlux_nl-professional_law": 0,
    "ogx_mmlux_nl-professional_medicine": 0,
    "ogx_mmlux_nl-professional_psychology": 0,
    "ogx_mmlux_nl-public_relations": 0,
    "ogx_mmlux_nl-security_studies": 0,
    "ogx_mmlux_nl-sociology": 0,
    "ogx_mmlux_nl-us_foreign_policy": 0,
    "ogx_mmlux_nl-virology": 0,
    "ogx_mmlux_nl-world_religions": 0,
    "ogx_mmlux_pl-abstract_algebra": 0,
    "ogx_mmlux_pl-anatomy": 0,
    "ogx_mmlux_pl-astronomy": 0,
    "ogx_mmlux_pl-business_ethics": 0,
    "ogx_mmlux_pl-clinical_knowledge": 0,
    "ogx_mmlux_pl-college_biology": 0,
    "ogx_mmlux_pl-college_chemistry": 0,
    "ogx_mmlux_pl-college_computer_science": 0,
    "ogx_mmlux_pl-college_mathematics": 0,
    "ogx_mmlux_pl-college_medicine": 0,
    "ogx_mmlux_pl-college_physics": 0,
    "ogx_mmlux_pl-computer_security": 0,
    "ogx_mmlux_pl-conceptual_physics": 0,
    "ogx_mmlux_pl-econometrics": 0,
    "ogx_mmlux_pl-electrical_engineering": 0,
    "ogx_mmlux_pl-elementary_mathematics": 0,
    "ogx_mmlux_pl-formal_logic": 0,
    "ogx_mmlux_pl-global_facts": 0,
    "ogx_mmlux_pl-high_school_biology": 0,
    "ogx_mmlux_pl-high_school_chemistry": 0,
    "ogx_mmlux_pl-high_school_computer_science": 0,
    "ogx_mmlux_pl-high_school_european_history": 0,
    "ogx_mmlux_pl-high_school_geography": 0,
    "ogx_mmlux_pl-high_school_government_and_politics": 0,
    "ogx_mmlux_pl-high_school_macroeconomics": 0,
    "ogx_mmlux_pl-high_school_mathematics": 0,
    "ogx_mmlux_pl-high_school_microeconomics": 0,
    "ogx_mmlux_pl-high_school_physics": 0,
    "ogx_mmlux_pl-high_school_psychology": 0,
    "ogx_mmlux_pl-high_school_statistics": 0,
    "ogx_mmlux_pl-high_school_us_history": 0,
    "ogx_mmlux_pl-high_school_world_history": 0,
    "ogx_mmlux_pl-human_aging": 0,
    "ogx_mmlux_pl-human_sexuality": 0,
    "ogx_mmlux_pl-international_law": 0,
    "ogx_mmlux_pl-jurisprudence": 0,
    "ogx_mmlux_pl-logical_fallacies": 0,
    "ogx_mmlux_pl-machine_learning": 0,
    "ogx_mmlux_pl-management": 0,
    "ogx_mmlux_pl-marketing": 0,
    "ogx_mmlux_pl-medical_genetics": 0,
    "ogx_mmlux_pl-miscellaneous": 0,
    "ogx_mmlux_pl-moral_disputes": 0,
    "ogx_mmlux_pl-moral_scenarios": 0,
    "ogx_mmlux_pl-nutrition": 0,
    "ogx_mmlux_pl-philosophy": 0,
    "ogx_mmlux_pl-prehistory": 0,
    "ogx_mmlux_pl-professional_accounting": 0,
    "ogx_mmlux_pl-professional_law": 0,
    "ogx_mmlux_pl-professional_medicine": 0,
    "ogx_mmlux_pl-professional_psychology": 0,
    "ogx_mmlux_pl-public_relations": 0,
    "ogx_mmlux_pl-security_studies": 0,
    "ogx_mmlux_pl-sociology": 0,
    "ogx_mmlux_pl-us_foreign_policy": 0,
    "ogx_mmlux_pl-virology": 0,
    "ogx_mmlux_pl-world_religions": 0,
    "ogx_mmlux_pt-pt-abstract_algebra": 0,
    "ogx_mmlux_pt-pt-anatomy": 0,
    "ogx_mmlux_pt-pt-astronomy": 0,
    "ogx_mmlux_pt-pt-business_ethics": 0,
    "ogx_mmlux_pt-pt-clinical_knowledge": 0,
    "ogx_mmlux_pt-pt-college_biology": 0,
    "ogx_mmlux_pt-pt-college_chemistry": 0,
    "ogx_mmlux_pt-pt-college_computer_science": 0,
    "ogx_mmlux_pt-pt-college_mathematics": 0,
    "ogx_mmlux_pt-pt-college_medicine": 0,
    "ogx_mmlux_pt-pt-college_physics": 0,
    "ogx_mmlux_pt-pt-computer_security": 0,
    "ogx_mmlux_pt-pt-conceptual_physics": 0,
    "ogx_mmlux_pt-pt-econometrics": 0,
    "ogx_mmlux_pt-pt-electrical_engineering": 0,
    "ogx_mmlux_pt-pt-elementary_mathematics": 0,
    "ogx_mmlux_pt-pt-formal_logic": 0,
    "ogx_mmlux_pt-pt-global_facts": 0,
    "ogx_mmlux_pt-pt-high_school_biology": 0,
    "ogx_mmlux_pt-pt-high_school_chemistry": 0,
    "ogx_mmlux_pt-pt-high_school_computer_science": 0,
    "ogx_mmlux_pt-pt-high_school_european_history": 0,
    "ogx_mmlux_pt-pt-high_school_geography": 0,
    "ogx_mmlux_pt-pt-high_school_government_and_politics": 0,
    "ogx_mmlux_pt-pt-high_school_macroeconomics": 0,
    "ogx_mmlux_pt-pt-high_school_mathematics": 0,
    "ogx_mmlux_pt-pt-high_school_microeconomics": 0,
    "ogx_mmlux_pt-pt-high_school_physics": 0,
    "ogx_mmlux_pt-pt-high_school_psychology": 0,
    "ogx_mmlux_pt-pt-high_school_statistics": 0,
    "ogx_mmlux_pt-pt-high_school_us_history": 0,
    "ogx_mmlux_pt-pt-high_school_world_history": 0,
    "ogx_mmlux_pt-pt-human_aging": 0,
    "ogx_mmlux_pt-pt-human_sexuality": 0,
    "ogx_mmlux_pt-pt-international_law": 0,
    "ogx_mmlux_pt-pt-jurisprudence": 0,
    "ogx_mmlux_pt-pt-logical_fallacies": 0,
    "ogx_mmlux_pt-pt-machine_learning": 0,
    "ogx_mmlux_pt-pt-management": 0,
    "ogx_mmlux_pt-pt-marketing": 0,
    "ogx_mmlux_pt-pt-medical_genetics": 0,
    "ogx_mmlux_pt-pt-miscellaneous": 0,
    "ogx_mmlux_pt-pt-moral_disputes": 0,
    "ogx_mmlux_pt-pt-moral_scenarios": 0,
    "ogx_mmlux_pt-pt-nutrition": 0,
    "ogx_mmlux_pt-pt-philosophy": 0,
    "ogx_mmlux_pt-pt-prehistory": 0,
    "ogx_mmlux_pt-pt-professional_accounting": 0,
    "ogx_mmlux_pt-pt-professional_law": 0,
    "ogx_mmlux_pt-pt-professional_medicine": 0,
    "ogx_mmlux_pt-pt-professional_psychology": 0,
    "ogx_mmlux_pt-pt-public_relations": 0,
    "ogx_mmlux_pt-pt-security_studies": 0,
    "ogx_mmlux_pt-pt-sociology": 0,
    "ogx_mmlux_pt-pt-us_foreign_policy": 0,
    "ogx_mmlux_pt-pt-virology": 0,
    "ogx_mmlux_pt-pt-world_religions": 0,
    "ogx_mmlux_ro-abstract_algebra": 0,
    "ogx_mmlux_ro-anatomy": 0,
    "ogx_mmlux_ro-astronomy": 0,
    "ogx_mmlux_ro-business_ethics": 0,
    "ogx_mmlux_ro-clinical_knowledge": 0,
    "ogx_mmlux_ro-college_biology": 0,
    "ogx_mmlux_ro-college_chemistry": 0,
    "ogx_mmlux_ro-college_computer_science": 0,
    "ogx_mmlux_ro-college_mathematics": 0,
    "ogx_mmlux_ro-college_medicine": 0,
    "ogx_mmlux_ro-college_physics": 0,
    "ogx_mmlux_ro-computer_security": 0,
    "ogx_mmlux_ro-conceptual_physics": 0,
    "ogx_mmlux_ro-econometrics": 0,
    "ogx_mmlux_ro-electrical_engineering": 0,
    "ogx_mmlux_ro-elementary_mathematics": 0,
    "ogx_mmlux_ro-formal_logic": 0,
    "ogx_mmlux_ro-global_facts": 0,
    "ogx_mmlux_ro-high_school_biology": 0,
    "ogx_mmlux_ro-high_school_chemistry": 0,
    "ogx_mmlux_ro-high_school_computer_science": 0,
    "ogx_mmlux_ro-high_school_european_history": 0,
    "ogx_mmlux_ro-high_school_geography": 0,
    "ogx_mmlux_ro-high_school_government_and_politics": 0,
    "ogx_mmlux_ro-high_school_macroeconomics": 0,
    "ogx_mmlux_ro-high_school_mathematics": 0,
    "ogx_mmlux_ro-high_school_microeconomics": 0,
    "ogx_mmlux_ro-high_school_physics": 0,
    "ogx_mmlux_ro-high_school_psychology": 0,
    "ogx_mmlux_ro-high_school_statistics": 0,
    "ogx_mmlux_ro-high_school_us_history": 0,
    "ogx_mmlux_ro-high_school_world_history": 0,
    "ogx_mmlux_ro-human_aging": 0,
    "ogx_mmlux_ro-human_sexuality": 0,
    "ogx_mmlux_ro-international_law": 0,
    "ogx_mmlux_ro-jurisprudence": 0,
    "ogx_mmlux_ro-logical_fallacies": 0,
    "ogx_mmlux_ro-machine_learning": 0,
    "ogx_mmlux_ro-management": 0,
    "ogx_mmlux_ro-marketing": 0,
    "ogx_mmlux_ro-medical_genetics": 0,
    "ogx_mmlux_ro-miscellaneous": 0,
    "ogx_mmlux_ro-moral_disputes": 0,
    "ogx_mmlux_ro-moral_scenarios": 0,
    "ogx_mmlux_ro-nutrition": 0,
    "ogx_mmlux_ro-philosophy": 0,
    "ogx_mmlux_ro-prehistory": 0,
    "ogx_mmlux_ro-professional_accounting": 0,
    "ogx_mmlux_ro-professional_law": 0,
    "ogx_mmlux_ro-professional_medicine": 0,
    "ogx_mmlux_ro-professional_psychology": 0,
    "ogx_mmlux_ro-public_relations": 0,
    "ogx_mmlux_ro-security_studies": 0,
    "ogx_mmlux_ro-sociology": 0,
    "ogx_mmlux_ro-us_foreign_policy": 0,
    "ogx_mmlux_ro-virology": 0,
    "ogx_mmlux_ro-world_religions": 0,
    "ogx_mmlux_sk-abstract_algebra": 0,
    "ogx_mmlux_sk-anatomy": 0,
    "ogx_mmlux_sk-astronomy": 0,
    "ogx_mmlux_sk-business_ethics": 0,
    "ogx_mmlux_sk-clinical_knowledge": 0,
    "ogx_mmlux_sk-college_biology": 0,
    "ogx_mmlux_sk-college_chemistry": 0,
    "ogx_mmlux_sk-college_computer_science": 0,
    "ogx_mmlux_sk-college_mathematics": 0,
    "ogx_mmlux_sk-college_medicine": 0,
    "ogx_mmlux_sk-college_physics": 0,
    "ogx_mmlux_sk-computer_security": 0,
    "ogx_mmlux_sk-conceptual_physics": 0,
    "ogx_mmlux_sk-econometrics": 0,
    "ogx_mmlux_sk-electrical_engineering": 0,
    "ogx_mmlux_sk-elementary_mathematics": 0,
    "ogx_mmlux_sk-formal_logic": 0,
    "ogx_mmlux_sk-global_facts": 0,
    "ogx_mmlux_sk-high_school_biology": 0,
    "ogx_mmlux_sk-high_school_chemistry": 0,
    "ogx_mmlux_sk-high_school_computer_science": 0,
    "ogx_mmlux_sk-high_school_european_history": 0,
    "ogx_mmlux_sk-high_school_geography": 0,
    "ogx_mmlux_sk-high_school_government_and_politics": 0,
    "ogx_mmlux_sk-high_school_macroeconomics": 0,
    "ogx_mmlux_sk-high_school_mathematics": 0,
    "ogx_mmlux_sk-high_school_microeconomics": 0,
    "ogx_mmlux_sk-high_school_physics": 0,
    "ogx_mmlux_sk-high_school_psychology": 0,
    "ogx_mmlux_sk-high_school_statistics": 0,
    "ogx_mmlux_sk-high_school_us_history": 0,
    "ogx_mmlux_sk-high_school_world_history": 0,
    "ogx_mmlux_sk-human_aging": 0,
    "ogx_mmlux_sk-human_sexuality": 0,
    "ogx_mmlux_sk-international_law": 0,
    "ogx_mmlux_sk-jurisprudence": 0,
    "ogx_mmlux_sk-logical_fallacies": 0,
    "ogx_mmlux_sk-machine_learning": 0,
    "ogx_mmlux_sk-management": 0,
    "ogx_mmlux_sk-marketing": 0,
    "ogx_mmlux_sk-medical_genetics": 0,
    "ogx_mmlux_sk-miscellaneous": 0,
    "ogx_mmlux_sk-moral_disputes": 0,
    "ogx_mmlux_sk-moral_scenarios": 0,
    "ogx_mmlux_sk-nutrition": 0,
    "ogx_mmlux_sk-philosophy": 0,
    "ogx_mmlux_sk-prehistory": 0,
    "ogx_mmlux_sk-professional_accounting": 0,
    "ogx_mmlux_sk-professional_law": 0,
    "ogx_mmlux_sk-professional_medicine": 0,
    "ogx_mmlux_sk-professional_psychology": 0,
    "ogx_mmlux_sk-public_relations": 0,
    "ogx_mmlux_sk-security_studies": 0,
    "ogx_mmlux_sk-sociology": 0,
    "ogx_mmlux_sk-us_foreign_policy": 0,
    "ogx_mmlux_sk-virology": 0,
    "ogx_mmlux_sk-world_religions": 0,
    "ogx_mmlux_sl-abstract_algebra": 0,
    "ogx_mmlux_sl-anatomy": 0,
    "ogx_mmlux_sl-astronomy": 0,
    "ogx_mmlux_sl-business_ethics": 0,
    "ogx_mmlux_sl-clinical_knowledge": 0,
    "ogx_mmlux_sl-college_biology": 0,
    "ogx_mmlux_sl-college_chemistry": 0,
    "ogx_mmlux_sl-college_computer_science": 0,
    "ogx_mmlux_sl-college_mathematics": 0,
    "ogx_mmlux_sl-college_medicine": 0,
    "ogx_mmlux_sl-college_physics": 0,
    "ogx_mmlux_sl-computer_security": 0,
    "ogx_mmlux_sl-conceptual_physics": 0,
    "ogx_mmlux_sl-econometrics": 0,
    "ogx_mmlux_sl-electrical_engineering": 0,
    "ogx_mmlux_sl-elementary_mathematics": 0,
    "ogx_mmlux_sl-formal_logic": 0,
    "ogx_mmlux_sl-global_facts": 0,
    "ogx_mmlux_sl-high_school_biology": 0,
    "ogx_mmlux_sl-high_school_chemistry": 0,
    "ogx_mmlux_sl-high_school_computer_science": 0,
    "ogx_mmlux_sl-high_school_european_history": 0,
    "ogx_mmlux_sl-high_school_geography": 0,
    "ogx_mmlux_sl-high_school_government_and_politics": 0,
    "ogx_mmlux_sl-high_school_macroeconomics": 0,
    "ogx_mmlux_sl-high_school_mathematics": 0,
    "ogx_mmlux_sl-high_school_microeconomics": 0,
    "ogx_mmlux_sl-high_school_physics": 0,
    "ogx_mmlux_sl-high_school_psychology": 0,
    "ogx_mmlux_sl-high_school_statistics": 0,
    "ogx_mmlux_sl-high_school_us_history": 0,
    "ogx_mmlux_sl-high_school_world_history": 0,
    "ogx_mmlux_sl-human_aging": 0,
    "ogx_mmlux_sl-human_sexuality": 0,
    "ogx_mmlux_sl-international_law": 0,
    "ogx_mmlux_sl-jurisprudence": 0,
    "ogx_mmlux_sl-logical_fallacies": 0,
    "ogx_mmlux_sl-machine_learning": 0,
    "ogx_mmlux_sl-management": 0,
    "ogx_mmlux_sl-marketing": 0,
    "ogx_mmlux_sl-medical_genetics": 0,
    "ogx_mmlux_sl-miscellaneous": 0,
    "ogx_mmlux_sl-moral_disputes": 0,
    "ogx_mmlux_sl-moral_scenarios": 0,
    "ogx_mmlux_sl-nutrition": 0,
    "ogx_mmlux_sl-philosophy": 0,
    "ogx_mmlux_sl-prehistory": 0,
    "ogx_mmlux_sl-professional_accounting": 0,
    "ogx_mmlux_sl-professional_law": 0,
    "ogx_mmlux_sl-professional_medicine": 0,
    "ogx_mmlux_sl-professional_psychology": 0,
    "ogx_mmlux_sl-public_relations": 0,
    "ogx_mmlux_sl-security_studies": 0,
    "ogx_mmlux_sl-sociology": 0,
    "ogx_mmlux_sl-us_foreign_policy": 0,
    "ogx_mmlux_sl-virology": 0,
    "ogx_mmlux_sl-world_religions": 0,
    "ogx_mmlux_sv-abstract_algebra": 0,
    "ogx_mmlux_sv-anatomy": 0,
    "ogx_mmlux_sv-astronomy": 0,
    "ogx_mmlux_sv-business_ethics": 0,
    "ogx_mmlux_sv-clinical_knowledge": 0,
    "ogx_mmlux_sv-college_biology": 0,
    "ogx_mmlux_sv-college_chemistry": 0,
    "ogx_mmlux_sv-college_computer_science": 0,
    "ogx_mmlux_sv-college_mathematics": 0,
    "ogx_mmlux_sv-college_medicine": 0,
    "ogx_mmlux_sv-college_physics": 0,
    "ogx_mmlux_sv-computer_security": 0,
    "ogx_mmlux_sv-conceptual_physics": 0,
    "ogx_mmlux_sv-econometrics": 0,
    "ogx_mmlux_sv-electrical_engineering": 0,
    "ogx_mmlux_sv-elementary_mathematics": 0,
    "ogx_mmlux_sv-formal_logic": 0,
    "ogx_mmlux_sv-global_facts": 0,
    "ogx_mmlux_sv-high_school_biology": 0,
    "ogx_mmlux_sv-high_school_chemistry": 0,
    "ogx_mmlux_sv-high_school_computer_science": 0,
    "ogx_mmlux_sv-high_school_european_history": 0,
    "ogx_mmlux_sv-high_school_geography": 0,
    "ogx_mmlux_sv-high_school_government_and_politics": 0,
    "ogx_mmlux_sv-high_school_macroeconomics": 0,
    "ogx_mmlux_sv-high_school_mathematics": 0,
    "ogx_mmlux_sv-high_school_microeconomics": 0,
    "ogx_mmlux_sv-high_school_physics": 0,
    "ogx_mmlux_sv-high_school_psychology": 0,
    "ogx_mmlux_sv-high_school_statistics": 0,
    "ogx_mmlux_sv-high_school_us_history": 0,
    "ogx_mmlux_sv-high_school_world_history": 0,
    "ogx_mmlux_sv-human_aging": 0,
    "ogx_mmlux_sv-human_sexuality": 0,
    "ogx_mmlux_sv-international_law": 0,
    "ogx_mmlux_sv-jurisprudence": 0,
    "ogx_mmlux_sv-logical_fallacies": 0,
    "ogx_mmlux_sv-machine_learning": 0,
    "ogx_mmlux_sv-management": 0,
    "ogx_mmlux_sv-marketing": 0,
    "ogx_mmlux_sv-medical_genetics": 0,
    "ogx_mmlux_sv-miscellaneous": 0,
    "ogx_mmlux_sv-moral_disputes": 0,
    "ogx_mmlux_sv-moral_scenarios": 0,
    "ogx_mmlux_sv-nutrition": 0,
    "ogx_mmlux_sv-philosophy": 0,
    "ogx_mmlux_sv-prehistory": 0,
    "ogx_mmlux_sv-professional_accounting": 0,
    "ogx_mmlux_sv-professional_law": 0,
    "ogx_mmlux_sv-professional_medicine": 0,
    "ogx_mmlux_sv-professional_psychology": 0,
    "ogx_mmlux_sv-public_relations": 0,
    "ogx_mmlux_sv-security_studies": 0,
    "ogx_mmlux_sv-sociology": 0,
    "ogx_mmlux_sv-us_foreign_policy": 0,
    "ogx_mmlux_sv-virology": 0,
    "ogx_mmlux_sv-world_religions": 0
  },
  "n-shot": {
    "ogx_mmlux_bg-abstract_algebra": 5,
    "ogx_mmlux_bg-anatomy": 5,
    "ogx_mmlux_bg-astronomy": 5,
    "ogx_mmlux_bg-business_ethics": 5,
    "ogx_mmlux_bg-clinical_knowledge": 5,
    "ogx_mmlux_bg-college_biology": 5,
    "ogx_mmlux_bg-college_chemistry": 5,
    "ogx_mmlux_bg-college_computer_science": 5,
    "ogx_mmlux_bg-college_mathematics": 5,
    "ogx_mmlux_bg-college_medicine": 5,
    "ogx_mmlux_bg-college_physics": 5,
    "ogx_mmlux_bg-computer_security": 5,
    "ogx_mmlux_bg-conceptual_physics": 5,
    "ogx_mmlux_bg-econometrics": 5,
    "ogx_mmlux_bg-electrical_engineering": 5,
    "ogx_mmlux_bg-elementary_mathematics": 5,
    "ogx_mmlux_bg-formal_logic": 5,
    "ogx_mmlux_bg-global_facts": 5,
    "ogx_mmlux_bg-high_school_biology": 5,
    "ogx_mmlux_bg-high_school_chemistry": 5,
    "ogx_mmlux_bg-high_school_computer_science": 5,
    "ogx_mmlux_bg-high_school_european_history": 5,
    "ogx_mmlux_bg-high_school_geography": 5,
    "ogx_mmlux_bg-high_school_government_and_politics": 5,
    "ogx_mmlux_bg-high_school_macroeconomics": 5,
    "ogx_mmlux_bg-high_school_mathematics": 5,
    "ogx_mmlux_bg-high_school_microeconomics": 5,
    "ogx_mmlux_bg-high_school_physics": 5,
    "ogx_mmlux_bg-high_school_psychology": 5,
    "ogx_mmlux_bg-high_school_statistics": 5,
    "ogx_mmlux_bg-high_school_us_history": 5,
    "ogx_mmlux_bg-high_school_world_history": 5,
    "ogx_mmlux_bg-human_aging": 5,
    "ogx_mmlux_bg-human_sexuality": 5,
    "ogx_mmlux_bg-international_law": 5,
    "ogx_mmlux_bg-jurisprudence": 5,
    "ogx_mmlux_bg-logical_fallacies": 5,
    "ogx_mmlux_bg-machine_learning": 5,
    "ogx_mmlux_bg-management": 5,
    "ogx_mmlux_bg-marketing": 5,
    "ogx_mmlux_bg-medical_genetics": 5,
    "ogx_mmlux_bg-miscellaneous": 5,
    "ogx_mmlux_bg-moral_disputes": 5,
    "ogx_mmlux_bg-moral_scenarios": 5,
    "ogx_mmlux_bg-nutrition": 5,
    "ogx_mmlux_bg-philosophy": 5,
    "ogx_mmlux_bg-prehistory": 5,
    "ogx_mmlux_bg-professional_accounting": 5,
    "ogx_mmlux_bg-professional_law": 5,
    "ogx_mmlux_bg-professional_medicine": 5,
    "ogx_mmlux_bg-professional_psychology": 5,
    "ogx_mmlux_bg-public_relations": 5,
    "ogx_mmlux_bg-security_studies": 5,
    "ogx_mmlux_bg-sociology": 5,
    "ogx_mmlux_bg-us_foreign_policy": 5,
    "ogx_mmlux_bg-virology": 5,
    "ogx_mmlux_bg-world_religions": 5,
    "ogx_mmlux_cs-abstract_algebra": 5,
    "ogx_mmlux_cs-anatomy": 5,
    "ogx_mmlux_cs-astronomy": 5,
    "ogx_mmlux_cs-business_ethics": 5,
    "ogx_mmlux_cs-clinical_knowledge": 5,
    "ogx_mmlux_cs-college_biology": 5,
    "ogx_mmlux_cs-college_chemistry": 5,
    "ogx_mmlux_cs-college_computer_science": 5,
    "ogx_mmlux_cs-college_mathematics": 5,
    "ogx_mmlux_cs-college_medicine": 5,
    "ogx_mmlux_cs-college_physics": 5,
    "ogx_mmlux_cs-computer_security": 5,
    "ogx_mmlux_cs-conceptual_physics": 5,
    "ogx_mmlux_cs-econometrics": 5,
    "ogx_mmlux_cs-electrical_engineering": 5,
    "ogx_mmlux_cs-elementary_mathematics": 5,
    "ogx_mmlux_cs-formal_logic": 5,
    "ogx_mmlux_cs-global_facts": 5,
    "ogx_mmlux_cs-high_school_biology": 5,
    "ogx_mmlux_cs-high_school_chemistry": 5,
    "ogx_mmlux_cs-high_school_computer_science": 5,
    "ogx_mmlux_cs-high_school_european_history": 5,
    "ogx_mmlux_cs-high_school_geography": 5,
    "ogx_mmlux_cs-high_school_government_and_politics": 5,
    "ogx_mmlux_cs-high_school_macroeconomics": 5,
    "ogx_mmlux_cs-high_school_mathematics": 5,
    "ogx_mmlux_cs-high_school_microeconomics": 5,
    "ogx_mmlux_cs-high_school_physics": 5,
    "ogx_mmlux_cs-high_school_psychology": 5,
    "ogx_mmlux_cs-high_school_statistics": 5,
    "ogx_mmlux_cs-high_school_us_history": 5,
    "ogx_mmlux_cs-high_school_world_history": 5,
    "ogx_mmlux_cs-human_aging": 5,
    "ogx_mmlux_cs-human_sexuality": 5,
    "ogx_mmlux_cs-international_law": 5,
    "ogx_mmlux_cs-jurisprudence": 5,
    "ogx_mmlux_cs-logical_fallacies": 5,
    "ogx_mmlux_cs-machine_learning": 5,
    "ogx_mmlux_cs-management": 5,
    "ogx_mmlux_cs-marketing": 5,
    "ogx_mmlux_cs-medical_genetics": 5,
    "ogx_mmlux_cs-miscellaneous": 5,
    "ogx_mmlux_cs-moral_disputes": 5,
    "ogx_mmlux_cs-moral_scenarios": 5,
    "ogx_mmlux_cs-nutrition": 5,
    "ogx_mmlux_cs-philosophy": 5,
    "ogx_mmlux_cs-prehistory": 5,
    "ogx_mmlux_cs-professional_accounting": 5,
    "ogx_mmlux_cs-professional_law": 5,
    "ogx_mmlux_cs-professional_medicine": 5,
    "ogx_mmlux_cs-professional_psychology": 5,
    "ogx_mmlux_cs-public_relations": 5,
    "ogx_mmlux_cs-security_studies": 5,
    "ogx_mmlux_cs-sociology": 5,
    "ogx_mmlux_cs-us_foreign_policy": 5,
    "ogx_mmlux_cs-virology": 5,
    "ogx_mmlux_cs-world_religions": 5,
    "ogx_mmlux_da-abstract_algebra": 5,
    "ogx_mmlux_da-anatomy": 5,
    "ogx_mmlux_da-astronomy": 5,
    "ogx_mmlux_da-business_ethics": 5,
    "ogx_mmlux_da-clinical_knowledge": 5,
    "ogx_mmlux_da-college_biology": 5,
    "ogx_mmlux_da-college_chemistry": 5,
    "ogx_mmlux_da-college_computer_science": 5,
    "ogx_mmlux_da-college_mathematics": 5,
    "ogx_mmlux_da-college_medicine": 5,
    "ogx_mmlux_da-college_physics": 5,
    "ogx_mmlux_da-computer_security": 5,
    "ogx_mmlux_da-conceptual_physics": 5,
    "ogx_mmlux_da-econometrics": 5,
    "ogx_mmlux_da-electrical_engineering": 5,
    "ogx_mmlux_da-elementary_mathematics": 5,
    "ogx_mmlux_da-formal_logic": 5,
    "ogx_mmlux_da-global_facts": 5,
    "ogx_mmlux_da-high_school_biology": 5,
    "ogx_mmlux_da-high_school_chemistry": 5,
    "ogx_mmlux_da-high_school_computer_science": 5,
    "ogx_mmlux_da-high_school_european_history": 5,
    "ogx_mmlux_da-high_school_geography": 5,
    "ogx_mmlux_da-high_school_government_and_politics": 5,
    "ogx_mmlux_da-high_school_macroeconomics": 5,
    "ogx_mmlux_da-high_school_mathematics": 5,
    "ogx_mmlux_da-high_school_microeconomics": 5,
    "ogx_mmlux_da-high_school_physics": 5,
    "ogx_mmlux_da-high_school_psychology": 5,
    "ogx_mmlux_da-high_school_statistics": 5,
    "ogx_mmlux_da-high_school_us_history": 5,
    "ogx_mmlux_da-high_school_world_history": 5,
    "ogx_mmlux_da-human_aging": 5,
    "ogx_mmlux_da-human_sexuality": 5,
    "ogx_mmlux_da-international_law": 5,
    "ogx_mmlux_da-jurisprudence": 5,
    "ogx_mmlux_da-logical_fallacies": 5,
    "ogx_mmlux_da-machine_learning": 5,
    "ogx_mmlux_da-management": 5,
    "ogx_mmlux_da-marketing": 5,
    "ogx_mmlux_da-medical_genetics": 5,
    "ogx_mmlux_da-miscellaneous": 5,
    "ogx_mmlux_da-moral_disputes": 5,
    "ogx_mmlux_da-moral_scenarios": 5,
    "ogx_mmlux_da-nutrition": 5,
    "ogx_mmlux_da-philosophy": 5,
    "ogx_mmlux_da-prehistory": 5,
    "ogx_mmlux_da-professional_accounting": 5,
    "ogx_mmlux_da-professional_law": 5,
    "ogx_mmlux_da-professional_medicine": 5,
    "ogx_mmlux_da-professional_psychology": 5,
    "ogx_mmlux_da-public_relations": 5,
    "ogx_mmlux_da-security_studies": 5,
    "ogx_mmlux_da-sociology": 5,
    "ogx_mmlux_da-us_foreign_policy": 5,
    "ogx_mmlux_da-virology": 5,
    "ogx_mmlux_da-world_religions": 5,
    "ogx_mmlux_de-abstract_algebra": 5,
    "ogx_mmlux_de-anatomy": 5,
    "ogx_mmlux_de-astronomy": 5,
    "ogx_mmlux_de-business_ethics": 5,
    "ogx_mmlux_de-clinical_knowledge": 5,
    "ogx_mmlux_de-college_biology": 5,
    "ogx_mmlux_de-college_chemistry": 5,
    "ogx_mmlux_de-college_computer_science": 5,
    "ogx_mmlux_de-college_mathematics": 5,
    "ogx_mmlux_de-college_medicine": 5,
    "ogx_mmlux_de-college_physics": 5,
    "ogx_mmlux_de-computer_security": 5,
    "ogx_mmlux_de-conceptual_physics": 5,
    "ogx_mmlux_de-econometrics": 5,
    "ogx_mmlux_de-electrical_engineering": 5,
    "ogx_mmlux_de-elementary_mathematics": 5,
    "ogx_mmlux_de-formal_logic": 5,
    "ogx_mmlux_de-global_facts": 5,
    "ogx_mmlux_de-high_school_biology": 5,
    "ogx_mmlux_de-high_school_chemistry": 5,
    "ogx_mmlux_de-high_school_computer_science": 5,
    "ogx_mmlux_de-high_school_european_history": 5,
    "ogx_mmlux_de-high_school_geography": 5,
    "ogx_mmlux_de-high_school_government_and_politics": 5,
    "ogx_mmlux_de-high_school_macroeconomics": 5,
    "ogx_mmlux_de-high_school_mathematics": 5,
    "ogx_mmlux_de-high_school_microeconomics": 5,
    "ogx_mmlux_de-high_school_physics": 5,
    "ogx_mmlux_de-high_school_psychology": 5,
    "ogx_mmlux_de-high_school_statistics": 5,
    "ogx_mmlux_de-high_school_us_history": 5,
    "ogx_mmlux_de-high_school_world_history": 5,
    "ogx_mmlux_de-human_aging": 5,
    "ogx_mmlux_de-human_sexuality": 5,
    "ogx_mmlux_de-international_law": 5,
    "ogx_mmlux_de-jurisprudence": 5,
    "ogx_mmlux_de-logical_fallacies": 5,
    "ogx_mmlux_de-machine_learning": 5,
    "ogx_mmlux_de-management": 5,
    "ogx_mmlux_de-marketing": 5,
    "ogx_mmlux_de-medical_genetics": 5,
    "ogx_mmlux_de-miscellaneous": 5,
    "ogx_mmlux_de-moral_disputes": 5,
    "ogx_mmlux_de-moral_scenarios": 5,
    "ogx_mmlux_de-nutrition": 5,
    "ogx_mmlux_de-philosophy": 5,
    "ogx_mmlux_de-prehistory": 5,
    "ogx_mmlux_de-professional_accounting": 5,
    "ogx_mmlux_de-professional_law": 5,
    "ogx_mmlux_de-professional_medicine": 5,
    "ogx_mmlux_de-professional_psychology": 5,
    "ogx_mmlux_de-public_relations": 5,
    "ogx_mmlux_de-security_studies": 5,
    "ogx_mmlux_de-sociology": 5,
    "ogx_mmlux_de-us_foreign_policy": 5,
    "ogx_mmlux_de-virology": 5,
    "ogx_mmlux_de-world_religions": 5,
    "ogx_mmlux_el-abstract_algebra": 5,
    "ogx_mmlux_el-anatomy": 5,
    "ogx_mmlux_el-astronomy": 5,
    "ogx_mmlux_el-business_ethics": 5,
    "ogx_mmlux_el-clinical_knowledge": 5,
    "ogx_mmlux_el-college_biology": 5,
    "ogx_mmlux_el-college_chemistry": 5,
    "ogx_mmlux_el-college_computer_science": 5,
    "ogx_mmlux_el-college_mathematics": 5,
    "ogx_mmlux_el-college_medicine": 5,
    "ogx_mmlux_el-college_physics": 5,
    "ogx_mmlux_el-computer_security": 5,
    "ogx_mmlux_el-conceptual_physics": 5,
    "ogx_mmlux_el-econometrics": 5,
    "ogx_mmlux_el-electrical_engineering": 5,
    "ogx_mmlux_el-elementary_mathematics": 5,
    "ogx_mmlux_el-formal_logic": 5,
    "ogx_mmlux_el-global_facts": 5,
    "ogx_mmlux_el-high_school_biology": 5,
    "ogx_mmlux_el-high_school_chemistry": 5,
    "ogx_mmlux_el-high_school_computer_science": 5,
    "ogx_mmlux_el-high_school_european_history": 5,
    "ogx_mmlux_el-high_school_geography": 5,
    "ogx_mmlux_el-high_school_government_and_politics": 5,
    "ogx_mmlux_el-high_school_macroeconomics": 5,
    "ogx_mmlux_el-high_school_mathematics": 5,
    "ogx_mmlux_el-high_school_microeconomics": 5,
    "ogx_mmlux_el-high_school_physics": 5,
    "ogx_mmlux_el-high_school_psychology": 5,
    "ogx_mmlux_el-high_school_statistics": 5,
    "ogx_mmlux_el-high_school_us_history": 5,
    "ogx_mmlux_el-high_school_world_history": 5,
    "ogx_mmlux_el-human_aging": 5,
    "ogx_mmlux_el-human_sexuality": 5,
    "ogx_mmlux_el-international_law": 5,
    "ogx_mmlux_el-jurisprudence": 5,
    "ogx_mmlux_el-logical_fallacies": 5,
    "ogx_mmlux_el-machine_learning": 5,
    "ogx_mmlux_el-management": 5,
    "ogx_mmlux_el-marketing": 5,
    "ogx_mmlux_el-medical_genetics": 5,
    "ogx_mmlux_el-miscellaneous": 5,
    "ogx_mmlux_el-moral_disputes": 5,
    "ogx_mmlux_el-moral_scenarios": 5,
    "ogx_mmlux_el-nutrition": 5,
    "ogx_mmlux_el-philosophy": 5,
    "ogx_mmlux_el-prehistory": 5,
    "ogx_mmlux_el-professional_accounting": 5,
    "ogx_mmlux_el-professional_law": 5,
    "ogx_mmlux_el-professional_medicine": 5,
    "ogx_mmlux_el-professional_psychology": 5,
    "ogx_mmlux_el-public_relations": 5,
    "ogx_mmlux_el-security_studies": 5,
    "ogx_mmlux_el-sociology": 5,
    "ogx_mmlux_el-us_foreign_policy": 5,
    "ogx_mmlux_el-virology": 5,
    "ogx_mmlux_el-world_religions": 5,
    "ogx_mmlux_es-abstract_algebra": 5,
    "ogx_mmlux_es-anatomy": 5,
    "ogx_mmlux_es-astronomy": 5,
    "ogx_mmlux_es-business_ethics": 5,
    "ogx_mmlux_es-clinical_knowledge": 5,
    "ogx_mmlux_es-college_biology": 5,
    "ogx_mmlux_es-college_chemistry": 5,
    "ogx_mmlux_es-college_computer_science": 5,
    "ogx_mmlux_es-college_mathematics": 5,
    "ogx_mmlux_es-college_medicine": 5,
    "ogx_mmlux_es-college_physics": 5,
    "ogx_mmlux_es-computer_security": 5,
    "ogx_mmlux_es-conceptual_physics": 5,
    "ogx_mmlux_es-econometrics": 5,
    "ogx_mmlux_es-electrical_engineering": 5,
    "ogx_mmlux_es-elementary_mathematics": 5,
    "ogx_mmlux_es-formal_logic": 5,
    "ogx_mmlux_es-global_facts": 5,
    "ogx_mmlux_es-high_school_biology": 5,
    "ogx_mmlux_es-high_school_chemistry": 5,
    "ogx_mmlux_es-high_school_computer_science": 5,
    "ogx_mmlux_es-high_school_european_history": 5,
    "ogx_mmlux_es-high_school_geography": 5,
    "ogx_mmlux_es-high_school_government_and_politics": 5,
    "ogx_mmlux_es-high_school_macroeconomics": 5,
    "ogx_mmlux_es-high_school_mathematics": 5,
    "ogx_mmlux_es-high_school_microeconomics": 5,
    "ogx_mmlux_es-high_school_physics": 5,
    "ogx_mmlux_es-high_school_psychology": 5,
    "ogx_mmlux_es-high_school_statistics": 5,
    "ogx_mmlux_es-high_school_us_history": 5,
    "ogx_mmlux_es-high_school_world_history": 5,
    "ogx_mmlux_es-human_aging": 5,
    "ogx_mmlux_es-human_sexuality": 5,
    "ogx_mmlux_es-international_law": 5,
    "ogx_mmlux_es-jurisprudence": 5,
    "ogx_mmlux_es-logical_fallacies": 5,
    "ogx_mmlux_es-machine_learning": 5,
    "ogx_mmlux_es-management": 5,
    "ogx_mmlux_es-marketing": 5,
    "ogx_mmlux_es-medical_genetics": 5,
    "ogx_mmlux_es-miscellaneous": 5,
    "ogx_mmlux_es-moral_disputes": 5,
    "ogx_mmlux_es-moral_scenarios": 5,
    "ogx_mmlux_es-nutrition": 5,
    "ogx_mmlux_es-philosophy": 5,
    "ogx_mmlux_es-prehistory": 5,
    "ogx_mmlux_es-professional_accounting": 5,
    "ogx_mmlux_es-professional_law": 5,
    "ogx_mmlux_es-professional_medicine": 5,
    "ogx_mmlux_es-professional_psychology": 5,
    "ogx_mmlux_es-public_relations": 5,
    "ogx_mmlux_es-security_studies": 5,
    "ogx_mmlux_es-sociology": 5,
    "ogx_mmlux_es-us_foreign_policy": 5,
    "ogx_mmlux_es-virology": 5,
    "ogx_mmlux_es-world_religions": 5,
    "ogx_mmlux_et-abstract_algebra": 5,
    "ogx_mmlux_et-anatomy": 5,
    "ogx_mmlux_et-astronomy": 5,
    "ogx_mmlux_et-business_ethics": 5,
    "ogx_mmlux_et-clinical_knowledge": 5,
    "ogx_mmlux_et-college_biology": 5,
    "ogx_mmlux_et-college_chemistry": 5,
    "ogx_mmlux_et-college_computer_science": 5,
    "ogx_mmlux_et-college_mathematics": 5,
    "ogx_mmlux_et-college_medicine": 5,
    "ogx_mmlux_et-college_physics": 5,
    "ogx_mmlux_et-computer_security": 5,
    "ogx_mmlux_et-conceptual_physics": 5,
    "ogx_mmlux_et-econometrics": 5,
    "ogx_mmlux_et-electrical_engineering": 5,
    "ogx_mmlux_et-elementary_mathematics": 5,
    "ogx_mmlux_et-formal_logic": 5,
    "ogx_mmlux_et-global_facts": 5,
    "ogx_mmlux_et-high_school_biology": 5,
    "ogx_mmlux_et-high_school_chemistry": 5,
    "ogx_mmlux_et-high_school_computer_science": 5,
    "ogx_mmlux_et-high_school_european_history": 5,
    "ogx_mmlux_et-high_school_geography": 5,
    "ogx_mmlux_et-high_school_government_and_politics": 5,
    "ogx_mmlux_et-high_school_macroeconomics": 5,
    "ogx_mmlux_et-high_school_mathematics": 5,
    "ogx_mmlux_et-high_school_microeconomics": 5,
    "ogx_mmlux_et-high_school_physics": 5,
    "ogx_mmlux_et-high_school_psychology": 5,
    "ogx_mmlux_et-high_school_statistics": 5,
    "ogx_mmlux_et-high_school_us_history": 5,
    "ogx_mmlux_et-high_school_world_history": 5,
    "ogx_mmlux_et-human_aging": 5,
    "ogx_mmlux_et-human_sexuality": 5,
    "ogx_mmlux_et-international_law": 5,
    "ogx_mmlux_et-jurisprudence": 5,
    "ogx_mmlux_et-logical_fallacies": 5,
    "ogx_mmlux_et-machine_learning": 5,
    "ogx_mmlux_et-management": 5,
    "ogx_mmlux_et-marketing": 5,
    "ogx_mmlux_et-medical_genetics": 5,
    "ogx_mmlux_et-miscellaneous": 5,
    "ogx_mmlux_et-moral_disputes": 5,
    "ogx_mmlux_et-moral_scenarios": 5,
    "ogx_mmlux_et-nutrition": 5,
    "ogx_mmlux_et-philosophy": 5,
    "ogx_mmlux_et-prehistory": 5,
    "ogx_mmlux_et-professional_accounting": 5,
    "ogx_mmlux_et-professional_law": 5,
    "ogx_mmlux_et-professional_medicine": 5,
    "ogx_mmlux_et-professional_psychology": 5,
    "ogx_mmlux_et-public_relations": 5,
    "ogx_mmlux_et-security_studies": 5,
    "ogx_mmlux_et-sociology": 5,
    "ogx_mmlux_et-us_foreign_policy": 5,
    "ogx_mmlux_et-virology": 5,
    "ogx_mmlux_et-world_religions": 5,
    "ogx_mmlux_fi-abstract_algebra": 5,
    "ogx_mmlux_fi-anatomy": 5,
    "ogx_mmlux_fi-astronomy": 5,
    "ogx_mmlux_fi-business_ethics": 5,
    "ogx_mmlux_fi-clinical_knowledge": 5,
    "ogx_mmlux_fi-college_biology": 5,
    "ogx_mmlux_fi-college_chemistry": 5,
    "ogx_mmlux_fi-college_computer_science": 5,
    "ogx_mmlux_fi-college_mathematics": 5,
    "ogx_mmlux_fi-college_medicine": 5,
    "ogx_mmlux_fi-college_physics": 5,
    "ogx_mmlux_fi-computer_security": 5,
    "ogx_mmlux_fi-conceptual_physics": 5,
    "ogx_mmlux_fi-econometrics": 5,
    "ogx_mmlux_fi-electrical_engineering": 5,
    "ogx_mmlux_fi-elementary_mathematics": 5,
    "ogx_mmlux_fi-formal_logic": 5,
    "ogx_mmlux_fi-global_facts": 5,
    "ogx_mmlux_fi-high_school_biology": 5,
    "ogx_mmlux_fi-high_school_chemistry": 5,
    "ogx_mmlux_fi-high_school_computer_science": 5,
    "ogx_mmlux_fi-high_school_european_history": 5,
    "ogx_mmlux_fi-high_school_geography": 5,
    "ogx_mmlux_fi-high_school_government_and_politics": 5,
    "ogx_mmlux_fi-high_school_macroeconomics": 5,
    "ogx_mmlux_fi-high_school_mathematics": 5,
    "ogx_mmlux_fi-high_school_microeconomics": 5,
    "ogx_mmlux_fi-high_school_physics": 5,
    "ogx_mmlux_fi-high_school_psychology": 5,
    "ogx_mmlux_fi-high_school_statistics": 5,
    "ogx_mmlux_fi-high_school_us_history": 5,
    "ogx_mmlux_fi-high_school_world_history": 5,
    "ogx_mmlux_fi-human_aging": 5,
    "ogx_mmlux_fi-human_sexuality": 5,
    "ogx_mmlux_fi-international_law": 5,
    "ogx_mmlux_fi-jurisprudence": 5,
    "ogx_mmlux_fi-logical_fallacies": 5,
    "ogx_mmlux_fi-machine_learning": 5,
    "ogx_mmlux_fi-management": 5,
    "ogx_mmlux_fi-marketing": 5,
    "ogx_mmlux_fi-medical_genetics": 5,
    "ogx_mmlux_fi-miscellaneous": 5,
    "ogx_mmlux_fi-moral_disputes": 5,
    "ogx_mmlux_fi-moral_scenarios": 5,
    "ogx_mmlux_fi-nutrition": 5,
    "ogx_mmlux_fi-philosophy": 5,
    "ogx_mmlux_fi-prehistory": 5,
    "ogx_mmlux_fi-professional_accounting": 5,
    "ogx_mmlux_fi-professional_law": 5,
    "ogx_mmlux_fi-professional_medicine": 5,
    "ogx_mmlux_fi-professional_psychology": 5,
    "ogx_mmlux_fi-public_relations": 5,
    "ogx_mmlux_fi-security_studies": 5,
    "ogx_mmlux_fi-sociology": 5,
    "ogx_mmlux_fi-us_foreign_policy": 5,
    "ogx_mmlux_fi-virology": 5,
    "ogx_mmlux_fi-world_religions": 5,
    "ogx_mmlux_fr-abstract_algebra": 5,
    "ogx_mmlux_fr-anatomy": 5,
    "ogx_mmlux_fr-astronomy": 5,
    "ogx_mmlux_fr-business_ethics": 5,
    "ogx_mmlux_fr-clinical_knowledge": 5,
    "ogx_mmlux_fr-college_biology": 5,
    "ogx_mmlux_fr-college_chemistry": 5,
    "ogx_mmlux_fr-college_computer_science": 5,
    "ogx_mmlux_fr-college_mathematics": 5,
    "ogx_mmlux_fr-college_medicine": 5,
    "ogx_mmlux_fr-college_physics": 5,
    "ogx_mmlux_fr-computer_security": 5,
    "ogx_mmlux_fr-conceptual_physics": 5,
    "ogx_mmlux_fr-econometrics": 5,
    "ogx_mmlux_fr-electrical_engineering": 5,
    "ogx_mmlux_fr-elementary_mathematics": 5,
    "ogx_mmlux_fr-formal_logic": 5,
    "ogx_mmlux_fr-global_facts": 5,
    "ogx_mmlux_fr-high_school_biology": 5,
    "ogx_mmlux_fr-high_school_chemistry": 5,
    "ogx_mmlux_fr-high_school_computer_science": 5,
    "ogx_mmlux_fr-high_school_european_history": 5,
    "ogx_mmlux_fr-high_school_geography": 5,
    "ogx_mmlux_fr-high_school_government_and_politics": 5,
    "ogx_mmlux_fr-high_school_macroeconomics": 5,
    "ogx_mmlux_fr-high_school_mathematics": 5,
    "ogx_mmlux_fr-high_school_microeconomics": 5,
    "ogx_mmlux_fr-high_school_physics": 5,
    "ogx_mmlux_fr-high_school_psychology": 5,
    "ogx_mmlux_fr-high_school_statistics": 5,
    "ogx_mmlux_fr-high_school_us_history": 5,
    "ogx_mmlux_fr-high_school_world_history": 5,
    "ogx_mmlux_fr-human_aging": 5,
    "ogx_mmlux_fr-human_sexuality": 5,
    "ogx_mmlux_fr-international_law": 5,
    "ogx_mmlux_fr-jurisprudence": 5,
    "ogx_mmlux_fr-logical_fallacies": 5,
    "ogx_mmlux_fr-machine_learning": 5,
    "ogx_mmlux_fr-management": 5,
    "ogx_mmlux_fr-marketing": 5,
    "ogx_mmlux_fr-medical_genetics": 5,
    "ogx_mmlux_fr-miscellaneous": 5,
    "ogx_mmlux_fr-moral_disputes": 5,
    "ogx_mmlux_fr-moral_scenarios": 5,
    "ogx_mmlux_fr-nutrition": 5,
    "ogx_mmlux_fr-philosophy": 5,
    "ogx_mmlux_fr-prehistory": 5,
    "ogx_mmlux_fr-professional_accounting": 5,
    "ogx_mmlux_fr-professional_law": 5,
    "ogx_mmlux_fr-professional_medicine": 5,
    "ogx_mmlux_fr-professional_psychology": 5,
    "ogx_mmlux_fr-public_relations": 5,
    "ogx_mmlux_fr-security_studies": 5,
    "ogx_mmlux_fr-sociology": 5,
    "ogx_mmlux_fr-us_foreign_policy": 5,
    "ogx_mmlux_fr-virology": 5,
    "ogx_mmlux_fr-world_religions": 5,
    "ogx_mmlux_hu-abstract_algebra": 5,
    "ogx_mmlux_hu-anatomy": 5,
    "ogx_mmlux_hu-astronomy": 5,
    "ogx_mmlux_hu-business_ethics": 5,
    "ogx_mmlux_hu-clinical_knowledge": 5,
    "ogx_mmlux_hu-college_biology": 5,
    "ogx_mmlux_hu-college_chemistry": 5,
    "ogx_mmlux_hu-college_computer_science": 5,
    "ogx_mmlux_hu-college_mathematics": 5,
    "ogx_mmlux_hu-college_medicine": 5,
    "ogx_mmlux_hu-college_physics": 5,
    "ogx_mmlux_hu-computer_security": 5,
    "ogx_mmlux_hu-conceptual_physics": 5,
    "ogx_mmlux_hu-econometrics": 5,
    "ogx_mmlux_hu-electrical_engineering": 5,
    "ogx_mmlux_hu-elementary_mathematics": 5,
    "ogx_mmlux_hu-formal_logic": 5,
    "ogx_mmlux_hu-global_facts": 5,
    "ogx_mmlux_hu-high_school_biology": 5,
    "ogx_mmlux_hu-high_school_chemistry": 5,
    "ogx_mmlux_hu-high_school_computer_science": 5,
    "ogx_mmlux_hu-high_school_european_history": 5,
    "ogx_mmlux_hu-high_school_geography": 5,
    "ogx_mmlux_hu-high_school_government_and_politics": 5,
    "ogx_mmlux_hu-high_school_macroeconomics": 5,
    "ogx_mmlux_hu-high_school_mathematics": 5,
    "ogx_mmlux_hu-high_school_microeconomics": 5,
    "ogx_mmlux_hu-high_school_physics": 5,
    "ogx_mmlux_hu-high_school_psychology": 5,
    "ogx_mmlux_hu-high_school_statistics": 5,
    "ogx_mmlux_hu-high_school_us_history": 5,
    "ogx_mmlux_hu-high_school_world_history": 5,
    "ogx_mmlux_hu-human_aging": 5,
    "ogx_mmlux_hu-human_sexuality": 5,
    "ogx_mmlux_hu-international_law": 5,
    "ogx_mmlux_hu-jurisprudence": 5,
    "ogx_mmlux_hu-logical_fallacies": 5,
    "ogx_mmlux_hu-machine_learning": 5,
    "ogx_mmlux_hu-management": 5,
    "ogx_mmlux_hu-marketing": 5,
    "ogx_mmlux_hu-medical_genetics": 5,
    "ogx_mmlux_hu-miscellaneous": 5,
    "ogx_mmlux_hu-moral_disputes": 5,
    "ogx_mmlux_hu-moral_scenarios": 5,
    "ogx_mmlux_hu-nutrition": 5,
    "ogx_mmlux_hu-philosophy": 5,
    "ogx_mmlux_hu-prehistory": 5,
    "ogx_mmlux_hu-professional_accounting": 5,
    "ogx_mmlux_hu-professional_law": 5,
    "ogx_mmlux_hu-professional_medicine": 5,
    "ogx_mmlux_hu-professional_psychology": 5,
    "ogx_mmlux_hu-public_relations": 5,
    "ogx_mmlux_hu-security_studies": 5,
    "ogx_mmlux_hu-sociology": 5,
    "ogx_mmlux_hu-us_foreign_policy": 5,
    "ogx_mmlux_hu-virology": 5,
    "ogx_mmlux_hu-world_religions": 5,
    "ogx_mmlux_it-abstract_algebra": 5,
    "ogx_mmlux_it-anatomy": 5,
    "ogx_mmlux_it-astronomy": 5,
    "ogx_mmlux_it-business_ethics": 5,
    "ogx_mmlux_it-clinical_knowledge": 5,
    "ogx_mmlux_it-college_biology": 5,
    "ogx_mmlux_it-college_chemistry": 5,
    "ogx_mmlux_it-college_computer_science": 5,
    "ogx_mmlux_it-college_mathematics": 5,
    "ogx_mmlux_it-college_medicine": 5,
    "ogx_mmlux_it-college_physics": 5,
    "ogx_mmlux_it-computer_security": 5,
    "ogx_mmlux_it-conceptual_physics": 5,
    "ogx_mmlux_it-econometrics": 5,
    "ogx_mmlux_it-electrical_engineering": 5,
    "ogx_mmlux_it-elementary_mathematics": 5,
    "ogx_mmlux_it-formal_logic": 5,
    "ogx_mmlux_it-global_facts": 5,
    "ogx_mmlux_it-high_school_biology": 5,
    "ogx_mmlux_it-high_school_chemistry": 5,
    "ogx_mmlux_it-high_school_computer_science": 5,
    "ogx_mmlux_it-high_school_european_history": 5,
    "ogx_mmlux_it-high_school_geography": 5,
    "ogx_mmlux_it-high_school_government_and_politics": 5,
    "ogx_mmlux_it-high_school_macroeconomics": 5,
    "ogx_mmlux_it-high_school_mathematics": 5,
    "ogx_mmlux_it-high_school_microeconomics": 5,
    "ogx_mmlux_it-high_school_physics": 5,
    "ogx_mmlux_it-high_school_psychology": 5,
    "ogx_mmlux_it-high_school_statistics": 5,
    "ogx_mmlux_it-high_school_us_history": 5,
    "ogx_mmlux_it-high_school_world_history": 5,
    "ogx_mmlux_it-human_aging": 5,
    "ogx_mmlux_it-human_sexuality": 5,
    "ogx_mmlux_it-international_law": 5,
    "ogx_mmlux_it-jurisprudence": 5,
    "ogx_mmlux_it-logical_fallacies": 5,
    "ogx_mmlux_it-machine_learning": 5,
    "ogx_mmlux_it-management": 5,
    "ogx_mmlux_it-marketing": 5,
    "ogx_mmlux_it-medical_genetics": 5,
    "ogx_mmlux_it-miscellaneous": 5,
    "ogx_mmlux_it-moral_disputes": 5,
    "ogx_mmlux_it-moral_scenarios": 5,
    "ogx_mmlux_it-nutrition": 5,
    "ogx_mmlux_it-philosophy": 5,
    "ogx_mmlux_it-prehistory": 5,
    "ogx_mmlux_it-professional_accounting": 5,
    "ogx_mmlux_it-professional_law": 5,
    "ogx_mmlux_it-professional_medicine": 5,
    "ogx_mmlux_it-professional_psychology": 5,
    "ogx_mmlux_it-public_relations": 5,
    "ogx_mmlux_it-security_studies": 5,
    "ogx_mmlux_it-sociology": 5,
    "ogx_mmlux_it-us_foreign_policy": 5,
    "ogx_mmlux_it-virology": 5,
    "ogx_mmlux_it-world_religions": 5,
    "ogx_mmlux_lt-abstract_algebra": 5,
    "ogx_mmlux_lt-anatomy": 5,
    "ogx_mmlux_lt-astronomy": 5,
    "ogx_mmlux_lt-business_ethics": 5,
    "ogx_mmlux_lt-clinical_knowledge": 5,
    "ogx_mmlux_lt-college_biology": 5,
    "ogx_mmlux_lt-college_chemistry": 5,
    "ogx_mmlux_lt-college_computer_science": 5,
    "ogx_mmlux_lt-college_mathematics": 5,
    "ogx_mmlux_lt-college_medicine": 5,
    "ogx_mmlux_lt-college_physics": 5,
    "ogx_mmlux_lt-computer_security": 5,
    "ogx_mmlux_lt-conceptual_physics": 5,
    "ogx_mmlux_lt-econometrics": 5,
    "ogx_mmlux_lt-electrical_engineering": 5,
    "ogx_mmlux_lt-elementary_mathematics": 5,
    "ogx_mmlux_lt-formal_logic": 5,
    "ogx_mmlux_lt-global_facts": 5,
    "ogx_mmlux_lt-high_school_biology": 5,
    "ogx_mmlux_lt-high_school_chemistry": 5,
    "ogx_mmlux_lt-high_school_computer_science": 5,
    "ogx_mmlux_lt-high_school_european_history": 5,
    "ogx_mmlux_lt-high_school_geography": 5,
    "ogx_mmlux_lt-high_school_government_and_politics": 5,
    "ogx_mmlux_lt-high_school_macroeconomics": 5,
    "ogx_mmlux_lt-high_school_mathematics": 5,
    "ogx_mmlux_lt-high_school_microeconomics": 5,
    "ogx_mmlux_lt-high_school_physics": 5,
    "ogx_mmlux_lt-high_school_psychology": 5,
    "ogx_mmlux_lt-high_school_statistics": 5,
    "ogx_mmlux_lt-high_school_us_history": 5,
    "ogx_mmlux_lt-high_school_world_history": 5,
    "ogx_mmlux_lt-human_aging": 5,
    "ogx_mmlux_lt-human_sexuality": 5,
    "ogx_mmlux_lt-international_law": 5,
    "ogx_mmlux_lt-jurisprudence": 5,
    "ogx_mmlux_lt-logical_fallacies": 5,
    "ogx_mmlux_lt-machine_learning": 5,
    "ogx_mmlux_lt-management": 5,
    "ogx_mmlux_lt-marketing": 5,
    "ogx_mmlux_lt-medical_genetics": 5,
    "ogx_mmlux_lt-miscellaneous": 5,
    "ogx_mmlux_lt-moral_disputes": 5,
    "ogx_mmlux_lt-moral_scenarios": 5,
    "ogx_mmlux_lt-nutrition": 5,
    "ogx_mmlux_lt-philosophy": 5,
    "ogx_mmlux_lt-prehistory": 5,
    "ogx_mmlux_lt-professional_accounting": 5,
    "ogx_mmlux_lt-professional_law": 5,
    "ogx_mmlux_lt-professional_medicine": 5,
    "ogx_mmlux_lt-professional_psychology": 5,
    "ogx_mmlux_lt-public_relations": 5,
    "ogx_mmlux_lt-security_studies": 5,
    "ogx_mmlux_lt-sociology": 5,
    "ogx_mmlux_lt-us_foreign_policy": 5,
    "ogx_mmlux_lt-virology": 5,
    "ogx_mmlux_lt-world_religions": 5,
    "ogx_mmlux_lv-abstract_algebra": 5,
    "ogx_mmlux_lv-anatomy": 5,
    "ogx_mmlux_lv-astronomy": 5,
    "ogx_mmlux_lv-business_ethics": 5,
    "ogx_mmlux_lv-clinical_knowledge": 5,
    "ogx_mmlux_lv-college_biology": 5,
    "ogx_mmlux_lv-college_chemistry": 5,
    "ogx_mmlux_lv-college_computer_science": 5,
    "ogx_mmlux_lv-college_mathematics": 5,
    "ogx_mmlux_lv-college_medicine": 5,
    "ogx_mmlux_lv-college_physics": 5,
    "ogx_mmlux_lv-computer_security": 5,
    "ogx_mmlux_lv-conceptual_physics": 5,
    "ogx_mmlux_lv-econometrics": 5,
    "ogx_mmlux_lv-electrical_engineering": 5,
    "ogx_mmlux_lv-elementary_mathematics": 5,
    "ogx_mmlux_lv-formal_logic": 5,
    "ogx_mmlux_lv-global_facts": 5,
    "ogx_mmlux_lv-high_school_biology": 5,
    "ogx_mmlux_lv-high_school_chemistry": 5,
    "ogx_mmlux_lv-high_school_computer_science": 5,
    "ogx_mmlux_lv-high_school_european_history": 5,
    "ogx_mmlux_lv-high_school_geography": 5,
    "ogx_mmlux_lv-high_school_government_and_politics": 5,
    "ogx_mmlux_lv-high_school_macroeconomics": 5,
    "ogx_mmlux_lv-high_school_mathematics": 5,
    "ogx_mmlux_lv-high_school_microeconomics": 5,
    "ogx_mmlux_lv-high_school_physics": 5,
    "ogx_mmlux_lv-high_school_psychology": 5,
    "ogx_mmlux_lv-high_school_statistics": 5,
    "ogx_mmlux_lv-high_school_us_history": 5,
    "ogx_mmlux_lv-high_school_world_history": 5,
    "ogx_mmlux_lv-human_aging": 5,
    "ogx_mmlux_lv-human_sexuality": 5,
    "ogx_mmlux_lv-international_law": 5,
    "ogx_mmlux_lv-jurisprudence": 5,
    "ogx_mmlux_lv-logical_fallacies": 5,
    "ogx_mmlux_lv-machine_learning": 5,
    "ogx_mmlux_lv-management": 5,
    "ogx_mmlux_lv-marketing": 5,
    "ogx_mmlux_lv-medical_genetics": 5,
    "ogx_mmlux_lv-miscellaneous": 5,
    "ogx_mmlux_lv-moral_disputes": 5,
    "ogx_mmlux_lv-moral_scenarios": 5,
    "ogx_mmlux_lv-nutrition": 5,
    "ogx_mmlux_lv-philosophy": 5,
    "ogx_mmlux_lv-prehistory": 5,
    "ogx_mmlux_lv-professional_accounting": 5,
    "ogx_mmlux_lv-professional_law": 5,
    "ogx_mmlux_lv-professional_medicine": 5,
    "ogx_mmlux_lv-professional_psychology": 5,
    "ogx_mmlux_lv-public_relations": 5,
    "ogx_mmlux_lv-security_studies": 5,
    "ogx_mmlux_lv-sociology": 5,
    "ogx_mmlux_lv-us_foreign_policy": 5,
    "ogx_mmlux_lv-virology": 5,
    "ogx_mmlux_lv-world_religions": 5,
    "ogx_mmlux_nl-abstract_algebra": 5,
    "ogx_mmlux_nl-anatomy": 5,
    "ogx_mmlux_nl-astronomy": 5,
    "ogx_mmlux_nl-business_ethics": 5,
    "ogx_mmlux_nl-clinical_knowledge": 5,
    "ogx_mmlux_nl-college_biology": 5,
    "ogx_mmlux_nl-college_chemistry": 5,
    "ogx_mmlux_nl-college_computer_science": 5,
    "ogx_mmlux_nl-college_mathematics": 5,
    "ogx_mmlux_nl-college_medicine": 5,
    "ogx_mmlux_nl-college_physics": 5,
    "ogx_mmlux_nl-computer_security": 5,
    "ogx_mmlux_nl-conceptual_physics": 5,
    "ogx_mmlux_nl-econometrics": 5,
    "ogx_mmlux_nl-electrical_engineering": 5,
    "ogx_mmlux_nl-elementary_mathematics": 5,
    "ogx_mmlux_nl-formal_logic": 5,
    "ogx_mmlux_nl-global_facts": 5,
    "ogx_mmlux_nl-high_school_biology": 5,
    "ogx_mmlux_nl-high_school_chemistry": 5,
    "ogx_mmlux_nl-high_school_computer_science": 5,
    "ogx_mmlux_nl-high_school_european_history": 5,
    "ogx_mmlux_nl-high_school_geography": 5,
    "ogx_mmlux_nl-high_school_government_and_politics": 5,
    "ogx_mmlux_nl-high_school_macroeconomics": 5,
    "ogx_mmlux_nl-high_school_mathematics": 5,
    "ogx_mmlux_nl-high_school_microeconomics": 5,
    "ogx_mmlux_nl-high_school_physics": 5,
    "ogx_mmlux_nl-high_school_psychology": 5,
    "ogx_mmlux_nl-high_school_statistics": 5,
    "ogx_mmlux_nl-high_school_us_history": 5,
    "ogx_mmlux_nl-high_school_world_history": 5,
    "ogx_mmlux_nl-human_aging": 5,
    "ogx_mmlux_nl-human_sexuality": 5,
    "ogx_mmlux_nl-international_law": 5,
    "ogx_mmlux_nl-jurisprudence": 5,
    "ogx_mmlux_nl-logical_fallacies": 5,
    "ogx_mmlux_nl-machine_learning": 5,
    "ogx_mmlux_nl-management": 5,
    "ogx_mmlux_nl-marketing": 5,
    "ogx_mmlux_nl-medical_genetics": 5,
    "ogx_mmlux_nl-miscellaneous": 5,
    "ogx_mmlux_nl-moral_disputes": 5,
    "ogx_mmlux_nl-moral_scenarios": 5,
    "ogx_mmlux_nl-nutrition": 5,
    "ogx_mmlux_nl-philosophy": 5,
    "ogx_mmlux_nl-prehistory": 5,
    "ogx_mmlux_nl-professional_accounting": 5,
    "ogx_mmlux_nl-professional_law": 5,
    "ogx_mmlux_nl-professional_medicine": 5,
    "ogx_mmlux_nl-professional_psychology": 5,
    "ogx_mmlux_nl-public_relations": 5,
    "ogx_mmlux_nl-security_studies": 5,
    "ogx_mmlux_nl-sociology": 5,
    "ogx_mmlux_nl-us_foreign_policy": 5,
    "ogx_mmlux_nl-virology": 5,
    "ogx_mmlux_nl-world_religions": 5,
    "ogx_mmlux_pl-abstract_algebra": 5,
    "ogx_mmlux_pl-anatomy": 5,
    "ogx_mmlux_pl-astronomy": 5,
    "ogx_mmlux_pl-business_ethics": 5,
    "ogx_mmlux_pl-clinical_knowledge": 5,
    "ogx_mmlux_pl-college_biology": 5,
    "ogx_mmlux_pl-college_chemistry": 5,
    "ogx_mmlux_pl-college_computer_science": 5,
    "ogx_mmlux_pl-college_mathematics": 5,
    "ogx_mmlux_pl-college_medicine": 5,
    "ogx_mmlux_pl-college_physics": 5,
    "ogx_mmlux_pl-computer_security": 5,
    "ogx_mmlux_pl-conceptual_physics": 5,
    "ogx_mmlux_pl-econometrics": 5,
    "ogx_mmlux_pl-electrical_engineering": 5,
    "ogx_mmlux_pl-elementary_mathematics": 5,
    "ogx_mmlux_pl-formal_logic": 5,
    "ogx_mmlux_pl-global_facts": 5,
    "ogx_mmlux_pl-high_school_biology": 5,
    "ogx_mmlux_pl-high_school_chemistry": 5,
    "ogx_mmlux_pl-high_school_computer_science": 5,
    "ogx_mmlux_pl-high_school_european_history": 5,
    "ogx_mmlux_pl-high_school_geography": 5,
    "ogx_mmlux_pl-high_school_government_and_politics": 5,
    "ogx_mmlux_pl-high_school_macroeconomics": 5,
    "ogx_mmlux_pl-high_school_mathematics": 5,
    "ogx_mmlux_pl-high_school_microeconomics": 5,
    "ogx_mmlux_pl-high_school_physics": 5,
    "ogx_mmlux_pl-high_school_psychology": 5,
    "ogx_mmlux_pl-high_school_statistics": 5,
    "ogx_mmlux_pl-high_school_us_history": 5,
    "ogx_mmlux_pl-high_school_world_history": 5,
    "ogx_mmlux_pl-human_aging": 5,
    "ogx_mmlux_pl-human_sexuality": 5,
    "ogx_mmlux_pl-international_law": 5,
    "ogx_mmlux_pl-jurisprudence": 5,
    "ogx_mmlux_pl-logical_fallacies": 5,
    "ogx_mmlux_pl-machine_learning": 5,
    "ogx_mmlux_pl-management": 5,
    "ogx_mmlux_pl-marketing": 5,
    "ogx_mmlux_pl-medical_genetics": 5,
    "ogx_mmlux_pl-miscellaneous": 5,
    "ogx_mmlux_pl-moral_disputes": 5,
    "ogx_mmlux_pl-moral_scenarios": 5,
    "ogx_mmlux_pl-nutrition": 5,
    "ogx_mmlux_pl-philosophy": 5,
    "ogx_mmlux_pl-prehistory": 5,
    "ogx_mmlux_pl-professional_accounting": 5,
    "ogx_mmlux_pl-professional_law": 5,
    "ogx_mmlux_pl-professional_medicine": 5,
    "ogx_mmlux_pl-professional_psychology": 5,
    "ogx_mmlux_pl-public_relations": 5,
    "ogx_mmlux_pl-security_studies": 5,
    "ogx_mmlux_pl-sociology": 5,
    "ogx_mmlux_pl-us_foreign_policy": 5,
    "ogx_mmlux_pl-virology": 5,
    "ogx_mmlux_pl-world_religions": 5,
    "ogx_mmlux_pt-pt-abstract_algebra": 5,
    "ogx_mmlux_pt-pt-anatomy": 5,
    "ogx_mmlux_pt-pt-astronomy": 5,
    "ogx_mmlux_pt-pt-business_ethics": 5,
    "ogx_mmlux_pt-pt-clinical_knowledge": 5,
    "ogx_mmlux_pt-pt-college_biology": 5,
    "ogx_mmlux_pt-pt-college_chemistry": 5,
    "ogx_mmlux_pt-pt-college_computer_science": 5,
    "ogx_mmlux_pt-pt-college_mathematics": 5,
    "ogx_mmlux_pt-pt-college_medicine": 5,
    "ogx_mmlux_pt-pt-college_physics": 5,
    "ogx_mmlux_pt-pt-computer_security": 5,
    "ogx_mmlux_pt-pt-conceptual_physics": 5,
    "ogx_mmlux_pt-pt-econometrics": 5,
    "ogx_mmlux_pt-pt-electrical_engineering": 5,
    "ogx_mmlux_pt-pt-elementary_mathematics": 5,
    "ogx_mmlux_pt-pt-formal_logic": 5,
    "ogx_mmlux_pt-pt-global_facts": 5,
    "ogx_mmlux_pt-pt-high_school_biology": 5,
    "ogx_mmlux_pt-pt-high_school_chemistry": 5,
    "ogx_mmlux_pt-pt-high_school_computer_science": 5,
    "ogx_mmlux_pt-pt-high_school_european_history": 5,
    "ogx_mmlux_pt-pt-high_school_geography": 5,
    "ogx_mmlux_pt-pt-high_school_government_and_politics": 5,
    "ogx_mmlux_pt-pt-high_school_macroeconomics": 5,
    "ogx_mmlux_pt-pt-high_school_mathematics": 5,
    "ogx_mmlux_pt-pt-high_school_microeconomics": 5,
    "ogx_mmlux_pt-pt-high_school_physics": 5,
    "ogx_mmlux_pt-pt-high_school_psychology": 5,
    "ogx_mmlux_pt-pt-high_school_statistics": 5,
    "ogx_mmlux_pt-pt-high_school_us_history": 5,
    "ogx_mmlux_pt-pt-high_school_world_history": 5,
    "ogx_mmlux_pt-pt-human_aging": 5,
    "ogx_mmlux_pt-pt-human_sexuality": 5,
    "ogx_mmlux_pt-pt-international_law": 5,
    "ogx_mmlux_pt-pt-jurisprudence": 5,
    "ogx_mmlux_pt-pt-logical_fallacies": 5,
    "ogx_mmlux_pt-pt-machine_learning": 5,
    "ogx_mmlux_pt-pt-management": 5,
    "ogx_mmlux_pt-pt-marketing": 5,
    "ogx_mmlux_pt-pt-medical_genetics": 5,
    "ogx_mmlux_pt-pt-miscellaneous": 5,
    "ogx_mmlux_pt-pt-moral_disputes": 5,
    "ogx_mmlux_pt-pt-moral_scenarios": 5,
    "ogx_mmlux_pt-pt-nutrition": 5,
    "ogx_mmlux_pt-pt-philosophy": 5,
    "ogx_mmlux_pt-pt-prehistory": 5,
    "ogx_mmlux_pt-pt-professional_accounting": 5,
    "ogx_mmlux_pt-pt-professional_law": 5,
    "ogx_mmlux_pt-pt-professional_medicine": 5,
    "ogx_mmlux_pt-pt-professional_psychology": 5,
    "ogx_mmlux_pt-pt-public_relations": 5,
    "ogx_mmlux_pt-pt-security_studies": 5,
    "ogx_mmlux_pt-pt-sociology": 5,
    "ogx_mmlux_pt-pt-us_foreign_policy": 5,
    "ogx_mmlux_pt-pt-virology": 5,
    "ogx_mmlux_pt-pt-world_religions": 5,
    "ogx_mmlux_ro-abstract_algebra": 5,
    "ogx_mmlux_ro-anatomy": 5,
    "ogx_mmlux_ro-astronomy": 5,
    "ogx_mmlux_ro-business_ethics": 5,
    "ogx_mmlux_ro-clinical_knowledge": 5,
    "ogx_mmlux_ro-college_biology": 5,
    "ogx_mmlux_ro-college_chemistry": 5,
    "ogx_mmlux_ro-college_computer_science": 5,
    "ogx_mmlux_ro-college_mathematics": 5,
    "ogx_mmlux_ro-college_medicine": 5,
    "ogx_mmlux_ro-college_physics": 5,
    "ogx_mmlux_ro-computer_security": 5,
    "ogx_mmlux_ro-conceptual_physics": 5,
    "ogx_mmlux_ro-econometrics": 5,
    "ogx_mmlux_ro-electrical_engineering": 5,
    "ogx_mmlux_ro-elementary_mathematics": 5,
    "ogx_mmlux_ro-formal_logic": 5,
    "ogx_mmlux_ro-global_facts": 5,
    "ogx_mmlux_ro-high_school_biology": 5,
    "ogx_mmlux_ro-high_school_chemistry": 5,
    "ogx_mmlux_ro-high_school_computer_science": 5,
    "ogx_mmlux_ro-high_school_european_history": 5,
    "ogx_mmlux_ro-high_school_geography": 5,
    "ogx_mmlux_ro-high_school_government_and_politics": 5,
    "ogx_mmlux_ro-high_school_macroeconomics": 5,
    "ogx_mmlux_ro-high_school_mathematics": 5,
    "ogx_mmlux_ro-high_school_microeconomics": 5,
    "ogx_mmlux_ro-high_school_physics": 5,
    "ogx_mmlux_ro-high_school_psychology": 5,
    "ogx_mmlux_ro-high_school_statistics": 5,
    "ogx_mmlux_ro-high_school_us_history": 5,
    "ogx_mmlux_ro-high_school_world_history": 5,
    "ogx_mmlux_ro-human_aging": 5,
    "ogx_mmlux_ro-human_sexuality": 5,
    "ogx_mmlux_ro-international_law": 5,
    "ogx_mmlux_ro-jurisprudence": 5,
    "ogx_mmlux_ro-logical_fallacies": 5,
    "ogx_mmlux_ro-machine_learning": 5,
    "ogx_mmlux_ro-management": 5,
    "ogx_mmlux_ro-marketing": 5,
    "ogx_mmlux_ro-medical_genetics": 5,
    "ogx_mmlux_ro-miscellaneous": 5,
    "ogx_mmlux_ro-moral_disputes": 5,
    "ogx_mmlux_ro-moral_scenarios": 5,
    "ogx_mmlux_ro-nutrition": 5,
    "ogx_mmlux_ro-philosophy": 5,
    "ogx_mmlux_ro-prehistory": 5,
    "ogx_mmlux_ro-professional_accounting": 5,
    "ogx_mmlux_ro-professional_law": 5,
    "ogx_mmlux_ro-professional_medicine": 5,
    "ogx_mmlux_ro-professional_psychology": 5,
    "ogx_mmlux_ro-public_relations": 5,
    "ogx_mmlux_ro-security_studies": 5,
    "ogx_mmlux_ro-sociology": 5,
    "ogx_mmlux_ro-us_foreign_policy": 5,
    "ogx_mmlux_ro-virology": 5,
    "ogx_mmlux_ro-world_religions": 5,
    "ogx_mmlux_sk-abstract_algebra": 5,
    "ogx_mmlux_sk-anatomy": 5,
    "ogx_mmlux_sk-astronomy": 5,
    "ogx_mmlux_sk-business_ethics": 5,
    "ogx_mmlux_sk-clinical_knowledge": 5,
    "ogx_mmlux_sk-college_biology": 5,
    "ogx_mmlux_sk-college_chemistry": 5,
    "ogx_mmlux_sk-college_computer_science": 5,
    "ogx_mmlux_sk-college_mathematics": 5,
    "ogx_mmlux_sk-college_medicine": 5,
    "ogx_mmlux_sk-college_physics": 5,
    "ogx_mmlux_sk-computer_security": 5,
    "ogx_mmlux_sk-conceptual_physics": 5,
    "ogx_mmlux_sk-econometrics": 5,
    "ogx_mmlux_sk-electrical_engineering": 5,
    "ogx_mmlux_sk-elementary_mathematics": 5,
    "ogx_mmlux_sk-formal_logic": 5,
    "ogx_mmlux_sk-global_facts": 5,
    "ogx_mmlux_sk-high_school_biology": 5,
    "ogx_mmlux_sk-high_school_chemistry": 5,
    "ogx_mmlux_sk-high_school_computer_science": 5,
    "ogx_mmlux_sk-high_school_european_history": 5,
    "ogx_mmlux_sk-high_school_geography": 5,
    "ogx_mmlux_sk-high_school_government_and_politics": 5,
    "ogx_mmlux_sk-high_school_macroeconomics": 5,
    "ogx_mmlux_sk-high_school_mathematics": 5,
    "ogx_mmlux_sk-high_school_microeconomics": 5,
    "ogx_mmlux_sk-high_school_physics": 5,
    "ogx_mmlux_sk-high_school_psychology": 5,
    "ogx_mmlux_sk-high_school_statistics": 5,
    "ogx_mmlux_sk-high_school_us_history": 5,
    "ogx_mmlux_sk-high_school_world_history": 5,
    "ogx_mmlux_sk-human_aging": 5,
    "ogx_mmlux_sk-human_sexuality": 5,
    "ogx_mmlux_sk-international_law": 5,
    "ogx_mmlux_sk-jurisprudence": 5,
    "ogx_mmlux_sk-logical_fallacies": 5,
    "ogx_mmlux_sk-machine_learning": 5,
    "ogx_mmlux_sk-management": 5,
    "ogx_mmlux_sk-marketing": 5,
    "ogx_mmlux_sk-medical_genetics": 5,
    "ogx_mmlux_sk-miscellaneous": 5,
    "ogx_mmlux_sk-moral_disputes": 5,
    "ogx_mmlux_sk-moral_scenarios": 5,
    "ogx_mmlux_sk-nutrition": 5,
    "ogx_mmlux_sk-philosophy": 5,
    "ogx_mmlux_sk-prehistory": 5,
    "ogx_mmlux_sk-professional_accounting": 5,
    "ogx_mmlux_sk-professional_law": 5,
    "ogx_mmlux_sk-professional_medicine": 5,
    "ogx_mmlux_sk-professional_psychology": 5,
    "ogx_mmlux_sk-public_relations": 5,
    "ogx_mmlux_sk-security_studies": 5,
    "ogx_mmlux_sk-sociology": 5,
    "ogx_mmlux_sk-us_foreign_policy": 5,
    "ogx_mmlux_sk-virology": 5,
    "ogx_mmlux_sk-world_religions": 5,
    "ogx_mmlux_sl-abstract_algebra": 5,
    "ogx_mmlux_sl-anatomy": 5,
    "ogx_mmlux_sl-astronomy": 5,
    "ogx_mmlux_sl-business_ethics": 5,
    "ogx_mmlux_sl-clinical_knowledge": 5,
    "ogx_mmlux_sl-college_biology": 5,
    "ogx_mmlux_sl-college_chemistry": 5,
    "ogx_mmlux_sl-college_computer_science": 5,
    "ogx_mmlux_sl-college_mathematics": 5,
    "ogx_mmlux_sl-college_medicine": 5,
    "ogx_mmlux_sl-college_physics": 5,
    "ogx_mmlux_sl-computer_security": 5,
    "ogx_mmlux_sl-conceptual_physics": 5,
    "ogx_mmlux_sl-econometrics": 5,
    "ogx_mmlux_sl-electrical_engineering": 5,
    "ogx_mmlux_sl-elementary_mathematics": 5,
    "ogx_mmlux_sl-formal_logic": 5,
    "ogx_mmlux_sl-global_facts": 5,
    "ogx_mmlux_sl-high_school_biology": 5,
    "ogx_mmlux_sl-high_school_chemistry": 5,
    "ogx_mmlux_sl-high_school_computer_science": 5,
    "ogx_mmlux_sl-high_school_european_history": 5,
    "ogx_mmlux_sl-high_school_geography": 5,
    "ogx_mmlux_sl-high_school_government_and_politics": 5,
    "ogx_mmlux_sl-high_school_macroeconomics": 5,
    "ogx_mmlux_sl-high_school_mathematics": 5,
    "ogx_mmlux_sl-high_school_microeconomics": 5,
    "ogx_mmlux_sl-high_school_physics": 5,
    "ogx_mmlux_sl-high_school_psychology": 5,
    "ogx_mmlux_sl-high_school_statistics": 5,
    "ogx_mmlux_sl-high_school_us_history": 5,
    "ogx_mmlux_sl-high_school_world_history": 5,
    "ogx_mmlux_sl-human_aging": 5,
    "ogx_mmlux_sl-human_sexuality": 5,
    "ogx_mmlux_sl-international_law": 5,
    "ogx_mmlux_sl-jurisprudence": 5,
    "ogx_mmlux_sl-logical_fallacies": 5,
    "ogx_mmlux_sl-machine_learning": 5,
    "ogx_mmlux_sl-management": 5,
    "ogx_mmlux_sl-marketing": 5,
    "ogx_mmlux_sl-medical_genetics": 5,
    "ogx_mmlux_sl-miscellaneous": 5,
    "ogx_mmlux_sl-moral_disputes": 5,
    "ogx_mmlux_sl-moral_scenarios": 5,
    "ogx_mmlux_sl-nutrition": 5,
    "ogx_mmlux_sl-philosophy": 5,
    "ogx_mmlux_sl-prehistory": 5,
    "ogx_mmlux_sl-professional_accounting": 5,
    "ogx_mmlux_sl-professional_law": 5,
    "ogx_mmlux_sl-professional_medicine": 5,
    "ogx_mmlux_sl-professional_psychology": 5,
    "ogx_mmlux_sl-public_relations": 5,
    "ogx_mmlux_sl-security_studies": 5,
    "ogx_mmlux_sl-sociology": 5,
    "ogx_mmlux_sl-us_foreign_policy": 5,
    "ogx_mmlux_sl-virology": 5,
    "ogx_mmlux_sl-world_religions": 5,
    "ogx_mmlux_sv-abstract_algebra": 5,
    "ogx_mmlux_sv-anatomy": 5,
    "ogx_mmlux_sv-astronomy": 5,
    "ogx_mmlux_sv-business_ethics": 5,
    "ogx_mmlux_sv-clinical_knowledge": 5,
    "ogx_mmlux_sv-college_biology": 5,
    "ogx_mmlux_sv-college_chemistry": 5,
    "ogx_mmlux_sv-college_computer_science": 5,
    "ogx_mmlux_sv-college_mathematics": 5,
    "ogx_mmlux_sv-college_medicine": 5,
    "ogx_mmlux_sv-college_physics": 5,
    "ogx_mmlux_sv-computer_security": 5,
    "ogx_mmlux_sv-conceptual_physics": 5,
    "ogx_mmlux_sv-econometrics": 5,
    "ogx_mmlux_sv-electrical_engineering": 5,
    "ogx_mmlux_sv-elementary_mathematics": 5,
    "ogx_mmlux_sv-formal_logic": 5,
    "ogx_mmlux_sv-global_facts": 5,
    "ogx_mmlux_sv-high_school_biology": 5,
    "ogx_mmlux_sv-high_school_chemistry": 5,
    "ogx_mmlux_sv-high_school_computer_science": 5,
    "ogx_mmlux_sv-high_school_european_history": 5,
    "ogx_mmlux_sv-high_school_geography": 5,
    "ogx_mmlux_sv-high_school_government_and_politics": 5,
    "ogx_mmlux_sv-high_school_macroeconomics": 5,
    "ogx_mmlux_sv-high_school_mathematics": 5,
    "ogx_mmlux_sv-high_school_microeconomics": 5,
    "ogx_mmlux_sv-high_school_physics": 5,
    "ogx_mmlux_sv-high_school_psychology": 5,
    "ogx_mmlux_sv-high_school_statistics": 5,
    "ogx_mmlux_sv-high_school_us_history": 5,
    "ogx_mmlux_sv-high_school_world_history": 5,
    "ogx_mmlux_sv-human_aging": 5,
    "ogx_mmlux_sv-human_sexuality": 5,
    "ogx_mmlux_sv-international_law": 5,
    "ogx_mmlux_sv-jurisprudence": 5,
    "ogx_mmlux_sv-logical_fallacies": 5,
    "ogx_mmlux_sv-machine_learning": 5,
    "ogx_mmlux_sv-management": 5,
    "ogx_mmlux_sv-marketing": 5,
    "ogx_mmlux_sv-medical_genetics": 5,
    "ogx_mmlux_sv-miscellaneous": 5,
    "ogx_mmlux_sv-moral_disputes": 5,
    "ogx_mmlux_sv-moral_scenarios": 5,
    "ogx_mmlux_sv-nutrition": 5,
    "ogx_mmlux_sv-philosophy": 5,
    "ogx_mmlux_sv-prehistory": 5,
    "ogx_mmlux_sv-professional_accounting": 5,
    "ogx_mmlux_sv-professional_law": 5,
    "ogx_mmlux_sv-professional_medicine": 5,
    "ogx_mmlux_sv-professional_psychology": 5,
    "ogx_mmlux_sv-public_relations": 5,
    "ogx_mmlux_sv-security_studies": 5,
    "ogx_mmlux_sv-sociology": 5,
    "ogx_mmlux_sv-us_foreign_policy": 5,
    "ogx_mmlux_sv-virology": 5,
    "ogx_mmlux_sv-world_religions": 5
  },
  "higher_is_better": {
    "ogx_mmlux_bg-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_bg-anatomy": {
      "acc": true
    },
    "ogx_mmlux_bg-astronomy": {
      "acc": true
    },
    "ogx_mmlux_bg-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_bg-college_biology": {
      "acc": true
    },
    "ogx_mmlux_bg-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_bg-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_bg-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_bg-college_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-computer_security": {
      "acc": true
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-econometrics": {
      "acc": true
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_bg-global_facts": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_bg-human_aging": {
      "acc": true
    },
    "ogx_mmlux_bg-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_bg-international_law": {
      "acc": true
    },
    "ogx_mmlux_bg-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_bg-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_bg-management": {
      "acc": true
    },
    "ogx_mmlux_bg-marketing": {
      "acc": true
    },
    "ogx_mmlux_bg-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_bg-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_bg-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_bg-nutrition": {
      "acc": true
    },
    "ogx_mmlux_bg-philosophy": {
      "acc": true
    },
    "ogx_mmlux_bg-prehistory": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_law": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_bg-public_relations": {
      "acc": true
    },
    "ogx_mmlux_bg-security_studies": {
      "acc": true
    },
    "ogx_mmlux_bg-sociology": {
      "acc": true
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_bg-virology": {
      "acc": true
    },
    "ogx_mmlux_bg-world_religions": {
      "acc": true
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_cs-anatomy": {
      "acc": true
    },
    "ogx_mmlux_cs-astronomy": {
      "acc": true
    },
    "ogx_mmlux_cs-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_cs-college_biology": {
      "acc": true
    },
    "ogx_mmlux_cs-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_cs-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_cs-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_cs-college_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-computer_security": {
      "acc": true
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-econometrics": {
      "acc": true
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_cs-global_facts": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_cs-human_aging": {
      "acc": true
    },
    "ogx_mmlux_cs-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_cs-international_law": {
      "acc": true
    },
    "ogx_mmlux_cs-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_cs-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_cs-management": {
      "acc": true
    },
    "ogx_mmlux_cs-marketing": {
      "acc": true
    },
    "ogx_mmlux_cs-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_cs-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_cs-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_cs-nutrition": {
      "acc": true
    },
    "ogx_mmlux_cs-philosophy": {
      "acc": true
    },
    "ogx_mmlux_cs-prehistory": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_law": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_cs-public_relations": {
      "acc": true
    },
    "ogx_mmlux_cs-security_studies": {
      "acc": true
    },
    "ogx_mmlux_cs-sociology": {
      "acc": true
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_cs-virology": {
      "acc": true
    },
    "ogx_mmlux_cs-world_religions": {
      "acc": true
    },
    "ogx_mmlux_da-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_da-anatomy": {
      "acc": true
    },
    "ogx_mmlux_da-astronomy": {
      "acc": true
    },
    "ogx_mmlux_da-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_da-college_biology": {
      "acc": true
    },
    "ogx_mmlux_da-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_da-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_da-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_da-college_physics": {
      "acc": true
    },
    "ogx_mmlux_da-computer_security": {
      "acc": true
    },
    "ogx_mmlux_da-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_da-econometrics": {
      "acc": true
    },
    "ogx_mmlux_da-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_da-global_facts": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_da-human_aging": {
      "acc": true
    },
    "ogx_mmlux_da-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_da-international_law": {
      "acc": true
    },
    "ogx_mmlux_da-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_da-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_da-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_da-management": {
      "acc": true
    },
    "ogx_mmlux_da-marketing": {
      "acc": true
    },
    "ogx_mmlux_da-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_da-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_da-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_da-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_da-nutrition": {
      "acc": true
    },
    "ogx_mmlux_da-philosophy": {
      "acc": true
    },
    "ogx_mmlux_da-prehistory": {
      "acc": true
    },
    "ogx_mmlux_da-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_da-professional_law": {
      "acc": true
    },
    "ogx_mmlux_da-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_da-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_da-public_relations": {
      "acc": true
    },
    "ogx_mmlux_da-security_studies": {
      "acc": true
    },
    "ogx_mmlux_da-sociology": {
      "acc": true
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_da-virology": {
      "acc": true
    },
    "ogx_mmlux_da-world_religions": {
      "acc": true
    },
    "ogx_mmlux_de-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_de-anatomy": {
      "acc": true
    },
    "ogx_mmlux_de-astronomy": {
      "acc": true
    },
    "ogx_mmlux_de-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_de-college_biology": {
      "acc": true
    },
    "ogx_mmlux_de-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_de-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_de-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_de-college_physics": {
      "acc": true
    },
    "ogx_mmlux_de-computer_security": {
      "acc": true
    },
    "ogx_mmlux_de-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_de-econometrics": {
      "acc": true
    },
    "ogx_mmlux_de-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_de-global_facts": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_de-human_aging": {
      "acc": true
    },
    "ogx_mmlux_de-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_de-international_law": {
      "acc": true
    },
    "ogx_mmlux_de-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_de-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_de-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_de-management": {
      "acc": true
    },
    "ogx_mmlux_de-marketing": {
      "acc": true
    },
    "ogx_mmlux_de-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_de-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_de-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_de-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_de-nutrition": {
      "acc": true
    },
    "ogx_mmlux_de-philosophy": {
      "acc": true
    },
    "ogx_mmlux_de-prehistory": {
      "acc": true
    },
    "ogx_mmlux_de-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_de-professional_law": {
      "acc": true
    },
    "ogx_mmlux_de-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_de-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_de-public_relations": {
      "acc": true
    },
    "ogx_mmlux_de-security_studies": {
      "acc": true
    },
    "ogx_mmlux_de-sociology": {
      "acc": true
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_de-virology": {
      "acc": true
    },
    "ogx_mmlux_de-world_religions": {
      "acc": true
    },
    "ogx_mmlux_el-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_el-anatomy": {
      "acc": true
    },
    "ogx_mmlux_el-astronomy": {
      "acc": true
    },
    "ogx_mmlux_el-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_el-college_biology": {
      "acc": true
    },
    "ogx_mmlux_el-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_el-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_el-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_el-college_physics": {
      "acc": true
    },
    "ogx_mmlux_el-computer_security": {
      "acc": true
    },
    "ogx_mmlux_el-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_el-econometrics": {
      "acc": true
    },
    "ogx_mmlux_el-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_el-global_facts": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_el-human_aging": {
      "acc": true
    },
    "ogx_mmlux_el-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_el-international_law": {
      "acc": true
    },
    "ogx_mmlux_el-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_el-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_el-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_el-management": {
      "acc": true
    },
    "ogx_mmlux_el-marketing": {
      "acc": true
    },
    "ogx_mmlux_el-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_el-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_el-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_el-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_el-nutrition": {
      "acc": true
    },
    "ogx_mmlux_el-philosophy": {
      "acc": true
    },
    "ogx_mmlux_el-prehistory": {
      "acc": true
    },
    "ogx_mmlux_el-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_el-professional_law": {
      "acc": true
    },
    "ogx_mmlux_el-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_el-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_el-public_relations": {
      "acc": true
    },
    "ogx_mmlux_el-security_studies": {
      "acc": true
    },
    "ogx_mmlux_el-sociology": {
      "acc": true
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_el-virology": {
      "acc": true
    },
    "ogx_mmlux_el-world_religions": {
      "acc": true
    },
    "ogx_mmlux_es-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_es-anatomy": {
      "acc": true
    },
    "ogx_mmlux_es-astronomy": {
      "acc": true
    },
    "ogx_mmlux_es-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_es-college_biology": {
      "acc": true
    },
    "ogx_mmlux_es-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_es-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_es-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_es-college_physics": {
      "acc": true
    },
    "ogx_mmlux_es-computer_security": {
      "acc": true
    },
    "ogx_mmlux_es-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_es-econometrics": {
      "acc": true
    },
    "ogx_mmlux_es-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_es-global_facts": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_es-human_aging": {
      "acc": true
    },
    "ogx_mmlux_es-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_es-international_law": {
      "acc": true
    },
    "ogx_mmlux_es-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_es-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_es-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_es-management": {
      "acc": true
    },
    "ogx_mmlux_es-marketing": {
      "acc": true
    },
    "ogx_mmlux_es-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_es-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_es-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_es-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_es-nutrition": {
      "acc": true
    },
    "ogx_mmlux_es-philosophy": {
      "acc": true
    },
    "ogx_mmlux_es-prehistory": {
      "acc": true
    },
    "ogx_mmlux_es-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_es-professional_law": {
      "acc": true
    },
    "ogx_mmlux_es-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_es-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_es-public_relations": {
      "acc": true
    },
    "ogx_mmlux_es-security_studies": {
      "acc": true
    },
    "ogx_mmlux_es-sociology": {
      "acc": true
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_es-virology": {
      "acc": true
    },
    "ogx_mmlux_es-world_religions": {
      "acc": true
    },
    "ogx_mmlux_et-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_et-anatomy": {
      "acc": true
    },
    "ogx_mmlux_et-astronomy": {
      "acc": true
    },
    "ogx_mmlux_et-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_et-college_biology": {
      "acc": true
    },
    "ogx_mmlux_et-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_et-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_et-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_et-college_physics": {
      "acc": true
    },
    "ogx_mmlux_et-computer_security": {
      "acc": true
    },
    "ogx_mmlux_et-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_et-econometrics": {
      "acc": true
    },
    "ogx_mmlux_et-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_et-global_facts": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_et-human_aging": {
      "acc": true
    },
    "ogx_mmlux_et-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_et-international_law": {
      "acc": true
    },
    "ogx_mmlux_et-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_et-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_et-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_et-management": {
      "acc": true
    },
    "ogx_mmlux_et-marketing": {
      "acc": true
    },
    "ogx_mmlux_et-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_et-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_et-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_et-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_et-nutrition": {
      "acc": true
    },
    "ogx_mmlux_et-philosophy": {
      "acc": true
    },
    "ogx_mmlux_et-prehistory": {
      "acc": true
    },
    "ogx_mmlux_et-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_et-professional_law": {
      "acc": true
    },
    "ogx_mmlux_et-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_et-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_et-public_relations": {
      "acc": true
    },
    "ogx_mmlux_et-security_studies": {
      "acc": true
    },
    "ogx_mmlux_et-sociology": {
      "acc": true
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_et-virology": {
      "acc": true
    },
    "ogx_mmlux_et-world_religions": {
      "acc": true
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_fi-anatomy": {
      "acc": true
    },
    "ogx_mmlux_fi-astronomy": {
      "acc": true
    },
    "ogx_mmlux_fi-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_fi-college_biology": {
      "acc": true
    },
    "ogx_mmlux_fi-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fi-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fi-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_fi-college_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-computer_security": {
      "acc": true
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-econometrics": {
      "acc": true
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_fi-global_facts": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_fi-human_aging": {
      "acc": true
    },
    "ogx_mmlux_fi-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_fi-international_law": {
      "acc": true
    },
    "ogx_mmlux_fi-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_fi-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_fi-management": {
      "acc": true
    },
    "ogx_mmlux_fi-marketing": {
      "acc": true
    },
    "ogx_mmlux_fi-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_fi-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_fi-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_fi-nutrition": {
      "acc": true
    },
    "ogx_mmlux_fi-philosophy": {
      "acc": true
    },
    "ogx_mmlux_fi-prehistory": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_law": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_fi-public_relations": {
      "acc": true
    },
    "ogx_mmlux_fi-security_studies": {
      "acc": true
    },
    "ogx_mmlux_fi-sociology": {
      "acc": true
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_fi-virology": {
      "acc": true
    },
    "ogx_mmlux_fi-world_religions": {
      "acc": true
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_fr-anatomy": {
      "acc": true
    },
    "ogx_mmlux_fr-astronomy": {
      "acc": true
    },
    "ogx_mmlux_fr-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_fr-college_biology": {
      "acc": true
    },
    "ogx_mmlux_fr-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fr-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fr-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_fr-college_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-computer_security": {
      "acc": true
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-econometrics": {
      "acc": true
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_fr-global_facts": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_fr-human_aging": {
      "acc": true
    },
    "ogx_mmlux_fr-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_fr-international_law": {
      "acc": true
    },
    "ogx_mmlux_fr-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_fr-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_fr-management": {
      "acc": true
    },
    "ogx_mmlux_fr-marketing": {
      "acc": true
    },
    "ogx_mmlux_fr-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_fr-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_fr-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_fr-nutrition": {
      "acc": true
    },
    "ogx_mmlux_fr-philosophy": {
      "acc": true
    },
    "ogx_mmlux_fr-prehistory": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_law": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_fr-public_relations": {
      "acc": true
    },
    "ogx_mmlux_fr-security_studies": {
      "acc": true
    },
    "ogx_mmlux_fr-sociology": {
      "acc": true
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_fr-virology": {
      "acc": true
    },
    "ogx_mmlux_fr-world_religions": {
      "acc": true
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_hu-anatomy": {
      "acc": true
    },
    "ogx_mmlux_hu-astronomy": {
      "acc": true
    },
    "ogx_mmlux_hu-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_hu-college_biology": {
      "acc": true
    },
    "ogx_mmlux_hu-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_hu-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_hu-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_hu-college_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-computer_security": {
      "acc": true
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-econometrics": {
      "acc": true
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_hu-global_facts": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_hu-human_aging": {
      "acc": true
    },
    "ogx_mmlux_hu-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_hu-international_law": {
      "acc": true
    },
    "ogx_mmlux_hu-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_hu-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_hu-management": {
      "acc": true
    },
    "ogx_mmlux_hu-marketing": {
      "acc": true
    },
    "ogx_mmlux_hu-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_hu-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_hu-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_hu-nutrition": {
      "acc": true
    },
    "ogx_mmlux_hu-philosophy": {
      "acc": true
    },
    "ogx_mmlux_hu-prehistory": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_law": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_hu-public_relations": {
      "acc": true
    },
    "ogx_mmlux_hu-security_studies": {
      "acc": true
    },
    "ogx_mmlux_hu-sociology": {
      "acc": true
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_hu-virology": {
      "acc": true
    },
    "ogx_mmlux_hu-world_religions": {
      "acc": true
    },
    "ogx_mmlux_it-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_it-anatomy": {
      "acc": true
    },
    "ogx_mmlux_it-astronomy": {
      "acc": true
    },
    "ogx_mmlux_it-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_it-college_biology": {
      "acc": true
    },
    "ogx_mmlux_it-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_it-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_it-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_it-college_physics": {
      "acc": true
    },
    "ogx_mmlux_it-computer_security": {
      "acc": true
    },
    "ogx_mmlux_it-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_it-econometrics": {
      "acc": true
    },
    "ogx_mmlux_it-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_it-global_facts": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_it-human_aging": {
      "acc": true
    },
    "ogx_mmlux_it-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_it-international_law": {
      "acc": true
    },
    "ogx_mmlux_it-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_it-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_it-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_it-management": {
      "acc": true
    },
    "ogx_mmlux_it-marketing": {
      "acc": true
    },
    "ogx_mmlux_it-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_it-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_it-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_it-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_it-nutrition": {
      "acc": true
    },
    "ogx_mmlux_it-philosophy": {
      "acc": true
    },
    "ogx_mmlux_it-prehistory": {
      "acc": true
    },
    "ogx_mmlux_it-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_it-professional_law": {
      "acc": true
    },
    "ogx_mmlux_it-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_it-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_it-public_relations": {
      "acc": true
    },
    "ogx_mmlux_it-security_studies": {
      "acc": true
    },
    "ogx_mmlux_it-sociology": {
      "acc": true
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_it-virology": {
      "acc": true
    },
    "ogx_mmlux_it-world_religions": {
      "acc": true
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_lt-anatomy": {
      "acc": true
    },
    "ogx_mmlux_lt-astronomy": {
      "acc": true
    },
    "ogx_mmlux_lt-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_lt-college_biology": {
      "acc": true
    },
    "ogx_mmlux_lt-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lt-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lt-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_lt-college_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-computer_security": {
      "acc": true
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-econometrics": {
      "acc": true
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_lt-global_facts": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_lt-human_aging": {
      "acc": true
    },
    "ogx_mmlux_lt-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_lt-international_law": {
      "acc": true
    },
    "ogx_mmlux_lt-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_lt-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_lt-management": {
      "acc": true
    },
    "ogx_mmlux_lt-marketing": {
      "acc": true
    },
    "ogx_mmlux_lt-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_lt-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_lt-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_lt-nutrition": {
      "acc": true
    },
    "ogx_mmlux_lt-philosophy": {
      "acc": true
    },
    "ogx_mmlux_lt-prehistory": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_law": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_lt-public_relations": {
      "acc": true
    },
    "ogx_mmlux_lt-security_studies": {
      "acc": true
    },
    "ogx_mmlux_lt-sociology": {
      "acc": true
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_lt-virology": {
      "acc": true
    },
    "ogx_mmlux_lt-world_religions": {
      "acc": true
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_lv-anatomy": {
      "acc": true
    },
    "ogx_mmlux_lv-astronomy": {
      "acc": true
    },
    "ogx_mmlux_lv-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_lv-college_biology": {
      "acc": true
    },
    "ogx_mmlux_lv-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lv-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lv-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_lv-college_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-computer_security": {
      "acc": true
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-econometrics": {
      "acc": true
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_lv-global_facts": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_lv-human_aging": {
      "acc": true
    },
    "ogx_mmlux_lv-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_lv-international_law": {
      "acc": true
    },
    "ogx_mmlux_lv-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_lv-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_lv-management": {
      "acc": true
    },
    "ogx_mmlux_lv-marketing": {
      "acc": true
    },
    "ogx_mmlux_lv-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_lv-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_lv-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_lv-nutrition": {
      "acc": true
    },
    "ogx_mmlux_lv-philosophy": {
      "acc": true
    },
    "ogx_mmlux_lv-prehistory": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_law": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_lv-public_relations": {
      "acc": true
    },
    "ogx_mmlux_lv-security_studies": {
      "acc": true
    },
    "ogx_mmlux_lv-sociology": {
      "acc": true
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_lv-virology": {
      "acc": true
    },
    "ogx_mmlux_lv-world_religions": {
      "acc": true
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_nl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_nl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_nl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_nl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_nl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_nl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_nl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_nl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_nl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_nl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_nl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_nl-international_law": {
      "acc": true
    },
    "ogx_mmlux_nl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_nl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_nl-management": {
      "acc": true
    },
    "ogx_mmlux_nl-marketing": {
      "acc": true
    },
    "ogx_mmlux_nl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_nl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_nl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_nl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_nl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_nl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_nl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_nl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_nl-sociology": {
      "acc": true
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_nl-virology": {
      "acc": true
    },
    "ogx_mmlux_nl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_pl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_pl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_pl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_pl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_pl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_pl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_pl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_pl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_pl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_pl-international_law": {
      "acc": true
    },
    "ogx_mmlux_pl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_pl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_pl-management": {
      "acc": true
    },
    "ogx_mmlux_pl-marketing": {
      "acc": true
    },
    "ogx_mmlux_pl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_pl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_pl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_pl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_pl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_pl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_pl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_pl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_pl-sociology": {
      "acc": true
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_pl-virology": {
      "acc": true
    },
    "ogx_mmlux_pl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-international_law": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-management": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-marketing": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-sociology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-virology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "acc": true
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_ro-anatomy": {
      "acc": true
    },
    "ogx_mmlux_ro-astronomy": {
      "acc": true
    },
    "ogx_mmlux_ro-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_ro-college_biology": {
      "acc": true
    },
    "ogx_mmlux_ro-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_ro-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_ro-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_ro-college_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-computer_security": {
      "acc": true
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-econometrics": {
      "acc": true
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_ro-global_facts": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_ro-human_aging": {
      "acc": true
    },
    "ogx_mmlux_ro-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_ro-international_law": {
      "acc": true
    },
    "ogx_mmlux_ro-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_ro-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_ro-management": {
      "acc": true
    },
    "ogx_mmlux_ro-marketing": {
      "acc": true
    },
    "ogx_mmlux_ro-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_ro-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_ro-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_ro-nutrition": {
      "acc": true
    },
    "ogx_mmlux_ro-philosophy": {
      "acc": true
    },
    "ogx_mmlux_ro-prehistory": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_law": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_ro-public_relations": {
      "acc": true
    },
    "ogx_mmlux_ro-security_studies": {
      "acc": true
    },
    "ogx_mmlux_ro-sociology": {
      "acc": true
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_ro-virology": {
      "acc": true
    },
    "ogx_mmlux_ro-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sk-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sk-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sk-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sk-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sk-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sk-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sk-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sk-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sk-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sk-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sk-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sk-international_law": {
      "acc": true
    },
    "ogx_mmlux_sk-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sk-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sk-management": {
      "acc": true
    },
    "ogx_mmlux_sk-marketing": {
      "acc": true
    },
    "ogx_mmlux_sk-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sk-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sk-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sk-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sk-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sk-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sk-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sk-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sk-sociology": {
      "acc": true
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sk-virology": {
      "acc": true
    },
    "ogx_mmlux_sk-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sl-international_law": {
      "acc": true
    },
    "ogx_mmlux_sl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sl-management": {
      "acc": true
    },
    "ogx_mmlux_sl-marketing": {
      "acc": true
    },
    "ogx_mmlux_sl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sl-sociology": {
      "acc": true
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sl-virology": {
      "acc": true
    },
    "ogx_mmlux_sl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sv-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sv-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sv-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sv-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sv-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sv-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sv-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sv-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sv-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sv-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sv-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sv-international_law": {
      "acc": true
    },
    "ogx_mmlux_sv-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sv-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sv-management": {
      "acc": true
    },
    "ogx_mmlux_sv-marketing": {
      "acc": true
    },
    "ogx_mmlux_sv-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sv-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sv-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sv-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sv-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sv-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sv-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sv-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sv-sociology": {
      "acc": true
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sv-virology": {
      "acc": true
    },
    "ogx_mmlux_sv-world_religions": {
      "acc": true
    }
  },
  "n-samples": {
    "ogx_mmlux_sv-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sv-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sv-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sv-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sv-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sv-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sv-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sv-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sv-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sv-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sv-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sv-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sv-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sv-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sv-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sv-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sv-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sv-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sv-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sv-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sv-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sv-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sv-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sv-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sv-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sv-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sv-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sv-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sv-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sv-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sk-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sk-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sk-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sk-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sk-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sk-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sk-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sk-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sk-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sk-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sk-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sk-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sk-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sk-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sk-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sk-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sk-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sk-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sk-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sk-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sk-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sk-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sk-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sk-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sk-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sk-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sk-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sk-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sk-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_ro-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_ro-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_ro-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_ro-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_ro-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_ro-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_ro-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_ro-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_ro-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_ro-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_ro-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_ro-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_ro-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_ro-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_ro-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_ro-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_ro-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_ro-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_ro-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_ro-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_ro-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_ro-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_ro-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_ro-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_ro-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_ro-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_ro-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_ro-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_ro-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_pt-pt-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_pt-pt-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_pt-pt-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_pl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_pl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_pl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_pl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_pl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_pl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_pl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_pl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_pl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_pl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_pl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_pl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_pl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_pl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_pl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_pl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_pl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_pl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_pl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_pl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_pl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_pl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_pl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_pl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_pl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_pl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_pl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_pl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_pl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_nl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_nl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_nl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_nl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_nl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_nl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_nl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_nl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_nl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_nl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_nl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_nl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_nl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_nl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_nl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_nl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_nl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_nl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_nl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_nl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_nl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_nl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_nl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_nl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_nl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_nl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_nl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_nl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_nl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_lv-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_lv-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_lv-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_lv-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_lv-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_lv-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_lv-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_lv-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_lv-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_lv-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_lv-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_lv-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_lv-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_lv-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_lv-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_lv-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_lv-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_lv-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_lv-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_lv-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_lv-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_lv-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_lv-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_lv-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_lv-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_lv-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_lv-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_lv-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_lv-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_lt-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_lt-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_lt-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_lt-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_lt-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_lt-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_lt-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_lt-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_lt-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_lt-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_lt-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_lt-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_lt-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_lt-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_lt-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_lt-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_lt-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_lt-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_lt-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_lt-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_lt-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_lt-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_lt-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_lt-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_lt-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_lt-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_lt-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_lt-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_lt-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_it-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_it-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_it-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_it-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_it-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_it-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_it-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_it-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_it-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_it-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_it-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_it-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_it-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_it-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_it-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_it-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_it-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_it-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_it-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_it-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_it-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_it-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_it-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_it-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_it-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_it-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_it-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_it-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_it-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_it-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_it-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_it-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_it-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_it-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_it-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_it-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_it-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_it-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_it-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_hu-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_hu-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_hu-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_hu-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_hu-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_hu-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_hu-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_hu-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_hu-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_hu-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_hu-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_hu-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_hu-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_hu-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_hu-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_hu-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_hu-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_hu-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_hu-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_hu-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_hu-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_hu-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_hu-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_hu-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_hu-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_hu-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_hu-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_hu-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_hu-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_fr-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_fr-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_fr-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_fr-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_fr-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_fr-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_fr-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_fr-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_fr-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_fr-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_fr-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_fr-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_fr-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_fr-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_fr-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_fr-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_fr-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_fr-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_fr-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_fr-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_fr-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_fr-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_fr-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_fr-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_fr-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_fr-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_fr-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_fr-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_fr-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_fi-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_fi-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_fi-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_fi-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_fi-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_fi-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_fi-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_fi-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_fi-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_fi-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_fi-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_fi-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_fi-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_fi-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_fi-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_fi-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_fi-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_fi-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_fi-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_fi-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_fi-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_fi-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_fi-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_fi-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_fi-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_fi-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_fi-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_fi-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_fi-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_et-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_et-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_et-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_et-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_et-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_et-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_et-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_et-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_et-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_et-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_et-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_et-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_et-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_et-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_et-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_et-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_et-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_et-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_et-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_et-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_et-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_et-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_et-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_et-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_et-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_et-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_et-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_et-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_et-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_et-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_et-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_et-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_et-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_et-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_et-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_et-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_et-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_et-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_et-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_es-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_es-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_es-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_es-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_es-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_es-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_es-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_es-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_es-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_es-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_es-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_es-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_es-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_es-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_es-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_es-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_es-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_es-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_es-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_es-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_es-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_es-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_es-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_es-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_es-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_es-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_es-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_es-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_es-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_es-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_es-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_es-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_es-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_es-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_es-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_es-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_es-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_es-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_es-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_el-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_el-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_el-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_el-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_el-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_el-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_el-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_el-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_el-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_el-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_el-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_el-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_el-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_el-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_el-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_el-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_el-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_el-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_el-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_el-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_el-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_el-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_el-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_el-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_el-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_el-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_el-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_el-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_el-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_el-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_el-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_el-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_el-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_el-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_el-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_el-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_el-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_el-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_el-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_de-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_de-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_de-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_de-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_de-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_de-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_de-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_de-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_de-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_de-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_de-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_de-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_de-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_de-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_de-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_de-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_de-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_de-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_de-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_de-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_de-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_de-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_de-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_de-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_de-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_de-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_de-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_de-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_de-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_de-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_de-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_de-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_de-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_de-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_de-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_de-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_de-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_de-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_de-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_da-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_da-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_da-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_da-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_da-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_da-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_da-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_da-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_da-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_da-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_da-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_da-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_da-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_da-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_da-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_da-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_da-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_da-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_da-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_da-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_da-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_da-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_da-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_da-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_da-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_da-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_da-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_da-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_da-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_da-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_da-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_da-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_da-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_da-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_da-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_da-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_da-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_da-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_da-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_cs-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_cs-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_cs-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_cs-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_cs-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_cs-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_cs-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_cs-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_cs-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_cs-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_cs-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_cs-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_cs-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_cs-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_cs-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_cs-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_cs-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_cs-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_cs-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_cs-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_cs-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_cs-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_cs-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_cs-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_cs-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_cs-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_cs-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_cs-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_cs-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_bg-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_bg-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_bg-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_bg-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_bg-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_bg-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_bg-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_bg-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_bg-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_bg-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_bg-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_bg-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_bg-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_bg-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_bg-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_bg-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_bg-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_bg-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_bg-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_bg-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_bg-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_bg-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_bg-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_bg-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_bg-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_bg-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_bg-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_bg-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_bg-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_bg-abstract_algebra": {
      "original": 100,
      "effective": 100
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=google/gemma-2-9b-it,dtype=bfloat16,trust_remote_code=True,nccl_timeout=3600,trust_remote_code=True",
    "model_num_parameters": 9241705984,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "11c9b309abf73637e4b6f9a3fa1e92e615547819",
    "batch_size": "auto:4",
    "batch_sizes": [
      4,
      16,
      32,
      32,
      64
    ],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": null,
  "date": 1741276047.9456854,
  "pretty_env_info": "PyTorch version: 2.6.0+cu124\nIs debug build: False\nCUDA used to build PyTorch: 12.4\nROCM used to build PyTorch: N/A\n\nOS: Ubuntu 22.04.5 LTS (x86_64)\nGCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\nClang version: Could not collect\nCMake version: Could not collect\nLibc version: glibc-2.35\n\nPython version: 3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0] (64-bit runtime)\nPython platform: Linux-5.15.0-133-generic-x86_64-with-glibc2.35\nIs CUDA available: True\nCUDA runtime version: 12.4.131\nCUDA_MODULE_LOADING set to: LAZY\nGPU models and configuration: \nGPU 0: NVIDIA H100 80GB HBM3\nGPU 1: NVIDIA H100 80GB HBM3\nGPU 2: NVIDIA H100 80GB HBM3\nGPU 3: NVIDIA H100 80GB HBM3\nGPU 4: NVIDIA H100 80GB HBM3\nGPU 5: NVIDIA H100 80GB HBM3\nGPU 6: NVIDIA H100 80GB HBM3\nGPU 7: NVIDIA H100 80GB HBM3\n\nNvidia driver version: 550.144.03\ncuDNN version: Could not collect\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nArchitecture:                         x86_64\nCPU op-mode(s):                       32-bit, 64-bit\nAddress sizes:                        52 bits physical, 57 bits virtual\nByte Order:                           Little Endian\nCPU(s):                               192\nOn-line CPU(s) list:                  0-191\nVendor ID:                            AuthenticAMD\nModel name:                           AMD EPYC 9654 96-Core Processor\nCPU family:                           25\nModel:                                17\nThread(s) per core:                   1\nCore(s) per socket:                   96\nSocket(s):                            2\nStepping:                             1\nFrequency boost:                      enabled\nCPU max MHz:                          3707.8120\nCPU min MHz:                          1500.0000\nBogoMIPS:                             4793.01\nFlags:                                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 invpcid_single hw_pstate ssbd mba ibrs ibpb stibp ibrs_enhanced vmmcall fsgsbase bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local avx512_bf16 clzero irperf xsaveerptr rdpru wbnoinvd amd_ppin cppc arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif v_spec_ctrl avx512vbmi umip pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg avx512_vpopcntdq la57 rdpid overflow_recov succor smca fsrm flush_l1d\nVirtualization:                       AMD-V\nL1d cache:                            6 MiB (192 instances)\nL1i cache:                            6 MiB (192 instances)\nL2 cache:                             192 MiB (192 instances)\nL3 cache:                             768 MiB (24 instances)\nNUMA node(s):                         2\nNUMA node0 CPU(s):                    0-95\nNUMA node1 CPU(s):                    96-191\nVulnerability Gather data sampling:   Not affected\nVulnerability Itlb multihit:          Not affected\nVulnerability L1tf:                   Not affected\nVulnerability Mds:                    Not affected\nVulnerability Meltdown:               Not affected\nVulnerability Mmio stale data:        Not affected\nVulnerability Reg file data sampling: Not affected\nVulnerability Retbleed:               Not affected\nVulnerability Spec rstack overflow:   Mitigation; safe RET\nVulnerability Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prctl and seccomp\nVulnerability Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointer sanitization\nVulnerability Spectre v2:             Mitigation; Enhanced / Automatic IBRS; IBPB conditional; STIBP disabled; RSB filling; PBRSB-eIBRS Not affected; BHI Not affected\nVulnerability Srbds:                  Not affected\nVulnerability Tsx async abort:        Not affected\n\nVersions of relevant libraries:\n[pip3] numpy==2.2.3\n[pip3] nvidia-cublas-cu12==12.4.5.8\n[pip3] nvidia-cuda-cupti-cu12==12.4.127\n[pip3] nvidia-cuda-nvrtc-cu12==12.4.127\n[pip3] nvidia-cuda-runtime-cu12==12.4.127\n[pip3] nvidia-cudnn-cu12==9.1.0.70\n[pip3] nvidia-cufft-cu12==11.2.1.3\n[pip3] nvidia-curand-cu12==10.3.5.147\n[pip3] nvidia-cusolver-cu12==11.6.1.9\n[pip3] nvidia-cusparse-cu12==12.3.1.170\n[pip3] nvidia-cusparselt-cu12==0.6.2\n[pip3] nvidia-nccl-cu12==2.21.5\n[pip3] nvidia-nvjitlink-cu12==12.4.127\n[pip3] nvidia-nvtx-cu12==12.4.127\n[pip3] torch==2.6.0\n[pip3] triton==3.2.0\n[conda] Could not collect",
  "transformers_version": "4.49.0",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<pad>",
    0
  ],
  "tokenizer_eos_token": [
    "<eos>",
    1
  ],
  "tokenizer_bos_token": [
    "<bos>",
    2
  ],
  "eot_token_id": 1,
  "max_length": 8192,
  "task_hashes": {},
  "model_source": "hf",
  "model_name": "google/gemma-2-9b-it",
  "model_name_sanitized": "google__gemma-2-9b-it",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": true,
  "chat_template": "{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}",
  "chat_template_sha": "ecd6ae513fe103f0eb62e8ab5bfa8d0fe45c1074fa398b089c93a7e70c15cfd6",
  "start_time": 168293.927675649,
  "end_time": 190672.073174574,
  "total_evaluation_time_seconds": "22378.145498925005"
}