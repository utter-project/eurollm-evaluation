{
  "results": {
    "ogx_mmlux_sv-world_religions": {
      "acc,none": 0.6023391812865497,
      "acc_stderr,none": 0.03753638955761691,
      "alias": "ogx_mmlux_sv-world_religions"
    },
    "ogx_mmlux_sv-virology": {
      "acc,none": 0.42771084337349397,
      "acc_stderr,none": 0.038515976837185335,
      "alias": "ogx_mmlux_sv-virology"
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_sv-us_foreign_policy"
    },
    "ogx_mmlux_sv-sociology": {
      "acc,none": 0.5970149253731343,
      "acc_stderr,none": 0.034683432951111266,
      "alias": "ogx_mmlux_sv-sociology"
    },
    "ogx_mmlux_sv-security_studies": {
      "acc,none": 0.5877551020408164,
      "acc_stderr,none": 0.03151236044674268,
      "alias": "ogx_mmlux_sv-security_studies"
    },
    "ogx_mmlux_sv-public_relations": {
      "acc,none": 0.45454545454545453,
      "acc_stderr,none": 0.04769300568972743,
      "alias": "ogx_mmlux_sv-public_relations"
    },
    "ogx_mmlux_sv-professional_psychology": {
      "acc,none": 0.41013071895424835,
      "acc_stderr,none": 0.019898412717635903,
      "alias": "ogx_mmlux_sv-professional_psychology"
    },
    "ogx_mmlux_sv-professional_medicine": {
      "acc,none": 0.3639705882352941,
      "acc_stderr,none": 0.029227192460032025,
      "alias": "ogx_mmlux_sv-professional_medicine"
    },
    "ogx_mmlux_sv-professional_law": {
      "acc,none": 0.3409387222946545,
      "acc_stderr,none": 0.012106817203067213,
      "alias": "ogx_mmlux_sv-professional_law"
    },
    "ogx_mmlux_sv-professional_accounting": {
      "acc,none": 0.3262411347517731,
      "acc_stderr,none": 0.027968453043563164,
      "alias": "ogx_mmlux_sv-professional_accounting"
    },
    "ogx_mmlux_sv-prehistory": {
      "acc,none": 0.4567901234567901,
      "acc_stderr,none": 0.027716661650194038,
      "alias": "ogx_mmlux_sv-prehistory"
    },
    "ogx_mmlux_sv-philosophy": {
      "acc,none": 0.4405144694533762,
      "acc_stderr,none": 0.028196400574197426,
      "alias": "ogx_mmlux_sv-philosophy"
    },
    "ogx_mmlux_sv-nutrition": {
      "acc,none": 0.5490196078431373,
      "acc_stderr,none": 0.02849199358617157,
      "alias": "ogx_mmlux_sv-nutrition"
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "acc,none": 0.23687150837988827,
      "acc_stderr,none": 0.014219570788103982,
      "alias": "ogx_mmlux_sv-moral_scenarios"
    },
    "ogx_mmlux_sv-moral_disputes": {
      "acc,none": 0.4797687861271676,
      "acc_stderr,none": 0.026897049996382875,
      "alias": "ogx_mmlux_sv-moral_disputes"
    },
    "ogx_mmlux_sv-miscellaneous": {
      "acc,none": 0.5363984674329502,
      "acc_stderr,none": 0.01783252407959326,
      "alias": "ogx_mmlux_sv-miscellaneous"
    },
    "ogx_mmlux_sv-medical_genetics": {
      "acc,none": 0.53,
      "acc_stderr,none": 0.050161355804659205,
      "alias": "ogx_mmlux_sv-medical_genetics"
    },
    "ogx_mmlux_sv-marketing": {
      "acc,none": 0.6923076923076923,
      "acc_stderr,none": 0.03023638994217309,
      "alias": "ogx_mmlux_sv-marketing"
    },
    "ogx_mmlux_sv-management": {
      "acc,none": 0.5825242718446602,
      "acc_stderr,none": 0.048828405482122375,
      "alias": "ogx_mmlux_sv-management"
    },
    "ogx_mmlux_sv-machine_learning": {
      "acc,none": 0.36607142857142855,
      "acc_stderr,none": 0.0457237235873743,
      "alias": "ogx_mmlux_sv-machine_learning"
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "acc,none": 0.43558282208588955,
      "acc_stderr,none": 0.03895632464138937,
      "alias": "ogx_mmlux_sv-logical_fallacies"
    },
    "ogx_mmlux_sv-jurisprudence": {
      "acc,none": 0.5092592592592593,
      "acc_stderr,none": 0.04832853553437055,
      "alias": "ogx_mmlux_sv-jurisprudence"
    },
    "ogx_mmlux_sv-international_law": {
      "acc,none": 0.5950413223140496,
      "acc_stderr,none": 0.04481137755942469,
      "alias": "ogx_mmlux_sv-international_law"
    },
    "ogx_mmlux_sv-human_sexuality": {
      "acc,none": 0.5190839694656488,
      "acc_stderr,none": 0.04382094705550988,
      "alias": "ogx_mmlux_sv-human_sexuality"
    },
    "ogx_mmlux_sv-human_aging": {
      "acc,none": 0.5560538116591929,
      "acc_stderr,none": 0.03334625674242728,
      "alias": "ogx_mmlux_sv-human_aging"
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "acc,none": 0.5949367088607594,
      "acc_stderr,none": 0.03195514741370672,
      "alias": "ogx_mmlux_sv-high_school_world_history"
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "acc,none": 0.5147058823529411,
      "acc_stderr,none": 0.03507793834791324,
      "alias": "ogx_mmlux_sv-high_school_us_history"
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "acc,none": 0.3287037037037037,
      "acc_stderr,none": 0.03203614084670058,
      "alias": "ogx_mmlux_sv-high_school_statistics"
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "acc,none": 0.4935779816513762,
      "acc_stderr,none": 0.021435554820013077,
      "alias": "ogx_mmlux_sv-high_school_psychology"
    },
    "ogx_mmlux_sv-high_school_physics": {
      "acc,none": 0.3576158940397351,
      "acc_stderr,none": 0.03913453431177258,
      "alias": "ogx_mmlux_sv-high_school_physics"
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "acc,none": 0.3865546218487395,
      "acc_stderr,none": 0.0316314580755238,
      "alias": "ogx_mmlux_sv-high_school_microeconomics"
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "acc,none": 0.29259259259259257,
      "acc_stderr,none": 0.02773896963217609,
      "alias": "ogx_mmlux_sv-high_school_mathematics"
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "acc,none": 0.3717948717948718,
      "acc_stderr,none": 0.024503472557110936,
      "alias": "ogx_mmlux_sv-high_school_macroeconomics"
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "acc,none": 0.5440414507772021,
      "acc_stderr,none": 0.03594413711272437,
      "alias": "ogx_mmlux_sv-high_school_government_and_politics"
    },
    "ogx_mmlux_sv-high_school_geography": {
      "acc,none": 0.5808080808080808,
      "acc_stderr,none": 0.035155207286704175,
      "alias": "ogx_mmlux_sv-high_school_geography"
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "acc,none": 0.593939393939394,
      "acc_stderr,none": 0.03834816355401181,
      "alias": "ogx_mmlux_sv-high_school_european_history"
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_sv-high_school_computer_science"
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "acc,none": 0.37438423645320196,
      "acc_stderr,none": 0.03405155380561952,
      "alias": "ogx_mmlux_sv-high_school_chemistry"
    },
    "ogx_mmlux_sv-high_school_biology": {
      "acc,none": 0.47096774193548385,
      "acc_stderr,none": 0.028396016402760998,
      "alias": "ogx_mmlux_sv-high_school_biology"
    },
    "ogx_mmlux_sv-global_facts": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.047258156262526045,
      "alias": "ogx_mmlux_sv-global_facts"
    },
    "ogx_mmlux_sv-formal_logic": {
      "acc,none": 0.2698412698412698,
      "acc_stderr,none": 0.03970158273235171,
      "alias": "ogx_mmlux_sv-formal_logic"
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "acc,none": 0.2857142857142857,
      "acc_stderr,none": 0.023266512213730554,
      "alias": "ogx_mmlux_sv-elementary_mathematics"
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "acc,none": 0.46206896551724136,
      "acc_stderr,none": 0.041546596717075474,
      "alias": "ogx_mmlux_sv-electrical_engineering"
    },
    "ogx_mmlux_sv-econometrics": {
      "acc,none": 0.34210526315789475,
      "acc_stderr,none": 0.04462917535336937,
      "alias": "ogx_mmlux_sv-econometrics"
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "acc,none": 0.3617021276595745,
      "acc_stderr,none": 0.0314108219759624,
      "alias": "ogx_mmlux_sv-conceptual_physics"
    },
    "ogx_mmlux_sv-computer_security": {
      "acc,none": 0.66,
      "acc_stderr,none": 0.04760952285695237,
      "alias": "ogx_mmlux_sv-computer_security"
    },
    "ogx_mmlux_sv-college_physics": {
      "acc,none": 0.19607843137254902,
      "acc_stderr,none": 0.03950581861179961,
      "alias": "ogx_mmlux_sv-college_physics"
    },
    "ogx_mmlux_sv-college_medicine": {
      "acc,none": 0.3699421965317919,
      "acc_stderr,none": 0.0368122963339432,
      "alias": "ogx_mmlux_sv-college_medicine"
    },
    "ogx_mmlux_sv-college_mathematics": {
      "acc,none": 0.26,
      "acc_stderr,none": 0.0440844002276808,
      "alias": "ogx_mmlux_sv-college_mathematics"
    },
    "ogx_mmlux_sv-college_computer_science": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939098,
      "alias": "ogx_mmlux_sv-college_computer_science"
    },
    "ogx_mmlux_sv-college_chemistry": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.045126085985421276,
      "alias": "ogx_mmlux_sv-college_chemistry"
    },
    "ogx_mmlux_sv-college_biology": {
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.04122728707651282,
      "alias": "ogx_mmlux_sv-college_biology"
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "acc,none": 0.4188679245283019,
      "acc_stderr,none": 0.030365050829115205,
      "alias": "ogx_mmlux_sv-clinical_knowledge"
    },
    "ogx_mmlux_sv-business_ethics": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_sv-business_ethics"
    },
    "ogx_mmlux_sv-astronomy": {
      "acc,none": 0.4473684210526316,
      "acc_stderr,none": 0.04046336883978251,
      "alias": "ogx_mmlux_sv-astronomy"
    },
    "ogx_mmlux_sv-anatomy": {
      "acc,none": 0.4444444444444444,
      "acc_stderr,none": 0.042925967182569816,
      "alias": "ogx_mmlux_sv-anatomy"
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_sv-abstract_algebra"
    },
    "ogx_mmlux_sl-world_religions": {
      "acc,none": 0.5380116959064327,
      "acc_stderr,none": 0.03823727092882307,
      "alias": "ogx_mmlux_sl-world_religions"
    },
    "ogx_mmlux_sl-virology": {
      "acc,none": 0.3313253012048193,
      "acc_stderr,none": 0.03664314777288086,
      "alias": "ogx_mmlux_sl-virology"
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "acc,none": 0.55,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_sl-us_foreign_policy"
    },
    "ogx_mmlux_sl-sociology": {
      "acc,none": 0.46766169154228854,
      "acc_stderr,none": 0.035281314729336065,
      "alias": "ogx_mmlux_sl-sociology"
    },
    "ogx_mmlux_sl-security_studies": {
      "acc,none": 0.5306122448979592,
      "acc_stderr,none": 0.031949171367580624,
      "alias": "ogx_mmlux_sl-security_studies"
    },
    "ogx_mmlux_sl-public_relations": {
      "acc,none": 0.43636363636363634,
      "acc_stderr,none": 0.04750185058907297,
      "alias": "ogx_mmlux_sl-public_relations"
    },
    "ogx_mmlux_sl-professional_psychology": {
      "acc,none": 0.3366013071895425,
      "acc_stderr,none": 0.01911721391149517,
      "alias": "ogx_mmlux_sl-professional_psychology"
    },
    "ogx_mmlux_sl-professional_medicine": {
      "acc,none": 0.3161764705882353,
      "acc_stderr,none": 0.02824568739146292,
      "alias": "ogx_mmlux_sl-professional_medicine"
    },
    "ogx_mmlux_sl-professional_law": {
      "acc,none": 0.3161668839634941,
      "acc_stderr,none": 0.01187578089438658,
      "alias": "ogx_mmlux_sl-professional_law"
    },
    "ogx_mmlux_sl-professional_accounting": {
      "acc,none": 0.30851063829787234,
      "acc_stderr,none": 0.027553366165101362,
      "alias": "ogx_mmlux_sl-professional_accounting"
    },
    "ogx_mmlux_sl-prehistory": {
      "acc,none": 0.4228395061728395,
      "acc_stderr,none": 0.027487472980871588,
      "alias": "ogx_mmlux_sl-prehistory"
    },
    "ogx_mmlux_sl-philosophy": {
      "acc,none": 0.42443729903536975,
      "acc_stderr,none": 0.028071928247946205,
      "alias": "ogx_mmlux_sl-philosophy"
    },
    "ogx_mmlux_sl-nutrition": {
      "acc,none": 0.48366013071895425,
      "acc_stderr,none": 0.028614624752805413,
      "alias": "ogx_mmlux_sl-nutrition"
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "acc,none": 0.23798882681564246,
      "acc_stderr,none": 0.014242630070574889,
      "alias": "ogx_mmlux_sl-moral_scenarios"
    },
    "ogx_mmlux_sl-moral_disputes": {
      "acc,none": 0.4508670520231214,
      "acc_stderr,none": 0.026788811931562757,
      "alias": "ogx_mmlux_sl-moral_disputes"
    },
    "ogx_mmlux_sl-miscellaneous": {
      "acc,none": 0.4776500638569604,
      "acc_stderr,none": 0.017862091778507862,
      "alias": "ogx_mmlux_sl-miscellaneous"
    },
    "ogx_mmlux_sl-medical_genetics": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_sl-medical_genetics"
    },
    "ogx_mmlux_sl-marketing": {
      "acc,none": 0.5470085470085471,
      "acc_stderr,none": 0.03261099873098619,
      "alias": "ogx_mmlux_sl-marketing"
    },
    "ogx_mmlux_sl-management": {
      "acc,none": 0.5436893203883495,
      "acc_stderr,none": 0.049318019942204146,
      "alias": "ogx_mmlux_sl-management"
    },
    "ogx_mmlux_sl-machine_learning": {
      "acc,none": 0.33035714285714285,
      "acc_stderr,none": 0.04464285714285714,
      "alias": "ogx_mmlux_sl-machine_learning"
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "acc,none": 0.4171779141104294,
      "acc_stderr,none": 0.038741028598180814,
      "alias": "ogx_mmlux_sl-logical_fallacies"
    },
    "ogx_mmlux_sl-jurisprudence": {
      "acc,none": 0.4537037037037037,
      "acc_stderr,none": 0.04812917324536823,
      "alias": "ogx_mmlux_sl-jurisprudence"
    },
    "ogx_mmlux_sl-international_law": {
      "acc,none": 0.5537190082644629,
      "acc_stderr,none": 0.0453793517794788,
      "alias": "ogx_mmlux_sl-international_law"
    },
    "ogx_mmlux_sl-human_sexuality": {
      "acc,none": 0.45038167938931295,
      "acc_stderr,none": 0.04363643698524779,
      "alias": "ogx_mmlux_sl-human_sexuality"
    },
    "ogx_mmlux_sl-human_aging": {
      "acc,none": 0.4080717488789238,
      "acc_stderr,none": 0.03298574607842821,
      "alias": "ogx_mmlux_sl-human_aging"
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "acc,none": 0.48945147679324896,
      "acc_stderr,none": 0.032539983791662855,
      "alias": "ogx_mmlux_sl-high_school_world_history"
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "acc,none": 0.4264705882352941,
      "acc_stderr,none": 0.03471157907953426,
      "alias": "ogx_mmlux_sl-high_school_us_history"
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "acc,none": 0.3194444444444444,
      "acc_stderr,none": 0.0317987634217685,
      "alias": "ogx_mmlux_sl-high_school_statistics"
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "acc,none": 0.3853211009174312,
      "acc_stderr,none": 0.020865850852794108,
      "alias": "ogx_mmlux_sl-high_school_psychology"
    },
    "ogx_mmlux_sl-high_school_physics": {
      "acc,none": 0.33774834437086093,
      "acc_stderr,none": 0.03861557546255169,
      "alias": "ogx_mmlux_sl-high_school_physics"
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "acc,none": 0.3277310924369748,
      "acc_stderr,none": 0.030489911417673227,
      "alias": "ogx_mmlux_sl-high_school_microeconomics"
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "acc,none": 0.2814814814814815,
      "acc_stderr,none": 0.02742001935094527,
      "alias": "ogx_mmlux_sl-high_school_mathematics"
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "acc,none": 0.3128205128205128,
      "acc_stderr,none": 0.02350757902064535,
      "alias": "ogx_mmlux_sl-high_school_macroeconomics"
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "acc,none": 0.48186528497409326,
      "acc_stderr,none": 0.036060650018329185,
      "alias": "ogx_mmlux_sl-high_school_government_and_politics"
    },
    "ogx_mmlux_sl-high_school_geography": {
      "acc,none": 0.4898989898989899,
      "acc_stderr,none": 0.035616254886737454,
      "alias": "ogx_mmlux_sl-high_school_geography"
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "acc,none": 0.4727272727272727,
      "acc_stderr,none": 0.03898531605579419,
      "alias": "ogx_mmlux_sl-high_school_european_history"
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_sl-high_school_computer_science"
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "acc,none": 0.33004926108374383,
      "acc_stderr,none": 0.033085304262282574,
      "alias": "ogx_mmlux_sl-high_school_chemistry"
    },
    "ogx_mmlux_sl-high_school_biology": {
      "acc,none": 0.45483870967741935,
      "acc_stderr,none": 0.028327743091561067,
      "alias": "ogx_mmlux_sl-high_school_biology"
    },
    "ogx_mmlux_sl-global_facts": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.04560480215720684,
      "alias": "ogx_mmlux_sl-global_facts"
    },
    "ogx_mmlux_sl-formal_logic": {
      "acc,none": 0.2777777777777778,
      "acc_stderr,none": 0.04006168083848877,
      "alias": "ogx_mmlux_sl-formal_logic"
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "acc,none": 0.30423280423280424,
      "acc_stderr,none": 0.023695415009463087,
      "alias": "ogx_mmlux_sl-elementary_mathematics"
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "acc,none": 0.3586206896551724,
      "acc_stderr,none": 0.039966295748767186,
      "alias": "ogx_mmlux_sl-electrical_engineering"
    },
    "ogx_mmlux_sl-econometrics": {
      "acc,none": 0.2982456140350877,
      "acc_stderr,none": 0.04303684033537316,
      "alias": "ogx_mmlux_sl-econometrics"
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "acc,none": 0.33191489361702126,
      "acc_stderr,none": 0.030783736757745653,
      "alias": "ogx_mmlux_sl-conceptual_physics"
    },
    "ogx_mmlux_sl-computer_security": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.04999999999999999,
      "alias": "ogx_mmlux_sl-computer_security"
    },
    "ogx_mmlux_sl-college_physics": {
      "acc,none": 0.24509803921568626,
      "acc_stderr,none": 0.04280105837364395,
      "alias": "ogx_mmlux_sl-college_physics"
    },
    "ogx_mmlux_sl-college_medicine": {
      "acc,none": 0.2832369942196532,
      "acc_stderr,none": 0.03435568056047875,
      "alias": "ogx_mmlux_sl-college_medicine"
    },
    "ogx_mmlux_sl-college_mathematics": {
      "acc,none": 0.26,
      "acc_stderr,none": 0.0440844002276808,
      "alias": "ogx_mmlux_sl-college_mathematics"
    },
    "ogx_mmlux_sl-college_computer_science": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_sl-college_computer_science"
    },
    "ogx_mmlux_sl-college_chemistry": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_sl-college_chemistry"
    },
    "ogx_mmlux_sl-college_biology": {
      "acc,none": 0.3263888888888889,
      "acc_stderr,none": 0.03921067198982266,
      "alias": "ogx_mmlux_sl-college_biology"
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "acc,none": 0.4075471698113208,
      "acc_stderr,none": 0.030242233800854498,
      "alias": "ogx_mmlux_sl-clinical_knowledge"
    },
    "ogx_mmlux_sl-business_ethics": {
      "acc,none": 0.41,
      "acc_stderr,none": 0.049431107042371025,
      "alias": "ogx_mmlux_sl-business_ethics"
    },
    "ogx_mmlux_sl-astronomy": {
      "acc,none": 0.3815789473684211,
      "acc_stderr,none": 0.03953173377749194,
      "alias": "ogx_mmlux_sl-astronomy"
    },
    "ogx_mmlux_sl-anatomy": {
      "acc,none": 0.3925925925925926,
      "acc_stderr,none": 0.04218506215368879,
      "alias": "ogx_mmlux_sl-anatomy"
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_sl-abstract_algebra"
    },
    "ogx_mmlux_sk-world_religions": {
      "acc,none": 0.6374269005847953,
      "acc_stderr,none": 0.0368713061556206,
      "alias": "ogx_mmlux_sk-world_religions"
    },
    "ogx_mmlux_sk-virology": {
      "acc,none": 0.42168674698795183,
      "acc_stderr,none": 0.03844453181770917,
      "alias": "ogx_mmlux_sk-virology"
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "acc,none": 0.69,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_sk-us_foreign_policy"
    },
    "ogx_mmlux_sk-sociology": {
      "acc,none": 0.6169154228855721,
      "acc_stderr,none": 0.034375193373382504,
      "alias": "ogx_mmlux_sk-sociology"
    },
    "ogx_mmlux_sk-security_studies": {
      "acc,none": 0.5755102040816327,
      "acc_stderr,none": 0.031642094879429414,
      "alias": "ogx_mmlux_sk-security_studies"
    },
    "ogx_mmlux_sk-public_relations": {
      "acc,none": 0.4818181818181818,
      "acc_stderr,none": 0.04785964010794917,
      "alias": "ogx_mmlux_sk-public_relations"
    },
    "ogx_mmlux_sk-professional_psychology": {
      "acc,none": 0.3954248366013072,
      "acc_stderr,none": 0.019780465954777518,
      "alias": "ogx_mmlux_sk-professional_psychology"
    },
    "ogx_mmlux_sk-professional_medicine": {
      "acc,none": 0.40441176470588236,
      "acc_stderr,none": 0.029812630701569743,
      "alias": "ogx_mmlux_sk-professional_medicine"
    },
    "ogx_mmlux_sk-professional_law": {
      "acc,none": 0.3428943937418514,
      "acc_stderr,none": 0.012123463271585897,
      "alias": "ogx_mmlux_sk-professional_law"
    },
    "ogx_mmlux_sk-professional_accounting": {
      "acc,none": 0.35815602836879434,
      "acc_stderr,none": 0.02860208586275942,
      "alias": "ogx_mmlux_sk-professional_accounting"
    },
    "ogx_mmlux_sk-prehistory": {
      "acc,none": 0.5030864197530864,
      "acc_stderr,none": 0.027820214158594377,
      "alias": "ogx_mmlux_sk-prehistory"
    },
    "ogx_mmlux_sk-philosophy": {
      "acc,none": 0.5112540192926045,
      "acc_stderr,none": 0.028390897396863533,
      "alias": "ogx_mmlux_sk-philosophy"
    },
    "ogx_mmlux_sk-nutrition": {
      "acc,none": 0.5392156862745098,
      "acc_stderr,none": 0.028541722692618874,
      "alias": "ogx_mmlux_sk-nutrition"
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "acc,none": 0.25027932960893856,
      "acc_stderr,none": 0.014487500852850423,
      "alias": "ogx_mmlux_sk-moral_scenarios"
    },
    "ogx_mmlux_sk-moral_disputes": {
      "acc,none": 0.4624277456647399,
      "acc_stderr,none": 0.02684298551961537,
      "alias": "ogx_mmlux_sk-moral_disputes"
    },
    "ogx_mmlux_sk-miscellaneous": {
      "acc,none": 0.5504469987228607,
      "acc_stderr,none": 0.017788725283507337,
      "alias": "ogx_mmlux_sk-miscellaneous"
    },
    "ogx_mmlux_sk-medical_genetics": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_sk-medical_genetics"
    },
    "ogx_mmlux_sk-marketing": {
      "acc,none": 0.688034188034188,
      "acc_stderr,none": 0.03035152732334495,
      "alias": "ogx_mmlux_sk-marketing"
    },
    "ogx_mmlux_sk-management": {
      "acc,none": 0.6990291262135923,
      "acc_stderr,none": 0.04541609446503948,
      "alias": "ogx_mmlux_sk-management"
    },
    "ogx_mmlux_sk-machine_learning": {
      "acc,none": 0.38392857142857145,
      "acc_stderr,none": 0.04616143075028547,
      "alias": "ogx_mmlux_sk-machine_learning"
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "acc,none": 0.48466257668711654,
      "acc_stderr,none": 0.039265223787088445,
      "alias": "ogx_mmlux_sk-logical_fallacies"
    },
    "ogx_mmlux_sk-jurisprudence": {
      "acc,none": 0.5277777777777778,
      "acc_stderr,none": 0.04826217294139894,
      "alias": "ogx_mmlux_sk-jurisprudence"
    },
    "ogx_mmlux_sk-international_law": {
      "acc,none": 0.5950413223140496,
      "acc_stderr,none": 0.04481137755942469,
      "alias": "ogx_mmlux_sk-international_law"
    },
    "ogx_mmlux_sk-human_sexuality": {
      "acc,none": 0.48091603053435117,
      "acc_stderr,none": 0.04382094705550988,
      "alias": "ogx_mmlux_sk-human_sexuality"
    },
    "ogx_mmlux_sk-human_aging": {
      "acc,none": 0.515695067264574,
      "acc_stderr,none": 0.0335412657542081,
      "alias": "ogx_mmlux_sk-human_aging"
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "acc,none": 0.569620253164557,
      "acc_stderr,none": 0.03223017195937599,
      "alias": "ogx_mmlux_sk-high_school_world_history"
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "acc,none": 0.5588235294117647,
      "acc_stderr,none": 0.034849415144292316,
      "alias": "ogx_mmlux_sk-high_school_us_history"
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "acc,none": 0.3148148148148148,
      "acc_stderr,none": 0.03167468706828979,
      "alias": "ogx_mmlux_sk-high_school_statistics"
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "acc,none": 0.5596330275229358,
      "acc_stderr,none": 0.021284310623761547,
      "alias": "ogx_mmlux_sk-high_school_psychology"
    },
    "ogx_mmlux_sk-high_school_physics": {
      "acc,none": 0.33112582781456956,
      "acc_stderr,none": 0.038425817186598696,
      "alias": "ogx_mmlux_sk-high_school_physics"
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "acc,none": 0.41596638655462187,
      "acc_stderr,none": 0.03201650100739615,
      "alias": "ogx_mmlux_sk-high_school_microeconomics"
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "acc,none": 0.3074074074074074,
      "acc_stderr,none": 0.028133252578815635,
      "alias": "ogx_mmlux_sk-high_school_mathematics"
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "acc,none": 0.3974358974358974,
      "acc_stderr,none": 0.024811920017903836,
      "alias": "ogx_mmlux_sk-high_school_macroeconomics"
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "acc,none": 0.538860103626943,
      "acc_stderr,none": 0.03597524411734578,
      "alias": "ogx_mmlux_sk-high_school_government_and_politics"
    },
    "ogx_mmlux_sk-high_school_geography": {
      "acc,none": 0.5303030303030303,
      "acc_stderr,none": 0.0355580405176393,
      "alias": "ogx_mmlux_sk-high_school_geography"
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "acc,none": 0.5151515151515151,
      "acc_stderr,none": 0.03902551007374448,
      "alias": "ogx_mmlux_sk-high_school_european_history"
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "acc,none": 0.57,
      "acc_stderr,none": 0.04975698519562428,
      "alias": "ogx_mmlux_sk-high_school_computer_science"
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "acc,none": 0.37438423645320196,
      "acc_stderr,none": 0.03405155380561952,
      "alias": "ogx_mmlux_sk-high_school_chemistry"
    },
    "ogx_mmlux_sk-high_school_biology": {
      "acc,none": 0.5096774193548387,
      "acc_stderr,none": 0.02843867799890955,
      "alias": "ogx_mmlux_sk-high_school_biology"
    },
    "ogx_mmlux_sk-global_facts": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.04688261722621504,
      "alias": "ogx_mmlux_sk-global_facts"
    },
    "ogx_mmlux_sk-formal_logic": {
      "acc,none": 0.30952380952380953,
      "acc_stderr,none": 0.04134913018303316,
      "alias": "ogx_mmlux_sk-formal_logic"
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "acc,none": 0.31746031746031744,
      "acc_stderr,none": 0.023973861998992083,
      "alias": "ogx_mmlux_sk-elementary_mathematics"
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "acc,none": 0.46206896551724136,
      "acc_stderr,none": 0.041546596717075474,
      "alias": "ogx_mmlux_sk-electrical_engineering"
    },
    "ogx_mmlux_sk-econometrics": {
      "acc,none": 0.2543859649122807,
      "acc_stderr,none": 0.040969851398436716,
      "alias": "ogx_mmlux_sk-econometrics"
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "acc,none": 0.3702127659574468,
      "acc_stderr,none": 0.03156564682236785,
      "alias": "ogx_mmlux_sk-conceptual_physics"
    },
    "ogx_mmlux_sk-computer_security": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_sk-computer_security"
    },
    "ogx_mmlux_sk-college_physics": {
      "acc,none": 0.17647058823529413,
      "acc_stderr,none": 0.03793281185307807,
      "alias": "ogx_mmlux_sk-college_physics"
    },
    "ogx_mmlux_sk-college_medicine": {
      "acc,none": 0.3468208092485549,
      "acc_stderr,none": 0.03629146670159663,
      "alias": "ogx_mmlux_sk-college_medicine"
    },
    "ogx_mmlux_sk-college_mathematics": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695236,
      "alias": "ogx_mmlux_sk-college_mathematics"
    },
    "ogx_mmlux_sk-college_computer_science": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001974,
      "alias": "ogx_mmlux_sk-college_computer_science"
    },
    "ogx_mmlux_sk-college_chemistry": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_sk-college_chemistry"
    },
    "ogx_mmlux_sk-college_biology": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.04076663253918567,
      "alias": "ogx_mmlux_sk-college_biology"
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "acc,none": 0.45660377358490567,
      "acc_stderr,none": 0.030656748696739435,
      "alias": "ogx_mmlux_sk-clinical_knowledge"
    },
    "ogx_mmlux_sk-business_ethics": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_sk-business_ethics"
    },
    "ogx_mmlux_sk-astronomy": {
      "acc,none": 0.46710526315789475,
      "acc_stderr,none": 0.04060127035236395,
      "alias": "ogx_mmlux_sk-astronomy"
    },
    "ogx_mmlux_sk-anatomy": {
      "acc,none": 0.37777777777777777,
      "acc_stderr,none": 0.04188307537595853,
      "alias": "ogx_mmlux_sk-anatomy"
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_sk-abstract_algebra"
    },
    "ogx_mmlux_ro-world_religions": {
      "acc,none": 0.6549707602339181,
      "acc_stderr,none": 0.036459813773888065,
      "alias": "ogx_mmlux_ro-world_religions"
    },
    "ogx_mmlux_ro-virology": {
      "acc,none": 0.4578313253012048,
      "acc_stderr,none": 0.038786267710023595,
      "alias": "ogx_mmlux_ro-virology"
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_ro-us_foreign_policy"
    },
    "ogx_mmlux_ro-sociology": {
      "acc,none": 0.7313432835820896,
      "acc_stderr,none": 0.03134328358208954,
      "alias": "ogx_mmlux_ro-sociology"
    },
    "ogx_mmlux_ro-security_studies": {
      "acc,none": 0.6489795918367347,
      "acc_stderr,none": 0.03055531675557364,
      "alias": "ogx_mmlux_ro-security_studies"
    },
    "ogx_mmlux_ro-public_relations": {
      "acc,none": 0.5545454545454546,
      "acc_stderr,none": 0.047605488214603246,
      "alias": "ogx_mmlux_ro-public_relations"
    },
    "ogx_mmlux_ro-professional_psychology": {
      "acc,none": 0.46405228758169936,
      "acc_stderr,none": 0.020175488765484043,
      "alias": "ogx_mmlux_ro-professional_psychology"
    },
    "ogx_mmlux_ro-professional_medicine": {
      "acc,none": 0.44485294117647056,
      "acc_stderr,none": 0.030187532060329376,
      "alias": "ogx_mmlux_ro-professional_medicine"
    },
    "ogx_mmlux_ro-professional_law": {
      "acc,none": 0.37614080834419816,
      "acc_stderr,none": 0.012372214430599819,
      "alias": "ogx_mmlux_ro-professional_law"
    },
    "ogx_mmlux_ro-professional_accounting": {
      "acc,none": 0.3723404255319149,
      "acc_stderr,none": 0.028838921471251458,
      "alias": "ogx_mmlux_ro-professional_accounting"
    },
    "ogx_mmlux_ro-prehistory": {
      "acc,none": 0.5679012345679012,
      "acc_stderr,none": 0.02756301097160667,
      "alias": "ogx_mmlux_ro-prehistory"
    },
    "ogx_mmlux_ro-philosophy": {
      "acc,none": 0.5787781350482315,
      "acc_stderr,none": 0.028043399858210628,
      "alias": "ogx_mmlux_ro-philosophy"
    },
    "ogx_mmlux_ro-nutrition": {
      "acc,none": 0.5882352941176471,
      "acc_stderr,none": 0.02818059632825928,
      "alias": "ogx_mmlux_ro-nutrition"
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "acc,none": 0.24581005586592178,
      "acc_stderr,none": 0.014400296429225598,
      "alias": "ogx_mmlux_ro-moral_scenarios"
    },
    "ogx_mmlux_ro-moral_disputes": {
      "acc,none": 0.5346820809248555,
      "acc_stderr,none": 0.026854257928258865,
      "alias": "ogx_mmlux_ro-moral_disputes"
    },
    "ogx_mmlux_ro-miscellaneous": {
      "acc,none": 0.648786717752235,
      "acc_stderr,none": 0.017069982051499427,
      "alias": "ogx_mmlux_ro-miscellaneous"
    },
    "ogx_mmlux_ro-medical_genetics": {
      "acc,none": 0.53,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_ro-medical_genetics"
    },
    "ogx_mmlux_ro-marketing": {
      "acc,none": 0.7478632478632479,
      "acc_stderr,none": 0.02844796547623102,
      "alias": "ogx_mmlux_ro-marketing"
    },
    "ogx_mmlux_ro-management": {
      "acc,none": 0.6990291262135923,
      "acc_stderr,none": 0.04541609446503948,
      "alias": "ogx_mmlux_ro-management"
    },
    "ogx_mmlux_ro-machine_learning": {
      "acc,none": 0.38392857142857145,
      "acc_stderr,none": 0.046161430750285455,
      "alias": "ogx_mmlux_ro-machine_learning"
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "acc,none": 0.50920245398773,
      "acc_stderr,none": 0.03927705600787443,
      "alias": "ogx_mmlux_ro-logical_fallacies"
    },
    "ogx_mmlux_ro-jurisprudence": {
      "acc,none": 0.6203703703703703,
      "acc_stderr,none": 0.04691521224077742,
      "alias": "ogx_mmlux_ro-jurisprudence"
    },
    "ogx_mmlux_ro-international_law": {
      "acc,none": 0.6776859504132231,
      "acc_stderr,none": 0.042664163633521685,
      "alias": "ogx_mmlux_ro-international_law"
    },
    "ogx_mmlux_ro-human_sexuality": {
      "acc,none": 0.5801526717557252,
      "acc_stderr,none": 0.04328577215262972,
      "alias": "ogx_mmlux_ro-human_sexuality"
    },
    "ogx_mmlux_ro-human_aging": {
      "acc,none": 0.6188340807174888,
      "acc_stderr,none": 0.03259625118416827,
      "alias": "ogx_mmlux_ro-human_aging"
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "acc,none": 0.6919831223628692,
      "acc_stderr,none": 0.030052389335605702,
      "alias": "ogx_mmlux_ro-high_school_world_history"
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "acc,none": 0.6715686274509803,
      "acc_stderr,none": 0.03296245110172229,
      "alias": "ogx_mmlux_ro-high_school_us_history"
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "acc,none": 0.3425925925925926,
      "acc_stderr,none": 0.03236585252602158,
      "alias": "ogx_mmlux_ro-high_school_statistics"
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "acc,none": 0.6403669724770642,
      "acc_stderr,none": 0.020575234660123776,
      "alias": "ogx_mmlux_ro-high_school_psychology"
    },
    "ogx_mmlux_ro-high_school_physics": {
      "acc,none": 0.2913907284768212,
      "acc_stderr,none": 0.037101857261199946,
      "alias": "ogx_mmlux_ro-high_school_physics"
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "acc,none": 0.39915966386554624,
      "acc_stderr,none": 0.03181110032413926,
      "alias": "ogx_mmlux_ro-high_school_microeconomics"
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "acc,none": 0.3111111111111111,
      "acc_stderr,none": 0.028226446749683515,
      "alias": "ogx_mmlux_ro-high_school_mathematics"
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "acc,none": 0.4641025641025641,
      "acc_stderr,none": 0.02528558599001784,
      "alias": "ogx_mmlux_ro-high_school_macroeconomics"
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "acc,none": 0.7357512953367875,
      "acc_stderr,none": 0.03182155050916649,
      "alias": "ogx_mmlux_ro-high_school_government_and_politics"
    },
    "ogx_mmlux_ro-high_school_geography": {
      "acc,none": 0.6363636363636364,
      "acc_stderr,none": 0.03427308652999934,
      "alias": "ogx_mmlux_ro-high_school_geography"
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "acc,none": 0.6303030303030303,
      "acc_stderr,none": 0.037694303145125674,
      "alias": "ogx_mmlux_ro-high_school_european_history"
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.04878317312145633,
      "alias": "ogx_mmlux_ro-high_school_computer_science"
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "acc,none": 0.3793103448275862,
      "acc_stderr,none": 0.034139638059062345,
      "alias": "ogx_mmlux_ro-high_school_chemistry"
    },
    "ogx_mmlux_ro-high_school_biology": {
      "acc,none": 0.5838709677419355,
      "acc_stderr,none": 0.028040981380761547,
      "alias": "ogx_mmlux_ro-high_school_biology"
    },
    "ogx_mmlux_ro-global_facts": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.04793724854411019,
      "alias": "ogx_mmlux_ro-global_facts"
    },
    "ogx_mmlux_ro-formal_logic": {
      "acc,none": 0.2698412698412698,
      "acc_stderr,none": 0.03970158273235172,
      "alias": "ogx_mmlux_ro-formal_logic"
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "acc,none": 0.328042328042328,
      "acc_stderr,none": 0.024180497164376882,
      "alias": "ogx_mmlux_ro-elementary_mathematics"
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "acc,none": 0.503448275862069,
      "acc_stderr,none": 0.04166567577101579,
      "alias": "ogx_mmlux_ro-electrical_engineering"
    },
    "ogx_mmlux_ro-econometrics": {
      "acc,none": 0.32456140350877194,
      "acc_stderr,none": 0.04404556157374768,
      "alias": "ogx_mmlux_ro-econometrics"
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "acc,none": 0.46808510638297873,
      "acc_stderr,none": 0.03261936918467382,
      "alias": "ogx_mmlux_ro-conceptual_physics"
    },
    "ogx_mmlux_ro-computer_security": {
      "acc,none": 0.65,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_ro-computer_security"
    },
    "ogx_mmlux_ro-college_physics": {
      "acc,none": 0.2549019607843137,
      "acc_stderr,none": 0.043364327079931785,
      "alias": "ogx_mmlux_ro-college_physics"
    },
    "ogx_mmlux_ro-college_medicine": {
      "acc,none": 0.4161849710982659,
      "acc_stderr,none": 0.03758517775404947,
      "alias": "ogx_mmlux_ro-college_medicine"
    },
    "ogx_mmlux_ro-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_ro-college_mathematics"
    },
    "ogx_mmlux_ro-college_computer_science": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_ro-college_computer_science"
    },
    "ogx_mmlux_ro-college_chemistry": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_ro-college_chemistry"
    },
    "ogx_mmlux_ro-college_biology": {
      "acc,none": 0.4513888888888889,
      "acc_stderr,none": 0.04161402398403279,
      "alias": "ogx_mmlux_ro-college_biology"
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "acc,none": 0.5094339622641509,
      "acc_stderr,none": 0.030767394707808093,
      "alias": "ogx_mmlux_ro-clinical_knowledge"
    },
    "ogx_mmlux_ro-business_ethics": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_ro-business_ethics"
    },
    "ogx_mmlux_ro-astronomy": {
      "acc,none": 0.5394736842105263,
      "acc_stderr,none": 0.04056242252249033,
      "alias": "ogx_mmlux_ro-astronomy"
    },
    "ogx_mmlux_ro-anatomy": {
      "acc,none": 0.4444444444444444,
      "acc_stderr,none": 0.04292596718256981,
      "alias": "ogx_mmlux_ro-anatomy"
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542127,
      "alias": "ogx_mmlux_ro-abstract_algebra"
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "acc,none": 0.6608187134502924,
      "acc_stderr,none": 0.03631053496488905,
      "alias": "ogx_mmlux_pt-pt-world_religions"
    },
    "ogx_mmlux_pt-pt-virology": {
      "acc,none": 0.42771084337349397,
      "acc_stderr,none": 0.03851597683718534,
      "alias": "ogx_mmlux_pt-pt-virology"
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "acc,none": 0.8,
      "acc_stderr,none": 0.04020151261036846,
      "alias": "ogx_mmlux_pt-pt-us_foreign_policy"
    },
    "ogx_mmlux_pt-pt-sociology": {
      "acc,none": 0.7313432835820896,
      "acc_stderr,none": 0.03134328358208954,
      "alias": "ogx_mmlux_pt-pt-sociology"
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "acc,none": 0.6775510204081633,
      "acc_stderr,none": 0.029923100563683906,
      "alias": "ogx_mmlux_pt-pt-security_studies"
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "acc,none": 0.6272727272727273,
      "acc_stderr,none": 0.04631381319425464,
      "alias": "ogx_mmlux_pt-pt-public_relations"
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "acc,none": 0.48366013071895425,
      "acc_stderr,none": 0.020217030653186453,
      "alias": "ogx_mmlux_pt-pt-professional_psychology"
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "acc,none": 0.4338235294117647,
      "acc_stderr,none": 0.03010563657001664,
      "alias": "ogx_mmlux_pt-pt-professional_medicine"
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "acc,none": 0.38005215123859193,
      "acc_stderr,none": 0.012397328205137812,
      "alias": "ogx_mmlux_pt-pt-professional_law"
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "acc,none": 0.3900709219858156,
      "acc_stderr,none": 0.029097675599463933,
      "alias": "ogx_mmlux_pt-pt-professional_accounting"
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "acc,none": 0.5925925925925926,
      "acc_stderr,none": 0.02733954664066273,
      "alias": "ogx_mmlux_pt-pt-prehistory"
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "acc,none": 0.5852090032154341,
      "acc_stderr,none": 0.02798268045975956,
      "alias": "ogx_mmlux_pt-pt-philosophy"
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "acc,none": 0.5686274509803921,
      "acc_stderr,none": 0.028358956313423545,
      "alias": "ogx_mmlux_pt-pt-nutrition"
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "acc,none": 0.2636871508379888,
      "acc_stderr,none": 0.014736926383761974,
      "alias": "ogx_mmlux_pt-pt-moral_scenarios"
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "acc,none": 0.5606936416184971,
      "acc_stderr,none": 0.02672003438051499,
      "alias": "ogx_mmlux_pt-pt-moral_disputes"
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "acc,none": 0.665389527458493,
      "acc_stderr,none": 0.016873468641592157,
      "alias": "ogx_mmlux_pt-pt-miscellaneous"
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "acc,none": 0.55,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_pt-pt-medical_genetics"
    },
    "ogx_mmlux_pt-pt-marketing": {
      "acc,none": 0.7735042735042735,
      "acc_stderr,none": 0.027421007295392912,
      "alias": "ogx_mmlux_pt-pt-marketing"
    },
    "ogx_mmlux_pt-pt-management": {
      "acc,none": 0.7281553398058253,
      "acc_stderr,none": 0.044052680241409216,
      "alias": "ogx_mmlux_pt-pt-management"
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "acc,none": 0.45535714285714285,
      "acc_stderr,none": 0.04726835553719099,
      "alias": "ogx_mmlux_pt-pt-machine_learning"
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "acc,none": 0.5705521472392638,
      "acc_stderr,none": 0.038890666191127216,
      "alias": "ogx_mmlux_pt-pt-logical_fallacies"
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "acc,none": 0.6111111111111112,
      "acc_stderr,none": 0.0471282125742677,
      "alias": "ogx_mmlux_pt-pt-jurisprudence"
    },
    "ogx_mmlux_pt-pt-international_law": {
      "acc,none": 0.6776859504132231,
      "acc_stderr,none": 0.042664163633521685,
      "alias": "ogx_mmlux_pt-pt-international_law"
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "acc,none": 0.5954198473282443,
      "acc_stderr,none": 0.043046937953806645,
      "alias": "ogx_mmlux_pt-pt-human_sexuality"
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "acc,none": 0.5919282511210763,
      "acc_stderr,none": 0.03298574607842822,
      "alias": "ogx_mmlux_pt-pt-human_aging"
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "acc,none": 0.70042194092827,
      "acc_stderr,none": 0.029818024749753102,
      "alias": "ogx_mmlux_pt-pt-high_school_world_history"
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "acc,none": 0.6862745098039216,
      "acc_stderr,none": 0.032566854844603886,
      "alias": "ogx_mmlux_pt-pt-high_school_us_history"
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "acc,none": 0.35648148148148145,
      "acc_stderr,none": 0.032664783315272714,
      "alias": "ogx_mmlux_pt-pt-high_school_statistics"
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "acc,none": 0.671559633027523,
      "acc_stderr,none": 0.020135902797298405,
      "alias": "ogx_mmlux_pt-pt-high_school_psychology"
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "acc,none": 0.31788079470198677,
      "acc_stderr,none": 0.038020397601079024,
      "alias": "ogx_mmlux_pt-pt-high_school_physics"
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "acc,none": 0.453781512605042,
      "acc_stderr,none": 0.03233943468182088,
      "alias": "ogx_mmlux_pt-pt-high_school_microeconomics"
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "acc,none": 0.31851851851851853,
      "acc_stderr,none": 0.02840653309060846,
      "alias": "ogx_mmlux_pt-pt-high_school_mathematics"
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "acc,none": 0.45897435897435895,
      "acc_stderr,none": 0.025265525491284295,
      "alias": "ogx_mmlux_pt-pt-high_school_macroeconomics"
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "acc,none": 0.7046632124352331,
      "acc_stderr,none": 0.032922966391551414,
      "alias": "ogx_mmlux_pt-pt-high_school_government_and_politics"
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "acc,none": 0.6212121212121212,
      "acc_stderr,none": 0.03456088731993747,
      "alias": "ogx_mmlux_pt-pt-high_school_geography"
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "acc,none": 0.6424242424242425,
      "acc_stderr,none": 0.03742597043806587,
      "alias": "ogx_mmlux_pt-pt-high_school_european_history"
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.04878317312145633,
      "alias": "ogx_mmlux_pt-pt-high_school_computer_science"
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "acc,none": 0.4187192118226601,
      "acc_stderr,none": 0.03471192860518468,
      "alias": "ogx_mmlux_pt-pt-high_school_chemistry"
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "acc,none": 0.5935483870967742,
      "acc_stderr,none": 0.027941727346256315,
      "alias": "ogx_mmlux_pt-pt-high_school_biology"
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_pt-pt-global_facts"
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "acc,none": 0.3253968253968254,
      "acc_stderr,none": 0.041905964388711366,
      "alias": "ogx_mmlux_pt-pt-formal_logic"
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "acc,none": 0.328042328042328,
      "acc_stderr,none": 0.02418049716437689,
      "alias": "ogx_mmlux_pt-pt-elementary_mathematics"
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "acc,none": 0.4413793103448276,
      "acc_stderr,none": 0.04137931034482757,
      "alias": "ogx_mmlux_pt-pt-electrical_engineering"
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "acc,none": 0.34210526315789475,
      "acc_stderr,none": 0.04462917535336937,
      "alias": "ogx_mmlux_pt-pt-econometrics"
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "acc,none": 0.41702127659574467,
      "acc_stderr,none": 0.03223276266711712,
      "alias": "ogx_mmlux_pt-pt-conceptual_physics"
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "acc,none": 0.66,
      "acc_stderr,none": 0.04760952285695237,
      "alias": "ogx_mmlux_pt-pt-computer_security"
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "acc,none": 0.20588235294117646,
      "acc_stderr,none": 0.04023382273617746,
      "alias": "ogx_mmlux_pt-pt-college_physics"
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "acc,none": 0.4913294797687861,
      "acc_stderr,none": 0.038118909889404126,
      "alias": "ogx_mmlux_pt-pt-college_medicine"
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542128,
      "alias": "ogx_mmlux_pt-pt-college_mathematics"
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_pt-pt-college_computer_science"
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_pt-pt-college_chemistry"
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "acc,none": 0.5138888888888888,
      "acc_stderr,none": 0.04179596617581,
      "alias": "ogx_mmlux_pt-pt-college_biology"
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "acc,none": 0.5018867924528302,
      "acc_stderr,none": 0.030772653642075664,
      "alias": "ogx_mmlux_pt-pt-clinical_knowledge"
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_pt-pt-business_ethics"
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "acc,none": 0.5526315789473685,
      "acc_stderr,none": 0.04046336883978251,
      "alias": "ogx_mmlux_pt-pt-astronomy"
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "acc,none": 0.4444444444444444,
      "acc_stderr,none": 0.042925967182569816,
      "alias": "ogx_mmlux_pt-pt-anatomy"
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_pt-pt-abstract_algebra"
    },
    "ogx_mmlux_pl-world_religions": {
      "acc,none": 0.631578947368421,
      "acc_stderr,none": 0.036996580176568775,
      "alias": "ogx_mmlux_pl-world_religions"
    },
    "ogx_mmlux_pl-virology": {
      "acc,none": 0.4036144578313253,
      "acc_stderr,none": 0.038194861407583984,
      "alias": "ogx_mmlux_pl-virology"
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_pl-us_foreign_policy"
    },
    "ogx_mmlux_pl-sociology": {
      "acc,none": 0.7064676616915423,
      "acc_stderr,none": 0.03220024104534205,
      "alias": "ogx_mmlux_pl-sociology"
    },
    "ogx_mmlux_pl-security_studies": {
      "acc,none": 0.6244897959183674,
      "acc_stderr,none": 0.031001209039894843,
      "alias": "ogx_mmlux_pl-security_studies"
    },
    "ogx_mmlux_pl-public_relations": {
      "acc,none": 0.5909090909090909,
      "acc_stderr,none": 0.04709306978661895,
      "alias": "ogx_mmlux_pl-public_relations"
    },
    "ogx_mmlux_pl-professional_psychology": {
      "acc,none": 0.47058823529411764,
      "acc_stderr,none": 0.02019280827143379,
      "alias": "ogx_mmlux_pl-professional_psychology"
    },
    "ogx_mmlux_pl-professional_medicine": {
      "acc,none": 0.43014705882352944,
      "acc_stderr,none": 0.030074971917302875,
      "alias": "ogx_mmlux_pl-professional_medicine"
    },
    "ogx_mmlux_pl-professional_law": {
      "acc,none": 0.36766623207301175,
      "acc_stderr,none": 0.012314845910071707,
      "alias": "ogx_mmlux_pl-professional_law"
    },
    "ogx_mmlux_pl-professional_accounting": {
      "acc,none": 0.33687943262411346,
      "acc_stderr,none": 0.028195534873966727,
      "alias": "ogx_mmlux_pl-professional_accounting"
    },
    "ogx_mmlux_pl-prehistory": {
      "acc,none": 0.5339506172839507,
      "acc_stderr,none": 0.027756535257347666,
      "alias": "ogx_mmlux_pl-prehistory"
    },
    "ogx_mmlux_pl-philosophy": {
      "acc,none": 0.5755627009646302,
      "acc_stderr,none": 0.028071928247946208,
      "alias": "ogx_mmlux_pl-philosophy"
    },
    "ogx_mmlux_pl-nutrition": {
      "acc,none": 0.5588235294117647,
      "acc_stderr,none": 0.02843109544417665,
      "alias": "ogx_mmlux_pl-nutrition"
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "acc,none": 0.2558659217877095,
      "acc_stderr,none": 0.014593620923210754,
      "alias": "ogx_mmlux_pl-moral_scenarios"
    },
    "ogx_mmlux_pl-moral_disputes": {
      "acc,none": 0.5404624277456648,
      "acc_stderr,none": 0.026830805998952243,
      "alias": "ogx_mmlux_pl-moral_disputes"
    },
    "ogx_mmlux_pl-miscellaneous": {
      "acc,none": 0.6385696040868455,
      "acc_stderr,none": 0.017179601328900736,
      "alias": "ogx_mmlux_pl-miscellaneous"
    },
    "ogx_mmlux_pl-medical_genetics": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_pl-medical_genetics"
    },
    "ogx_mmlux_pl-marketing": {
      "acc,none": 0.7564102564102564,
      "acc_stderr,none": 0.028120966503914407,
      "alias": "ogx_mmlux_pl-marketing"
    },
    "ogx_mmlux_pl-management": {
      "acc,none": 0.6990291262135923,
      "acc_stderr,none": 0.04541609446503948,
      "alias": "ogx_mmlux_pl-management"
    },
    "ogx_mmlux_pl-machine_learning": {
      "acc,none": 0.4107142857142857,
      "acc_stderr,none": 0.04669510663875192,
      "alias": "ogx_mmlux_pl-machine_learning"
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "acc,none": 0.48466257668711654,
      "acc_stderr,none": 0.03926522378708843,
      "alias": "ogx_mmlux_pl-logical_fallacies"
    },
    "ogx_mmlux_pl-jurisprudence": {
      "acc,none": 0.5833333333333334,
      "acc_stderr,none": 0.04766075165356461,
      "alias": "ogx_mmlux_pl-jurisprudence"
    },
    "ogx_mmlux_pl-international_law": {
      "acc,none": 0.6611570247933884,
      "acc_stderr,none": 0.04320767807536671,
      "alias": "ogx_mmlux_pl-international_law"
    },
    "ogx_mmlux_pl-human_sexuality": {
      "acc,none": 0.5801526717557252,
      "acc_stderr,none": 0.04328577215262972,
      "alias": "ogx_mmlux_pl-human_sexuality"
    },
    "ogx_mmlux_pl-human_aging": {
      "acc,none": 0.6053811659192825,
      "acc_stderr,none": 0.03280400504755291,
      "alias": "ogx_mmlux_pl-human_aging"
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "acc,none": 0.6582278481012658,
      "acc_stderr,none": 0.030874537537553617,
      "alias": "ogx_mmlux_pl-high_school_world_history"
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "acc,none": 0.6225490196078431,
      "acc_stderr,none": 0.03402272044340703,
      "alias": "ogx_mmlux_pl-high_school_us_history"
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "acc,none": 0.36574074074074076,
      "acc_stderr,none": 0.032847388576472056,
      "alias": "ogx_mmlux_pl-high_school_statistics"
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "acc,none": 0.6201834862385321,
      "acc_stderr,none": 0.020808825617866244,
      "alias": "ogx_mmlux_pl-high_school_psychology"
    },
    "ogx_mmlux_pl-high_school_physics": {
      "acc,none": 0.3509933774834437,
      "acc_stderr,none": 0.038969819642573754,
      "alias": "ogx_mmlux_pl-high_school_physics"
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "acc,none": 0.453781512605042,
      "acc_stderr,none": 0.03233943468182088,
      "alias": "ogx_mmlux_pl-high_school_microeconomics"
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "acc,none": 0.31851851851851853,
      "acc_stderr,none": 0.02840653309060846,
      "alias": "ogx_mmlux_pl-high_school_mathematics"
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "acc,none": 0.45897435897435895,
      "acc_stderr,none": 0.025265525491284295,
      "alias": "ogx_mmlux_pl-high_school_macroeconomics"
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "acc,none": 0.6839378238341969,
      "acc_stderr,none": 0.033553973696861736,
      "alias": "ogx_mmlux_pl-high_school_government_and_politics"
    },
    "ogx_mmlux_pl-high_school_geography": {
      "acc,none": 0.6161616161616161,
      "acc_stderr,none": 0.03464881675016338,
      "alias": "ogx_mmlux_pl-high_school_geography"
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "acc,none": 0.6181818181818182,
      "acc_stderr,none": 0.03793713171165635,
      "alias": "ogx_mmlux_pl-high_school_european_history"
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "acc,none": 0.57,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_pl-high_school_computer_science"
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "acc,none": 0.3448275862068966,
      "acc_stderr,none": 0.033442837442804574,
      "alias": "ogx_mmlux_pl-high_school_chemistry"
    },
    "ogx_mmlux_pl-high_school_biology": {
      "acc,none": 0.5645161290322581,
      "acc_stderr,none": 0.028206225591502744,
      "alias": "ogx_mmlux_pl-high_school_biology"
    },
    "ogx_mmlux_pl-global_facts": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_pl-global_facts"
    },
    "ogx_mmlux_pl-formal_logic": {
      "acc,none": 0.29365079365079366,
      "acc_stderr,none": 0.04073524322147127,
      "alias": "ogx_mmlux_pl-formal_logic"
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "acc,none": 0.3201058201058201,
      "acc_stderr,none": 0.024026846392873506,
      "alias": "ogx_mmlux_pl-elementary_mathematics"
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "acc,none": 0.45517241379310347,
      "acc_stderr,none": 0.04149886942192117,
      "alias": "ogx_mmlux_pl-electrical_engineering"
    },
    "ogx_mmlux_pl-econometrics": {
      "acc,none": 0.35964912280701755,
      "acc_stderr,none": 0.04514496132873633,
      "alias": "ogx_mmlux_pl-econometrics"
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "acc,none": 0.40425531914893614,
      "acc_stderr,none": 0.032081157507886836,
      "alias": "ogx_mmlux_pl-conceptual_physics"
    },
    "ogx_mmlux_pl-computer_security": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.04878317312145633,
      "alias": "ogx_mmlux_pl-computer_security"
    },
    "ogx_mmlux_pl-college_physics": {
      "acc,none": 0.22549019607843138,
      "acc_stderr,none": 0.04158307533083286,
      "alias": "ogx_mmlux_pl-college_physics"
    },
    "ogx_mmlux_pl-college_medicine": {
      "acc,none": 0.43352601156069365,
      "acc_stderr,none": 0.037786210790920566,
      "alias": "ogx_mmlux_pl-college_medicine"
    },
    "ogx_mmlux_pl-college_mathematics": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_pl-college_mathematics"
    },
    "ogx_mmlux_pl-college_computer_science": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_pl-college_computer_science"
    },
    "ogx_mmlux_pl-college_chemistry": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_pl-college_chemistry"
    },
    "ogx_mmlux_pl-college_biology": {
      "acc,none": 0.4375,
      "acc_stderr,none": 0.04148415739394154,
      "alias": "ogx_mmlux_pl-college_biology"
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "acc,none": 0.47924528301886793,
      "acc_stderr,none": 0.03074634997572347,
      "alias": "ogx_mmlux_pl-clinical_knowledge"
    },
    "ogx_mmlux_pl-business_ethics": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_pl-business_ethics"
    },
    "ogx_mmlux_pl-astronomy": {
      "acc,none": 0.5592105263157895,
      "acc_stderr,none": 0.04040311062490436,
      "alias": "ogx_mmlux_pl-astronomy"
    },
    "ogx_mmlux_pl-anatomy": {
      "acc,none": 0.45185185185185184,
      "acc_stderr,none": 0.04299268905480864,
      "alias": "ogx_mmlux_pl-anatomy"
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_pl-abstract_algebra"
    },
    "ogx_mmlux_nl-world_religions": {
      "acc,none": 0.6666666666666666,
      "acc_stderr,none": 0.03615507630310937,
      "alias": "ogx_mmlux_nl-world_religions"
    },
    "ogx_mmlux_nl-virology": {
      "acc,none": 0.42168674698795183,
      "acc_stderr,none": 0.03844453181770917,
      "alias": "ogx_mmlux_nl-virology"
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "acc,none": 0.76,
      "acc_stderr,none": 0.04292346959909282,
      "alias": "ogx_mmlux_nl-us_foreign_policy"
    },
    "ogx_mmlux_nl-sociology": {
      "acc,none": 0.7512437810945274,
      "acc_stderr,none": 0.030567675938916714,
      "alias": "ogx_mmlux_nl-sociology"
    },
    "ogx_mmlux_nl-security_studies": {
      "acc,none": 0.6285714285714286,
      "acc_stderr,none": 0.030932858792789848,
      "alias": "ogx_mmlux_nl-security_studies"
    },
    "ogx_mmlux_nl-public_relations": {
      "acc,none": 0.6090909090909091,
      "acc_stderr,none": 0.04673752333670239,
      "alias": "ogx_mmlux_nl-public_relations"
    },
    "ogx_mmlux_nl-professional_psychology": {
      "acc,none": 0.46568627450980393,
      "acc_stderr,none": 0.020180144843307296,
      "alias": "ogx_mmlux_nl-professional_psychology"
    },
    "ogx_mmlux_nl-professional_medicine": {
      "acc,none": 0.4485294117647059,
      "acc_stderr,none": 0.030211479609121603,
      "alias": "ogx_mmlux_nl-professional_medicine"
    },
    "ogx_mmlux_nl-professional_law": {
      "acc,none": 0.37614080834419816,
      "acc_stderr,none": 0.012372214430599816,
      "alias": "ogx_mmlux_nl-professional_law"
    },
    "ogx_mmlux_nl-professional_accounting": {
      "acc,none": 0.3475177304964539,
      "acc_stderr,none": 0.02840662780959095,
      "alias": "ogx_mmlux_nl-professional_accounting"
    },
    "ogx_mmlux_nl-prehistory": {
      "acc,none": 0.5401234567901234,
      "acc_stderr,none": 0.027731022753539284,
      "alias": "ogx_mmlux_nl-prehistory"
    },
    "ogx_mmlux_nl-philosophy": {
      "acc,none": 0.5434083601286174,
      "acc_stderr,none": 0.0282908690541976,
      "alias": "ogx_mmlux_nl-philosophy"
    },
    "ogx_mmlux_nl-nutrition": {
      "acc,none": 0.5816993464052288,
      "acc_stderr,none": 0.028245134024387296,
      "alias": "ogx_mmlux_nl-nutrition"
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "acc,none": 0.2737430167597765,
      "acc_stderr,none": 0.014912413096372432,
      "alias": "ogx_mmlux_nl-moral_scenarios"
    },
    "ogx_mmlux_nl-moral_disputes": {
      "acc,none": 0.5144508670520231,
      "acc_stderr,none": 0.026907849856282542,
      "alias": "ogx_mmlux_nl-moral_disputes"
    },
    "ogx_mmlux_nl-miscellaneous": {
      "acc,none": 0.6768837803320562,
      "acc_stderr,none": 0.016723726512343048,
      "alias": "ogx_mmlux_nl-miscellaneous"
    },
    "ogx_mmlux_nl-medical_genetics": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.04878317312145632,
      "alias": "ogx_mmlux_nl-medical_genetics"
    },
    "ogx_mmlux_nl-marketing": {
      "acc,none": 0.7606837606837606,
      "acc_stderr,none": 0.027951826808924333,
      "alias": "ogx_mmlux_nl-marketing"
    },
    "ogx_mmlux_nl-management": {
      "acc,none": 0.6699029126213593,
      "acc_stderr,none": 0.0465614711001235,
      "alias": "ogx_mmlux_nl-management"
    },
    "ogx_mmlux_nl-machine_learning": {
      "acc,none": 0.3482142857142857,
      "acc_stderr,none": 0.045218299028335865,
      "alias": "ogx_mmlux_nl-machine_learning"
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "acc,none": 0.5460122699386503,
      "acc_stderr,none": 0.0391170190467718,
      "alias": "ogx_mmlux_nl-logical_fallacies"
    },
    "ogx_mmlux_nl-jurisprudence": {
      "acc,none": 0.6481481481481481,
      "acc_stderr,none": 0.04616631111801713,
      "alias": "ogx_mmlux_nl-jurisprudence"
    },
    "ogx_mmlux_nl-international_law": {
      "acc,none": 0.6611570247933884,
      "acc_stderr,none": 0.043207678075366705,
      "alias": "ogx_mmlux_nl-international_law"
    },
    "ogx_mmlux_nl-human_sexuality": {
      "acc,none": 0.5954198473282443,
      "acc_stderr,none": 0.043046937953806645,
      "alias": "ogx_mmlux_nl-human_sexuality"
    },
    "ogx_mmlux_nl-human_aging": {
      "acc,none": 0.6143497757847534,
      "acc_stderr,none": 0.03266842214289201,
      "alias": "ogx_mmlux_nl-human_aging"
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "acc,none": 0.7215189873417721,
      "acc_stderr,none": 0.029178682304842534,
      "alias": "ogx_mmlux_nl-high_school_world_history"
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "acc,none": 0.6862745098039216,
      "acc_stderr,none": 0.03256685484460389,
      "alias": "ogx_mmlux_nl-high_school_us_history"
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "acc,none": 0.3472222222222222,
      "acc_stderr,none": 0.032468872436376486,
      "alias": "ogx_mmlux_nl-high_school_statistics"
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "acc,none": 0.6678899082568808,
      "acc_stderr,none": 0.020192682985423337,
      "alias": "ogx_mmlux_nl-high_school_psychology"
    },
    "ogx_mmlux_nl-high_school_physics": {
      "acc,none": 0.37748344370860926,
      "acc_stderr,none": 0.0395802723112157,
      "alias": "ogx_mmlux_nl-high_school_physics"
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "acc,none": 0.4789915966386555,
      "acc_stderr,none": 0.03244980849990029,
      "alias": "ogx_mmlux_nl-high_school_microeconomics"
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "acc,none": 0.3296296296296296,
      "acc_stderr,none": 0.028661201116524575,
      "alias": "ogx_mmlux_nl-high_school_mathematics"
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "acc,none": 0.46923076923076923,
      "acc_stderr,none": 0.025302958890850154,
      "alias": "ogx_mmlux_nl-high_school_macroeconomics"
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "acc,none": 0.7046632124352331,
      "acc_stderr,none": 0.03292296639155139,
      "alias": "ogx_mmlux_nl-high_school_government_and_politics"
    },
    "ogx_mmlux_nl-high_school_geography": {
      "acc,none": 0.6868686868686869,
      "acc_stderr,none": 0.033042050878136525,
      "alias": "ogx_mmlux_nl-high_school_geography"
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "acc,none": 0.6121212121212121,
      "acc_stderr,none": 0.0380491365397101,
      "alias": "ogx_mmlux_nl-high_school_european_history"
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "acc,none": 0.57,
      "acc_stderr,none": 0.04975698519562428,
      "alias": "ogx_mmlux_nl-high_school_computer_science"
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "acc,none": 0.39408866995073893,
      "acc_stderr,none": 0.034381579670365446,
      "alias": "ogx_mmlux_nl-high_school_chemistry"
    },
    "ogx_mmlux_nl-high_school_biology": {
      "acc,none": 0.5709677419354838,
      "acc_stderr,none": 0.028156036538233193,
      "alias": "ogx_mmlux_nl-high_school_biology"
    },
    "ogx_mmlux_nl-global_facts": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_nl-global_facts"
    },
    "ogx_mmlux_nl-formal_logic": {
      "acc,none": 0.30158730158730157,
      "acc_stderr,none": 0.04104947269903394,
      "alias": "ogx_mmlux_nl-formal_logic"
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "acc,none": 0.36507936507936506,
      "acc_stderr,none": 0.024796060602699965,
      "alias": "ogx_mmlux_nl-elementary_mathematics"
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "acc,none": 0.43448275862068964,
      "acc_stderr,none": 0.04130740879555497,
      "alias": "ogx_mmlux_nl-electrical_engineering"
    },
    "ogx_mmlux_nl-econometrics": {
      "acc,none": 0.2894736842105263,
      "acc_stderr,none": 0.04266339443159394,
      "alias": "ogx_mmlux_nl-econometrics"
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "acc,none": 0.4553191489361702,
      "acc_stderr,none": 0.03255525359340354,
      "alias": "ogx_mmlux_nl-conceptual_physics"
    },
    "ogx_mmlux_nl-computer_security": {
      "acc,none": 0.65,
      "acc_stderr,none": 0.047937248544110196,
      "alias": "ogx_mmlux_nl-computer_security"
    },
    "ogx_mmlux_nl-college_physics": {
      "acc,none": 0.20588235294117646,
      "acc_stderr,none": 0.04023382273617746,
      "alias": "ogx_mmlux_nl-college_physics"
    },
    "ogx_mmlux_nl-college_medicine": {
      "acc,none": 0.4797687861271676,
      "acc_stderr,none": 0.03809342081273957,
      "alias": "ogx_mmlux_nl-college_medicine"
    },
    "ogx_mmlux_nl-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_nl-college_mathematics"
    },
    "ogx_mmlux_nl-college_computer_science": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_nl-college_computer_science"
    },
    "ogx_mmlux_nl-college_chemistry": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.04923659639173309,
      "alias": "ogx_mmlux_nl-college_chemistry"
    },
    "ogx_mmlux_nl-college_biology": {
      "acc,none": 0.5138888888888888,
      "acc_stderr,none": 0.041795966175810016,
      "alias": "ogx_mmlux_nl-college_biology"
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "acc,none": 0.5169811320754717,
      "acc_stderr,none": 0.030755120364119905,
      "alias": "ogx_mmlux_nl-clinical_knowledge"
    },
    "ogx_mmlux_nl-business_ethics": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_nl-business_ethics"
    },
    "ogx_mmlux_nl-astronomy": {
      "acc,none": 0.5197368421052632,
      "acc_stderr,none": 0.040657710025626036,
      "alias": "ogx_mmlux_nl-astronomy"
    },
    "ogx_mmlux_nl-anatomy": {
      "acc,none": 0.4222222222222222,
      "acc_stderr,none": 0.04266763404099582,
      "alias": "ogx_mmlux_nl-anatomy"
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_nl-abstract_algebra"
    },
    "ogx_mmlux_lv-world_religions": {
      "acc,none": 0.4152046783625731,
      "acc_stderr,none": 0.03779275945503201,
      "alias": "ogx_mmlux_lv-world_religions"
    },
    "ogx_mmlux_lv-virology": {
      "acc,none": 0.2891566265060241,
      "acc_stderr,none": 0.03529486801511115,
      "alias": "ogx_mmlux_lv-virology"
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_lv-us_foreign_policy"
    },
    "ogx_mmlux_lv-sociology": {
      "acc,none": 0.373134328358209,
      "acc_stderr,none": 0.034198326081760065,
      "alias": "ogx_mmlux_lv-sociology"
    },
    "ogx_mmlux_lv-security_studies": {
      "acc,none": 0.45714285714285713,
      "acc_stderr,none": 0.031891418324213966,
      "alias": "ogx_mmlux_lv-security_studies"
    },
    "ogx_mmlux_lv-public_relations": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.0469237132203465,
      "alias": "ogx_mmlux_lv-public_relations"
    },
    "ogx_mmlux_lv-professional_psychology": {
      "acc,none": 0.31209150326797386,
      "acc_stderr,none": 0.01874501120127766,
      "alias": "ogx_mmlux_lv-professional_psychology"
    },
    "ogx_mmlux_lv-professional_medicine": {
      "acc,none": 0.2757352941176471,
      "acc_stderr,none": 0.027146271936625162,
      "alias": "ogx_mmlux_lv-professional_medicine"
    },
    "ogx_mmlux_lv-professional_law": {
      "acc,none": 0.28683181225554105,
      "acc_stderr,none": 0.011551504781176931,
      "alias": "ogx_mmlux_lv-professional_law"
    },
    "ogx_mmlux_lv-professional_accounting": {
      "acc,none": 0.3120567375886525,
      "acc_stderr,none": 0.02764012054516992,
      "alias": "ogx_mmlux_lv-professional_accounting"
    },
    "ogx_mmlux_lv-prehistory": {
      "acc,none": 0.3148148148148148,
      "acc_stderr,none": 0.02584224870090217,
      "alias": "ogx_mmlux_lv-prehistory"
    },
    "ogx_mmlux_lv-philosophy": {
      "acc,none": 0.34726688102893893,
      "acc_stderr,none": 0.027040745502307336,
      "alias": "ogx_mmlux_lv-philosophy"
    },
    "ogx_mmlux_lv-nutrition": {
      "acc,none": 0.3627450980392157,
      "acc_stderr,none": 0.027530078447110303,
      "alias": "ogx_mmlux_lv-nutrition"
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "acc,none": 0.24022346368715083,
      "acc_stderr,none": 0.0142883438039253,
      "alias": "ogx_mmlux_lv-moral_scenarios"
    },
    "ogx_mmlux_lv-moral_disputes": {
      "acc,none": 0.3815028901734104,
      "acc_stderr,none": 0.0261521986197268,
      "alias": "ogx_mmlux_lv-moral_disputes"
    },
    "ogx_mmlux_lv-miscellaneous": {
      "acc,none": 0.34355044699872284,
      "acc_stderr,none": 0.01698214563265247,
      "alias": "ogx_mmlux_lv-miscellaneous"
    },
    "ogx_mmlux_lv-medical_genetics": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001974,
      "alias": "ogx_mmlux_lv-medical_genetics"
    },
    "ogx_mmlux_lv-marketing": {
      "acc,none": 0.4658119658119658,
      "acc_stderr,none": 0.03267942734081228,
      "alias": "ogx_mmlux_lv-marketing"
    },
    "ogx_mmlux_lv-management": {
      "acc,none": 0.3786407766990291,
      "acc_stderr,none": 0.048026946982589726,
      "alias": "ogx_mmlux_lv-management"
    },
    "ogx_mmlux_lv-machine_learning": {
      "acc,none": 0.2857142857142857,
      "acc_stderr,none": 0.042878587513404544,
      "alias": "ogx_mmlux_lv-machine_learning"
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "acc,none": 0.32515337423312884,
      "acc_stderr,none": 0.03680350371286461,
      "alias": "ogx_mmlux_lv-logical_fallacies"
    },
    "ogx_mmlux_lv-jurisprudence": {
      "acc,none": 0.4444444444444444,
      "acc_stderr,none": 0.04803752235190192,
      "alias": "ogx_mmlux_lv-jurisprudence"
    },
    "ogx_mmlux_lv-international_law": {
      "acc,none": 0.512396694214876,
      "acc_stderr,none": 0.045629515481807666,
      "alias": "ogx_mmlux_lv-international_law"
    },
    "ogx_mmlux_lv-human_sexuality": {
      "acc,none": 0.4198473282442748,
      "acc_stderr,none": 0.04328577215262972,
      "alias": "ogx_mmlux_lv-human_sexuality"
    },
    "ogx_mmlux_lv-human_aging": {
      "acc,none": 0.34977578475336324,
      "acc_stderr,none": 0.03200736719484503,
      "alias": "ogx_mmlux_lv-human_aging"
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "acc,none": 0.43037974683544306,
      "acc_stderr,none": 0.032230171959375976,
      "alias": "ogx_mmlux_lv-high_school_world_history"
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "acc,none": 0.36764705882352944,
      "acc_stderr,none": 0.03384132045674118,
      "alias": "ogx_mmlux_lv-high_school_us_history"
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "acc,none": 0.28703703703703703,
      "acc_stderr,none": 0.030851992993257013,
      "alias": "ogx_mmlux_lv-high_school_statistics"
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "acc,none": 0.3211009174311927,
      "acc_stderr,none": 0.020018149772733747,
      "alias": "ogx_mmlux_lv-high_school_psychology"
    },
    "ogx_mmlux_lv-high_school_physics": {
      "acc,none": 0.33112582781456956,
      "acc_stderr,none": 0.038425817186598696,
      "alias": "ogx_mmlux_lv-high_school_physics"
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "acc,none": 0.37815126050420167,
      "acc_stderr,none": 0.03149930577784906,
      "alias": "ogx_mmlux_lv-high_school_microeconomics"
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "acc,none": 0.2851851851851852,
      "acc_stderr,none": 0.027528599210340492,
      "alias": "ogx_mmlux_lv-high_school_mathematics"
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "acc,none": 0.2846153846153846,
      "acc_stderr,none": 0.022878322799706283,
      "alias": "ogx_mmlux_lv-high_school_macroeconomics"
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "acc,none": 0.32124352331606215,
      "acc_stderr,none": 0.033699508685490674,
      "alias": "ogx_mmlux_lv-high_school_government_and_politics"
    },
    "ogx_mmlux_lv-high_school_geography": {
      "acc,none": 0.35353535353535354,
      "acc_stderr,none": 0.03406086723547153,
      "alias": "ogx_mmlux_lv-high_school_geography"
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "acc,none": 0.3090909090909091,
      "acc_stderr,none": 0.03608541011573967,
      "alias": "ogx_mmlux_lv-high_school_european_history"
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.04999999999999999,
      "alias": "ogx_mmlux_lv-high_school_computer_science"
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "acc,none": 0.24630541871921183,
      "acc_stderr,none": 0.030315099285617722,
      "alias": "ogx_mmlux_lv-high_school_chemistry"
    },
    "ogx_mmlux_lv-high_school_biology": {
      "acc,none": 0.33548387096774196,
      "acc_stderr,none": 0.026860206444724352,
      "alias": "ogx_mmlux_lv-high_school_biology"
    },
    "ogx_mmlux_lv-global_facts": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_lv-global_facts"
    },
    "ogx_mmlux_lv-formal_logic": {
      "acc,none": 0.23809523809523808,
      "acc_stderr,none": 0.03809523809523811,
      "alias": "ogx_mmlux_lv-formal_logic"
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "acc,none": 0.29365079365079366,
      "acc_stderr,none": 0.023456037383982033,
      "alias": "ogx_mmlux_lv-elementary_mathematics"
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "acc,none": 0.38620689655172413,
      "acc_stderr,none": 0.04057324734419035,
      "alias": "ogx_mmlux_lv-electrical_engineering"
    },
    "ogx_mmlux_lv-econometrics": {
      "acc,none": 0.2631578947368421,
      "acc_stderr,none": 0.04142439719489361,
      "alias": "ogx_mmlux_lv-econometrics"
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "acc,none": 0.3148936170212766,
      "acc_stderr,none": 0.03036358219723816,
      "alias": "ogx_mmlux_lv-conceptual_physics"
    },
    "ogx_mmlux_lv-computer_security": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_lv-computer_security"
    },
    "ogx_mmlux_lv-college_physics": {
      "acc,none": 0.21568627450980393,
      "acc_stderr,none": 0.04092563958237653,
      "alias": "ogx_mmlux_lv-college_physics"
    },
    "ogx_mmlux_lv-college_medicine": {
      "acc,none": 0.3179190751445087,
      "acc_stderr,none": 0.035506839891655796,
      "alias": "ogx_mmlux_lv-college_medicine"
    },
    "ogx_mmlux_lv-college_mathematics": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_lv-college_mathematics"
    },
    "ogx_mmlux_lv-college_computer_science": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_lv-college_computer_science"
    },
    "ogx_mmlux_lv-college_chemistry": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_lv-college_chemistry"
    },
    "ogx_mmlux_lv-college_biology": {
      "acc,none": 0.2986111111111111,
      "acc_stderr,none": 0.03827052357950756,
      "alias": "ogx_mmlux_lv-college_biology"
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "acc,none": 0.33584905660377357,
      "acc_stderr,none": 0.029067220146644826,
      "alias": "ogx_mmlux_lv-clinical_knowledge"
    },
    "ogx_mmlux_lv-business_ethics": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.04560480215720684,
      "alias": "ogx_mmlux_lv-business_ethics"
    },
    "ogx_mmlux_lv-astronomy": {
      "acc,none": 0.27631578947368424,
      "acc_stderr,none": 0.03639057569952925,
      "alias": "ogx_mmlux_lv-astronomy"
    },
    "ogx_mmlux_lv-anatomy": {
      "acc,none": 0.3037037037037037,
      "acc_stderr,none": 0.03972552884785137,
      "alias": "ogx_mmlux_lv-anatomy"
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_lv-abstract_algebra"
    },
    "ogx_mmlux_lt-world_religions": {
      "acc,none": 0.5087719298245614,
      "acc_stderr,none": 0.038342347441649924,
      "alias": "ogx_mmlux_lt-world_religions"
    },
    "ogx_mmlux_lt-virology": {
      "acc,none": 0.4036144578313253,
      "acc_stderr,none": 0.038194861407583984,
      "alias": "ogx_mmlux_lt-virology"
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.04923659639173309,
      "alias": "ogx_mmlux_lt-us_foreign_policy"
    },
    "ogx_mmlux_lt-sociology": {
      "acc,none": 0.5621890547263682,
      "acc_stderr,none": 0.035080801121998406,
      "alias": "ogx_mmlux_lt-sociology"
    },
    "ogx_mmlux_lt-security_studies": {
      "acc,none": 0.5346938775510204,
      "acc_stderr,none": 0.03193207024425314,
      "alias": "ogx_mmlux_lt-security_studies"
    },
    "ogx_mmlux_lt-public_relations": {
      "acc,none": 0.4818181818181818,
      "acc_stderr,none": 0.04785964010794916,
      "alias": "ogx_mmlux_lt-public_relations"
    },
    "ogx_mmlux_lt-professional_psychology": {
      "acc,none": 0.3660130718954248,
      "acc_stderr,none": 0.019488025745529672,
      "alias": "ogx_mmlux_lt-professional_psychology"
    },
    "ogx_mmlux_lt-professional_medicine": {
      "acc,none": 0.3272058823529412,
      "acc_stderr,none": 0.02850145286039656,
      "alias": "ogx_mmlux_lt-professional_medicine"
    },
    "ogx_mmlux_lt-professional_law": {
      "acc,none": 0.3350717079530639,
      "acc_stderr,none": 0.012055499471330373,
      "alias": "ogx_mmlux_lt-professional_law"
    },
    "ogx_mmlux_lt-professional_accounting": {
      "acc,none": 0.32978723404255317,
      "acc_stderr,none": 0.028045946942042405,
      "alias": "ogx_mmlux_lt-professional_accounting"
    },
    "ogx_mmlux_lt-prehistory": {
      "acc,none": 0.36419753086419754,
      "acc_stderr,none": 0.026774929899722324,
      "alias": "ogx_mmlux_lt-prehistory"
    },
    "ogx_mmlux_lt-philosophy": {
      "acc,none": 0.43086816720257237,
      "acc_stderr,none": 0.028125340983972714,
      "alias": "ogx_mmlux_lt-philosophy"
    },
    "ogx_mmlux_lt-nutrition": {
      "acc,none": 0.4542483660130719,
      "acc_stderr,none": 0.028509807802626567,
      "alias": "ogx_mmlux_lt-nutrition"
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "acc,none": 0.24134078212290502,
      "acc_stderr,none": 0.014310999547961464,
      "alias": "ogx_mmlux_lt-moral_scenarios"
    },
    "ogx_mmlux_lt-moral_disputes": {
      "acc,none": 0.43641618497109824,
      "acc_stderr,none": 0.026700545424943684,
      "alias": "ogx_mmlux_lt-moral_disputes"
    },
    "ogx_mmlux_lt-miscellaneous": {
      "acc,none": 0.41762452107279696,
      "acc_stderr,none": 0.017635637326951517,
      "alias": "ogx_mmlux_lt-miscellaneous"
    },
    "ogx_mmlux_lt-medical_genetics": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_lt-medical_genetics"
    },
    "ogx_mmlux_lt-marketing": {
      "acc,none": 0.5854700854700855,
      "acc_stderr,none": 0.0322739656762378,
      "alias": "ogx_mmlux_lt-marketing"
    },
    "ogx_mmlux_lt-management": {
      "acc,none": 0.5825242718446602,
      "acc_stderr,none": 0.04882840548212238,
      "alias": "ogx_mmlux_lt-management"
    },
    "ogx_mmlux_lt-machine_learning": {
      "acc,none": 0.32142857142857145,
      "acc_stderr,none": 0.044328040552915206,
      "alias": "ogx_mmlux_lt-machine_learning"
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "acc,none": 0.3987730061349693,
      "acc_stderr,none": 0.03847021420456024,
      "alias": "ogx_mmlux_lt-logical_fallacies"
    },
    "ogx_mmlux_lt-jurisprudence": {
      "acc,none": 0.5648148148148148,
      "acc_stderr,none": 0.04792898170907062,
      "alias": "ogx_mmlux_lt-jurisprudence"
    },
    "ogx_mmlux_lt-international_law": {
      "acc,none": 0.5371900826446281,
      "acc_stderr,none": 0.045517111961042175,
      "alias": "ogx_mmlux_lt-international_law"
    },
    "ogx_mmlux_lt-human_sexuality": {
      "acc,none": 0.4351145038167939,
      "acc_stderr,none": 0.043482080516448585,
      "alias": "ogx_mmlux_lt-human_sexuality"
    },
    "ogx_mmlux_lt-human_aging": {
      "acc,none": 0.42152466367713004,
      "acc_stderr,none": 0.03314190222110658,
      "alias": "ogx_mmlux_lt-human_aging"
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "acc,none": 0.5021097046413502,
      "acc_stderr,none": 0.032546938018020076,
      "alias": "ogx_mmlux_lt-high_school_world_history"
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "acc,none": 0.4362745098039216,
      "acc_stderr,none": 0.03480693138457039,
      "alias": "ogx_mmlux_lt-high_school_us_history"
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "acc,none": 0.3101851851851852,
      "acc_stderr,none": 0.03154696285656629,
      "alias": "ogx_mmlux_lt-high_school_statistics"
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "acc,none": 0.3834862385321101,
      "acc_stderr,none": 0.02084715664191599,
      "alias": "ogx_mmlux_lt-high_school_psychology"
    },
    "ogx_mmlux_lt-high_school_physics": {
      "acc,none": 0.32450331125827814,
      "acc_stderr,none": 0.038227469376587525,
      "alias": "ogx_mmlux_lt-high_school_physics"
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "acc,none": 0.36554621848739494,
      "acc_stderr,none": 0.0312821770636846,
      "alias": "ogx_mmlux_lt-high_school_microeconomics"
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "acc,none": 0.3037037037037037,
      "acc_stderr,none": 0.028037929969114986,
      "alias": "ogx_mmlux_lt-high_school_mathematics"
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "acc,none": 0.382051282051282,
      "acc_stderr,none": 0.024635549163908234,
      "alias": "ogx_mmlux_lt-high_school_macroeconomics"
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "acc,none": 0.40932642487046633,
      "acc_stderr,none": 0.03548608168860806,
      "alias": "ogx_mmlux_lt-high_school_government_and_politics"
    },
    "ogx_mmlux_lt-high_school_geography": {
      "acc,none": 0.47474747474747475,
      "acc_stderr,none": 0.03557806245087314,
      "alias": "ogx_mmlux_lt-high_school_geography"
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.03825460278380025,
      "alias": "ogx_mmlux_lt-high_school_european_history"
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_lt-high_school_computer_science"
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "acc,none": 0.2857142857142857,
      "acc_stderr,none": 0.03178529710642748,
      "alias": "ogx_mmlux_lt-high_school_chemistry"
    },
    "ogx_mmlux_lt-high_school_biology": {
      "acc,none": 0.3870967741935484,
      "acc_stderr,none": 0.02770935967503249,
      "alias": "ogx_mmlux_lt-high_school_biology"
    },
    "ogx_mmlux_lt-global_facts": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.04560480215720683,
      "alias": "ogx_mmlux_lt-global_facts"
    },
    "ogx_mmlux_lt-formal_logic": {
      "acc,none": 0.2777777777777778,
      "acc_stderr,none": 0.040061680838488774,
      "alias": "ogx_mmlux_lt-formal_logic"
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "acc,none": 0.30158730158730157,
      "acc_stderr,none": 0.0236369759961018,
      "alias": "ogx_mmlux_lt-elementary_mathematics"
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "acc,none": 0.43448275862068964,
      "acc_stderr,none": 0.04130740879555497,
      "alias": "ogx_mmlux_lt-electrical_engineering"
    },
    "ogx_mmlux_lt-econometrics": {
      "acc,none": 0.2982456140350877,
      "acc_stderr,none": 0.043036840335373173,
      "alias": "ogx_mmlux_lt-econometrics"
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "acc,none": 0.3148936170212766,
      "acc_stderr,none": 0.03036358219723817,
      "alias": "ogx_mmlux_lt-conceptual_physics"
    },
    "ogx_mmlux_lt-computer_security": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_lt-computer_security"
    },
    "ogx_mmlux_lt-college_physics": {
      "acc,none": 0.19607843137254902,
      "acc_stderr,none": 0.03950581861179961,
      "alias": "ogx_mmlux_lt-college_physics"
    },
    "ogx_mmlux_lt-college_medicine": {
      "acc,none": 0.31213872832369943,
      "acc_stderr,none": 0.03533133389323657,
      "alias": "ogx_mmlux_lt-college_medicine"
    },
    "ogx_mmlux_lt-college_mathematics": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542128,
      "alias": "ogx_mmlux_lt-college_mathematics"
    },
    "ogx_mmlux_lt-college_computer_science": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_lt-college_computer_science"
    },
    "ogx_mmlux_lt-college_chemistry": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_lt-college_chemistry"
    },
    "ogx_mmlux_lt-college_biology": {
      "acc,none": 0.2986111111111111,
      "acc_stderr,none": 0.03827052357950756,
      "alias": "ogx_mmlux_lt-college_biology"
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "acc,none": 0.3660377358490566,
      "acc_stderr,none": 0.029647813539365252,
      "alias": "ogx_mmlux_lt-clinical_knowledge"
    },
    "ogx_mmlux_lt-business_ethics": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_lt-business_ethics"
    },
    "ogx_mmlux_lt-astronomy": {
      "acc,none": 0.3355263157894737,
      "acc_stderr,none": 0.038424985593952694,
      "alias": "ogx_mmlux_lt-astronomy"
    },
    "ogx_mmlux_lt-anatomy": {
      "acc,none": 0.37037037037037035,
      "acc_stderr,none": 0.04171654161354543,
      "alias": "ogx_mmlux_lt-anatomy"
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.047258156262526045,
      "alias": "ogx_mmlux_lt-abstract_algebra"
    },
    "ogx_mmlux_it-world_religions": {
      "acc,none": 0.7076023391812866,
      "acc_stderr,none": 0.03488647713457922,
      "alias": "ogx_mmlux_it-world_religions"
    },
    "ogx_mmlux_it-virology": {
      "acc,none": 0.4397590361445783,
      "acc_stderr,none": 0.03864139923699121,
      "alias": "ogx_mmlux_it-virology"
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.0446196043338474,
      "alias": "ogx_mmlux_it-us_foreign_policy"
    },
    "ogx_mmlux_it-sociology": {
      "acc,none": 0.736318407960199,
      "acc_stderr,none": 0.031157150869355575,
      "alias": "ogx_mmlux_it-sociology"
    },
    "ogx_mmlux_it-security_studies": {
      "acc,none": 0.6448979591836734,
      "acc_stderr,none": 0.030635655150387634,
      "alias": "ogx_mmlux_it-security_studies"
    },
    "ogx_mmlux_it-public_relations": {
      "acc,none": 0.5454545454545454,
      "acc_stderr,none": 0.04769300568972744,
      "alias": "ogx_mmlux_it-public_relations"
    },
    "ogx_mmlux_it-professional_psychology": {
      "acc,none": 0.49019607843137253,
      "acc_stderr,none": 0.0202239460050743,
      "alias": "ogx_mmlux_it-professional_psychology"
    },
    "ogx_mmlux_it-professional_medicine": {
      "acc,none": 0.4522058823529412,
      "acc_stderr,none": 0.03023375855159646,
      "alias": "ogx_mmlux_it-professional_medicine"
    },
    "ogx_mmlux_it-professional_law": {
      "acc,none": 0.3820078226857888,
      "acc_stderr,none": 0.012409564470235567,
      "alias": "ogx_mmlux_it-professional_law"
    },
    "ogx_mmlux_it-professional_accounting": {
      "acc,none": 0.3546099290780142,
      "acc_stderr,none": 0.028538650028878627,
      "alias": "ogx_mmlux_it-professional_accounting"
    },
    "ogx_mmlux_it-prehistory": {
      "acc,none": 0.5740740740740741,
      "acc_stderr,none": 0.02751374728437942,
      "alias": "ogx_mmlux_it-prehistory"
    },
    "ogx_mmlux_it-philosophy": {
      "acc,none": 0.5980707395498392,
      "acc_stderr,none": 0.02784647600593048,
      "alias": "ogx_mmlux_it-philosophy"
    },
    "ogx_mmlux_it-nutrition": {
      "acc,none": 0.5784313725490197,
      "acc_stderr,none": 0.028275490156791455,
      "alias": "ogx_mmlux_it-nutrition"
    },
    "ogx_mmlux_it-moral_scenarios": {
      "acc,none": 0.27039106145251396,
      "acc_stderr,none": 0.014854993938010092,
      "alias": "ogx_mmlux_it-moral_scenarios"
    },
    "ogx_mmlux_it-moral_disputes": {
      "acc,none": 0.5433526011560693,
      "acc_stderr,none": 0.026817718130348913,
      "alias": "ogx_mmlux_it-moral_disputes"
    },
    "ogx_mmlux_it-miscellaneous": {
      "acc,none": 0.6564495530012772,
      "acc_stderr,none": 0.016982145632652473,
      "alias": "ogx_mmlux_it-miscellaneous"
    },
    "ogx_mmlux_it-medical_genetics": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_it-medical_genetics"
    },
    "ogx_mmlux_it-marketing": {
      "acc,none": 0.7948717948717948,
      "acc_stderr,none": 0.026453508054040332,
      "alias": "ogx_mmlux_it-marketing"
    },
    "ogx_mmlux_it-management": {
      "acc,none": 0.6990291262135923,
      "acc_stderr,none": 0.04541609446503949,
      "alias": "ogx_mmlux_it-management"
    },
    "ogx_mmlux_it-machine_learning": {
      "acc,none": 0.36607142857142855,
      "acc_stderr,none": 0.0457237235873743,
      "alias": "ogx_mmlux_it-machine_learning"
    },
    "ogx_mmlux_it-logical_fallacies": {
      "acc,none": 0.5030674846625767,
      "acc_stderr,none": 0.03928297078179663,
      "alias": "ogx_mmlux_it-logical_fallacies"
    },
    "ogx_mmlux_it-jurisprudence": {
      "acc,none": 0.6018518518518519,
      "acc_stderr,none": 0.04732332615978814,
      "alias": "ogx_mmlux_it-jurisprudence"
    },
    "ogx_mmlux_it-international_law": {
      "acc,none": 0.6942148760330579,
      "acc_stderr,none": 0.04205953933884122,
      "alias": "ogx_mmlux_it-international_law"
    },
    "ogx_mmlux_it-human_sexuality": {
      "acc,none": 0.5725190839694656,
      "acc_stderr,none": 0.043389203057924,
      "alias": "ogx_mmlux_it-human_sexuality"
    },
    "ogx_mmlux_it-human_aging": {
      "acc,none": 0.6547085201793722,
      "acc_stderr,none": 0.03191100192835794,
      "alias": "ogx_mmlux_it-human_aging"
    },
    "ogx_mmlux_it-high_school_world_history": {
      "acc,none": 0.7215189873417721,
      "acc_stderr,none": 0.029178682304842534,
      "alias": "ogx_mmlux_it-high_school_world_history"
    },
    "ogx_mmlux_it-high_school_us_history": {
      "acc,none": 0.6764705882352942,
      "acc_stderr,none": 0.0328347205610856,
      "alias": "ogx_mmlux_it-high_school_us_history"
    },
    "ogx_mmlux_it-high_school_statistics": {
      "acc,none": 0.35648148148148145,
      "acc_stderr,none": 0.03266478331527272,
      "alias": "ogx_mmlux_it-high_school_statistics"
    },
    "ogx_mmlux_it-high_school_psychology": {
      "acc,none": 0.6660550458715596,
      "acc_stderr,none": 0.02022055419673641,
      "alias": "ogx_mmlux_it-high_school_psychology"
    },
    "ogx_mmlux_it-high_school_physics": {
      "acc,none": 0.3576158940397351,
      "acc_stderr,none": 0.03913453431177258,
      "alias": "ogx_mmlux_it-high_school_physics"
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "acc,none": 0.46218487394957986,
      "acc_stderr,none": 0.032385469487589795,
      "alias": "ogx_mmlux_it-high_school_microeconomics"
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "acc,none": 0.337037037037037,
      "acc_stderr,none": 0.02882088466625326,
      "alias": "ogx_mmlux_it-high_school_mathematics"
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "acc,none": 0.4512820512820513,
      "acc_stderr,none": 0.025230381238934837,
      "alias": "ogx_mmlux_it-high_school_macroeconomics"
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "acc,none": 0.6787564766839378,
      "acc_stderr,none": 0.033699508685490674,
      "alias": "ogx_mmlux_it-high_school_government_and_politics"
    },
    "ogx_mmlux_it-high_school_geography": {
      "acc,none": 0.6515151515151515,
      "acc_stderr,none": 0.033948539651564025,
      "alias": "ogx_mmlux_it-high_school_geography"
    },
    "ogx_mmlux_it-high_school_european_history": {
      "acc,none": 0.6484848484848484,
      "acc_stderr,none": 0.037282069986826503,
      "alias": "ogx_mmlux_it-high_school_european_history"
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "acc,none": 0.61,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_it-high_school_computer_science"
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "acc,none": 0.37438423645320196,
      "acc_stderr,none": 0.03405155380561952,
      "alias": "ogx_mmlux_it-high_school_chemistry"
    },
    "ogx_mmlux_it-high_school_biology": {
      "acc,none": 0.5387096774193548,
      "acc_stderr,none": 0.028358634859836935,
      "alias": "ogx_mmlux_it-high_school_biology"
    },
    "ogx_mmlux_it-global_facts": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.04923659639173309,
      "alias": "ogx_mmlux_it-global_facts"
    },
    "ogx_mmlux_it-formal_logic": {
      "acc,none": 0.29365079365079366,
      "acc_stderr,none": 0.04073524322147127,
      "alias": "ogx_mmlux_it-formal_logic"
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.024278568024307706,
      "alias": "ogx_mmlux_it-elementary_mathematics"
    },
    "ogx_mmlux_it-electrical_engineering": {
      "acc,none": 0.503448275862069,
      "acc_stderr,none": 0.04166567577101579,
      "alias": "ogx_mmlux_it-electrical_engineering"
    },
    "ogx_mmlux_it-econometrics": {
      "acc,none": 0.34210526315789475,
      "acc_stderr,none": 0.04462917535336937,
      "alias": "ogx_mmlux_it-econometrics"
    },
    "ogx_mmlux_it-conceptual_physics": {
      "acc,none": 0.4297872340425532,
      "acc_stderr,none": 0.03236214467715564,
      "alias": "ogx_mmlux_it-conceptual_physics"
    },
    "ogx_mmlux_it-computer_security": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_it-computer_security"
    },
    "ogx_mmlux_it-college_physics": {
      "acc,none": 0.19607843137254902,
      "acc_stderr,none": 0.03950581861179961,
      "alias": "ogx_mmlux_it-college_physics"
    },
    "ogx_mmlux_it-college_medicine": {
      "acc,none": 0.4508670520231214,
      "acc_stderr,none": 0.0379401267469703,
      "alias": "ogx_mmlux_it-college_medicine"
    },
    "ogx_mmlux_it-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_it-college_mathematics"
    },
    "ogx_mmlux_it-college_computer_science": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_it-college_computer_science"
    },
    "ogx_mmlux_it-college_chemistry": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_it-college_chemistry"
    },
    "ogx_mmlux_it-college_biology": {
      "acc,none": 0.5277777777777778,
      "acc_stderr,none": 0.04174752578923183,
      "alias": "ogx_mmlux_it-college_biology"
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "acc,none": 0.5056603773584906,
      "acc_stderr,none": 0.03077090076385131,
      "alias": "ogx_mmlux_it-clinical_knowledge"
    },
    "ogx_mmlux_it-business_ethics": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_it-business_ethics"
    },
    "ogx_mmlux_it-astronomy": {
      "acc,none": 0.5723684210526315,
      "acc_stderr,none": 0.04026097083296564,
      "alias": "ogx_mmlux_it-astronomy"
    },
    "ogx_mmlux_it-anatomy": {
      "acc,none": 0.43703703703703706,
      "acc_stderr,none": 0.04284958639753399,
      "alias": "ogx_mmlux_it-anatomy"
    },
    "ogx_mmlux_it-abstract_algebra": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_it-abstract_algebra"
    },
    "ogx_mmlux_hu-world_religions": {
      "acc,none": 0.49707602339181284,
      "acc_stderr,none": 0.03834759370936839,
      "alias": "ogx_mmlux_hu-world_religions"
    },
    "ogx_mmlux_hu-virology": {
      "acc,none": 0.3614457831325301,
      "acc_stderr,none": 0.0374005938202932,
      "alias": "ogx_mmlux_hu-virology"
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "acc,none": 0.57,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_hu-us_foreign_policy"
    },
    "ogx_mmlux_hu-sociology": {
      "acc,none": 0.527363184079602,
      "acc_stderr,none": 0.03530235517334682,
      "alias": "ogx_mmlux_hu-sociology"
    },
    "ogx_mmlux_hu-security_studies": {
      "acc,none": 0.49387755102040815,
      "acc_stderr,none": 0.03200682020163908,
      "alias": "ogx_mmlux_hu-security_studies"
    },
    "ogx_mmlux_hu-public_relations": {
      "acc,none": 0.4090909090909091,
      "acc_stderr,none": 0.047093069786618966,
      "alias": "ogx_mmlux_hu-public_relations"
    },
    "ogx_mmlux_hu-professional_psychology": {
      "acc,none": 0.33986928104575165,
      "acc_stderr,none": 0.019162418588623546,
      "alias": "ogx_mmlux_hu-professional_psychology"
    },
    "ogx_mmlux_hu-professional_medicine": {
      "acc,none": 0.3088235294117647,
      "acc_stderr,none": 0.028064998167040094,
      "alias": "ogx_mmlux_hu-professional_medicine"
    },
    "ogx_mmlux_hu-professional_law": {
      "acc,none": 0.28226857887874834,
      "acc_stderr,none": 0.01149585217624195,
      "alias": "ogx_mmlux_hu-professional_law"
    },
    "ogx_mmlux_hu-professional_accounting": {
      "acc,none": 0.2765957446808511,
      "acc_stderr,none": 0.026684564340460994,
      "alias": "ogx_mmlux_hu-professional_accounting"
    },
    "ogx_mmlux_hu-prehistory": {
      "acc,none": 0.36419753086419754,
      "acc_stderr,none": 0.02677492989972233,
      "alias": "ogx_mmlux_hu-prehistory"
    },
    "ogx_mmlux_hu-philosophy": {
      "acc,none": 0.3890675241157556,
      "acc_stderr,none": 0.027690337536485372,
      "alias": "ogx_mmlux_hu-philosophy"
    },
    "ogx_mmlux_hu-nutrition": {
      "acc,none": 0.43790849673202614,
      "acc_stderr,none": 0.02840830202033269,
      "alias": "ogx_mmlux_hu-nutrition"
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "acc,none": 0.2424581005586592,
      "acc_stderr,none": 0.014333522059217889,
      "alias": "ogx_mmlux_hu-moral_scenarios"
    },
    "ogx_mmlux_hu-moral_disputes": {
      "acc,none": 0.3554913294797688,
      "acc_stderr,none": 0.025770292082977243,
      "alias": "ogx_mmlux_hu-moral_disputes"
    },
    "ogx_mmlux_hu-miscellaneous": {
      "acc,none": 0.42017879948914433,
      "acc_stderr,none": 0.01765065136307801,
      "alias": "ogx_mmlux_hu-miscellaneous"
    },
    "ogx_mmlux_hu-medical_genetics": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.04878317312145632,
      "alias": "ogx_mmlux_hu-medical_genetics"
    },
    "ogx_mmlux_hu-marketing": {
      "acc,none": 0.5897435897435898,
      "acc_stderr,none": 0.032224140452411065,
      "alias": "ogx_mmlux_hu-marketing"
    },
    "ogx_mmlux_hu-management": {
      "acc,none": 0.47572815533980584,
      "acc_stderr,none": 0.049449010929737795,
      "alias": "ogx_mmlux_hu-management"
    },
    "ogx_mmlux_hu-machine_learning": {
      "acc,none": 0.375,
      "acc_stderr,none": 0.04595091388086298,
      "alias": "ogx_mmlux_hu-machine_learning"
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "acc,none": 0.37423312883435583,
      "acc_stderr,none": 0.03802068102899615,
      "alias": "ogx_mmlux_hu-logical_fallacies"
    },
    "ogx_mmlux_hu-jurisprudence": {
      "acc,none": 0.4537037037037037,
      "acc_stderr,none": 0.048129173245368216,
      "alias": "ogx_mmlux_hu-jurisprudence"
    },
    "ogx_mmlux_hu-international_law": {
      "acc,none": 0.512396694214876,
      "acc_stderr,none": 0.045629515481807666,
      "alias": "ogx_mmlux_hu-international_law"
    },
    "ogx_mmlux_hu-human_sexuality": {
      "acc,none": 0.42748091603053434,
      "acc_stderr,none": 0.04338920305792399,
      "alias": "ogx_mmlux_hu-human_sexuality"
    },
    "ogx_mmlux_hu-human_aging": {
      "acc,none": 0.452914798206278,
      "acc_stderr,none": 0.033408675019233246,
      "alias": "ogx_mmlux_hu-human_aging"
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "acc,none": 0.4472573839662447,
      "acc_stderr,none": 0.03236564251614193,
      "alias": "ogx_mmlux_hu-high_school_world_history"
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "acc,none": 0.45588235294117646,
      "acc_stderr,none": 0.03495624522015474,
      "alias": "ogx_mmlux_hu-high_school_us_history"
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "acc,none": 0.30092592592592593,
      "acc_stderr,none": 0.03128039084329882,
      "alias": "ogx_mmlux_hu-high_school_statistics"
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "acc,none": 0.3651376146788991,
      "acc_stderr,none": 0.020642801454384005,
      "alias": "ogx_mmlux_hu-high_school_psychology"
    },
    "ogx_mmlux_hu-high_school_physics": {
      "acc,none": 0.3443708609271523,
      "acc_stderr,none": 0.038796870240733264,
      "alias": "ogx_mmlux_hu-high_school_physics"
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "acc,none": 0.3403361344537815,
      "acc_stderr,none": 0.030778057422931673,
      "alias": "ogx_mmlux_hu-high_school_microeconomics"
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "acc,none": 0.26296296296296295,
      "acc_stderr,none": 0.026842057873833706,
      "alias": "ogx_mmlux_hu-high_school_mathematics"
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.02323458108842849,
      "alias": "ogx_mmlux_hu-high_school_macroeconomics"
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "acc,none": 0.46632124352331605,
      "acc_stderr,none": 0.036002440698671784,
      "alias": "ogx_mmlux_hu-high_school_government_and_politics"
    },
    "ogx_mmlux_hu-high_school_geography": {
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.03358618145732522,
      "alias": "ogx_mmlux_hu-high_school_geography"
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "acc,none": 0.38181818181818183,
      "acc_stderr,none": 0.037937131711656344,
      "alias": "ogx_mmlux_hu-high_school_european_history"
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "acc,none": 0.55,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_hu-high_school_computer_science"
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "acc,none": 0.270935960591133,
      "acc_stderr,none": 0.031270907132977,
      "alias": "ogx_mmlux_hu-high_school_chemistry"
    },
    "ogx_mmlux_hu-high_school_biology": {
      "acc,none": 0.36774193548387096,
      "acc_stderr,none": 0.027430866579973467,
      "alias": "ogx_mmlux_hu-high_school_biology"
    },
    "ogx_mmlux_hu-global_facts": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_hu-global_facts"
    },
    "ogx_mmlux_hu-formal_logic": {
      "acc,none": 0.23809523809523808,
      "acc_stderr,none": 0.03809523809523811,
      "alias": "ogx_mmlux_hu-formal_logic"
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "acc,none": 0.2724867724867725,
      "acc_stderr,none": 0.02293097307163334,
      "alias": "ogx_mmlux_hu-elementary_mathematics"
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "acc,none": 0.45517241379310347,
      "acc_stderr,none": 0.04149886942192117,
      "alias": "ogx_mmlux_hu-electrical_engineering"
    },
    "ogx_mmlux_hu-econometrics": {
      "acc,none": 0.2982456140350877,
      "acc_stderr,none": 0.043036840335373173,
      "alias": "ogx_mmlux_hu-econometrics"
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "acc,none": 0.2765957446808511,
      "acc_stderr,none": 0.029241883869628806,
      "alias": "ogx_mmlux_hu-conceptual_physics"
    },
    "ogx_mmlux_hu-computer_security": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_hu-computer_security"
    },
    "ogx_mmlux_hu-college_physics": {
      "acc,none": 0.23529411764705882,
      "acc_stderr,none": 0.04220773659171453,
      "alias": "ogx_mmlux_hu-college_physics"
    },
    "ogx_mmlux_hu-college_medicine": {
      "acc,none": 0.28901734104046245,
      "acc_stderr,none": 0.03456425745086999,
      "alias": "ogx_mmlux_hu-college_medicine"
    },
    "ogx_mmlux_hu-college_mathematics": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542127,
      "alias": "ogx_mmlux_hu-college_mathematics"
    },
    "ogx_mmlux_hu-college_computer_science": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_hu-college_computer_science"
    },
    "ogx_mmlux_hu-college_chemistry": {
      "acc,none": 0.23,
      "acc_stderr,none": 0.04229525846816506,
      "alias": "ogx_mmlux_hu-college_chemistry"
    },
    "ogx_mmlux_hu-college_biology": {
      "acc,none": 0.3263888888888889,
      "acc_stderr,none": 0.03921067198982266,
      "alias": "ogx_mmlux_hu-college_biology"
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "acc,none": 0.37735849056603776,
      "acc_stderr,none": 0.02983280811479601,
      "alias": "ogx_mmlux_hu-clinical_knowledge"
    },
    "ogx_mmlux_hu-business_ethics": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_hu-business_ethics"
    },
    "ogx_mmlux_hu-astronomy": {
      "acc,none": 0.3157894736842105,
      "acc_stderr,none": 0.037827289808654685,
      "alias": "ogx_mmlux_hu-astronomy"
    },
    "ogx_mmlux_hu-anatomy": {
      "acc,none": 0.3111111111111111,
      "acc_stderr,none": 0.03999262876617721,
      "alias": "ogx_mmlux_hu-anatomy"
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.04688261722621505,
      "alias": "ogx_mmlux_hu-abstract_algebra"
    },
    "ogx_mmlux_fr-world_religions": {
      "acc,none": 0.7134502923976608,
      "acc_stderr,none": 0.03467826685703826,
      "alias": "ogx_mmlux_fr-world_religions"
    },
    "ogx_mmlux_fr-virology": {
      "acc,none": 0.4397590361445783,
      "acc_stderr,none": 0.03864139923699121,
      "alias": "ogx_mmlux_fr-virology"
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.044084400227680794,
      "alias": "ogx_mmlux_fr-us_foreign_policy"
    },
    "ogx_mmlux_fr-sociology": {
      "acc,none": 0.7263681592039801,
      "acc_stderr,none": 0.03152439186555404,
      "alias": "ogx_mmlux_fr-sociology"
    },
    "ogx_mmlux_fr-security_studies": {
      "acc,none": 0.673469387755102,
      "acc_stderr,none": 0.030021056238440307,
      "alias": "ogx_mmlux_fr-security_studies"
    },
    "ogx_mmlux_fr-public_relations": {
      "acc,none": 0.5727272727272728,
      "acc_stderr,none": 0.04738198703545483,
      "alias": "ogx_mmlux_fr-public_relations"
    },
    "ogx_mmlux_fr-professional_psychology": {
      "acc,none": 0.48366013071895425,
      "acc_stderr,none": 0.020217030653186453,
      "alias": "ogx_mmlux_fr-professional_psychology"
    },
    "ogx_mmlux_fr-professional_medicine": {
      "acc,none": 0.4485294117647059,
      "acc_stderr,none": 0.030211479609121596,
      "alias": "ogx_mmlux_fr-professional_medicine"
    },
    "ogx_mmlux_fr-professional_law": {
      "acc,none": 0.38396349413298564,
      "acc_stderr,none": 0.012421587833134231,
      "alias": "ogx_mmlux_fr-professional_law"
    },
    "ogx_mmlux_fr-professional_accounting": {
      "acc,none": 0.3617021276595745,
      "acc_stderr,none": 0.02866382014719948,
      "alias": "ogx_mmlux_fr-professional_accounting"
    },
    "ogx_mmlux_fr-prehistory": {
      "acc,none": 0.6080246913580247,
      "acc_stderr,none": 0.027163686038271143,
      "alias": "ogx_mmlux_fr-prehistory"
    },
    "ogx_mmlux_fr-philosophy": {
      "acc,none": 0.5852090032154341,
      "acc_stderr,none": 0.02798268045975956,
      "alias": "ogx_mmlux_fr-philosophy"
    },
    "ogx_mmlux_fr-nutrition": {
      "acc,none": 0.565359477124183,
      "acc_stderr,none": 0.028384256704883034,
      "alias": "ogx_mmlux_fr-nutrition"
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "acc,none": 0.2223463687150838,
      "acc_stderr,none": 0.013907189208156881,
      "alias": "ogx_mmlux_fr-moral_scenarios"
    },
    "ogx_mmlux_fr-moral_disputes": {
      "acc,none": 0.5520231213872833,
      "acc_stderr,none": 0.02677299065336183,
      "alias": "ogx_mmlux_fr-moral_disputes"
    },
    "ogx_mmlux_fr-miscellaneous": {
      "acc,none": 0.6768837803320562,
      "acc_stderr,none": 0.016723726512343044,
      "alias": "ogx_mmlux_fr-miscellaneous"
    },
    "ogx_mmlux_fr-medical_genetics": {
      "acc,none": 0.54,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_fr-medical_genetics"
    },
    "ogx_mmlux_fr-marketing": {
      "acc,none": 0.8034188034188035,
      "acc_stderr,none": 0.02603538609895129,
      "alias": "ogx_mmlux_fr-marketing"
    },
    "ogx_mmlux_fr-management": {
      "acc,none": 0.6893203883495146,
      "acc_stderr,none": 0.04582124160161549,
      "alias": "ogx_mmlux_fr-management"
    },
    "ogx_mmlux_fr-machine_learning": {
      "acc,none": 0.39285714285714285,
      "acc_stderr,none": 0.04635550135609976,
      "alias": "ogx_mmlux_fr-machine_learning"
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "acc,none": 0.5950920245398773,
      "acc_stderr,none": 0.038566721635489125,
      "alias": "ogx_mmlux_fr-logical_fallacies"
    },
    "ogx_mmlux_fr-jurisprudence": {
      "acc,none": 0.5833333333333334,
      "acc_stderr,none": 0.04766075165356461,
      "alias": "ogx_mmlux_fr-jurisprudence"
    },
    "ogx_mmlux_fr-international_law": {
      "acc,none": 0.7272727272727273,
      "acc_stderr,none": 0.04065578140908705,
      "alias": "ogx_mmlux_fr-international_law"
    },
    "ogx_mmlux_fr-human_sexuality": {
      "acc,none": 0.6030534351145038,
      "acc_stderr,none": 0.04291135671009224,
      "alias": "ogx_mmlux_fr-human_sexuality"
    },
    "ogx_mmlux_fr-human_aging": {
      "acc,none": 0.6547085201793722,
      "acc_stderr,none": 0.03191100192835794,
      "alias": "ogx_mmlux_fr-human_aging"
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "acc,none": 0.7426160337552743,
      "acc_stderr,none": 0.028458820991460302,
      "alias": "ogx_mmlux_fr-high_school_world_history"
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "acc,none": 0.7058823529411765,
      "acc_stderr,none": 0.03198001660115071,
      "alias": "ogx_mmlux_fr-high_school_us_history"
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "acc,none": 0.3611111111111111,
      "acc_stderr,none": 0.03275773486100999,
      "alias": "ogx_mmlux_fr-high_school_statistics"
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "acc,none": 0.6770642201834862,
      "acc_stderr,none": 0.020048115923415332,
      "alias": "ogx_mmlux_fr-high_school_psychology"
    },
    "ogx_mmlux_fr-high_school_physics": {
      "acc,none": 0.37748344370860926,
      "acc_stderr,none": 0.03958027231121569,
      "alias": "ogx_mmlux_fr-high_school_physics"
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "acc,none": 0.4495798319327731,
      "acc_stderr,none": 0.03231293497137707,
      "alias": "ogx_mmlux_fr-high_school_microeconomics"
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "acc,none": 0.31851851851851853,
      "acc_stderr,none": 0.02840653309060846,
      "alias": "ogx_mmlux_fr-high_school_mathematics"
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "acc,none": 0.43846153846153846,
      "acc_stderr,none": 0.025158266016868568,
      "alias": "ogx_mmlux_fr-high_school_macroeconomics"
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "acc,none": 0.7150259067357513,
      "acc_stderr,none": 0.0325771407770966,
      "alias": "ogx_mmlux_fr-high_school_government_and_politics"
    },
    "ogx_mmlux_fr-high_school_geography": {
      "acc,none": 0.6666666666666666,
      "acc_stderr,none": 0.03358618145732522,
      "alias": "ogx_mmlux_fr-high_school_geography"
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "acc,none": 0.6727272727272727,
      "acc_stderr,none": 0.03663974994391242,
      "alias": "ogx_mmlux_fr-high_school_european_history"
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_fr-high_school_computer_science"
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "acc,none": 0.39408866995073893,
      "acc_stderr,none": 0.03438157967036546,
      "alias": "ogx_mmlux_fr-high_school_chemistry"
    },
    "ogx_mmlux_fr-high_school_biology": {
      "acc,none": 0.6064516129032258,
      "acc_stderr,none": 0.027791878753132267,
      "alias": "ogx_mmlux_fr-high_school_biology"
    },
    "ogx_mmlux_fr-global_facts": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_fr-global_facts"
    },
    "ogx_mmlux_fr-formal_logic": {
      "acc,none": 0.3492063492063492,
      "acc_stderr,none": 0.04263906892795131,
      "alias": "ogx_mmlux_fr-formal_logic"
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "acc,none": 0.328042328042328,
      "acc_stderr,none": 0.024180497164376896,
      "alias": "ogx_mmlux_fr-elementary_mathematics"
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "acc,none": 0.4827586206896552,
      "acc_stderr,none": 0.04164188720169377,
      "alias": "ogx_mmlux_fr-electrical_engineering"
    },
    "ogx_mmlux_fr-econometrics": {
      "acc,none": 0.34210526315789475,
      "acc_stderr,none": 0.04462917535336937,
      "alias": "ogx_mmlux_fr-econometrics"
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "acc,none": 0.40425531914893614,
      "acc_stderr,none": 0.032081157507886836,
      "alias": "ogx_mmlux_fr-conceptual_physics"
    },
    "ogx_mmlux_fr-computer_security": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_fr-computer_security"
    },
    "ogx_mmlux_fr-college_physics": {
      "acc,none": 0.23529411764705882,
      "acc_stderr,none": 0.04220773659171453,
      "alias": "ogx_mmlux_fr-college_physics"
    },
    "ogx_mmlux_fr-college_medicine": {
      "acc,none": 0.4682080924855491,
      "acc_stderr,none": 0.03804749744364764,
      "alias": "ogx_mmlux_fr-college_medicine"
    },
    "ogx_mmlux_fr-college_mathematics": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695236,
      "alias": "ogx_mmlux_fr-college_mathematics"
    },
    "ogx_mmlux_fr-college_computer_science": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_fr-college_computer_science"
    },
    "ogx_mmlux_fr-college_chemistry": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_fr-college_chemistry"
    },
    "ogx_mmlux_fr-college_biology": {
      "acc,none": 0.5069444444444444,
      "acc_stderr,none": 0.04180806750294938,
      "alias": "ogx_mmlux_fr-college_biology"
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "acc,none": 0.5018867924528302,
      "acc_stderr,none": 0.030772653642075657,
      "alias": "ogx_mmlux_fr-clinical_knowledge"
    },
    "ogx_mmlux_fr-business_ethics": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_fr-business_ethics"
    },
    "ogx_mmlux_fr-astronomy": {
      "acc,none": 0.5723684210526315,
      "acc_stderr,none": 0.04026097083296563,
      "alias": "ogx_mmlux_fr-astronomy"
    },
    "ogx_mmlux_fr-anatomy": {
      "acc,none": 0.4740740740740741,
      "acc_stderr,none": 0.04313531696750574,
      "alias": "ogx_mmlux_fr-anatomy"
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_fr-abstract_algebra"
    },
    "ogx_mmlux_fi-world_religions": {
      "acc,none": 0.43859649122807015,
      "acc_stderr,none": 0.038057975055904594,
      "alias": "ogx_mmlux_fi-world_religions"
    },
    "ogx_mmlux_fi-virology": {
      "acc,none": 0.3493975903614458,
      "acc_stderr,none": 0.03711725190740749,
      "alias": "ogx_mmlux_fi-virology"
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.04975698519562428,
      "alias": "ogx_mmlux_fi-us_foreign_policy"
    },
    "ogx_mmlux_fi-sociology": {
      "acc,none": 0.4626865671641791,
      "acc_stderr,none": 0.03525675167467975,
      "alias": "ogx_mmlux_fi-sociology"
    },
    "ogx_mmlux_fi-security_studies": {
      "acc,none": 0.4530612244897959,
      "acc_stderr,none": 0.03186785930004128,
      "alias": "ogx_mmlux_fi-security_studies"
    },
    "ogx_mmlux_fi-public_relations": {
      "acc,none": 0.35454545454545455,
      "acc_stderr,none": 0.04582004841505417,
      "alias": "ogx_mmlux_fi-public_relations"
    },
    "ogx_mmlux_fi-professional_psychology": {
      "acc,none": 0.315359477124183,
      "acc_stderr,none": 0.01879808628488689,
      "alias": "ogx_mmlux_fi-professional_psychology"
    },
    "ogx_mmlux_fi-professional_medicine": {
      "acc,none": 0.29411764705882354,
      "acc_stderr,none": 0.027678468642144696,
      "alias": "ogx_mmlux_fi-professional_medicine"
    },
    "ogx_mmlux_fi-professional_law": {
      "acc,none": 0.2861799217731421,
      "acc_stderr,none": 0.011543642878150757,
      "alias": "ogx_mmlux_fi-professional_law"
    },
    "ogx_mmlux_fi-professional_accounting": {
      "acc,none": 0.30141843971631205,
      "acc_stderr,none": 0.02737412888263115,
      "alias": "ogx_mmlux_fi-professional_accounting"
    },
    "ogx_mmlux_fi-prehistory": {
      "acc,none": 0.3487654320987654,
      "acc_stderr,none": 0.026517597724465013,
      "alias": "ogx_mmlux_fi-prehistory"
    },
    "ogx_mmlux_fi-philosophy": {
      "acc,none": 0.36012861736334406,
      "acc_stderr,none": 0.027264297599804015,
      "alias": "ogx_mmlux_fi-philosophy"
    },
    "ogx_mmlux_fi-nutrition": {
      "acc,none": 0.369281045751634,
      "acc_stderr,none": 0.02763417668960266,
      "alias": "ogx_mmlux_fi-nutrition"
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "acc,none": 0.24022346368715083,
      "acc_stderr,none": 0.014288343803925307,
      "alias": "ogx_mmlux_fi-moral_scenarios"
    },
    "ogx_mmlux_fi-moral_disputes": {
      "acc,none": 0.4161849710982659,
      "acc_stderr,none": 0.026538189104705474,
      "alias": "ogx_mmlux_fi-moral_disputes"
    },
    "ogx_mmlux_fi-miscellaneous": {
      "acc,none": 0.3959131545338442,
      "acc_stderr,none": 0.017488247006979266,
      "alias": "ogx_mmlux_fi-miscellaneous"
    },
    "ogx_mmlux_fi-medical_genetics": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_fi-medical_genetics"
    },
    "ogx_mmlux_fi-marketing": {
      "acc,none": 0.49572649572649574,
      "acc_stderr,none": 0.032754892643821316,
      "alias": "ogx_mmlux_fi-marketing"
    },
    "ogx_mmlux_fi-management": {
      "acc,none": 0.4368932038834951,
      "acc_stderr,none": 0.04911147107365777,
      "alias": "ogx_mmlux_fi-management"
    },
    "ogx_mmlux_fi-machine_learning": {
      "acc,none": 0.3392857142857143,
      "acc_stderr,none": 0.04493949068613539,
      "alias": "ogx_mmlux_fi-machine_learning"
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "acc,none": 0.39263803680981596,
      "acc_stderr,none": 0.03836740907831029,
      "alias": "ogx_mmlux_fi-logical_fallacies"
    },
    "ogx_mmlux_fi-jurisprudence": {
      "acc,none": 0.42592592592592593,
      "acc_stderr,none": 0.0478034362693679,
      "alias": "ogx_mmlux_fi-jurisprudence"
    },
    "ogx_mmlux_fi-international_law": {
      "acc,none": 0.4049586776859504,
      "acc_stderr,none": 0.04481137755942469,
      "alias": "ogx_mmlux_fi-international_law"
    },
    "ogx_mmlux_fi-human_sexuality": {
      "acc,none": 0.3511450381679389,
      "acc_stderr,none": 0.04186445163013751,
      "alias": "ogx_mmlux_fi-human_sexuality"
    },
    "ogx_mmlux_fi-human_aging": {
      "acc,none": 0.3183856502242152,
      "acc_stderr,none": 0.03126580522513713,
      "alias": "ogx_mmlux_fi-human_aging"
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "acc,none": 0.4430379746835443,
      "acc_stderr,none": 0.03233532777533484,
      "alias": "ogx_mmlux_fi-high_school_world_history"
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "acc,none": 0.37254901960784315,
      "acc_stderr,none": 0.033933885849584046,
      "alias": "ogx_mmlux_fi-high_school_us_history"
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "acc,none": 0.25462962962962965,
      "acc_stderr,none": 0.029711275860005354,
      "alias": "ogx_mmlux_fi-high_school_statistics"
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "acc,none": 0.3229357798165138,
      "acc_stderr,none": 0.020048115923415325,
      "alias": "ogx_mmlux_fi-high_school_psychology"
    },
    "ogx_mmlux_fi-high_school_physics": {
      "acc,none": 0.304635761589404,
      "acc_stderr,none": 0.03757949922943342,
      "alias": "ogx_mmlux_fi-high_school_physics"
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "acc,none": 0.3277310924369748,
      "acc_stderr,none": 0.030489911417673227,
      "alias": "ogx_mmlux_fi-high_school_microeconomics"
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "acc,none": 0.3074074074074074,
      "acc_stderr,none": 0.028133252578815635,
      "alias": "ogx_mmlux_fi-high_school_mathematics"
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "acc,none": 0.3384615384615385,
      "acc_stderr,none": 0.023991500500313036,
      "alias": "ogx_mmlux_fi-high_school_macroeconomics"
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "acc,none": 0.43005181347150256,
      "acc_stderr,none": 0.035729543331448094,
      "alias": "ogx_mmlux_fi-high_school_government_and_politics"
    },
    "ogx_mmlux_fi-high_school_geography": {
      "acc,none": 0.3383838383838384,
      "acc_stderr,none": 0.03371124142626302,
      "alias": "ogx_mmlux_fi-high_school_geography"
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "acc,none": 0.38181818181818183,
      "acc_stderr,none": 0.03793713171165635,
      "alias": "ogx_mmlux_fi-high_school_european_history"
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001974,
      "alias": "ogx_mmlux_fi-high_school_computer_science"
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "acc,none": 0.28078817733990147,
      "acc_stderr,none": 0.03161856335358611,
      "alias": "ogx_mmlux_fi-high_school_chemistry"
    },
    "ogx_mmlux_fi-high_school_biology": {
      "acc,none": 0.36129032258064514,
      "acc_stderr,none": 0.027327548447957522,
      "alias": "ogx_mmlux_fi-high_school_biology"
    },
    "ogx_mmlux_fi-global_facts": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.0446196043338474,
      "alias": "ogx_mmlux_fi-global_facts"
    },
    "ogx_mmlux_fi-formal_logic": {
      "acc,none": 0.21428571428571427,
      "acc_stderr,none": 0.03670066451047181,
      "alias": "ogx_mmlux_fi-formal_logic"
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "acc,none": 0.291005291005291,
      "acc_stderr,none": 0.02339382650048486,
      "alias": "ogx_mmlux_fi-elementary_mathematics"
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "acc,none": 0.46206896551724136,
      "acc_stderr,none": 0.041546596717075474,
      "alias": "ogx_mmlux_fi-electrical_engineering"
    },
    "ogx_mmlux_fi-econometrics": {
      "acc,none": 0.2631578947368421,
      "acc_stderr,none": 0.04142439719489362,
      "alias": "ogx_mmlux_fi-econometrics"
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "acc,none": 0.3574468085106383,
      "acc_stderr,none": 0.03132941789476425,
      "alias": "ogx_mmlux_fi-conceptual_physics"
    },
    "ogx_mmlux_fi-computer_security": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_fi-computer_security"
    },
    "ogx_mmlux_fi-college_physics": {
      "acc,none": 0.24509803921568626,
      "acc_stderr,none": 0.042801058373643945,
      "alias": "ogx_mmlux_fi-college_physics"
    },
    "ogx_mmlux_fi-college_medicine": {
      "acc,none": 0.27167630057803466,
      "acc_stderr,none": 0.03391750322321658,
      "alias": "ogx_mmlux_fi-college_medicine"
    },
    "ogx_mmlux_fi-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_fi-college_mathematics"
    },
    "ogx_mmlux_fi-college_computer_science": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001974,
      "alias": "ogx_mmlux_fi-college_computer_science"
    },
    "ogx_mmlux_fi-college_chemistry": {
      "acc,none": 0.24,
      "acc_stderr,none": 0.042923469599092816,
      "alias": "ogx_mmlux_fi-college_chemistry"
    },
    "ogx_mmlux_fi-college_biology": {
      "acc,none": 0.2847222222222222,
      "acc_stderr,none": 0.03773809990686935,
      "alias": "ogx_mmlux_fi-college_biology"
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "acc,none": 0.2943396226415094,
      "acc_stderr,none": 0.028049186315695248,
      "alias": "ogx_mmlux_fi-clinical_knowledge"
    },
    "ogx_mmlux_fi-business_ethics": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.047258156262526045,
      "alias": "ogx_mmlux_fi-business_ethics"
    },
    "ogx_mmlux_fi-astronomy": {
      "acc,none": 0.3157894736842105,
      "acc_stderr,none": 0.0378272898086547,
      "alias": "ogx_mmlux_fi-astronomy"
    },
    "ogx_mmlux_fi-anatomy": {
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.04072314811876837,
      "alias": "ogx_mmlux_fi-anatomy"
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_fi-abstract_algebra"
    },
    "ogx_mmlux_et-world_religions": {
      "acc,none": 0.47953216374269003,
      "acc_stderr,none": 0.0383161053282193,
      "alias": "ogx_mmlux_et-world_religions"
    },
    "ogx_mmlux_et-virology": {
      "acc,none": 0.35542168674698793,
      "acc_stderr,none": 0.03726214354322415,
      "alias": "ogx_mmlux_et-virology"
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.050161355804659205,
      "alias": "ogx_mmlux_et-us_foreign_policy"
    },
    "ogx_mmlux_et-sociology": {
      "acc,none": 0.417910447761194,
      "acc_stderr,none": 0.034875586404620636,
      "alias": "ogx_mmlux_et-sociology"
    },
    "ogx_mmlux_et-security_studies": {
      "acc,none": 0.40408163265306124,
      "acc_stderr,none": 0.03141470802586589,
      "alias": "ogx_mmlux_et-security_studies"
    },
    "ogx_mmlux_et-public_relations": {
      "acc,none": 0.35454545454545455,
      "acc_stderr,none": 0.04582004841505417,
      "alias": "ogx_mmlux_et-public_relations"
    },
    "ogx_mmlux_et-professional_psychology": {
      "acc,none": 0.3431372549019608,
      "acc_stderr,none": 0.019206606848825365,
      "alias": "ogx_mmlux_et-professional_psychology"
    },
    "ogx_mmlux_et-professional_medicine": {
      "acc,none": 0.24632352941176472,
      "acc_stderr,none": 0.02617343857052,
      "alias": "ogx_mmlux_et-professional_medicine"
    },
    "ogx_mmlux_et-professional_law": {
      "acc,none": 0.2953063885267275,
      "acc_stderr,none": 0.011651061936208816,
      "alias": "ogx_mmlux_et-professional_law"
    },
    "ogx_mmlux_et-professional_accounting": {
      "acc,none": 0.32269503546099293,
      "acc_stderr,none": 0.027889139300534795,
      "alias": "ogx_mmlux_et-professional_accounting"
    },
    "ogx_mmlux_et-prehistory": {
      "acc,none": 0.3148148148148148,
      "acc_stderr,none": 0.02584224870090217,
      "alias": "ogx_mmlux_et-prehistory"
    },
    "ogx_mmlux_et-philosophy": {
      "acc,none": 0.33762057877813506,
      "acc_stderr,none": 0.026858825879488554,
      "alias": "ogx_mmlux_et-philosophy"
    },
    "ogx_mmlux_et-nutrition": {
      "acc,none": 0.3366013071895425,
      "acc_stderr,none": 0.027057974624494382,
      "alias": "ogx_mmlux_et-nutrition"
    },
    "ogx_mmlux_et-moral_scenarios": {
      "acc,none": 0.24804469273743016,
      "acc_stderr,none": 0.014444157808261441,
      "alias": "ogx_mmlux_et-moral_scenarios"
    },
    "ogx_mmlux_et-moral_disputes": {
      "acc,none": 0.37283236994219654,
      "acc_stderr,none": 0.02603389061357628,
      "alias": "ogx_mmlux_et-moral_disputes"
    },
    "ogx_mmlux_et-miscellaneous": {
      "acc,none": 0.37292464878671777,
      "acc_stderr,none": 0.017292868269453913,
      "alias": "ogx_mmlux_et-miscellaneous"
    },
    "ogx_mmlux_et-medical_genetics": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.046882617226215034,
      "alias": "ogx_mmlux_et-medical_genetics"
    },
    "ogx_mmlux_et-marketing": {
      "acc,none": 0.405982905982906,
      "acc_stderr,none": 0.03217180182641086,
      "alias": "ogx_mmlux_et-marketing"
    },
    "ogx_mmlux_et-management": {
      "acc,none": 0.3300970873786408,
      "acc_stderr,none": 0.046561471100123514,
      "alias": "ogx_mmlux_et-management"
    },
    "ogx_mmlux_et-machine_learning": {
      "acc,none": 0.3125,
      "acc_stderr,none": 0.043994650575715215,
      "alias": "ogx_mmlux_et-machine_learning"
    },
    "ogx_mmlux_et-logical_fallacies": {
      "acc,none": 0.3128834355828221,
      "acc_stderr,none": 0.036429145782924055,
      "alias": "ogx_mmlux_et-logical_fallacies"
    },
    "ogx_mmlux_et-jurisprudence": {
      "acc,none": 0.37037037037037035,
      "acc_stderr,none": 0.04668408033024932,
      "alias": "ogx_mmlux_et-jurisprudence"
    },
    "ogx_mmlux_et-international_law": {
      "acc,none": 0.4462809917355372,
      "acc_stderr,none": 0.0453793517794788,
      "alias": "ogx_mmlux_et-international_law"
    },
    "ogx_mmlux_et-human_sexuality": {
      "acc,none": 0.3816793893129771,
      "acc_stderr,none": 0.042607351576445594,
      "alias": "ogx_mmlux_et-human_sexuality"
    },
    "ogx_mmlux_et-human_aging": {
      "acc,none": 0.33183856502242154,
      "acc_stderr,none": 0.031602951437766785,
      "alias": "ogx_mmlux_et-human_aging"
    },
    "ogx_mmlux_et-high_school_world_history": {
      "acc,none": 0.35864978902953587,
      "acc_stderr,none": 0.031219569445301847,
      "alias": "ogx_mmlux_et-high_school_world_history"
    },
    "ogx_mmlux_et-high_school_us_history": {
      "acc,none": 0.35294117647058826,
      "acc_stderr,none": 0.033540924375915195,
      "alias": "ogx_mmlux_et-high_school_us_history"
    },
    "ogx_mmlux_et-high_school_statistics": {
      "acc,none": 0.22685185185185186,
      "acc_stderr,none": 0.02856165010242226,
      "alias": "ogx_mmlux_et-high_school_statistics"
    },
    "ogx_mmlux_et-high_school_psychology": {
      "acc,none": 0.28440366972477066,
      "acc_stderr,none": 0.019342036587702602,
      "alias": "ogx_mmlux_et-high_school_psychology"
    },
    "ogx_mmlux_et-high_school_physics": {
      "acc,none": 0.2980132450331126,
      "acc_stderr,none": 0.03734535676787198,
      "alias": "ogx_mmlux_et-high_school_physics"
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "acc,none": 0.3445378151260504,
      "acc_stderr,none": 0.03086868260412163,
      "alias": "ogx_mmlux_et-high_school_microeconomics"
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "acc,none": 0.27037037037037037,
      "acc_stderr,none": 0.027080372815145668,
      "alias": "ogx_mmlux_et-high_school_mathematics"
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "acc,none": 0.28717948717948716,
      "acc_stderr,none": 0.022939925418530627,
      "alias": "ogx_mmlux_et-high_school_macroeconomics"
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "acc,none": 0.35233160621761656,
      "acc_stderr,none": 0.034474782864143586,
      "alias": "ogx_mmlux_et-high_school_government_and_politics"
    },
    "ogx_mmlux_et-high_school_geography": {
      "acc,none": 0.3686868686868687,
      "acc_stderr,none": 0.03437305501980619,
      "alias": "ogx_mmlux_et-high_school_geography"
    },
    "ogx_mmlux_et-high_school_european_history": {
      "acc,none": 0.3515151515151515,
      "acc_stderr,none": 0.037282069986826503,
      "alias": "ogx_mmlux_et-high_school_european_history"
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "acc,none": 0.41,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_et-high_school_computer_science"
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "acc,none": 0.2660098522167488,
      "acc_stderr,none": 0.03108982600293753,
      "alias": "ogx_mmlux_et-high_school_chemistry"
    },
    "ogx_mmlux_et-high_school_biology": {
      "acc,none": 0.3419354838709677,
      "acc_stderr,none": 0.026985289576552742,
      "alias": "ogx_mmlux_et-high_school_biology"
    },
    "ogx_mmlux_et-global_facts": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.047258156262526045,
      "alias": "ogx_mmlux_et-global_facts"
    },
    "ogx_mmlux_et-formal_logic": {
      "acc,none": 0.21428571428571427,
      "acc_stderr,none": 0.03670066451047181,
      "alias": "ogx_mmlux_et-formal_logic"
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "acc,none": 0.2804232804232804,
      "acc_stderr,none": 0.023135287974325607,
      "alias": "ogx_mmlux_et-elementary_mathematics"
    },
    "ogx_mmlux_et-electrical_engineering": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.040824829046386284,
      "alias": "ogx_mmlux_et-electrical_engineering"
    },
    "ogx_mmlux_et-econometrics": {
      "acc,none": 0.2982456140350877,
      "acc_stderr,none": 0.043036840335373173,
      "alias": "ogx_mmlux_et-econometrics"
    },
    "ogx_mmlux_et-conceptual_physics": {
      "acc,none": 0.3021276595744681,
      "acc_stderr,none": 0.030017554471880557,
      "alias": "ogx_mmlux_et-conceptual_physics"
    },
    "ogx_mmlux_et-computer_security": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001974,
      "alias": "ogx_mmlux_et-computer_security"
    },
    "ogx_mmlux_et-college_physics": {
      "acc,none": 0.27450980392156865,
      "acc_stderr,none": 0.04440521906179328,
      "alias": "ogx_mmlux_et-college_physics"
    },
    "ogx_mmlux_et-college_medicine": {
      "acc,none": 0.30057803468208094,
      "acc_stderr,none": 0.0349610148119118,
      "alias": "ogx_mmlux_et-college_medicine"
    },
    "ogx_mmlux_et-college_mathematics": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542128,
      "alias": "ogx_mmlux_et-college_mathematics"
    },
    "ogx_mmlux_et-college_computer_science": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_et-college_computer_science"
    },
    "ogx_mmlux_et-college_chemistry": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542127,
      "alias": "ogx_mmlux_et-college_chemistry"
    },
    "ogx_mmlux_et-college_biology": {
      "acc,none": 0.2916666666666667,
      "acc_stderr,none": 0.03800968060554858,
      "alias": "ogx_mmlux_et-college_biology"
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "acc,none": 0.35471698113207545,
      "acc_stderr,none": 0.029445175328199593,
      "alias": "ogx_mmlux_et-clinical_knowledge"
    },
    "ogx_mmlux_et-business_ethics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_et-business_ethics"
    },
    "ogx_mmlux_et-astronomy": {
      "acc,none": 0.27631578947368424,
      "acc_stderr,none": 0.03639057569952925,
      "alias": "ogx_mmlux_et-astronomy"
    },
    "ogx_mmlux_et-anatomy": {
      "acc,none": 0.2962962962962963,
      "acc_stderr,none": 0.039446241625011175,
      "alias": "ogx_mmlux_et-anatomy"
    },
    "ogx_mmlux_et-abstract_algebra": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_et-abstract_algebra"
    },
    "ogx_mmlux_es-world_religions": {
      "acc,none": 0.6783625730994152,
      "acc_stderr,none": 0.03582529442573122,
      "alias": "ogx_mmlux_es-world_religions"
    },
    "ogx_mmlux_es-virology": {
      "acc,none": 0.4939759036144578,
      "acc_stderr,none": 0.03892212195333045,
      "alias": "ogx_mmlux_es-virology"
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "acc,none": 0.76,
      "acc_stderr,none": 0.042923469599092816,
      "alias": "ogx_mmlux_es-us_foreign_policy"
    },
    "ogx_mmlux_es-sociology": {
      "acc,none": 0.736318407960199,
      "acc_stderr,none": 0.03115715086935558,
      "alias": "ogx_mmlux_es-sociology"
    },
    "ogx_mmlux_es-security_studies": {
      "acc,none": 0.6448979591836734,
      "acc_stderr,none": 0.030635655150387634,
      "alias": "ogx_mmlux_es-security_studies"
    },
    "ogx_mmlux_es-public_relations": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.0469237132203465,
      "alias": "ogx_mmlux_es-public_relations"
    },
    "ogx_mmlux_es-professional_psychology": {
      "acc,none": 0.4591503267973856,
      "acc_stderr,none": 0.020160213617222516,
      "alias": "ogx_mmlux_es-professional_psychology"
    },
    "ogx_mmlux_es-professional_medicine": {
      "acc,none": 0.4522058823529412,
      "acc_stderr,none": 0.030233758551596455,
      "alias": "ogx_mmlux_es-professional_medicine"
    },
    "ogx_mmlux_es-professional_law": {
      "acc,none": 0.38265971316818775,
      "acc_stderr,none": 0.01241359588289328,
      "alias": "ogx_mmlux_es-professional_law"
    },
    "ogx_mmlux_es-professional_accounting": {
      "acc,none": 0.3617021276595745,
      "acc_stderr,none": 0.028663820147199492,
      "alias": "ogx_mmlux_es-professional_accounting"
    },
    "ogx_mmlux_es-prehistory": {
      "acc,none": 0.5740740740740741,
      "acc_stderr,none": 0.027513747284379417,
      "alias": "ogx_mmlux_es-prehistory"
    },
    "ogx_mmlux_es-philosophy": {
      "acc,none": 0.6270096463022508,
      "acc_stderr,none": 0.0274666102131401,
      "alias": "ogx_mmlux_es-philosophy"
    },
    "ogx_mmlux_es-nutrition": {
      "acc,none": 0.5816993464052288,
      "acc_stderr,none": 0.0282451340243873,
      "alias": "ogx_mmlux_es-nutrition"
    },
    "ogx_mmlux_es-moral_scenarios": {
      "acc,none": 0.2670391061452514,
      "acc_stderr,none": 0.014796502622562543,
      "alias": "ogx_mmlux_es-moral_scenarios"
    },
    "ogx_mmlux_es-moral_disputes": {
      "acc,none": 0.5346820809248555,
      "acc_stderr,none": 0.026854257928258865,
      "alias": "ogx_mmlux_es-moral_disputes"
    },
    "ogx_mmlux_es-miscellaneous": {
      "acc,none": 0.6743295019157088,
      "acc_stderr,none": 0.01675798945854968,
      "alias": "ogx_mmlux_es-miscellaneous"
    },
    "ogx_mmlux_es-medical_genetics": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_es-medical_genetics"
    },
    "ogx_mmlux_es-marketing": {
      "acc,none": 0.7905982905982906,
      "acc_stderr,none": 0.026655699653922737,
      "alias": "ogx_mmlux_es-marketing"
    },
    "ogx_mmlux_es-management": {
      "acc,none": 0.7378640776699029,
      "acc_stderr,none": 0.04354631077260595,
      "alias": "ogx_mmlux_es-management"
    },
    "ogx_mmlux_es-machine_learning": {
      "acc,none": 0.4107142857142857,
      "acc_stderr,none": 0.04669510663875191,
      "alias": "ogx_mmlux_es-machine_learning"
    },
    "ogx_mmlux_es-logical_fallacies": {
      "acc,none": 0.5950920245398773,
      "acc_stderr,none": 0.038566721635489125,
      "alias": "ogx_mmlux_es-logical_fallacies"
    },
    "ogx_mmlux_es-jurisprudence": {
      "acc,none": 0.6666666666666666,
      "acc_stderr,none": 0.04557239513497752,
      "alias": "ogx_mmlux_es-jurisprudence"
    },
    "ogx_mmlux_es-international_law": {
      "acc,none": 0.6776859504132231,
      "acc_stderr,none": 0.042664163633521685,
      "alias": "ogx_mmlux_es-international_law"
    },
    "ogx_mmlux_es-human_sexuality": {
      "acc,none": 0.6106870229007634,
      "acc_stderr,none": 0.04276486542814591,
      "alias": "ogx_mmlux_es-human_sexuality"
    },
    "ogx_mmlux_es-human_aging": {
      "acc,none": 0.6457399103139013,
      "acc_stderr,none": 0.032100621541349864,
      "alias": "ogx_mmlux_es-human_aging"
    },
    "ogx_mmlux_es-high_school_world_history": {
      "acc,none": 0.70042194092827,
      "acc_stderr,none": 0.029818024749753095,
      "alias": "ogx_mmlux_es-high_school_world_history"
    },
    "ogx_mmlux_es-high_school_us_history": {
      "acc,none": 0.6568627450980392,
      "acc_stderr,none": 0.033321399446680854,
      "alias": "ogx_mmlux_es-high_school_us_history"
    },
    "ogx_mmlux_es-high_school_statistics": {
      "acc,none": 0.37037037037037035,
      "acc_stderr,none": 0.03293377139415191,
      "alias": "ogx_mmlux_es-high_school_statistics"
    },
    "ogx_mmlux_es-high_school_psychology": {
      "acc,none": 0.7064220183486238,
      "acc_stderr,none": 0.019525151122639667,
      "alias": "ogx_mmlux_es-high_school_psychology"
    },
    "ogx_mmlux_es-high_school_physics": {
      "acc,none": 0.3443708609271523,
      "acc_stderr,none": 0.038796870240733264,
      "alias": "ogx_mmlux_es-high_school_physics"
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "acc,none": 0.48739495798319327,
      "acc_stderr,none": 0.03246816765752174,
      "alias": "ogx_mmlux_es-high_school_microeconomics"
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "acc,none": 0.32592592592592595,
      "acc_stderr,none": 0.02857834836547308,
      "alias": "ogx_mmlux_es-high_school_mathematics"
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "acc,none": 0.46923076923076923,
      "acc_stderr,none": 0.025302958890850154,
      "alias": "ogx_mmlux_es-high_school_macroeconomics"
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "acc,none": 0.7202072538860104,
      "acc_stderr,none": 0.03239637046735703,
      "alias": "ogx_mmlux_es-high_school_government_and_politics"
    },
    "ogx_mmlux_es-high_school_geography": {
      "acc,none": 0.6515151515151515,
      "acc_stderr,none": 0.033948539651564025,
      "alias": "ogx_mmlux_es-high_school_geography"
    },
    "ogx_mmlux_es-high_school_european_history": {
      "acc,none": 0.6303030303030303,
      "acc_stderr,none": 0.037694303145125674,
      "alias": "ogx_mmlux_es-high_school_european_history"
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "acc,none": 0.56,
      "acc_stderr,none": 0.049888765156985884,
      "alias": "ogx_mmlux_es-high_school_computer_science"
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "acc,none": 0.3891625615763547,
      "acc_stderr,none": 0.03430462416103872,
      "alias": "ogx_mmlux_es-high_school_chemistry"
    },
    "ogx_mmlux_es-high_school_biology": {
      "acc,none": 0.5741935483870968,
      "acc_stderr,none": 0.028129112709165908,
      "alias": "ogx_mmlux_es-high_school_biology"
    },
    "ogx_mmlux_es-global_facts": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_es-global_facts"
    },
    "ogx_mmlux_es-formal_logic": {
      "acc,none": 0.36507936507936506,
      "acc_stderr,none": 0.04306241259127153,
      "alias": "ogx_mmlux_es-formal_logic"
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "acc,none": 0.328042328042328,
      "acc_stderr,none": 0.024180497164376882,
      "alias": "ogx_mmlux_es-elementary_mathematics"
    },
    "ogx_mmlux_es-electrical_engineering": {
      "acc,none": 0.45517241379310347,
      "acc_stderr,none": 0.04149886942192117,
      "alias": "ogx_mmlux_es-electrical_engineering"
    },
    "ogx_mmlux_es-econometrics": {
      "acc,none": 0.3508771929824561,
      "acc_stderr,none": 0.044895393502706986,
      "alias": "ogx_mmlux_es-econometrics"
    },
    "ogx_mmlux_es-conceptual_physics": {
      "acc,none": 0.4297872340425532,
      "acc_stderr,none": 0.03236214467715564,
      "alias": "ogx_mmlux_es-conceptual_physics"
    },
    "ogx_mmlux_es-computer_security": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_es-computer_security"
    },
    "ogx_mmlux_es-college_physics": {
      "acc,none": 0.21568627450980393,
      "acc_stderr,none": 0.04092563958237655,
      "alias": "ogx_mmlux_es-college_physics"
    },
    "ogx_mmlux_es-college_medicine": {
      "acc,none": 0.4624277456647399,
      "acc_stderr,none": 0.0380168510452446,
      "alias": "ogx_mmlux_es-college_medicine"
    },
    "ogx_mmlux_es-college_mathematics": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542128,
      "alias": "ogx_mmlux_es-college_mathematics"
    },
    "ogx_mmlux_es-college_computer_science": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_es-college_computer_science"
    },
    "ogx_mmlux_es-college_chemistry": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_es-college_chemistry"
    },
    "ogx_mmlux_es-college_biology": {
      "acc,none": 0.5555555555555556,
      "acc_stderr,none": 0.041553199555931467,
      "alias": "ogx_mmlux_es-college_biology"
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "acc,none": 0.5207547169811321,
      "acc_stderr,none": 0.03074634997572347,
      "alias": "ogx_mmlux_es-clinical_knowledge"
    },
    "ogx_mmlux_es-business_ethics": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_es-business_ethics"
    },
    "ogx_mmlux_es-astronomy": {
      "acc,none": 0.5789473684210527,
      "acc_stderr,none": 0.040179012759817494,
      "alias": "ogx_mmlux_es-astronomy"
    },
    "ogx_mmlux_es-anatomy": {
      "acc,none": 0.45185185185185184,
      "acc_stderr,none": 0.04299268905480863,
      "alias": "ogx_mmlux_es-anatomy"
    },
    "ogx_mmlux_es-abstract_algebra": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_es-abstract_algebra"
    },
    "ogx_mmlux_el-world_religions": {
      "acc,none": 0.6198830409356725,
      "acc_stderr,none": 0.037229657413855394,
      "alias": "ogx_mmlux_el-world_religions"
    },
    "ogx_mmlux_el-virology": {
      "acc,none": 0.4457831325301205,
      "acc_stderr,none": 0.03869543323472101,
      "alias": "ogx_mmlux_el-virology"
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.04461960433384741,
      "alias": "ogx_mmlux_el-us_foreign_policy"
    },
    "ogx_mmlux_el-sociology": {
      "acc,none": 0.7064676616915423,
      "acc_stderr,none": 0.03220024104534205,
      "alias": "ogx_mmlux_el-sociology"
    },
    "ogx_mmlux_el-security_studies": {
      "acc,none": 0.6326530612244898,
      "acc_stderr,none": 0.030862144921087555,
      "alias": "ogx_mmlux_el-security_studies"
    },
    "ogx_mmlux_el-public_relations": {
      "acc,none": 0.5636363636363636,
      "acc_stderr,none": 0.04750185058907296,
      "alias": "ogx_mmlux_el-public_relations"
    },
    "ogx_mmlux_el-professional_psychology": {
      "acc,none": 0.4493464052287582,
      "acc_stderr,none": 0.020123766528027262,
      "alias": "ogx_mmlux_el-professional_psychology"
    },
    "ogx_mmlux_el-professional_medicine": {
      "acc,none": 0.3897058823529412,
      "acc_stderr,none": 0.029624663581159696,
      "alias": "ogx_mmlux_el-professional_medicine"
    },
    "ogx_mmlux_el-professional_law": {
      "acc,none": 0.3833116036505867,
      "acc_stderr,none": 0.01241760366290119,
      "alias": "ogx_mmlux_el-professional_law"
    },
    "ogx_mmlux_el-professional_accounting": {
      "acc,none": 0.33687943262411346,
      "acc_stderr,none": 0.02819553487396673,
      "alias": "ogx_mmlux_el-professional_accounting"
    },
    "ogx_mmlux_el-prehistory": {
      "acc,none": 0.5185185185185185,
      "acc_stderr,none": 0.027801656212323667,
      "alias": "ogx_mmlux_el-prehistory"
    },
    "ogx_mmlux_el-philosophy": {
      "acc,none": 0.5916398713826366,
      "acc_stderr,none": 0.02791705074848463,
      "alias": "ogx_mmlux_el-philosophy"
    },
    "ogx_mmlux_el-nutrition": {
      "acc,none": 0.48366013071895425,
      "acc_stderr,none": 0.028614624752805413,
      "alias": "ogx_mmlux_el-nutrition"
    },
    "ogx_mmlux_el-moral_scenarios": {
      "acc,none": 0.2435754189944134,
      "acc_stderr,none": 0.01435591196476786,
      "alias": "ogx_mmlux_el-moral_scenarios"
    },
    "ogx_mmlux_el-moral_disputes": {
      "acc,none": 0.5260115606936416,
      "acc_stderr,none": 0.02688264343402289,
      "alias": "ogx_mmlux_el-moral_disputes"
    },
    "ogx_mmlux_el-miscellaneous": {
      "acc,none": 0.6104725415070242,
      "acc_stderr,none": 0.017438082556264594,
      "alias": "ogx_mmlux_el-miscellaneous"
    },
    "ogx_mmlux_el-medical_genetics": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_el-medical_genetics"
    },
    "ogx_mmlux_el-marketing": {
      "acc,none": 0.7521367521367521,
      "acc_stderr,none": 0.028286324075564386,
      "alias": "ogx_mmlux_el-marketing"
    },
    "ogx_mmlux_el-management": {
      "acc,none": 0.5922330097087378,
      "acc_stderr,none": 0.048657775704107696,
      "alias": "ogx_mmlux_el-management"
    },
    "ogx_mmlux_el-machine_learning": {
      "acc,none": 0.4107142857142857,
      "acc_stderr,none": 0.04669510663875191,
      "alias": "ogx_mmlux_el-machine_learning"
    },
    "ogx_mmlux_el-logical_fallacies": {
      "acc,none": 0.5276073619631901,
      "acc_stderr,none": 0.03922378290610991,
      "alias": "ogx_mmlux_el-logical_fallacies"
    },
    "ogx_mmlux_el-jurisprudence": {
      "acc,none": 0.5648148148148148,
      "acc_stderr,none": 0.04792898170907062,
      "alias": "ogx_mmlux_el-jurisprudence"
    },
    "ogx_mmlux_el-international_law": {
      "acc,none": 0.7272727272727273,
      "acc_stderr,none": 0.04065578140908705,
      "alias": "ogx_mmlux_el-international_law"
    },
    "ogx_mmlux_el-human_sexuality": {
      "acc,none": 0.5648854961832062,
      "acc_stderr,none": 0.04348208051644858,
      "alias": "ogx_mmlux_el-human_sexuality"
    },
    "ogx_mmlux_el-human_aging": {
      "acc,none": 0.5515695067264574,
      "acc_stderr,none": 0.033378837362550984,
      "alias": "ogx_mmlux_el-human_aging"
    },
    "ogx_mmlux_el-high_school_world_history": {
      "acc,none": 0.6835443037974683,
      "acc_stderr,none": 0.030274974880218977,
      "alias": "ogx_mmlux_el-high_school_world_history"
    },
    "ogx_mmlux_el-high_school_us_history": {
      "acc,none": 0.6029411764705882,
      "acc_stderr,none": 0.034341311647191286,
      "alias": "ogx_mmlux_el-high_school_us_history"
    },
    "ogx_mmlux_el-high_school_statistics": {
      "acc,none": 0.33796296296296297,
      "acc_stderr,none": 0.03225941352631295,
      "alias": "ogx_mmlux_el-high_school_statistics"
    },
    "ogx_mmlux_el-high_school_psychology": {
      "acc,none": 0.5559633027522936,
      "acc_stderr,none": 0.021302621211654514,
      "alias": "ogx_mmlux_el-high_school_psychology"
    },
    "ogx_mmlux_el-high_school_physics": {
      "acc,none": 0.31125827814569534,
      "acc_stderr,none": 0.03780445850526733,
      "alias": "ogx_mmlux_el-high_school_physics"
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "acc,none": 0.42857142857142855,
      "acc_stderr,none": 0.032145368597886394,
      "alias": "ogx_mmlux_el-high_school_microeconomics"
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "acc,none": 0.2851851851851852,
      "acc_stderr,none": 0.027528599210340492,
      "alias": "ogx_mmlux_el-high_school_mathematics"
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "acc,none": 0.41794871794871796,
      "acc_stderr,none": 0.02500732988246122,
      "alias": "ogx_mmlux_el-high_school_macroeconomics"
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "acc,none": 0.6528497409326425,
      "acc_stderr,none": 0.03435696168361357,
      "alias": "ogx_mmlux_el-high_school_government_and_politics"
    },
    "ogx_mmlux_el-high_school_geography": {
      "acc,none": 0.6111111111111112,
      "acc_stderr,none": 0.0347327959083696,
      "alias": "ogx_mmlux_el-high_school_geography"
    },
    "ogx_mmlux_el-high_school_european_history": {
      "acc,none": 0.6242424242424243,
      "acc_stderr,none": 0.03781887353205982,
      "alias": "ogx_mmlux_el-high_school_european_history"
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.04923659639173309,
      "alias": "ogx_mmlux_el-high_school_computer_science"
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "acc,none": 0.3251231527093596,
      "acc_stderr,none": 0.032957975663112704,
      "alias": "ogx_mmlux_el-high_school_chemistry"
    },
    "ogx_mmlux_el-high_school_biology": {
      "acc,none": 0.5161290322580645,
      "acc_stderr,none": 0.028429203176724555,
      "alias": "ogx_mmlux_el-high_school_biology"
    },
    "ogx_mmlux_el-global_facts": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001974,
      "alias": "ogx_mmlux_el-global_facts"
    },
    "ogx_mmlux_el-formal_logic": {
      "acc,none": 0.2857142857142857,
      "acc_stderr,none": 0.0404061017820884,
      "alias": "ogx_mmlux_el-formal_logic"
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "acc,none": 0.31746031746031744,
      "acc_stderr,none": 0.023973861998992072,
      "alias": "ogx_mmlux_el-elementary_mathematics"
    },
    "ogx_mmlux_el-electrical_engineering": {
      "acc,none": 0.46206896551724136,
      "acc_stderr,none": 0.041546596717075474,
      "alias": "ogx_mmlux_el-electrical_engineering"
    },
    "ogx_mmlux_el-econometrics": {
      "acc,none": 0.32456140350877194,
      "acc_stderr,none": 0.04404556157374768,
      "alias": "ogx_mmlux_el-econometrics"
    },
    "ogx_mmlux_el-conceptual_physics": {
      "acc,none": 0.35319148936170214,
      "acc_stderr,none": 0.031245325202761926,
      "alias": "ogx_mmlux_el-conceptual_physics"
    },
    "ogx_mmlux_el-computer_security": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_el-computer_security"
    },
    "ogx_mmlux_el-college_physics": {
      "acc,none": 0.22549019607843138,
      "acc_stderr,none": 0.04158307533083286,
      "alias": "ogx_mmlux_el-college_physics"
    },
    "ogx_mmlux_el-college_medicine": {
      "acc,none": 0.3815028901734104,
      "acc_stderr,none": 0.03703851193099522,
      "alias": "ogx_mmlux_el-college_medicine"
    },
    "ogx_mmlux_el-college_mathematics": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206824,
      "alias": "ogx_mmlux_el-college_mathematics"
    },
    "ogx_mmlux_el-college_computer_science": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_el-college_computer_science"
    },
    "ogx_mmlux_el-college_chemistry": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.04461960433384741,
      "alias": "ogx_mmlux_el-college_chemistry"
    },
    "ogx_mmlux_el-college_biology": {
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.041227287076512825,
      "alias": "ogx_mmlux_el-college_biology"
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "acc,none": 0.49056603773584906,
      "acc_stderr,none": 0.030767394707808093,
      "alias": "ogx_mmlux_el-clinical_knowledge"
    },
    "ogx_mmlux_el-business_ethics": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_el-business_ethics"
    },
    "ogx_mmlux_el-astronomy": {
      "acc,none": 0.506578947368421,
      "acc_stderr,none": 0.040685900502249704,
      "alias": "ogx_mmlux_el-astronomy"
    },
    "ogx_mmlux_el-anatomy": {
      "acc,none": 0.42962962962962964,
      "acc_stderr,none": 0.04276349494376599,
      "alias": "ogx_mmlux_el-anatomy"
    },
    "ogx_mmlux_el-abstract_algebra": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_el-abstract_algebra"
    },
    "ogx_mmlux_de-world_religions": {
      "acc,none": 0.6666666666666666,
      "acc_stderr,none": 0.03615507630310935,
      "alias": "ogx_mmlux_de-world_religions"
    },
    "ogx_mmlux_de-virology": {
      "acc,none": 0.4036144578313253,
      "acc_stderr,none": 0.038194861407583984,
      "alias": "ogx_mmlux_de-virology"
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "acc,none": 0.77,
      "acc_stderr,none": 0.042295258468165065,
      "alias": "ogx_mmlux_de-us_foreign_policy"
    },
    "ogx_mmlux_de-sociology": {
      "acc,none": 0.736318407960199,
      "acc_stderr,none": 0.031157150869355554,
      "alias": "ogx_mmlux_de-sociology"
    },
    "ogx_mmlux_de-security_studies": {
      "acc,none": 0.6612244897959184,
      "acc_stderr,none": 0.03029950656215418,
      "alias": "ogx_mmlux_de-security_studies"
    },
    "ogx_mmlux_de-public_relations": {
      "acc,none": 0.5909090909090909,
      "acc_stderr,none": 0.04709306978661896,
      "alias": "ogx_mmlux_de-public_relations"
    },
    "ogx_mmlux_de-professional_psychology": {
      "acc,none": 0.4738562091503268,
      "acc_stderr,none": 0.020200164564804588,
      "alias": "ogx_mmlux_de-professional_psychology"
    },
    "ogx_mmlux_de-professional_medicine": {
      "acc,none": 0.48161764705882354,
      "acc_stderr,none": 0.030352303395351964,
      "alias": "ogx_mmlux_de-professional_medicine"
    },
    "ogx_mmlux_de-professional_law": {
      "acc,none": 0.379400260756193,
      "acc_stderr,none": 0.012393202029825407,
      "alias": "ogx_mmlux_de-professional_law"
    },
    "ogx_mmlux_de-professional_accounting": {
      "acc,none": 0.3829787234042553,
      "acc_stderr,none": 0.02899908090480618,
      "alias": "ogx_mmlux_de-professional_accounting"
    },
    "ogx_mmlux_de-prehistory": {
      "acc,none": 0.5555555555555556,
      "acc_stderr,none": 0.02764847787741332,
      "alias": "ogx_mmlux_de-prehistory"
    },
    "ogx_mmlux_de-philosophy": {
      "acc,none": 0.5787781350482315,
      "acc_stderr,none": 0.028043399858210628,
      "alias": "ogx_mmlux_de-philosophy"
    },
    "ogx_mmlux_de-nutrition": {
      "acc,none": 0.5947712418300654,
      "acc_stderr,none": 0.028110928492809065,
      "alias": "ogx_mmlux_de-nutrition"
    },
    "ogx_mmlux_de-moral_scenarios": {
      "acc,none": 0.2636871508379888,
      "acc_stderr,none": 0.014736926383761976,
      "alias": "ogx_mmlux_de-moral_scenarios"
    },
    "ogx_mmlux_de-moral_disputes": {
      "acc,none": 0.5664739884393064,
      "acc_stderr,none": 0.026680134761679217,
      "alias": "ogx_mmlux_de-moral_disputes"
    },
    "ogx_mmlux_de-miscellaneous": {
      "acc,none": 0.6832694763729247,
      "acc_stderr,none": 0.016635566427712578,
      "alias": "ogx_mmlux_de-miscellaneous"
    },
    "ogx_mmlux_de-medical_genetics": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_de-medical_genetics"
    },
    "ogx_mmlux_de-marketing": {
      "acc,none": 0.7393162393162394,
      "acc_stderr,none": 0.02876034895652341,
      "alias": "ogx_mmlux_de-marketing"
    },
    "ogx_mmlux_de-management": {
      "acc,none": 0.6796116504854369,
      "acc_stderr,none": 0.04620284082280041,
      "alias": "ogx_mmlux_de-management"
    },
    "ogx_mmlux_de-machine_learning": {
      "acc,none": 0.4017857142857143,
      "acc_stderr,none": 0.04653333146973646,
      "alias": "ogx_mmlux_de-machine_learning"
    },
    "ogx_mmlux_de-logical_fallacies": {
      "acc,none": 0.5828220858895705,
      "acc_stderr,none": 0.038741028598180814,
      "alias": "ogx_mmlux_de-logical_fallacies"
    },
    "ogx_mmlux_de-jurisprudence": {
      "acc,none": 0.5925925925925926,
      "acc_stderr,none": 0.04750077341199985,
      "alias": "ogx_mmlux_de-jurisprudence"
    },
    "ogx_mmlux_de-international_law": {
      "acc,none": 0.7272727272727273,
      "acc_stderr,none": 0.04065578140908705,
      "alias": "ogx_mmlux_de-international_law"
    },
    "ogx_mmlux_de-human_sexuality": {
      "acc,none": 0.6259541984732825,
      "acc_stderr,none": 0.04243869242230524,
      "alias": "ogx_mmlux_de-human_sexuality"
    },
    "ogx_mmlux_de-human_aging": {
      "acc,none": 0.6143497757847534,
      "acc_stderr,none": 0.03266842214289201,
      "alias": "ogx_mmlux_de-human_aging"
    },
    "ogx_mmlux_de-high_school_world_history": {
      "acc,none": 0.729957805907173,
      "acc_stderr,none": 0.028900721906293426,
      "alias": "ogx_mmlux_de-high_school_world_history"
    },
    "ogx_mmlux_de-high_school_us_history": {
      "acc,none": 0.7156862745098039,
      "acc_stderr,none": 0.03166009679399811,
      "alias": "ogx_mmlux_de-high_school_us_history"
    },
    "ogx_mmlux_de-high_school_statistics": {
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.033622774366080424,
      "alias": "ogx_mmlux_de-high_school_statistics"
    },
    "ogx_mmlux_de-high_school_psychology": {
      "acc,none": 0.6642201834862386,
      "acc_stderr,none": 0.020248081396752927,
      "alias": "ogx_mmlux_de-high_school_psychology"
    },
    "ogx_mmlux_de-high_school_physics": {
      "acc,none": 0.39072847682119205,
      "acc_stderr,none": 0.03983798306659806,
      "alias": "ogx_mmlux_de-high_school_physics"
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "acc,none": 0.46638655462184875,
      "acc_stderr,none": 0.03240501447690071,
      "alias": "ogx_mmlux_de-high_school_microeconomics"
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "acc,none": 0.32222222222222224,
      "acc_stderr,none": 0.028493465091028597,
      "alias": "ogx_mmlux_de-high_school_mathematics"
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "acc,none": 0.47692307692307695,
      "acc_stderr,none": 0.025323990861736118,
      "alias": "ogx_mmlux_de-high_school_macroeconomics"
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "acc,none": 0.6839378238341969,
      "acc_stderr,none": 0.033553973696861736,
      "alias": "ogx_mmlux_de-high_school_government_and_politics"
    },
    "ogx_mmlux_de-high_school_geography": {
      "acc,none": 0.696969696969697,
      "acc_stderr,none": 0.032742879140268674,
      "alias": "ogx_mmlux_de-high_school_geography"
    },
    "ogx_mmlux_de-high_school_european_history": {
      "acc,none": 0.6787878787878788,
      "acc_stderr,none": 0.03646204963253812,
      "alias": "ogx_mmlux_de-high_school_european_history"
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.04878317312145633,
      "alias": "ogx_mmlux_de-high_school_computer_science"
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "acc,none": 0.3842364532019704,
      "acc_stderr,none": 0.03422398565657551,
      "alias": "ogx_mmlux_de-high_school_chemistry"
    },
    "ogx_mmlux_de-high_school_biology": {
      "acc,none": 0.5709677419354838,
      "acc_stderr,none": 0.028156036538233193,
      "alias": "ogx_mmlux_de-high_school_biology"
    },
    "ogx_mmlux_de-global_facts": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_de-global_facts"
    },
    "ogx_mmlux_de-formal_logic": {
      "acc,none": 0.29365079365079366,
      "acc_stderr,none": 0.04073524322147126,
      "alias": "ogx_mmlux_de-formal_logic"
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "acc,none": 0.3439153439153439,
      "acc_stderr,none": 0.024464426625596437,
      "alias": "ogx_mmlux_de-elementary_mathematics"
    },
    "ogx_mmlux_de-electrical_engineering": {
      "acc,none": 0.4896551724137931,
      "acc_stderr,none": 0.04165774775728763,
      "alias": "ogx_mmlux_de-electrical_engineering"
    },
    "ogx_mmlux_de-econometrics": {
      "acc,none": 0.2719298245614035,
      "acc_stderr,none": 0.04185774424022056,
      "alias": "ogx_mmlux_de-econometrics"
    },
    "ogx_mmlux_de-conceptual_physics": {
      "acc,none": 0.4127659574468085,
      "acc_stderr,none": 0.03218471141400352,
      "alias": "ogx_mmlux_de-conceptual_physics"
    },
    "ogx_mmlux_de-computer_security": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_de-computer_security"
    },
    "ogx_mmlux_de-college_physics": {
      "acc,none": 0.24509803921568626,
      "acc_stderr,none": 0.042801058373643945,
      "alias": "ogx_mmlux_de-college_physics"
    },
    "ogx_mmlux_de-college_medicine": {
      "acc,none": 0.4797687861271676,
      "acc_stderr,none": 0.03809342081273957,
      "alias": "ogx_mmlux_de-college_medicine"
    },
    "ogx_mmlux_de-college_mathematics": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_de-college_mathematics"
    },
    "ogx_mmlux_de-college_computer_science": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_de-college_computer_science"
    },
    "ogx_mmlux_de-college_chemistry": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_de-college_chemistry"
    },
    "ogx_mmlux_de-college_biology": {
      "acc,none": 0.4722222222222222,
      "acc_stderr,none": 0.04174752578923185,
      "alias": "ogx_mmlux_de-college_biology"
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "acc,none": 0.49056603773584906,
      "acc_stderr,none": 0.0307673947078081,
      "alias": "ogx_mmlux_de-clinical_knowledge"
    },
    "ogx_mmlux_de-business_ethics": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_de-business_ethics"
    },
    "ogx_mmlux_de-astronomy": {
      "acc,none": 0.5592105263157895,
      "acc_stderr,none": 0.04040311062490436,
      "alias": "ogx_mmlux_de-astronomy"
    },
    "ogx_mmlux_de-anatomy": {
      "acc,none": 0.4740740740740741,
      "acc_stderr,none": 0.04313531696750574,
      "alias": "ogx_mmlux_de-anatomy"
    },
    "ogx_mmlux_de-abstract_algebra": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_de-abstract_algebra"
    },
    "ogx_mmlux_da-world_religions": {
      "acc,none": 0.6081871345029239,
      "acc_stderr,none": 0.037439798259264,
      "alias": "ogx_mmlux_da-world_religions"
    },
    "ogx_mmlux_da-virology": {
      "acc,none": 0.42168674698795183,
      "acc_stderr,none": 0.03844453181770917,
      "alias": "ogx_mmlux_da-virology"
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_da-us_foreign_policy"
    },
    "ogx_mmlux_da-sociology": {
      "acc,none": 0.6517412935323383,
      "acc_stderr,none": 0.03368787466115459,
      "alias": "ogx_mmlux_da-sociology"
    },
    "ogx_mmlux_da-security_studies": {
      "acc,none": 0.5591836734693878,
      "acc_stderr,none": 0.03178419114175364,
      "alias": "ogx_mmlux_da-security_studies"
    },
    "ogx_mmlux_da-public_relations": {
      "acc,none": 0.4909090909090909,
      "acc_stderr,none": 0.04788339768702861,
      "alias": "ogx_mmlux_da-public_relations"
    },
    "ogx_mmlux_da-professional_psychology": {
      "acc,none": 0.3839869281045752,
      "acc_stderr,none": 0.01967580813528152,
      "alias": "ogx_mmlux_da-professional_psychology"
    },
    "ogx_mmlux_da-professional_medicine": {
      "acc,none": 0.3492647058823529,
      "acc_stderr,none": 0.02895975519682486,
      "alias": "ogx_mmlux_da-professional_medicine"
    },
    "ogx_mmlux_da-professional_law": {
      "acc,none": 0.32333767926988266,
      "acc_stderr,none": 0.011946565758447197,
      "alias": "ogx_mmlux_da-professional_law"
    },
    "ogx_mmlux_da-professional_accounting": {
      "acc,none": 0.31560283687943264,
      "acc_stderr,none": 0.027724989449509314,
      "alias": "ogx_mmlux_da-professional_accounting"
    },
    "ogx_mmlux_da-prehistory": {
      "acc,none": 0.4351851851851852,
      "acc_stderr,none": 0.027586006221607708,
      "alias": "ogx_mmlux_da-prehistory"
    },
    "ogx_mmlux_da-philosophy": {
      "acc,none": 0.4694533762057878,
      "acc_stderr,none": 0.028345045864840684,
      "alias": "ogx_mmlux_da-philosophy"
    },
    "ogx_mmlux_da-nutrition": {
      "acc,none": 0.4869281045751634,
      "acc_stderr,none": 0.028620130800700246,
      "alias": "ogx_mmlux_da-nutrition"
    },
    "ogx_mmlux_da-moral_scenarios": {
      "acc,none": 0.23910614525139665,
      "acc_stderr,none": 0.01426555419233115,
      "alias": "ogx_mmlux_da-moral_scenarios"
    },
    "ogx_mmlux_da-moral_disputes": {
      "acc,none": 0.5115606936416185,
      "acc_stderr,none": 0.02691189868637792,
      "alias": "ogx_mmlux_da-moral_disputes"
    },
    "ogx_mmlux_da-miscellaneous": {
      "acc,none": 0.5363984674329502,
      "acc_stderr,none": 0.01783252407959326,
      "alias": "ogx_mmlux_da-miscellaneous"
    },
    "ogx_mmlux_da-medical_genetics": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_da-medical_genetics"
    },
    "ogx_mmlux_da-marketing": {
      "acc,none": 0.6495726495726496,
      "acc_stderr,none": 0.03125610824421881,
      "alias": "ogx_mmlux_da-marketing"
    },
    "ogx_mmlux_da-management": {
      "acc,none": 0.5825242718446602,
      "acc_stderr,none": 0.048828405482122375,
      "alias": "ogx_mmlux_da-management"
    },
    "ogx_mmlux_da-machine_learning": {
      "acc,none": 0.38392857142857145,
      "acc_stderr,none": 0.04616143075028547,
      "alias": "ogx_mmlux_da-machine_learning"
    },
    "ogx_mmlux_da-logical_fallacies": {
      "acc,none": 0.44785276073619634,
      "acc_stderr,none": 0.03906947479456601,
      "alias": "ogx_mmlux_da-logical_fallacies"
    },
    "ogx_mmlux_da-jurisprudence": {
      "acc,none": 0.5648148148148148,
      "acc_stderr,none": 0.04792898170907062,
      "alias": "ogx_mmlux_da-jurisprudence"
    },
    "ogx_mmlux_da-international_law": {
      "acc,none": 0.5867768595041323,
      "acc_stderr,none": 0.04495087843548408,
      "alias": "ogx_mmlux_da-international_law"
    },
    "ogx_mmlux_da-human_sexuality": {
      "acc,none": 0.4961832061068702,
      "acc_stderr,none": 0.043851623256015534,
      "alias": "ogx_mmlux_da-human_sexuality"
    },
    "ogx_mmlux_da-human_aging": {
      "acc,none": 0.48878923766816146,
      "acc_stderr,none": 0.033549366530984746,
      "alias": "ogx_mmlux_da-human_aging"
    },
    "ogx_mmlux_da-high_school_world_history": {
      "acc,none": 0.5949367088607594,
      "acc_stderr,none": 0.03195514741370671,
      "alias": "ogx_mmlux_da-high_school_world_history"
    },
    "ogx_mmlux_da-high_school_us_history": {
      "acc,none": 0.5441176470588235,
      "acc_stderr,none": 0.03495624522015477,
      "alias": "ogx_mmlux_da-high_school_us_history"
    },
    "ogx_mmlux_da-high_school_statistics": {
      "acc,none": 0.28703703703703703,
      "acc_stderr,none": 0.030851992993257017,
      "alias": "ogx_mmlux_da-high_school_statistics"
    },
    "ogx_mmlux_da-high_school_psychology": {
      "acc,none": 0.48440366972477067,
      "acc_stderr,none": 0.02142689153920805,
      "alias": "ogx_mmlux_da-high_school_psychology"
    },
    "ogx_mmlux_da-high_school_physics": {
      "acc,none": 0.3509933774834437,
      "acc_stderr,none": 0.03896981964257375,
      "alias": "ogx_mmlux_da-high_school_physics"
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "acc,none": 0.4369747899159664,
      "acc_stderr,none": 0.03221943636566196,
      "alias": "ogx_mmlux_da-high_school_microeconomics"
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "acc,none": 0.2518518518518518,
      "acc_stderr,none": 0.026466117538959912,
      "alias": "ogx_mmlux_da-high_school_mathematics"
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "acc,none": 0.3641025641025641,
      "acc_stderr,none": 0.024396672985094774,
      "alias": "ogx_mmlux_da-high_school_macroeconomics"
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "acc,none": 0.5077720207253886,
      "acc_stderr,none": 0.03608003225569653,
      "alias": "ogx_mmlux_da-high_school_government_and_politics"
    },
    "ogx_mmlux_da-high_school_geography": {
      "acc,none": 0.5353535353535354,
      "acc_stderr,none": 0.03553436368828063,
      "alias": "ogx_mmlux_da-high_school_geography"
    },
    "ogx_mmlux_da-high_school_european_history": {
      "acc,none": 0.5515151515151515,
      "acc_stderr,none": 0.03883565977956928,
      "alias": "ogx_mmlux_da-high_school_european_history"
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_da-high_school_computer_science"
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "acc,none": 0.37438423645320196,
      "acc_stderr,none": 0.03405155380561952,
      "alias": "ogx_mmlux_da-high_school_chemistry"
    },
    "ogx_mmlux_da-high_school_biology": {
      "acc,none": 0.43870967741935485,
      "acc_stderr,none": 0.028229497320317216,
      "alias": "ogx_mmlux_da-high_school_biology"
    },
    "ogx_mmlux_da-global_facts": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.04461960433384739,
      "alias": "ogx_mmlux_da-global_facts"
    },
    "ogx_mmlux_da-formal_logic": {
      "acc,none": 0.2698412698412698,
      "acc_stderr,none": 0.03970158273235172,
      "alias": "ogx_mmlux_da-formal_logic"
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "acc,none": 0.29365079365079366,
      "acc_stderr,none": 0.02345603738398203,
      "alias": "ogx_mmlux_da-elementary_mathematics"
    },
    "ogx_mmlux_da-electrical_engineering": {
      "acc,none": 0.4896551724137931,
      "acc_stderr,none": 0.04165774775728763,
      "alias": "ogx_mmlux_da-electrical_engineering"
    },
    "ogx_mmlux_da-econometrics": {
      "acc,none": 0.2982456140350877,
      "acc_stderr,none": 0.04303684033537315,
      "alias": "ogx_mmlux_da-econometrics"
    },
    "ogx_mmlux_da-conceptual_physics": {
      "acc,none": 0.37446808510638296,
      "acc_stderr,none": 0.03163910665367291,
      "alias": "ogx_mmlux_da-conceptual_physics"
    },
    "ogx_mmlux_da-computer_security": {
      "acc,none": 0.57,
      "acc_stderr,none": 0.04975698519562428,
      "alias": "ogx_mmlux_da-computer_security"
    },
    "ogx_mmlux_da-college_physics": {
      "acc,none": 0.24509803921568626,
      "acc_stderr,none": 0.042801058373643945,
      "alias": "ogx_mmlux_da-college_physics"
    },
    "ogx_mmlux_da-college_medicine": {
      "acc,none": 0.41040462427745666,
      "acc_stderr,none": 0.03750757044895537,
      "alias": "ogx_mmlux_da-college_medicine"
    },
    "ogx_mmlux_da-college_mathematics": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_da-college_mathematics"
    },
    "ogx_mmlux_da-college_computer_science": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_da-college_computer_science"
    },
    "ogx_mmlux_da-college_chemistry": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252604,
      "alias": "ogx_mmlux_da-college_chemistry"
    },
    "ogx_mmlux_da-college_biology": {
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.039420826399272135,
      "alias": "ogx_mmlux_da-college_biology"
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "acc,none": 0.39245283018867927,
      "acc_stderr,none": 0.030052580579557852,
      "alias": "ogx_mmlux_da-clinical_knowledge"
    },
    "ogx_mmlux_da-business_ethics": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_da-business_ethics"
    },
    "ogx_mmlux_da-astronomy": {
      "acc,none": 0.45394736842105265,
      "acc_stderr,none": 0.04051646342874142,
      "alias": "ogx_mmlux_da-astronomy"
    },
    "ogx_mmlux_da-anatomy": {
      "acc,none": 0.42962962962962964,
      "acc_stderr,none": 0.04276349494376599,
      "alias": "ogx_mmlux_da-anatomy"
    },
    "ogx_mmlux_da-abstract_algebra": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_da-abstract_algebra"
    },
    "ogx_mmlux_cs-world_religions": {
      "acc,none": 0.6257309941520468,
      "acc_stderr,none": 0.03711601185389481,
      "alias": "ogx_mmlux_cs-world_religions"
    },
    "ogx_mmlux_cs-virology": {
      "acc,none": 0.41566265060240964,
      "acc_stderr,none": 0.03836722176598052,
      "alias": "ogx_mmlux_cs-virology"
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "acc,none": 0.69,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_cs-us_foreign_policy"
    },
    "ogx_mmlux_cs-sociology": {
      "acc,none": 0.6965174129353234,
      "acc_stderr,none": 0.03251006816458618,
      "alias": "ogx_mmlux_cs-sociology"
    },
    "ogx_mmlux_cs-security_studies": {
      "acc,none": 0.6489795918367347,
      "acc_stderr,none": 0.03055531675557364,
      "alias": "ogx_mmlux_cs-security_studies"
    },
    "ogx_mmlux_cs-public_relations": {
      "acc,none": 0.6090909090909091,
      "acc_stderr,none": 0.04673752333670238,
      "alias": "ogx_mmlux_cs-public_relations"
    },
    "ogx_mmlux_cs-professional_psychology": {
      "acc,none": 0.45098039215686275,
      "acc_stderr,none": 0.020130388312904528,
      "alias": "ogx_mmlux_cs-professional_psychology"
    },
    "ogx_mmlux_cs-professional_medicine": {
      "acc,none": 0.39705882352941174,
      "acc_stderr,none": 0.029722152099280058,
      "alias": "ogx_mmlux_cs-professional_medicine"
    },
    "ogx_mmlux_cs-professional_law": {
      "acc,none": 0.3898305084745763,
      "acc_stderr,none": 0.012456386619082606,
      "alias": "ogx_mmlux_cs-professional_law"
    },
    "ogx_mmlux_cs-professional_accounting": {
      "acc,none": 0.3475177304964539,
      "acc_stderr,none": 0.02840662780959095,
      "alias": "ogx_mmlux_cs-professional_accounting"
    },
    "ogx_mmlux_cs-prehistory": {
      "acc,none": 0.5123456790123457,
      "acc_stderr,none": 0.027812262269327235,
      "alias": "ogx_mmlux_cs-prehistory"
    },
    "ogx_mmlux_cs-philosophy": {
      "acc,none": 0.572347266881029,
      "acc_stderr,none": 0.02809924077580957,
      "alias": "ogx_mmlux_cs-philosophy"
    },
    "ogx_mmlux_cs-nutrition": {
      "acc,none": 0.5915032679738562,
      "acc_stderr,none": 0.028146405993096358,
      "alias": "ogx_mmlux_cs-nutrition"
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "acc,none": 0.2324022346368715,
      "acc_stderr,none": 0.014125968754673392,
      "alias": "ogx_mmlux_cs-moral_scenarios"
    },
    "ogx_mmlux_cs-moral_disputes": {
      "acc,none": 0.5317919075144508,
      "acc_stderr,none": 0.02686462436675666,
      "alias": "ogx_mmlux_cs-moral_disputes"
    },
    "ogx_mmlux_cs-miscellaneous": {
      "acc,none": 0.6462324393358876,
      "acc_stderr,none": 0.017098184708161903,
      "alias": "ogx_mmlux_cs-miscellaneous"
    },
    "ogx_mmlux_cs-medical_genetics": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_cs-medical_genetics"
    },
    "ogx_mmlux_cs-marketing": {
      "acc,none": 0.7435897435897436,
      "acc_stderr,none": 0.028605953702004257,
      "alias": "ogx_mmlux_cs-marketing"
    },
    "ogx_mmlux_cs-management": {
      "acc,none": 0.6310679611650486,
      "acc_stderr,none": 0.0477761518115674,
      "alias": "ogx_mmlux_cs-management"
    },
    "ogx_mmlux_cs-machine_learning": {
      "acc,none": 0.38392857142857145,
      "acc_stderr,none": 0.04616143075028547,
      "alias": "ogx_mmlux_cs-machine_learning"
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "acc,none": 0.5337423312883436,
      "acc_stderr,none": 0.039194155450484096,
      "alias": "ogx_mmlux_cs-logical_fallacies"
    },
    "ogx_mmlux_cs-jurisprudence": {
      "acc,none": 0.5740740740740741,
      "acc_stderr,none": 0.0478034362693679,
      "alias": "ogx_mmlux_cs-jurisprudence"
    },
    "ogx_mmlux_cs-international_law": {
      "acc,none": 0.6446280991735537,
      "acc_stderr,none": 0.04369236326573981,
      "alias": "ogx_mmlux_cs-international_law"
    },
    "ogx_mmlux_cs-human_sexuality": {
      "acc,none": 0.6259541984732825,
      "acc_stderr,none": 0.042438692422305246,
      "alias": "ogx_mmlux_cs-human_sexuality"
    },
    "ogx_mmlux_cs-human_aging": {
      "acc,none": 0.6143497757847534,
      "acc_stderr,none": 0.03266842214289201,
      "alias": "ogx_mmlux_cs-human_aging"
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "acc,none": 0.6455696202531646,
      "acc_stderr,none": 0.031137304297185812,
      "alias": "ogx_mmlux_cs-high_school_world_history"
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "acc,none": 0.6617647058823529,
      "acc_stderr,none": 0.03320574612945431,
      "alias": "ogx_mmlux_cs-high_school_us_history"
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "acc,none": 0.39351851851851855,
      "acc_stderr,none": 0.03331747876370312,
      "alias": "ogx_mmlux_cs-high_school_statistics"
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "acc,none": 0.673394495412844,
      "acc_stderr,none": 0.020106990889937296,
      "alias": "ogx_mmlux_cs-high_school_psychology"
    },
    "ogx_mmlux_cs-high_school_physics": {
      "acc,none": 0.3443708609271523,
      "acc_stderr,none": 0.038796870240733264,
      "alias": "ogx_mmlux_cs-high_school_physics"
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "acc,none": 0.44537815126050423,
      "acc_stderr,none": 0.032284106267163895,
      "alias": "ogx_mmlux_cs-high_school_microeconomics"
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.027940457136228416,
      "alias": "ogx_mmlux_cs-high_school_mathematics"
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "acc,none": 0.4307692307692308,
      "acc_stderr,none": 0.02510682066053975,
      "alias": "ogx_mmlux_cs-high_school_macroeconomics"
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "acc,none": 0.616580310880829,
      "acc_stderr,none": 0.03508984236295343,
      "alias": "ogx_mmlux_cs-high_school_government_and_politics"
    },
    "ogx_mmlux_cs-high_school_geography": {
      "acc,none": 0.6414141414141414,
      "acc_stderr,none": 0.034169036403915214,
      "alias": "ogx_mmlux_cs-high_school_geography"
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "acc,none": 0.6848484848484848,
      "acc_stderr,none": 0.0362773057502241,
      "alias": "ogx_mmlux_cs-high_school_european_history"
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_cs-high_school_computer_science"
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "acc,none": 0.35467980295566504,
      "acc_stderr,none": 0.03366124489051449,
      "alias": "ogx_mmlux_cs-high_school_chemistry"
    },
    "ogx_mmlux_cs-high_school_biology": {
      "acc,none": 0.5516129032258065,
      "acc_stderr,none": 0.028292056830112728,
      "alias": "ogx_mmlux_cs-high_school_biology"
    },
    "ogx_mmlux_cs-global_facts": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_cs-global_facts"
    },
    "ogx_mmlux_cs-formal_logic": {
      "acc,none": 0.30952380952380953,
      "acc_stderr,none": 0.04134913018303316,
      "alias": "ogx_mmlux_cs-formal_logic"
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "acc,none": 0.3544973544973545,
      "acc_stderr,none": 0.024636830602841997,
      "alias": "ogx_mmlux_cs-elementary_mathematics"
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "acc,none": 0.5241379310344828,
      "acc_stderr,none": 0.0416180850350153,
      "alias": "ogx_mmlux_cs-electrical_engineering"
    },
    "ogx_mmlux_cs-econometrics": {
      "acc,none": 0.34210526315789475,
      "acc_stderr,none": 0.044629175353369376,
      "alias": "ogx_mmlux_cs-econometrics"
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "acc,none": 0.40425531914893614,
      "acc_stderr,none": 0.032081157507886836,
      "alias": "ogx_mmlux_cs-conceptual_physics"
    },
    "ogx_mmlux_cs-computer_security": {
      "acc,none": 0.64,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_cs-computer_security"
    },
    "ogx_mmlux_cs-college_physics": {
      "acc,none": 0.20588235294117646,
      "acc_stderr,none": 0.040233822736177455,
      "alias": "ogx_mmlux_cs-college_physics"
    },
    "ogx_mmlux_cs-college_medicine": {
      "acc,none": 0.4277456647398844,
      "acc_stderr,none": 0.03772446857518026,
      "alias": "ogx_mmlux_cs-college_medicine"
    },
    "ogx_mmlux_cs-college_mathematics": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_cs-college_mathematics"
    },
    "ogx_mmlux_cs-college_computer_science": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_cs-college_computer_science"
    },
    "ogx_mmlux_cs-college_chemistry": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_cs-college_chemistry"
    },
    "ogx_mmlux_cs-college_biology": {
      "acc,none": 0.4722222222222222,
      "acc_stderr,none": 0.04174752578923185,
      "alias": "ogx_mmlux_cs-college_biology"
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "acc,none": 0.5018867924528302,
      "acc_stderr,none": 0.030772653642075664,
      "alias": "ogx_mmlux_cs-clinical_knowledge"
    },
    "ogx_mmlux_cs-business_ethics": {
      "acc,none": 0.55,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_cs-business_ethics"
    },
    "ogx_mmlux_cs-astronomy": {
      "acc,none": 0.5592105263157895,
      "acc_stderr,none": 0.04040311062490436,
      "alias": "ogx_mmlux_cs-astronomy"
    },
    "ogx_mmlux_cs-anatomy": {
      "acc,none": 0.4148148148148148,
      "acc_stderr,none": 0.042561937679014075,
      "alias": "ogx_mmlux_cs-anatomy"
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.047258156262526045,
      "alias": "ogx_mmlux_cs-abstract_algebra"
    },
    "ogx_mmlux_bg-world_religions": {
      "acc,none": 0.5555555555555556,
      "acc_stderr,none": 0.038110796698335316,
      "alias": "ogx_mmlux_bg-world_religions"
    },
    "ogx_mmlux_bg-virology": {
      "acc,none": 0.39759036144578314,
      "acc_stderr,none": 0.03809973084540218,
      "alias": "ogx_mmlux_bg-virology"
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "acc,none": 0.56,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_bg-us_foreign_policy"
    },
    "ogx_mmlux_bg-sociology": {
      "acc,none": 0.48756218905472637,
      "acc_stderr,none": 0.03534439848539579,
      "alias": "ogx_mmlux_bg-sociology"
    },
    "ogx_mmlux_bg-security_studies": {
      "acc,none": 0.5306122448979592,
      "acc_stderr,none": 0.031949171367580624,
      "alias": "ogx_mmlux_bg-security_studies"
    },
    "ogx_mmlux_bg-public_relations": {
      "acc,none": 0.45454545454545453,
      "acc_stderr,none": 0.04769300568972744,
      "alias": "ogx_mmlux_bg-public_relations"
    },
    "ogx_mmlux_bg-professional_psychology": {
      "acc,none": 0.35947712418300654,
      "acc_stderr,none": 0.01941253924203216,
      "alias": "ogx_mmlux_bg-professional_psychology"
    },
    "ogx_mmlux_bg-professional_medicine": {
      "acc,none": 0.3125,
      "acc_stderr,none": 0.02815637344037142,
      "alias": "ogx_mmlux_bg-professional_medicine"
    },
    "ogx_mmlux_bg-professional_law": {
      "acc,none": 0.31486310299869624,
      "acc_stderr,none": 0.011862561755715928,
      "alias": "ogx_mmlux_bg-professional_law"
    },
    "ogx_mmlux_bg-professional_accounting": {
      "acc,none": 0.3723404255319149,
      "acc_stderr,none": 0.028838921471251455,
      "alias": "ogx_mmlux_bg-professional_accounting"
    },
    "ogx_mmlux_bg-prehistory": {
      "acc,none": 0.38271604938271603,
      "acc_stderr,none": 0.027044538138402602,
      "alias": "ogx_mmlux_bg-prehistory"
    },
    "ogx_mmlux_bg-philosophy": {
      "acc,none": 0.4790996784565916,
      "acc_stderr,none": 0.028373270961069414,
      "alias": "ogx_mmlux_bg-philosophy"
    },
    "ogx_mmlux_bg-nutrition": {
      "acc,none": 0.4411764705882353,
      "acc_stderr,none": 0.028431095444176647,
      "alias": "ogx_mmlux_bg-nutrition"
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "acc,none": 0.23687150837988827,
      "acc_stderr,none": 0.01421957078810398,
      "alias": "ogx_mmlux_bg-moral_scenarios"
    },
    "ogx_mmlux_bg-moral_disputes": {
      "acc,none": 0.4653179190751445,
      "acc_stderr,none": 0.026854257928258893,
      "alias": "ogx_mmlux_bg-moral_disputes"
    },
    "ogx_mmlux_bg-miscellaneous": {
      "acc,none": 0.4955300127713921,
      "acc_stderr,none": 0.017879248970584374,
      "alias": "ogx_mmlux_bg-miscellaneous"
    },
    "ogx_mmlux_bg-medical_genetics": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_bg-medical_genetics"
    },
    "ogx_mmlux_bg-marketing": {
      "acc,none": 0.6068376068376068,
      "acc_stderr,none": 0.03199957924651047,
      "alias": "ogx_mmlux_bg-marketing"
    },
    "ogx_mmlux_bg-management": {
      "acc,none": 0.5242718446601942,
      "acc_stderr,none": 0.049449010929737795,
      "alias": "ogx_mmlux_bg-management"
    },
    "ogx_mmlux_bg-machine_learning": {
      "acc,none": 0.375,
      "acc_stderr,none": 0.04595091388086298,
      "alias": "ogx_mmlux_bg-machine_learning"
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "acc,none": 0.4662576687116564,
      "acc_stderr,none": 0.039194155450484096,
      "alias": "ogx_mmlux_bg-logical_fallacies"
    },
    "ogx_mmlux_bg-jurisprudence": {
      "acc,none": 0.5277777777777778,
      "acc_stderr,none": 0.04826217294139894,
      "alias": "ogx_mmlux_bg-jurisprudence"
    },
    "ogx_mmlux_bg-international_law": {
      "acc,none": 0.5454545454545454,
      "acc_stderr,none": 0.045454545454545484,
      "alias": "ogx_mmlux_bg-international_law"
    },
    "ogx_mmlux_bg-human_sexuality": {
      "acc,none": 0.42748091603053434,
      "acc_stderr,none": 0.04338920305792401,
      "alias": "ogx_mmlux_bg-human_sexuality"
    },
    "ogx_mmlux_bg-human_aging": {
      "acc,none": 0.38565022421524664,
      "acc_stderr,none": 0.03266842214289201,
      "alias": "ogx_mmlux_bg-human_aging"
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "acc,none": 0.5358649789029536,
      "acc_stderr,none": 0.03246338898055659,
      "alias": "ogx_mmlux_bg-high_school_world_history"
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "acc,none": 0.4362745098039216,
      "acc_stderr,none": 0.03480693138457039,
      "alias": "ogx_mmlux_bg-high_school_us_history"
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.032149521478027486,
      "alias": "ogx_mmlux_bg-high_school_statistics"
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "acc,none": 0.42385321100917434,
      "acc_stderr,none": 0.02118726320908751,
      "alias": "ogx_mmlux_bg-high_school_psychology"
    },
    "ogx_mmlux_bg-high_school_physics": {
      "acc,none": 0.32450331125827814,
      "acc_stderr,none": 0.038227469376587525,
      "alias": "ogx_mmlux_bg-high_school_physics"
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "acc,none": 0.3739495798319328,
      "acc_stderr,none": 0.031429466378837076,
      "alias": "ogx_mmlux_bg-high_school_microeconomics"
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "acc,none": 0.25925925925925924,
      "acc_stderr,none": 0.02671924078371217,
      "alias": "ogx_mmlux_bg-high_school_mathematics"
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "acc,none": 0.3230769230769231,
      "acc_stderr,none": 0.02371088850197057,
      "alias": "ogx_mmlux_bg-high_school_macroeconomics"
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "acc,none": 0.45077720207253885,
      "acc_stderr,none": 0.03590910952235524,
      "alias": "ogx_mmlux_bg-high_school_government_and_politics"
    },
    "ogx_mmlux_bg-high_school_geography": {
      "acc,none": 0.4797979797979798,
      "acc_stderr,none": 0.035594435655639196,
      "alias": "ogx_mmlux_bg-high_school_geography"
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "acc,none": 0.43636363636363634,
      "acc_stderr,none": 0.03872592983524754,
      "alias": "ogx_mmlux_bg-high_school_european_history"
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_bg-high_school_computer_science"
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "acc,none": 0.32019704433497537,
      "acc_stderr,none": 0.032826493853041504,
      "alias": "ogx_mmlux_bg-high_school_chemistry"
    },
    "ogx_mmlux_bg-high_school_biology": {
      "acc,none": 0.44516129032258067,
      "acc_stderr,none": 0.028272410186214906,
      "alias": "ogx_mmlux_bg-high_school_biology"
    },
    "ogx_mmlux_bg-global_facts": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_bg-global_facts"
    },
    "ogx_mmlux_bg-formal_logic": {
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.04216370213557835,
      "alias": "ogx_mmlux_bg-formal_logic"
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "acc,none": 0.2962962962962963,
      "acc_stderr,none": 0.023517294335963283,
      "alias": "ogx_mmlux_bg-elementary_mathematics"
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "acc,none": 0.45517241379310347,
      "acc_stderr,none": 0.04149886942192117,
      "alias": "ogx_mmlux_bg-electrical_engineering"
    },
    "ogx_mmlux_bg-econometrics": {
      "acc,none": 0.30701754385964913,
      "acc_stderr,none": 0.043391383225798594,
      "alias": "ogx_mmlux_bg-econometrics"
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "acc,none": 0.30638297872340425,
      "acc_stderr,none": 0.030135906478517563,
      "alias": "ogx_mmlux_bg-conceptual_physics"
    },
    "ogx_mmlux_bg-computer_security": {
      "acc,none": 0.54,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_bg-computer_security"
    },
    "ogx_mmlux_bg-college_physics": {
      "acc,none": 0.2549019607843137,
      "acc_stderr,none": 0.043364327079931785,
      "alias": "ogx_mmlux_bg-college_physics"
    },
    "ogx_mmlux_bg-college_medicine": {
      "acc,none": 0.3583815028901734,
      "acc_stderr,none": 0.036563436533531585,
      "alias": "ogx_mmlux_bg-college_medicine"
    },
    "ogx_mmlux_bg-college_mathematics": {
      "acc,none": 0.24,
      "acc_stderr,none": 0.042923469599092816,
      "alias": "ogx_mmlux_bg-college_mathematics"
    },
    "ogx_mmlux_bg-college_computer_science": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_bg-college_computer_science"
    },
    "ogx_mmlux_bg-college_chemistry": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695236,
      "alias": "ogx_mmlux_bg-college_chemistry"
    },
    "ogx_mmlux_bg-college_biology": {
      "acc,none": 0.3958333333333333,
      "acc_stderr,none": 0.04089465449325582,
      "alias": "ogx_mmlux_bg-college_biology"
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "acc,none": 0.41509433962264153,
      "acc_stderr,none": 0.030325945789286105,
      "alias": "ogx_mmlux_bg-clinical_knowledge"
    },
    "ogx_mmlux_bg-business_ethics": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_bg-business_ethics"
    },
    "ogx_mmlux_bg-astronomy": {
      "acc,none": 0.35526315789473684,
      "acc_stderr,none": 0.038947344870133176,
      "alias": "ogx_mmlux_bg-astronomy"
    },
    "ogx_mmlux_bg-anatomy": {
      "acc,none": 0.31851851851851853,
      "acc_stderr,none": 0.0402477840197711,
      "alias": "ogx_mmlux_bg-anatomy"
    },
    "ogx_mmlux_bg-abstract_algebra": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252604,
      "alias": "ogx_mmlux_bg-abstract_algebra"
    }
  },
  "group_subtasks": {
    "ogx_mmlux_bg-abstract_algebra": [],
    "ogx_mmlux_bg-anatomy": [],
    "ogx_mmlux_bg-astronomy": [],
    "ogx_mmlux_bg-business_ethics": [],
    "ogx_mmlux_bg-clinical_knowledge": [],
    "ogx_mmlux_bg-college_biology": [],
    "ogx_mmlux_bg-college_chemistry": [],
    "ogx_mmlux_bg-college_computer_science": [],
    "ogx_mmlux_bg-college_mathematics": [],
    "ogx_mmlux_bg-college_medicine": [],
    "ogx_mmlux_bg-college_physics": [],
    "ogx_mmlux_bg-computer_security": [],
    "ogx_mmlux_bg-conceptual_physics": [],
    "ogx_mmlux_bg-econometrics": [],
    "ogx_mmlux_bg-electrical_engineering": [],
    "ogx_mmlux_bg-elementary_mathematics": [],
    "ogx_mmlux_bg-formal_logic": [],
    "ogx_mmlux_bg-global_facts": [],
    "ogx_mmlux_bg-high_school_biology": [],
    "ogx_mmlux_bg-high_school_chemistry": [],
    "ogx_mmlux_bg-high_school_computer_science": [],
    "ogx_mmlux_bg-high_school_european_history": [],
    "ogx_mmlux_bg-high_school_geography": [],
    "ogx_mmlux_bg-high_school_government_and_politics": [],
    "ogx_mmlux_bg-high_school_macroeconomics": [],
    "ogx_mmlux_bg-high_school_mathematics": [],
    "ogx_mmlux_bg-high_school_microeconomics": [],
    "ogx_mmlux_bg-high_school_physics": [],
    "ogx_mmlux_bg-high_school_psychology": [],
    "ogx_mmlux_bg-high_school_statistics": [],
    "ogx_mmlux_bg-high_school_us_history": [],
    "ogx_mmlux_bg-high_school_world_history": [],
    "ogx_mmlux_bg-human_aging": [],
    "ogx_mmlux_bg-human_sexuality": [],
    "ogx_mmlux_bg-international_law": [],
    "ogx_mmlux_bg-jurisprudence": [],
    "ogx_mmlux_bg-logical_fallacies": [],
    "ogx_mmlux_bg-machine_learning": [],
    "ogx_mmlux_bg-management": [],
    "ogx_mmlux_bg-marketing": [],
    "ogx_mmlux_bg-medical_genetics": [],
    "ogx_mmlux_bg-miscellaneous": [],
    "ogx_mmlux_bg-moral_disputes": [],
    "ogx_mmlux_bg-moral_scenarios": [],
    "ogx_mmlux_bg-nutrition": [],
    "ogx_mmlux_bg-philosophy": [],
    "ogx_mmlux_bg-prehistory": [],
    "ogx_mmlux_bg-professional_accounting": [],
    "ogx_mmlux_bg-professional_law": [],
    "ogx_mmlux_bg-professional_medicine": [],
    "ogx_mmlux_bg-professional_psychology": [],
    "ogx_mmlux_bg-public_relations": [],
    "ogx_mmlux_bg-security_studies": [],
    "ogx_mmlux_bg-sociology": [],
    "ogx_mmlux_bg-us_foreign_policy": [],
    "ogx_mmlux_bg-virology": [],
    "ogx_mmlux_bg-world_religions": [],
    "ogx_mmlux_cs-abstract_algebra": [],
    "ogx_mmlux_cs-anatomy": [],
    "ogx_mmlux_cs-astronomy": [],
    "ogx_mmlux_cs-business_ethics": [],
    "ogx_mmlux_cs-clinical_knowledge": [],
    "ogx_mmlux_cs-college_biology": [],
    "ogx_mmlux_cs-college_chemistry": [],
    "ogx_mmlux_cs-college_computer_science": [],
    "ogx_mmlux_cs-college_mathematics": [],
    "ogx_mmlux_cs-college_medicine": [],
    "ogx_mmlux_cs-college_physics": [],
    "ogx_mmlux_cs-computer_security": [],
    "ogx_mmlux_cs-conceptual_physics": [],
    "ogx_mmlux_cs-econometrics": [],
    "ogx_mmlux_cs-electrical_engineering": [],
    "ogx_mmlux_cs-elementary_mathematics": [],
    "ogx_mmlux_cs-formal_logic": [],
    "ogx_mmlux_cs-global_facts": [],
    "ogx_mmlux_cs-high_school_biology": [],
    "ogx_mmlux_cs-high_school_chemistry": [],
    "ogx_mmlux_cs-high_school_computer_science": [],
    "ogx_mmlux_cs-high_school_european_history": [],
    "ogx_mmlux_cs-high_school_geography": [],
    "ogx_mmlux_cs-high_school_government_and_politics": [],
    "ogx_mmlux_cs-high_school_macroeconomics": [],
    "ogx_mmlux_cs-high_school_mathematics": [],
    "ogx_mmlux_cs-high_school_microeconomics": [],
    "ogx_mmlux_cs-high_school_physics": [],
    "ogx_mmlux_cs-high_school_psychology": [],
    "ogx_mmlux_cs-high_school_statistics": [],
    "ogx_mmlux_cs-high_school_us_history": [],
    "ogx_mmlux_cs-high_school_world_history": [],
    "ogx_mmlux_cs-human_aging": [],
    "ogx_mmlux_cs-human_sexuality": [],
    "ogx_mmlux_cs-international_law": [],
    "ogx_mmlux_cs-jurisprudence": [],
    "ogx_mmlux_cs-logical_fallacies": [],
    "ogx_mmlux_cs-machine_learning": [],
    "ogx_mmlux_cs-management": [],
    "ogx_mmlux_cs-marketing": [],
    "ogx_mmlux_cs-medical_genetics": [],
    "ogx_mmlux_cs-miscellaneous": [],
    "ogx_mmlux_cs-moral_disputes": [],
    "ogx_mmlux_cs-moral_scenarios": [],
    "ogx_mmlux_cs-nutrition": [],
    "ogx_mmlux_cs-philosophy": [],
    "ogx_mmlux_cs-prehistory": [],
    "ogx_mmlux_cs-professional_accounting": [],
    "ogx_mmlux_cs-professional_law": [],
    "ogx_mmlux_cs-professional_medicine": [],
    "ogx_mmlux_cs-professional_psychology": [],
    "ogx_mmlux_cs-public_relations": [],
    "ogx_mmlux_cs-security_studies": [],
    "ogx_mmlux_cs-sociology": [],
    "ogx_mmlux_cs-us_foreign_policy": [],
    "ogx_mmlux_cs-virology": [],
    "ogx_mmlux_cs-world_religions": [],
    "ogx_mmlux_da-abstract_algebra": [],
    "ogx_mmlux_da-anatomy": [],
    "ogx_mmlux_da-astronomy": [],
    "ogx_mmlux_da-business_ethics": [],
    "ogx_mmlux_da-clinical_knowledge": [],
    "ogx_mmlux_da-college_biology": [],
    "ogx_mmlux_da-college_chemistry": [],
    "ogx_mmlux_da-college_computer_science": [],
    "ogx_mmlux_da-college_mathematics": [],
    "ogx_mmlux_da-college_medicine": [],
    "ogx_mmlux_da-college_physics": [],
    "ogx_mmlux_da-computer_security": [],
    "ogx_mmlux_da-conceptual_physics": [],
    "ogx_mmlux_da-econometrics": [],
    "ogx_mmlux_da-electrical_engineering": [],
    "ogx_mmlux_da-elementary_mathematics": [],
    "ogx_mmlux_da-formal_logic": [],
    "ogx_mmlux_da-global_facts": [],
    "ogx_mmlux_da-high_school_biology": [],
    "ogx_mmlux_da-high_school_chemistry": [],
    "ogx_mmlux_da-high_school_computer_science": [],
    "ogx_mmlux_da-high_school_european_history": [],
    "ogx_mmlux_da-high_school_geography": [],
    "ogx_mmlux_da-high_school_government_and_politics": [],
    "ogx_mmlux_da-high_school_macroeconomics": [],
    "ogx_mmlux_da-high_school_mathematics": [],
    "ogx_mmlux_da-high_school_microeconomics": [],
    "ogx_mmlux_da-high_school_physics": [],
    "ogx_mmlux_da-high_school_psychology": [],
    "ogx_mmlux_da-high_school_statistics": [],
    "ogx_mmlux_da-high_school_us_history": [],
    "ogx_mmlux_da-high_school_world_history": [],
    "ogx_mmlux_da-human_aging": [],
    "ogx_mmlux_da-human_sexuality": [],
    "ogx_mmlux_da-international_law": [],
    "ogx_mmlux_da-jurisprudence": [],
    "ogx_mmlux_da-logical_fallacies": [],
    "ogx_mmlux_da-machine_learning": [],
    "ogx_mmlux_da-management": [],
    "ogx_mmlux_da-marketing": [],
    "ogx_mmlux_da-medical_genetics": [],
    "ogx_mmlux_da-miscellaneous": [],
    "ogx_mmlux_da-moral_disputes": [],
    "ogx_mmlux_da-moral_scenarios": [],
    "ogx_mmlux_da-nutrition": [],
    "ogx_mmlux_da-philosophy": [],
    "ogx_mmlux_da-prehistory": [],
    "ogx_mmlux_da-professional_accounting": [],
    "ogx_mmlux_da-professional_law": [],
    "ogx_mmlux_da-professional_medicine": [],
    "ogx_mmlux_da-professional_psychology": [],
    "ogx_mmlux_da-public_relations": [],
    "ogx_mmlux_da-security_studies": [],
    "ogx_mmlux_da-sociology": [],
    "ogx_mmlux_da-us_foreign_policy": [],
    "ogx_mmlux_da-virology": [],
    "ogx_mmlux_da-world_religions": [],
    "ogx_mmlux_de-abstract_algebra": [],
    "ogx_mmlux_de-anatomy": [],
    "ogx_mmlux_de-astronomy": [],
    "ogx_mmlux_de-business_ethics": [],
    "ogx_mmlux_de-clinical_knowledge": [],
    "ogx_mmlux_de-college_biology": [],
    "ogx_mmlux_de-college_chemistry": [],
    "ogx_mmlux_de-college_computer_science": [],
    "ogx_mmlux_de-college_mathematics": [],
    "ogx_mmlux_de-college_medicine": [],
    "ogx_mmlux_de-college_physics": [],
    "ogx_mmlux_de-computer_security": [],
    "ogx_mmlux_de-conceptual_physics": [],
    "ogx_mmlux_de-econometrics": [],
    "ogx_mmlux_de-electrical_engineering": [],
    "ogx_mmlux_de-elementary_mathematics": [],
    "ogx_mmlux_de-formal_logic": [],
    "ogx_mmlux_de-global_facts": [],
    "ogx_mmlux_de-high_school_biology": [],
    "ogx_mmlux_de-high_school_chemistry": [],
    "ogx_mmlux_de-high_school_computer_science": [],
    "ogx_mmlux_de-high_school_european_history": [],
    "ogx_mmlux_de-high_school_geography": [],
    "ogx_mmlux_de-high_school_government_and_politics": [],
    "ogx_mmlux_de-high_school_macroeconomics": [],
    "ogx_mmlux_de-high_school_mathematics": [],
    "ogx_mmlux_de-high_school_microeconomics": [],
    "ogx_mmlux_de-high_school_physics": [],
    "ogx_mmlux_de-high_school_psychology": [],
    "ogx_mmlux_de-high_school_statistics": [],
    "ogx_mmlux_de-high_school_us_history": [],
    "ogx_mmlux_de-high_school_world_history": [],
    "ogx_mmlux_de-human_aging": [],
    "ogx_mmlux_de-human_sexuality": [],
    "ogx_mmlux_de-international_law": [],
    "ogx_mmlux_de-jurisprudence": [],
    "ogx_mmlux_de-logical_fallacies": [],
    "ogx_mmlux_de-machine_learning": [],
    "ogx_mmlux_de-management": [],
    "ogx_mmlux_de-marketing": [],
    "ogx_mmlux_de-medical_genetics": [],
    "ogx_mmlux_de-miscellaneous": [],
    "ogx_mmlux_de-moral_disputes": [],
    "ogx_mmlux_de-moral_scenarios": [],
    "ogx_mmlux_de-nutrition": [],
    "ogx_mmlux_de-philosophy": [],
    "ogx_mmlux_de-prehistory": [],
    "ogx_mmlux_de-professional_accounting": [],
    "ogx_mmlux_de-professional_law": [],
    "ogx_mmlux_de-professional_medicine": [],
    "ogx_mmlux_de-professional_psychology": [],
    "ogx_mmlux_de-public_relations": [],
    "ogx_mmlux_de-security_studies": [],
    "ogx_mmlux_de-sociology": [],
    "ogx_mmlux_de-us_foreign_policy": [],
    "ogx_mmlux_de-virology": [],
    "ogx_mmlux_de-world_religions": [],
    "ogx_mmlux_el-abstract_algebra": [],
    "ogx_mmlux_el-anatomy": [],
    "ogx_mmlux_el-astronomy": [],
    "ogx_mmlux_el-business_ethics": [],
    "ogx_mmlux_el-clinical_knowledge": [],
    "ogx_mmlux_el-college_biology": [],
    "ogx_mmlux_el-college_chemistry": [],
    "ogx_mmlux_el-college_computer_science": [],
    "ogx_mmlux_el-college_mathematics": [],
    "ogx_mmlux_el-college_medicine": [],
    "ogx_mmlux_el-college_physics": [],
    "ogx_mmlux_el-computer_security": [],
    "ogx_mmlux_el-conceptual_physics": [],
    "ogx_mmlux_el-econometrics": [],
    "ogx_mmlux_el-electrical_engineering": [],
    "ogx_mmlux_el-elementary_mathematics": [],
    "ogx_mmlux_el-formal_logic": [],
    "ogx_mmlux_el-global_facts": [],
    "ogx_mmlux_el-high_school_biology": [],
    "ogx_mmlux_el-high_school_chemistry": [],
    "ogx_mmlux_el-high_school_computer_science": [],
    "ogx_mmlux_el-high_school_european_history": [],
    "ogx_mmlux_el-high_school_geography": [],
    "ogx_mmlux_el-high_school_government_and_politics": [],
    "ogx_mmlux_el-high_school_macroeconomics": [],
    "ogx_mmlux_el-high_school_mathematics": [],
    "ogx_mmlux_el-high_school_microeconomics": [],
    "ogx_mmlux_el-high_school_physics": [],
    "ogx_mmlux_el-high_school_psychology": [],
    "ogx_mmlux_el-high_school_statistics": [],
    "ogx_mmlux_el-high_school_us_history": [],
    "ogx_mmlux_el-high_school_world_history": [],
    "ogx_mmlux_el-human_aging": [],
    "ogx_mmlux_el-human_sexuality": [],
    "ogx_mmlux_el-international_law": [],
    "ogx_mmlux_el-jurisprudence": [],
    "ogx_mmlux_el-logical_fallacies": [],
    "ogx_mmlux_el-machine_learning": [],
    "ogx_mmlux_el-management": [],
    "ogx_mmlux_el-marketing": [],
    "ogx_mmlux_el-medical_genetics": [],
    "ogx_mmlux_el-miscellaneous": [],
    "ogx_mmlux_el-moral_disputes": [],
    "ogx_mmlux_el-moral_scenarios": [],
    "ogx_mmlux_el-nutrition": [],
    "ogx_mmlux_el-philosophy": [],
    "ogx_mmlux_el-prehistory": [],
    "ogx_mmlux_el-professional_accounting": [],
    "ogx_mmlux_el-professional_law": [],
    "ogx_mmlux_el-professional_medicine": [],
    "ogx_mmlux_el-professional_psychology": [],
    "ogx_mmlux_el-public_relations": [],
    "ogx_mmlux_el-security_studies": [],
    "ogx_mmlux_el-sociology": [],
    "ogx_mmlux_el-us_foreign_policy": [],
    "ogx_mmlux_el-virology": [],
    "ogx_mmlux_el-world_religions": [],
    "ogx_mmlux_es-abstract_algebra": [],
    "ogx_mmlux_es-anatomy": [],
    "ogx_mmlux_es-astronomy": [],
    "ogx_mmlux_es-business_ethics": [],
    "ogx_mmlux_es-clinical_knowledge": [],
    "ogx_mmlux_es-college_biology": [],
    "ogx_mmlux_es-college_chemistry": [],
    "ogx_mmlux_es-college_computer_science": [],
    "ogx_mmlux_es-college_mathematics": [],
    "ogx_mmlux_es-college_medicine": [],
    "ogx_mmlux_es-college_physics": [],
    "ogx_mmlux_es-computer_security": [],
    "ogx_mmlux_es-conceptual_physics": [],
    "ogx_mmlux_es-econometrics": [],
    "ogx_mmlux_es-electrical_engineering": [],
    "ogx_mmlux_es-elementary_mathematics": [],
    "ogx_mmlux_es-formal_logic": [],
    "ogx_mmlux_es-global_facts": [],
    "ogx_mmlux_es-high_school_biology": [],
    "ogx_mmlux_es-high_school_chemistry": [],
    "ogx_mmlux_es-high_school_computer_science": [],
    "ogx_mmlux_es-high_school_european_history": [],
    "ogx_mmlux_es-high_school_geography": [],
    "ogx_mmlux_es-high_school_government_and_politics": [],
    "ogx_mmlux_es-high_school_macroeconomics": [],
    "ogx_mmlux_es-high_school_mathematics": [],
    "ogx_mmlux_es-high_school_microeconomics": [],
    "ogx_mmlux_es-high_school_physics": [],
    "ogx_mmlux_es-high_school_psychology": [],
    "ogx_mmlux_es-high_school_statistics": [],
    "ogx_mmlux_es-high_school_us_history": [],
    "ogx_mmlux_es-high_school_world_history": [],
    "ogx_mmlux_es-human_aging": [],
    "ogx_mmlux_es-human_sexuality": [],
    "ogx_mmlux_es-international_law": [],
    "ogx_mmlux_es-jurisprudence": [],
    "ogx_mmlux_es-logical_fallacies": [],
    "ogx_mmlux_es-machine_learning": [],
    "ogx_mmlux_es-management": [],
    "ogx_mmlux_es-marketing": [],
    "ogx_mmlux_es-medical_genetics": [],
    "ogx_mmlux_es-miscellaneous": [],
    "ogx_mmlux_es-moral_disputes": [],
    "ogx_mmlux_es-moral_scenarios": [],
    "ogx_mmlux_es-nutrition": [],
    "ogx_mmlux_es-philosophy": [],
    "ogx_mmlux_es-prehistory": [],
    "ogx_mmlux_es-professional_accounting": [],
    "ogx_mmlux_es-professional_law": [],
    "ogx_mmlux_es-professional_medicine": [],
    "ogx_mmlux_es-professional_psychology": [],
    "ogx_mmlux_es-public_relations": [],
    "ogx_mmlux_es-security_studies": [],
    "ogx_mmlux_es-sociology": [],
    "ogx_mmlux_es-us_foreign_policy": [],
    "ogx_mmlux_es-virology": [],
    "ogx_mmlux_es-world_religions": [],
    "ogx_mmlux_et-abstract_algebra": [],
    "ogx_mmlux_et-anatomy": [],
    "ogx_mmlux_et-astronomy": [],
    "ogx_mmlux_et-business_ethics": [],
    "ogx_mmlux_et-clinical_knowledge": [],
    "ogx_mmlux_et-college_biology": [],
    "ogx_mmlux_et-college_chemistry": [],
    "ogx_mmlux_et-college_computer_science": [],
    "ogx_mmlux_et-college_mathematics": [],
    "ogx_mmlux_et-college_medicine": [],
    "ogx_mmlux_et-college_physics": [],
    "ogx_mmlux_et-computer_security": [],
    "ogx_mmlux_et-conceptual_physics": [],
    "ogx_mmlux_et-econometrics": [],
    "ogx_mmlux_et-electrical_engineering": [],
    "ogx_mmlux_et-elementary_mathematics": [],
    "ogx_mmlux_et-formal_logic": [],
    "ogx_mmlux_et-global_facts": [],
    "ogx_mmlux_et-high_school_biology": [],
    "ogx_mmlux_et-high_school_chemistry": [],
    "ogx_mmlux_et-high_school_computer_science": [],
    "ogx_mmlux_et-high_school_european_history": [],
    "ogx_mmlux_et-high_school_geography": [],
    "ogx_mmlux_et-high_school_government_and_politics": [],
    "ogx_mmlux_et-high_school_macroeconomics": [],
    "ogx_mmlux_et-high_school_mathematics": [],
    "ogx_mmlux_et-high_school_microeconomics": [],
    "ogx_mmlux_et-high_school_physics": [],
    "ogx_mmlux_et-high_school_psychology": [],
    "ogx_mmlux_et-high_school_statistics": [],
    "ogx_mmlux_et-high_school_us_history": [],
    "ogx_mmlux_et-high_school_world_history": [],
    "ogx_mmlux_et-human_aging": [],
    "ogx_mmlux_et-human_sexuality": [],
    "ogx_mmlux_et-international_law": [],
    "ogx_mmlux_et-jurisprudence": [],
    "ogx_mmlux_et-logical_fallacies": [],
    "ogx_mmlux_et-machine_learning": [],
    "ogx_mmlux_et-management": [],
    "ogx_mmlux_et-marketing": [],
    "ogx_mmlux_et-medical_genetics": [],
    "ogx_mmlux_et-miscellaneous": [],
    "ogx_mmlux_et-moral_disputes": [],
    "ogx_mmlux_et-moral_scenarios": [],
    "ogx_mmlux_et-nutrition": [],
    "ogx_mmlux_et-philosophy": [],
    "ogx_mmlux_et-prehistory": [],
    "ogx_mmlux_et-professional_accounting": [],
    "ogx_mmlux_et-professional_law": [],
    "ogx_mmlux_et-professional_medicine": [],
    "ogx_mmlux_et-professional_psychology": [],
    "ogx_mmlux_et-public_relations": [],
    "ogx_mmlux_et-security_studies": [],
    "ogx_mmlux_et-sociology": [],
    "ogx_mmlux_et-us_foreign_policy": [],
    "ogx_mmlux_et-virology": [],
    "ogx_mmlux_et-world_religions": [],
    "ogx_mmlux_fi-abstract_algebra": [],
    "ogx_mmlux_fi-anatomy": [],
    "ogx_mmlux_fi-astronomy": [],
    "ogx_mmlux_fi-business_ethics": [],
    "ogx_mmlux_fi-clinical_knowledge": [],
    "ogx_mmlux_fi-college_biology": [],
    "ogx_mmlux_fi-college_chemistry": [],
    "ogx_mmlux_fi-college_computer_science": [],
    "ogx_mmlux_fi-college_mathematics": [],
    "ogx_mmlux_fi-college_medicine": [],
    "ogx_mmlux_fi-college_physics": [],
    "ogx_mmlux_fi-computer_security": [],
    "ogx_mmlux_fi-conceptual_physics": [],
    "ogx_mmlux_fi-econometrics": [],
    "ogx_mmlux_fi-electrical_engineering": [],
    "ogx_mmlux_fi-elementary_mathematics": [],
    "ogx_mmlux_fi-formal_logic": [],
    "ogx_mmlux_fi-global_facts": [],
    "ogx_mmlux_fi-high_school_biology": [],
    "ogx_mmlux_fi-high_school_chemistry": [],
    "ogx_mmlux_fi-high_school_computer_science": [],
    "ogx_mmlux_fi-high_school_european_history": [],
    "ogx_mmlux_fi-high_school_geography": [],
    "ogx_mmlux_fi-high_school_government_and_politics": [],
    "ogx_mmlux_fi-high_school_macroeconomics": [],
    "ogx_mmlux_fi-high_school_mathematics": [],
    "ogx_mmlux_fi-high_school_microeconomics": [],
    "ogx_mmlux_fi-high_school_physics": [],
    "ogx_mmlux_fi-high_school_psychology": [],
    "ogx_mmlux_fi-high_school_statistics": [],
    "ogx_mmlux_fi-high_school_us_history": [],
    "ogx_mmlux_fi-high_school_world_history": [],
    "ogx_mmlux_fi-human_aging": [],
    "ogx_mmlux_fi-human_sexuality": [],
    "ogx_mmlux_fi-international_law": [],
    "ogx_mmlux_fi-jurisprudence": [],
    "ogx_mmlux_fi-logical_fallacies": [],
    "ogx_mmlux_fi-machine_learning": [],
    "ogx_mmlux_fi-management": [],
    "ogx_mmlux_fi-marketing": [],
    "ogx_mmlux_fi-medical_genetics": [],
    "ogx_mmlux_fi-miscellaneous": [],
    "ogx_mmlux_fi-moral_disputes": [],
    "ogx_mmlux_fi-moral_scenarios": [],
    "ogx_mmlux_fi-nutrition": [],
    "ogx_mmlux_fi-philosophy": [],
    "ogx_mmlux_fi-prehistory": [],
    "ogx_mmlux_fi-professional_accounting": [],
    "ogx_mmlux_fi-professional_law": [],
    "ogx_mmlux_fi-professional_medicine": [],
    "ogx_mmlux_fi-professional_psychology": [],
    "ogx_mmlux_fi-public_relations": [],
    "ogx_mmlux_fi-security_studies": [],
    "ogx_mmlux_fi-sociology": [],
    "ogx_mmlux_fi-us_foreign_policy": [],
    "ogx_mmlux_fi-virology": [],
    "ogx_mmlux_fi-world_religions": [],
    "ogx_mmlux_fr-abstract_algebra": [],
    "ogx_mmlux_fr-anatomy": [],
    "ogx_mmlux_fr-astronomy": [],
    "ogx_mmlux_fr-business_ethics": [],
    "ogx_mmlux_fr-clinical_knowledge": [],
    "ogx_mmlux_fr-college_biology": [],
    "ogx_mmlux_fr-college_chemistry": [],
    "ogx_mmlux_fr-college_computer_science": [],
    "ogx_mmlux_fr-college_mathematics": [],
    "ogx_mmlux_fr-college_medicine": [],
    "ogx_mmlux_fr-college_physics": [],
    "ogx_mmlux_fr-computer_security": [],
    "ogx_mmlux_fr-conceptual_physics": [],
    "ogx_mmlux_fr-econometrics": [],
    "ogx_mmlux_fr-electrical_engineering": [],
    "ogx_mmlux_fr-elementary_mathematics": [],
    "ogx_mmlux_fr-formal_logic": [],
    "ogx_mmlux_fr-global_facts": [],
    "ogx_mmlux_fr-high_school_biology": [],
    "ogx_mmlux_fr-high_school_chemistry": [],
    "ogx_mmlux_fr-high_school_computer_science": [],
    "ogx_mmlux_fr-high_school_european_history": [],
    "ogx_mmlux_fr-high_school_geography": [],
    "ogx_mmlux_fr-high_school_government_and_politics": [],
    "ogx_mmlux_fr-high_school_macroeconomics": [],
    "ogx_mmlux_fr-high_school_mathematics": [],
    "ogx_mmlux_fr-high_school_microeconomics": [],
    "ogx_mmlux_fr-high_school_physics": [],
    "ogx_mmlux_fr-high_school_psychology": [],
    "ogx_mmlux_fr-high_school_statistics": [],
    "ogx_mmlux_fr-high_school_us_history": [],
    "ogx_mmlux_fr-high_school_world_history": [],
    "ogx_mmlux_fr-human_aging": [],
    "ogx_mmlux_fr-human_sexuality": [],
    "ogx_mmlux_fr-international_law": [],
    "ogx_mmlux_fr-jurisprudence": [],
    "ogx_mmlux_fr-logical_fallacies": [],
    "ogx_mmlux_fr-machine_learning": [],
    "ogx_mmlux_fr-management": [],
    "ogx_mmlux_fr-marketing": [],
    "ogx_mmlux_fr-medical_genetics": [],
    "ogx_mmlux_fr-miscellaneous": [],
    "ogx_mmlux_fr-moral_disputes": [],
    "ogx_mmlux_fr-moral_scenarios": [],
    "ogx_mmlux_fr-nutrition": [],
    "ogx_mmlux_fr-philosophy": [],
    "ogx_mmlux_fr-prehistory": [],
    "ogx_mmlux_fr-professional_accounting": [],
    "ogx_mmlux_fr-professional_law": [],
    "ogx_mmlux_fr-professional_medicine": [],
    "ogx_mmlux_fr-professional_psychology": [],
    "ogx_mmlux_fr-public_relations": [],
    "ogx_mmlux_fr-security_studies": [],
    "ogx_mmlux_fr-sociology": [],
    "ogx_mmlux_fr-us_foreign_policy": [],
    "ogx_mmlux_fr-virology": [],
    "ogx_mmlux_fr-world_religions": [],
    "ogx_mmlux_hu-abstract_algebra": [],
    "ogx_mmlux_hu-anatomy": [],
    "ogx_mmlux_hu-astronomy": [],
    "ogx_mmlux_hu-business_ethics": [],
    "ogx_mmlux_hu-clinical_knowledge": [],
    "ogx_mmlux_hu-college_biology": [],
    "ogx_mmlux_hu-college_chemistry": [],
    "ogx_mmlux_hu-college_computer_science": [],
    "ogx_mmlux_hu-college_mathematics": [],
    "ogx_mmlux_hu-college_medicine": [],
    "ogx_mmlux_hu-college_physics": [],
    "ogx_mmlux_hu-computer_security": [],
    "ogx_mmlux_hu-conceptual_physics": [],
    "ogx_mmlux_hu-econometrics": [],
    "ogx_mmlux_hu-electrical_engineering": [],
    "ogx_mmlux_hu-elementary_mathematics": [],
    "ogx_mmlux_hu-formal_logic": [],
    "ogx_mmlux_hu-global_facts": [],
    "ogx_mmlux_hu-high_school_biology": [],
    "ogx_mmlux_hu-high_school_chemistry": [],
    "ogx_mmlux_hu-high_school_computer_science": [],
    "ogx_mmlux_hu-high_school_european_history": [],
    "ogx_mmlux_hu-high_school_geography": [],
    "ogx_mmlux_hu-high_school_government_and_politics": [],
    "ogx_mmlux_hu-high_school_macroeconomics": [],
    "ogx_mmlux_hu-high_school_mathematics": [],
    "ogx_mmlux_hu-high_school_microeconomics": [],
    "ogx_mmlux_hu-high_school_physics": [],
    "ogx_mmlux_hu-high_school_psychology": [],
    "ogx_mmlux_hu-high_school_statistics": [],
    "ogx_mmlux_hu-high_school_us_history": [],
    "ogx_mmlux_hu-high_school_world_history": [],
    "ogx_mmlux_hu-human_aging": [],
    "ogx_mmlux_hu-human_sexuality": [],
    "ogx_mmlux_hu-international_law": [],
    "ogx_mmlux_hu-jurisprudence": [],
    "ogx_mmlux_hu-logical_fallacies": [],
    "ogx_mmlux_hu-machine_learning": [],
    "ogx_mmlux_hu-management": [],
    "ogx_mmlux_hu-marketing": [],
    "ogx_mmlux_hu-medical_genetics": [],
    "ogx_mmlux_hu-miscellaneous": [],
    "ogx_mmlux_hu-moral_disputes": [],
    "ogx_mmlux_hu-moral_scenarios": [],
    "ogx_mmlux_hu-nutrition": [],
    "ogx_mmlux_hu-philosophy": [],
    "ogx_mmlux_hu-prehistory": [],
    "ogx_mmlux_hu-professional_accounting": [],
    "ogx_mmlux_hu-professional_law": [],
    "ogx_mmlux_hu-professional_medicine": [],
    "ogx_mmlux_hu-professional_psychology": [],
    "ogx_mmlux_hu-public_relations": [],
    "ogx_mmlux_hu-security_studies": [],
    "ogx_mmlux_hu-sociology": [],
    "ogx_mmlux_hu-us_foreign_policy": [],
    "ogx_mmlux_hu-virology": [],
    "ogx_mmlux_hu-world_religions": [],
    "ogx_mmlux_it-abstract_algebra": [],
    "ogx_mmlux_it-anatomy": [],
    "ogx_mmlux_it-astronomy": [],
    "ogx_mmlux_it-business_ethics": [],
    "ogx_mmlux_it-clinical_knowledge": [],
    "ogx_mmlux_it-college_biology": [],
    "ogx_mmlux_it-college_chemistry": [],
    "ogx_mmlux_it-college_computer_science": [],
    "ogx_mmlux_it-college_mathematics": [],
    "ogx_mmlux_it-college_medicine": [],
    "ogx_mmlux_it-college_physics": [],
    "ogx_mmlux_it-computer_security": [],
    "ogx_mmlux_it-conceptual_physics": [],
    "ogx_mmlux_it-econometrics": [],
    "ogx_mmlux_it-electrical_engineering": [],
    "ogx_mmlux_it-elementary_mathematics": [],
    "ogx_mmlux_it-formal_logic": [],
    "ogx_mmlux_it-global_facts": [],
    "ogx_mmlux_it-high_school_biology": [],
    "ogx_mmlux_it-high_school_chemistry": [],
    "ogx_mmlux_it-high_school_computer_science": [],
    "ogx_mmlux_it-high_school_european_history": [],
    "ogx_mmlux_it-high_school_geography": [],
    "ogx_mmlux_it-high_school_government_and_politics": [],
    "ogx_mmlux_it-high_school_macroeconomics": [],
    "ogx_mmlux_it-high_school_mathematics": [],
    "ogx_mmlux_it-high_school_microeconomics": [],
    "ogx_mmlux_it-high_school_physics": [],
    "ogx_mmlux_it-high_school_psychology": [],
    "ogx_mmlux_it-high_school_statistics": [],
    "ogx_mmlux_it-high_school_us_history": [],
    "ogx_mmlux_it-high_school_world_history": [],
    "ogx_mmlux_it-human_aging": [],
    "ogx_mmlux_it-human_sexuality": [],
    "ogx_mmlux_it-international_law": [],
    "ogx_mmlux_it-jurisprudence": [],
    "ogx_mmlux_it-logical_fallacies": [],
    "ogx_mmlux_it-machine_learning": [],
    "ogx_mmlux_it-management": [],
    "ogx_mmlux_it-marketing": [],
    "ogx_mmlux_it-medical_genetics": [],
    "ogx_mmlux_it-miscellaneous": [],
    "ogx_mmlux_it-moral_disputes": [],
    "ogx_mmlux_it-moral_scenarios": [],
    "ogx_mmlux_it-nutrition": [],
    "ogx_mmlux_it-philosophy": [],
    "ogx_mmlux_it-prehistory": [],
    "ogx_mmlux_it-professional_accounting": [],
    "ogx_mmlux_it-professional_law": [],
    "ogx_mmlux_it-professional_medicine": [],
    "ogx_mmlux_it-professional_psychology": [],
    "ogx_mmlux_it-public_relations": [],
    "ogx_mmlux_it-security_studies": [],
    "ogx_mmlux_it-sociology": [],
    "ogx_mmlux_it-us_foreign_policy": [],
    "ogx_mmlux_it-virology": [],
    "ogx_mmlux_it-world_religions": [],
    "ogx_mmlux_lt-abstract_algebra": [],
    "ogx_mmlux_lt-anatomy": [],
    "ogx_mmlux_lt-astronomy": [],
    "ogx_mmlux_lt-business_ethics": [],
    "ogx_mmlux_lt-clinical_knowledge": [],
    "ogx_mmlux_lt-college_biology": [],
    "ogx_mmlux_lt-college_chemistry": [],
    "ogx_mmlux_lt-college_computer_science": [],
    "ogx_mmlux_lt-college_mathematics": [],
    "ogx_mmlux_lt-college_medicine": [],
    "ogx_mmlux_lt-college_physics": [],
    "ogx_mmlux_lt-computer_security": [],
    "ogx_mmlux_lt-conceptual_physics": [],
    "ogx_mmlux_lt-econometrics": [],
    "ogx_mmlux_lt-electrical_engineering": [],
    "ogx_mmlux_lt-elementary_mathematics": [],
    "ogx_mmlux_lt-formal_logic": [],
    "ogx_mmlux_lt-global_facts": [],
    "ogx_mmlux_lt-high_school_biology": [],
    "ogx_mmlux_lt-high_school_chemistry": [],
    "ogx_mmlux_lt-high_school_computer_science": [],
    "ogx_mmlux_lt-high_school_european_history": [],
    "ogx_mmlux_lt-high_school_geography": [],
    "ogx_mmlux_lt-high_school_government_and_politics": [],
    "ogx_mmlux_lt-high_school_macroeconomics": [],
    "ogx_mmlux_lt-high_school_mathematics": [],
    "ogx_mmlux_lt-high_school_microeconomics": [],
    "ogx_mmlux_lt-high_school_physics": [],
    "ogx_mmlux_lt-high_school_psychology": [],
    "ogx_mmlux_lt-high_school_statistics": [],
    "ogx_mmlux_lt-high_school_us_history": [],
    "ogx_mmlux_lt-high_school_world_history": [],
    "ogx_mmlux_lt-human_aging": [],
    "ogx_mmlux_lt-human_sexuality": [],
    "ogx_mmlux_lt-international_law": [],
    "ogx_mmlux_lt-jurisprudence": [],
    "ogx_mmlux_lt-logical_fallacies": [],
    "ogx_mmlux_lt-machine_learning": [],
    "ogx_mmlux_lt-management": [],
    "ogx_mmlux_lt-marketing": [],
    "ogx_mmlux_lt-medical_genetics": [],
    "ogx_mmlux_lt-miscellaneous": [],
    "ogx_mmlux_lt-moral_disputes": [],
    "ogx_mmlux_lt-moral_scenarios": [],
    "ogx_mmlux_lt-nutrition": [],
    "ogx_mmlux_lt-philosophy": [],
    "ogx_mmlux_lt-prehistory": [],
    "ogx_mmlux_lt-professional_accounting": [],
    "ogx_mmlux_lt-professional_law": [],
    "ogx_mmlux_lt-professional_medicine": [],
    "ogx_mmlux_lt-professional_psychology": [],
    "ogx_mmlux_lt-public_relations": [],
    "ogx_mmlux_lt-security_studies": [],
    "ogx_mmlux_lt-sociology": [],
    "ogx_mmlux_lt-us_foreign_policy": [],
    "ogx_mmlux_lt-virology": [],
    "ogx_mmlux_lt-world_religions": [],
    "ogx_mmlux_lv-abstract_algebra": [],
    "ogx_mmlux_lv-anatomy": [],
    "ogx_mmlux_lv-astronomy": [],
    "ogx_mmlux_lv-business_ethics": [],
    "ogx_mmlux_lv-clinical_knowledge": [],
    "ogx_mmlux_lv-college_biology": [],
    "ogx_mmlux_lv-college_chemistry": [],
    "ogx_mmlux_lv-college_computer_science": [],
    "ogx_mmlux_lv-college_mathematics": [],
    "ogx_mmlux_lv-college_medicine": [],
    "ogx_mmlux_lv-college_physics": [],
    "ogx_mmlux_lv-computer_security": [],
    "ogx_mmlux_lv-conceptual_physics": [],
    "ogx_mmlux_lv-econometrics": [],
    "ogx_mmlux_lv-electrical_engineering": [],
    "ogx_mmlux_lv-elementary_mathematics": [],
    "ogx_mmlux_lv-formal_logic": [],
    "ogx_mmlux_lv-global_facts": [],
    "ogx_mmlux_lv-high_school_biology": [],
    "ogx_mmlux_lv-high_school_chemistry": [],
    "ogx_mmlux_lv-high_school_computer_science": [],
    "ogx_mmlux_lv-high_school_european_history": [],
    "ogx_mmlux_lv-high_school_geography": [],
    "ogx_mmlux_lv-high_school_government_and_politics": [],
    "ogx_mmlux_lv-high_school_macroeconomics": [],
    "ogx_mmlux_lv-high_school_mathematics": [],
    "ogx_mmlux_lv-high_school_microeconomics": [],
    "ogx_mmlux_lv-high_school_physics": [],
    "ogx_mmlux_lv-high_school_psychology": [],
    "ogx_mmlux_lv-high_school_statistics": [],
    "ogx_mmlux_lv-high_school_us_history": [],
    "ogx_mmlux_lv-high_school_world_history": [],
    "ogx_mmlux_lv-human_aging": [],
    "ogx_mmlux_lv-human_sexuality": [],
    "ogx_mmlux_lv-international_law": [],
    "ogx_mmlux_lv-jurisprudence": [],
    "ogx_mmlux_lv-logical_fallacies": [],
    "ogx_mmlux_lv-machine_learning": [],
    "ogx_mmlux_lv-management": [],
    "ogx_mmlux_lv-marketing": [],
    "ogx_mmlux_lv-medical_genetics": [],
    "ogx_mmlux_lv-miscellaneous": [],
    "ogx_mmlux_lv-moral_disputes": [],
    "ogx_mmlux_lv-moral_scenarios": [],
    "ogx_mmlux_lv-nutrition": [],
    "ogx_mmlux_lv-philosophy": [],
    "ogx_mmlux_lv-prehistory": [],
    "ogx_mmlux_lv-professional_accounting": [],
    "ogx_mmlux_lv-professional_law": [],
    "ogx_mmlux_lv-professional_medicine": [],
    "ogx_mmlux_lv-professional_psychology": [],
    "ogx_mmlux_lv-public_relations": [],
    "ogx_mmlux_lv-security_studies": [],
    "ogx_mmlux_lv-sociology": [],
    "ogx_mmlux_lv-us_foreign_policy": [],
    "ogx_mmlux_lv-virology": [],
    "ogx_mmlux_lv-world_religions": [],
    "ogx_mmlux_nl-abstract_algebra": [],
    "ogx_mmlux_nl-anatomy": [],
    "ogx_mmlux_nl-astronomy": [],
    "ogx_mmlux_nl-business_ethics": [],
    "ogx_mmlux_nl-clinical_knowledge": [],
    "ogx_mmlux_nl-college_biology": [],
    "ogx_mmlux_nl-college_chemistry": [],
    "ogx_mmlux_nl-college_computer_science": [],
    "ogx_mmlux_nl-college_mathematics": [],
    "ogx_mmlux_nl-college_medicine": [],
    "ogx_mmlux_nl-college_physics": [],
    "ogx_mmlux_nl-computer_security": [],
    "ogx_mmlux_nl-conceptual_physics": [],
    "ogx_mmlux_nl-econometrics": [],
    "ogx_mmlux_nl-electrical_engineering": [],
    "ogx_mmlux_nl-elementary_mathematics": [],
    "ogx_mmlux_nl-formal_logic": [],
    "ogx_mmlux_nl-global_facts": [],
    "ogx_mmlux_nl-high_school_biology": [],
    "ogx_mmlux_nl-high_school_chemistry": [],
    "ogx_mmlux_nl-high_school_computer_science": [],
    "ogx_mmlux_nl-high_school_european_history": [],
    "ogx_mmlux_nl-high_school_geography": [],
    "ogx_mmlux_nl-high_school_government_and_politics": [],
    "ogx_mmlux_nl-high_school_macroeconomics": [],
    "ogx_mmlux_nl-high_school_mathematics": [],
    "ogx_mmlux_nl-high_school_microeconomics": [],
    "ogx_mmlux_nl-high_school_physics": [],
    "ogx_mmlux_nl-high_school_psychology": [],
    "ogx_mmlux_nl-high_school_statistics": [],
    "ogx_mmlux_nl-high_school_us_history": [],
    "ogx_mmlux_nl-high_school_world_history": [],
    "ogx_mmlux_nl-human_aging": [],
    "ogx_mmlux_nl-human_sexuality": [],
    "ogx_mmlux_nl-international_law": [],
    "ogx_mmlux_nl-jurisprudence": [],
    "ogx_mmlux_nl-logical_fallacies": [],
    "ogx_mmlux_nl-machine_learning": [],
    "ogx_mmlux_nl-management": [],
    "ogx_mmlux_nl-marketing": [],
    "ogx_mmlux_nl-medical_genetics": [],
    "ogx_mmlux_nl-miscellaneous": [],
    "ogx_mmlux_nl-moral_disputes": [],
    "ogx_mmlux_nl-moral_scenarios": [],
    "ogx_mmlux_nl-nutrition": [],
    "ogx_mmlux_nl-philosophy": [],
    "ogx_mmlux_nl-prehistory": [],
    "ogx_mmlux_nl-professional_accounting": [],
    "ogx_mmlux_nl-professional_law": [],
    "ogx_mmlux_nl-professional_medicine": [],
    "ogx_mmlux_nl-professional_psychology": [],
    "ogx_mmlux_nl-public_relations": [],
    "ogx_mmlux_nl-security_studies": [],
    "ogx_mmlux_nl-sociology": [],
    "ogx_mmlux_nl-us_foreign_policy": [],
    "ogx_mmlux_nl-virology": [],
    "ogx_mmlux_nl-world_religions": [],
    "ogx_mmlux_pl-abstract_algebra": [],
    "ogx_mmlux_pl-anatomy": [],
    "ogx_mmlux_pl-astronomy": [],
    "ogx_mmlux_pl-business_ethics": [],
    "ogx_mmlux_pl-clinical_knowledge": [],
    "ogx_mmlux_pl-college_biology": [],
    "ogx_mmlux_pl-college_chemistry": [],
    "ogx_mmlux_pl-college_computer_science": [],
    "ogx_mmlux_pl-college_mathematics": [],
    "ogx_mmlux_pl-college_medicine": [],
    "ogx_mmlux_pl-college_physics": [],
    "ogx_mmlux_pl-computer_security": [],
    "ogx_mmlux_pl-conceptual_physics": [],
    "ogx_mmlux_pl-econometrics": [],
    "ogx_mmlux_pl-electrical_engineering": [],
    "ogx_mmlux_pl-elementary_mathematics": [],
    "ogx_mmlux_pl-formal_logic": [],
    "ogx_mmlux_pl-global_facts": [],
    "ogx_mmlux_pl-high_school_biology": [],
    "ogx_mmlux_pl-high_school_chemistry": [],
    "ogx_mmlux_pl-high_school_computer_science": [],
    "ogx_mmlux_pl-high_school_european_history": [],
    "ogx_mmlux_pl-high_school_geography": [],
    "ogx_mmlux_pl-high_school_government_and_politics": [],
    "ogx_mmlux_pl-high_school_macroeconomics": [],
    "ogx_mmlux_pl-high_school_mathematics": [],
    "ogx_mmlux_pl-high_school_microeconomics": [],
    "ogx_mmlux_pl-high_school_physics": [],
    "ogx_mmlux_pl-high_school_psychology": [],
    "ogx_mmlux_pl-high_school_statistics": [],
    "ogx_mmlux_pl-high_school_us_history": [],
    "ogx_mmlux_pl-high_school_world_history": [],
    "ogx_mmlux_pl-human_aging": [],
    "ogx_mmlux_pl-human_sexuality": [],
    "ogx_mmlux_pl-international_law": [],
    "ogx_mmlux_pl-jurisprudence": [],
    "ogx_mmlux_pl-logical_fallacies": [],
    "ogx_mmlux_pl-machine_learning": [],
    "ogx_mmlux_pl-management": [],
    "ogx_mmlux_pl-marketing": [],
    "ogx_mmlux_pl-medical_genetics": [],
    "ogx_mmlux_pl-miscellaneous": [],
    "ogx_mmlux_pl-moral_disputes": [],
    "ogx_mmlux_pl-moral_scenarios": [],
    "ogx_mmlux_pl-nutrition": [],
    "ogx_mmlux_pl-philosophy": [],
    "ogx_mmlux_pl-prehistory": [],
    "ogx_mmlux_pl-professional_accounting": [],
    "ogx_mmlux_pl-professional_law": [],
    "ogx_mmlux_pl-professional_medicine": [],
    "ogx_mmlux_pl-professional_psychology": [],
    "ogx_mmlux_pl-public_relations": [],
    "ogx_mmlux_pl-security_studies": [],
    "ogx_mmlux_pl-sociology": [],
    "ogx_mmlux_pl-us_foreign_policy": [],
    "ogx_mmlux_pl-virology": [],
    "ogx_mmlux_pl-world_religions": [],
    "ogx_mmlux_pt-pt-abstract_algebra": [],
    "ogx_mmlux_pt-pt-anatomy": [],
    "ogx_mmlux_pt-pt-astronomy": [],
    "ogx_mmlux_pt-pt-business_ethics": [],
    "ogx_mmlux_pt-pt-clinical_knowledge": [],
    "ogx_mmlux_pt-pt-college_biology": [],
    "ogx_mmlux_pt-pt-college_chemistry": [],
    "ogx_mmlux_pt-pt-college_computer_science": [],
    "ogx_mmlux_pt-pt-college_mathematics": [],
    "ogx_mmlux_pt-pt-college_medicine": [],
    "ogx_mmlux_pt-pt-college_physics": [],
    "ogx_mmlux_pt-pt-computer_security": [],
    "ogx_mmlux_pt-pt-conceptual_physics": [],
    "ogx_mmlux_pt-pt-econometrics": [],
    "ogx_mmlux_pt-pt-electrical_engineering": [],
    "ogx_mmlux_pt-pt-elementary_mathematics": [],
    "ogx_mmlux_pt-pt-formal_logic": [],
    "ogx_mmlux_pt-pt-global_facts": [],
    "ogx_mmlux_pt-pt-high_school_biology": [],
    "ogx_mmlux_pt-pt-high_school_chemistry": [],
    "ogx_mmlux_pt-pt-high_school_computer_science": [],
    "ogx_mmlux_pt-pt-high_school_european_history": [],
    "ogx_mmlux_pt-pt-high_school_geography": [],
    "ogx_mmlux_pt-pt-high_school_government_and_politics": [],
    "ogx_mmlux_pt-pt-high_school_macroeconomics": [],
    "ogx_mmlux_pt-pt-high_school_mathematics": [],
    "ogx_mmlux_pt-pt-high_school_microeconomics": [],
    "ogx_mmlux_pt-pt-high_school_physics": [],
    "ogx_mmlux_pt-pt-high_school_psychology": [],
    "ogx_mmlux_pt-pt-high_school_statistics": [],
    "ogx_mmlux_pt-pt-high_school_us_history": [],
    "ogx_mmlux_pt-pt-high_school_world_history": [],
    "ogx_mmlux_pt-pt-human_aging": [],
    "ogx_mmlux_pt-pt-human_sexuality": [],
    "ogx_mmlux_pt-pt-international_law": [],
    "ogx_mmlux_pt-pt-jurisprudence": [],
    "ogx_mmlux_pt-pt-logical_fallacies": [],
    "ogx_mmlux_pt-pt-machine_learning": [],
    "ogx_mmlux_pt-pt-management": [],
    "ogx_mmlux_pt-pt-marketing": [],
    "ogx_mmlux_pt-pt-medical_genetics": [],
    "ogx_mmlux_pt-pt-miscellaneous": [],
    "ogx_mmlux_pt-pt-moral_disputes": [],
    "ogx_mmlux_pt-pt-moral_scenarios": [],
    "ogx_mmlux_pt-pt-nutrition": [],
    "ogx_mmlux_pt-pt-philosophy": [],
    "ogx_mmlux_pt-pt-prehistory": [],
    "ogx_mmlux_pt-pt-professional_accounting": [],
    "ogx_mmlux_pt-pt-professional_law": [],
    "ogx_mmlux_pt-pt-professional_medicine": [],
    "ogx_mmlux_pt-pt-professional_psychology": [],
    "ogx_mmlux_pt-pt-public_relations": [],
    "ogx_mmlux_pt-pt-security_studies": [],
    "ogx_mmlux_pt-pt-sociology": [],
    "ogx_mmlux_pt-pt-us_foreign_policy": [],
    "ogx_mmlux_pt-pt-virology": [],
    "ogx_mmlux_pt-pt-world_religions": [],
    "ogx_mmlux_ro-abstract_algebra": [],
    "ogx_mmlux_ro-anatomy": [],
    "ogx_mmlux_ro-astronomy": [],
    "ogx_mmlux_ro-business_ethics": [],
    "ogx_mmlux_ro-clinical_knowledge": [],
    "ogx_mmlux_ro-college_biology": [],
    "ogx_mmlux_ro-college_chemistry": [],
    "ogx_mmlux_ro-college_computer_science": [],
    "ogx_mmlux_ro-college_mathematics": [],
    "ogx_mmlux_ro-college_medicine": [],
    "ogx_mmlux_ro-college_physics": [],
    "ogx_mmlux_ro-computer_security": [],
    "ogx_mmlux_ro-conceptual_physics": [],
    "ogx_mmlux_ro-econometrics": [],
    "ogx_mmlux_ro-electrical_engineering": [],
    "ogx_mmlux_ro-elementary_mathematics": [],
    "ogx_mmlux_ro-formal_logic": [],
    "ogx_mmlux_ro-global_facts": [],
    "ogx_mmlux_ro-high_school_biology": [],
    "ogx_mmlux_ro-high_school_chemistry": [],
    "ogx_mmlux_ro-high_school_computer_science": [],
    "ogx_mmlux_ro-high_school_european_history": [],
    "ogx_mmlux_ro-high_school_geography": [],
    "ogx_mmlux_ro-high_school_government_and_politics": [],
    "ogx_mmlux_ro-high_school_macroeconomics": [],
    "ogx_mmlux_ro-high_school_mathematics": [],
    "ogx_mmlux_ro-high_school_microeconomics": [],
    "ogx_mmlux_ro-high_school_physics": [],
    "ogx_mmlux_ro-high_school_psychology": [],
    "ogx_mmlux_ro-high_school_statistics": [],
    "ogx_mmlux_ro-high_school_us_history": [],
    "ogx_mmlux_ro-high_school_world_history": [],
    "ogx_mmlux_ro-human_aging": [],
    "ogx_mmlux_ro-human_sexuality": [],
    "ogx_mmlux_ro-international_law": [],
    "ogx_mmlux_ro-jurisprudence": [],
    "ogx_mmlux_ro-logical_fallacies": [],
    "ogx_mmlux_ro-machine_learning": [],
    "ogx_mmlux_ro-management": [],
    "ogx_mmlux_ro-marketing": [],
    "ogx_mmlux_ro-medical_genetics": [],
    "ogx_mmlux_ro-miscellaneous": [],
    "ogx_mmlux_ro-moral_disputes": [],
    "ogx_mmlux_ro-moral_scenarios": [],
    "ogx_mmlux_ro-nutrition": [],
    "ogx_mmlux_ro-philosophy": [],
    "ogx_mmlux_ro-prehistory": [],
    "ogx_mmlux_ro-professional_accounting": [],
    "ogx_mmlux_ro-professional_law": [],
    "ogx_mmlux_ro-professional_medicine": [],
    "ogx_mmlux_ro-professional_psychology": [],
    "ogx_mmlux_ro-public_relations": [],
    "ogx_mmlux_ro-security_studies": [],
    "ogx_mmlux_ro-sociology": [],
    "ogx_mmlux_ro-us_foreign_policy": [],
    "ogx_mmlux_ro-virology": [],
    "ogx_mmlux_ro-world_religions": [],
    "ogx_mmlux_sk-abstract_algebra": [],
    "ogx_mmlux_sk-anatomy": [],
    "ogx_mmlux_sk-astronomy": [],
    "ogx_mmlux_sk-business_ethics": [],
    "ogx_mmlux_sk-clinical_knowledge": [],
    "ogx_mmlux_sk-college_biology": [],
    "ogx_mmlux_sk-college_chemistry": [],
    "ogx_mmlux_sk-college_computer_science": [],
    "ogx_mmlux_sk-college_mathematics": [],
    "ogx_mmlux_sk-college_medicine": [],
    "ogx_mmlux_sk-college_physics": [],
    "ogx_mmlux_sk-computer_security": [],
    "ogx_mmlux_sk-conceptual_physics": [],
    "ogx_mmlux_sk-econometrics": [],
    "ogx_mmlux_sk-electrical_engineering": [],
    "ogx_mmlux_sk-elementary_mathematics": [],
    "ogx_mmlux_sk-formal_logic": [],
    "ogx_mmlux_sk-global_facts": [],
    "ogx_mmlux_sk-high_school_biology": [],
    "ogx_mmlux_sk-high_school_chemistry": [],
    "ogx_mmlux_sk-high_school_computer_science": [],
    "ogx_mmlux_sk-high_school_european_history": [],
    "ogx_mmlux_sk-high_school_geography": [],
    "ogx_mmlux_sk-high_school_government_and_politics": [],
    "ogx_mmlux_sk-high_school_macroeconomics": [],
    "ogx_mmlux_sk-high_school_mathematics": [],
    "ogx_mmlux_sk-high_school_microeconomics": [],
    "ogx_mmlux_sk-high_school_physics": [],
    "ogx_mmlux_sk-high_school_psychology": [],
    "ogx_mmlux_sk-high_school_statistics": [],
    "ogx_mmlux_sk-high_school_us_history": [],
    "ogx_mmlux_sk-high_school_world_history": [],
    "ogx_mmlux_sk-human_aging": [],
    "ogx_mmlux_sk-human_sexuality": [],
    "ogx_mmlux_sk-international_law": [],
    "ogx_mmlux_sk-jurisprudence": [],
    "ogx_mmlux_sk-logical_fallacies": [],
    "ogx_mmlux_sk-machine_learning": [],
    "ogx_mmlux_sk-management": [],
    "ogx_mmlux_sk-marketing": [],
    "ogx_mmlux_sk-medical_genetics": [],
    "ogx_mmlux_sk-miscellaneous": [],
    "ogx_mmlux_sk-moral_disputes": [],
    "ogx_mmlux_sk-moral_scenarios": [],
    "ogx_mmlux_sk-nutrition": [],
    "ogx_mmlux_sk-philosophy": [],
    "ogx_mmlux_sk-prehistory": [],
    "ogx_mmlux_sk-professional_accounting": [],
    "ogx_mmlux_sk-professional_law": [],
    "ogx_mmlux_sk-professional_medicine": [],
    "ogx_mmlux_sk-professional_psychology": [],
    "ogx_mmlux_sk-public_relations": [],
    "ogx_mmlux_sk-security_studies": [],
    "ogx_mmlux_sk-sociology": [],
    "ogx_mmlux_sk-us_foreign_policy": [],
    "ogx_mmlux_sk-virology": [],
    "ogx_mmlux_sk-world_religions": [],
    "ogx_mmlux_sl-abstract_algebra": [],
    "ogx_mmlux_sl-anatomy": [],
    "ogx_mmlux_sl-astronomy": [],
    "ogx_mmlux_sl-business_ethics": [],
    "ogx_mmlux_sl-clinical_knowledge": [],
    "ogx_mmlux_sl-college_biology": [],
    "ogx_mmlux_sl-college_chemistry": [],
    "ogx_mmlux_sl-college_computer_science": [],
    "ogx_mmlux_sl-college_mathematics": [],
    "ogx_mmlux_sl-college_medicine": [],
    "ogx_mmlux_sl-college_physics": [],
    "ogx_mmlux_sl-computer_security": [],
    "ogx_mmlux_sl-conceptual_physics": [],
    "ogx_mmlux_sl-econometrics": [],
    "ogx_mmlux_sl-electrical_engineering": [],
    "ogx_mmlux_sl-elementary_mathematics": [],
    "ogx_mmlux_sl-formal_logic": [],
    "ogx_mmlux_sl-global_facts": [],
    "ogx_mmlux_sl-high_school_biology": [],
    "ogx_mmlux_sl-high_school_chemistry": [],
    "ogx_mmlux_sl-high_school_computer_science": [],
    "ogx_mmlux_sl-high_school_european_history": [],
    "ogx_mmlux_sl-high_school_geography": [],
    "ogx_mmlux_sl-high_school_government_and_politics": [],
    "ogx_mmlux_sl-high_school_macroeconomics": [],
    "ogx_mmlux_sl-high_school_mathematics": [],
    "ogx_mmlux_sl-high_school_microeconomics": [],
    "ogx_mmlux_sl-high_school_physics": [],
    "ogx_mmlux_sl-high_school_psychology": [],
    "ogx_mmlux_sl-high_school_statistics": [],
    "ogx_mmlux_sl-high_school_us_history": [],
    "ogx_mmlux_sl-high_school_world_history": [],
    "ogx_mmlux_sl-human_aging": [],
    "ogx_mmlux_sl-human_sexuality": [],
    "ogx_mmlux_sl-international_law": [],
    "ogx_mmlux_sl-jurisprudence": [],
    "ogx_mmlux_sl-logical_fallacies": [],
    "ogx_mmlux_sl-machine_learning": [],
    "ogx_mmlux_sl-management": [],
    "ogx_mmlux_sl-marketing": [],
    "ogx_mmlux_sl-medical_genetics": [],
    "ogx_mmlux_sl-miscellaneous": [],
    "ogx_mmlux_sl-moral_disputes": [],
    "ogx_mmlux_sl-moral_scenarios": [],
    "ogx_mmlux_sl-nutrition": [],
    "ogx_mmlux_sl-philosophy": [],
    "ogx_mmlux_sl-prehistory": [],
    "ogx_mmlux_sl-professional_accounting": [],
    "ogx_mmlux_sl-professional_law": [],
    "ogx_mmlux_sl-professional_medicine": [],
    "ogx_mmlux_sl-professional_psychology": [],
    "ogx_mmlux_sl-public_relations": [],
    "ogx_mmlux_sl-security_studies": [],
    "ogx_mmlux_sl-sociology": [],
    "ogx_mmlux_sl-us_foreign_policy": [],
    "ogx_mmlux_sl-virology": [],
    "ogx_mmlux_sl-world_religions": [],
    "ogx_mmlux_sv-abstract_algebra": [],
    "ogx_mmlux_sv-anatomy": [],
    "ogx_mmlux_sv-astronomy": [],
    "ogx_mmlux_sv-business_ethics": [],
    "ogx_mmlux_sv-clinical_knowledge": [],
    "ogx_mmlux_sv-college_biology": [],
    "ogx_mmlux_sv-college_chemistry": [],
    "ogx_mmlux_sv-college_computer_science": [],
    "ogx_mmlux_sv-college_mathematics": [],
    "ogx_mmlux_sv-college_medicine": [],
    "ogx_mmlux_sv-college_physics": [],
    "ogx_mmlux_sv-computer_security": [],
    "ogx_mmlux_sv-conceptual_physics": [],
    "ogx_mmlux_sv-econometrics": [],
    "ogx_mmlux_sv-electrical_engineering": [],
    "ogx_mmlux_sv-elementary_mathematics": [],
    "ogx_mmlux_sv-formal_logic": [],
    "ogx_mmlux_sv-global_facts": [],
    "ogx_mmlux_sv-high_school_biology": [],
    "ogx_mmlux_sv-high_school_chemistry": [],
    "ogx_mmlux_sv-high_school_computer_science": [],
    "ogx_mmlux_sv-high_school_european_history": [],
    "ogx_mmlux_sv-high_school_geography": [],
    "ogx_mmlux_sv-high_school_government_and_politics": [],
    "ogx_mmlux_sv-high_school_macroeconomics": [],
    "ogx_mmlux_sv-high_school_mathematics": [],
    "ogx_mmlux_sv-high_school_microeconomics": [],
    "ogx_mmlux_sv-high_school_physics": [],
    "ogx_mmlux_sv-high_school_psychology": [],
    "ogx_mmlux_sv-high_school_statistics": [],
    "ogx_mmlux_sv-high_school_us_history": [],
    "ogx_mmlux_sv-high_school_world_history": [],
    "ogx_mmlux_sv-human_aging": [],
    "ogx_mmlux_sv-human_sexuality": [],
    "ogx_mmlux_sv-international_law": [],
    "ogx_mmlux_sv-jurisprudence": [],
    "ogx_mmlux_sv-logical_fallacies": [],
    "ogx_mmlux_sv-machine_learning": [],
    "ogx_mmlux_sv-management": [],
    "ogx_mmlux_sv-marketing": [],
    "ogx_mmlux_sv-medical_genetics": [],
    "ogx_mmlux_sv-miscellaneous": [],
    "ogx_mmlux_sv-moral_disputes": [],
    "ogx_mmlux_sv-moral_scenarios": [],
    "ogx_mmlux_sv-nutrition": [],
    "ogx_mmlux_sv-philosophy": [],
    "ogx_mmlux_sv-prehistory": [],
    "ogx_mmlux_sv-professional_accounting": [],
    "ogx_mmlux_sv-professional_law": [],
    "ogx_mmlux_sv-professional_medicine": [],
    "ogx_mmlux_sv-professional_psychology": [],
    "ogx_mmlux_sv-public_relations": [],
    "ogx_mmlux_sv-security_studies": [],
    "ogx_mmlux_sv-sociology": [],
    "ogx_mmlux_sv-us_foreign_policy": [],
    "ogx_mmlux_sv-virology": [],
    "ogx_mmlux_sv-world_religions": []
  },
  "configs": {
    "ogx_mmlux_bg-abstract_algebra": {
      "task": "ogx_mmlux_bg-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за абстрактната алгебра.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-anatomy": {
      "task": "ogx_mmlux_bg-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за анатомията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-astronomy": {
      "task": "ogx_mmlux_bg-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за астрономията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-business_ethics": {
      "task": "ogx_mmlux_bg-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за бизнес етиката.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "task": "ogx_mmlux_bg-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за клинични знания.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_biology": {
      "task": "ogx_mmlux_bg-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по биология в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_chemistry": {
      "task": "ogx_mmlux_bg-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по химия в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_computer_science": {
      "task": "ogx_mmlux_bg-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по информатика в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_mathematics": {
      "task": "ogx_mmlux_bg-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по математика в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_medicine": {
      "task": "ogx_mmlux_bg-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за университетската медицина.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_physics": {
      "task": "ogx_mmlux_bg-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по физика в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-computer_security": {
      "task": "ogx_mmlux_bg-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за компютърната сигурност.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "task": "ogx_mmlux_bg-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за концептуалната физика.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-econometrics": {
      "task": "ogx_mmlux_bg-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за иконометрията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "task": "ogx_mmlux_bg-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за електротехниката.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "task": "ogx_mmlux_bg-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по елементарна математика.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-formal_logic": {
      "task": "ogx_mmlux_bg-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за формалната логика.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-global_facts": {
      "task": "ogx_mmlux_bg-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за глобалните факти.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_biology": {
      "task": "ogx_mmlux_bg-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по биология за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "task": "ogx_mmlux_bg-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по химия за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "task": "ogx_mmlux_bg-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по информатика в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "task": "ogx_mmlux_bg-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по история на Европа в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_geography": {
      "task": "ogx_mmlux_bg-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по география за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "task": "ogx_mmlux_bg-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за управлението и политиката в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "task": "ogx_mmlux_bg-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по макроикономика за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "task": "ogx_mmlux_bg-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за математиката в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "task": "ogx_mmlux_bg-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по микроикономика за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_physics": {
      "task": "ogx_mmlux_bg-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по физика за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "task": "ogx_mmlux_bg-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по психология в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "task": "ogx_mmlux_bg-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за статистиката в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "task": "ogx_mmlux_bg-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по история на САЩ в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "task": "ogx_mmlux_bg-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по история на света в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-human_aging": {
      "task": "ogx_mmlux_bg-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за човешкото стареене.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-human_sexuality": {
      "task": "ogx_mmlux_bg-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за човешката сексуалност.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-international_law": {
      "task": "ogx_mmlux_bg-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за международното право.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-jurisprudence": {
      "task": "ogx_mmlux_bg-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за юриспруденцията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "task": "ogx_mmlux_bg-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за логическите грешки.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-machine_learning": {
      "task": "ogx_mmlux_bg-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за машинното обучение.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-management": {
      "task": "ogx_mmlux_bg-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за управлението.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-marketing": {
      "task": "ogx_mmlux_bg-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за маркетинга.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-medical_genetics": {
      "task": "ogx_mmlux_bg-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за медицинската генетика.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-miscellaneous": {
      "task": "ogx_mmlux_bg-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с въпроси с избор (с отговори) за miscellaneous.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-moral_disputes": {
      "task": "ogx_mmlux_bg-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за морални спорове.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "task": "ogx_mmlux_bg-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за морални сценарии.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-nutrition": {
      "task": "ogx_mmlux_bg-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за храненето.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-philosophy": {
      "task": "ogx_mmlux_bg-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за философията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-prehistory": {
      "task": "ogx_mmlux_bg-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за праисторията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_accounting": {
      "task": "ogx_mmlux_bg-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за професионалното счетоводство.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_law": {
      "task": "ogx_mmlux_bg-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора, свързани с професионалното право.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_medicine": {
      "task": "ogx_mmlux_bg-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за професионалната медицина.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_psychology": {
      "task": "ogx_mmlux_bg-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за професионалната психология.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-public_relations": {
      "task": "ogx_mmlux_bg-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за връзките с обществеността.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-security_studies": {
      "task": "ogx_mmlux_bg-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за проучвания в областта на сигурността.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-sociology": {
      "task": "ogx_mmlux_bg-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по социология.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "task": "ogx_mmlux_bg-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с въпроси с избор (с отговори) за външната политика на САЩ.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-virology": {
      "task": "ogx_mmlux_bg-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за вирусологията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-world_religions": {
      "task": "ogx_mmlux_bg-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за световните религии.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "task": "ogx_mmlux_cs-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o abstraktní algebře.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-anatomy": {
      "task": "ogx_mmlux_cs-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o anatomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-astronomy": {
      "task": "ogx_mmlux_cs-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o astronomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-business_ethics": {
      "task": "ogx_mmlux_cs-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o etice podnikání.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "task": "ogx_mmlux_cs-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o klinických znalostech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_biology": {
      "task": "ogx_mmlux_cs-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské biologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_chemistry": {
      "task": "ogx_mmlux_cs-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské chemii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_computer_science": {
      "task": "ogx_mmlux_cs-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské informatice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_mathematics": {
      "task": "ogx_mmlux_cs-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_medicine": {
      "task": "ogx_mmlux_cs-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské medicíně.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_physics": {
      "task": "ogx_mmlux_cs-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z vysokoškolské fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-computer_security": {
      "task": "ogx_mmlux_cs-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o počítačové bezpečnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "task": "ogx_mmlux_cs-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z konceptuální fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-econometrics": {
      "task": "ogx_mmlux_cs-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "task": "ogx_mmlux_cs-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o elektrotechnice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "task": "ogx_mmlux_cs-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o elementární matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-formal_logic": {
      "task": "ogx_mmlux_cs-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o formální logice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-global_facts": {
      "task": "ogx_mmlux_cs-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o globálních faktech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_biology": {
      "task": "ogx_mmlux_cs-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské biologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "task": "ogx_mmlux_cs-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské chemii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "task": "ogx_mmlux_cs-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské informatice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "task": "ogx_mmlux_cs-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z dějin Evropy pro střední školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_geography": {
      "task": "ogx_mmlux_cs-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolském zeměpisu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "task": "ogx_mmlux_cs-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské vládě a politice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "task": "ogx_mmlux_cs-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z makroekonomie pro střední školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "task": "ogx_mmlux_cs-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "task": "ogx_mmlux_cs-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z mikroekonomie pro střední školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_physics": {
      "task": "ogx_mmlux_cs-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí ze středoškolské fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "task": "ogx_mmlux_cs-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské psychologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "task": "ogx_mmlux_cs-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské statistice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "task": "ogx_mmlux_cs-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky s výběrem odpovědí se týkají středoškolské historie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "task": "ogx_mmlux_cs-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí ze světových dějin pro střední školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-human_aging": {
      "task": "ogx_mmlux_cs-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o stárnutí člověka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-human_sexuality": {
      "task": "ogx_mmlux_cs-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o lidské sexualitě.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-international_law": {
      "task": "ogx_mmlux_cs-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o mezinárodním právu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-jurisprudence": {
      "task": "ogx_mmlux_cs-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o právu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "task": "ogx_mmlux_cs-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o logických klamech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-machine_learning": {
      "task": "ogx_mmlux_cs-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o strojovém učení.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-management": {
      "task": "ogx_mmlux_cs-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky (s odpověďmi) se týkají managementu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-marketing": {
      "task": "ogx_mmlux_cs-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky (s odpověďmi) se týkají marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-medical_genetics": {
      "task": "ogx_mmlux_cs-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o lékařské genetice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-miscellaneous": {
      "task": "ogx_mmlux_cs-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky s výběrem odpovědi se týkají tématu miscellaneous.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-moral_disputes": {
      "task": "ogx_mmlux_cs-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky s výběrem odpovědí se týkají morálních sporů.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "task": "ogx_mmlux_cs-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o morálních scénářích.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-nutrition": {
      "task": "ogx_mmlux_cs-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o výživě.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-philosophy": {
      "task": "ogx_mmlux_cs-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-prehistory": {
      "task": "ogx_mmlux_cs-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o pravěku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_accounting": {
      "task": "ogx_mmlux_cs-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o odborném účetnictví.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_law": {
      "task": "ogx_mmlux_cs-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o profesním právu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_medicine": {
      "task": "ogx_mmlux_cs-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o profesionální medicíně.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_psychology": {
      "task": "ogx_mmlux_cs-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o odborné psychologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-public_relations": {
      "task": "ogx_mmlux_cs-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vztazích s veřejností.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-security_studies": {
      "task": "ogx_mmlux_cs-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o bezpečnostních studiích.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-sociology": {
      "task": "ogx_mmlux_cs-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o sociologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "task": "ogx_mmlux_cs-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky s výběrem odpovědí se týkají zahraniční politiky USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-virology": {
      "task": "ogx_mmlux_cs-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o virologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-world_religions": {
      "task": "ogx_mmlux_cs-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o světových náboženstvích.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-abstract_algebra": {
      "task": "ogx_mmlux_da-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om abstrakt algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-anatomy": {
      "task": "ogx_mmlux_da-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om anatomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-astronomy": {
      "task": "ogx_mmlux_da-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om astronomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-business_ethics": {
      "task": "ogx_mmlux_da-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om forretningsetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "task": "ogx_mmlux_da-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om klinisk viden.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_biology": {
      "task": "ogx_mmlux_da-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om universitetsbiologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_chemistry": {
      "task": "ogx_mmlux_da-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om kemi på college.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_computer_science": {
      "task": "ogx_mmlux_da-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om computervidenskab på college.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_mathematics": {
      "task": "ogx_mmlux_da-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om universitetsmatematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_medicine": {
      "task": "ogx_mmlux_da-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om universitetsmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_physics": {
      "task": "ogx_mmlux_da-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om universitetsfysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-computer_security": {
      "task": "ogx_mmlux_da-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om computersikkerhed.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-conceptual_physics": {
      "task": "ogx_mmlux_da-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om konceptuel fysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-econometrics": {
      "task": "ogx_mmlux_da-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om økonometri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-electrical_engineering": {
      "task": "ogx_mmlux_da-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om elektroteknik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "task": "ogx_mmlux_da-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om elementær matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-formal_logic": {
      "task": "ogx_mmlux_da-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om formel logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-global_facts": {
      "task": "ogx_mmlux_da-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om globale fakta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_biology": {
      "task": "ogx_mmlux_da-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om biologi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "task": "ogx_mmlux_da-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om kemi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "task": "ogx_mmlux_da-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om computervidenskab i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_european_history": {
      "task": "ogx_mmlux_da-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om europæisk historie i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_geography": {
      "task": "ogx_mmlux_da-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om geografi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "task": "ogx_mmlux_da-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om regering og politik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "task": "ogx_mmlux_da-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om makroøkonomi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "task": "ogx_mmlux_da-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om matematik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "task": "ogx_mmlux_da-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det følgende er multiple choice-spørgsmål (med svar) om mikroøkonomi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_physics": {
      "task": "ogx_mmlux_da-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om fysik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_psychology": {
      "task": "ogx_mmlux_da-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om psykologi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_statistics": {
      "task": "ogx_mmlux_da-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om statistik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_us_history": {
      "task": "ogx_mmlux_da-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om amerikansk historie i high school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_world_history": {
      "task": "ogx_mmlux_da-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om verdenshistorie i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-human_aging": {
      "task": "ogx_mmlux_da-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om menneskets aldring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-human_sexuality": {
      "task": "ogx_mmlux_da-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om menneskelig seksualitet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-international_law": {
      "task": "ogx_mmlux_da-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om international lov.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-jurisprudence": {
      "task": "ogx_mmlux_da-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om retsvidenskab.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-logical_fallacies": {
      "task": "ogx_mmlux_da-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om logiske fejlslutninger.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-machine_learning": {
      "task": "ogx_mmlux_da-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om maskinlæring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-management": {
      "task": "ogx_mmlux_da-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om ledelse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-marketing": {
      "task": "ogx_mmlux_da-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-medical_genetics": {
      "task": "ogx_mmlux_da-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om medicinsk genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-miscellaneous": {
      "task": "ogx_mmlux_da-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-moral_disputes": {
      "task": "ogx_mmlux_da-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om moralske tvister.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-moral_scenarios": {
      "task": "ogx_mmlux_da-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om moralske scenarier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-nutrition": {
      "task": "ogx_mmlux_da-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om ernæring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-philosophy": {
      "task": "ogx_mmlux_da-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om filosofi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-prehistory": {
      "task": "ogx_mmlux_da-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det følgende er multiple choice-spørgsmål (med svar) om forhistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_accounting": {
      "task": "ogx_mmlux_da-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om professionelt regnskab.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_law": {
      "task": "ogx_mmlux_da-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om erhvervsret.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_medicine": {
      "task": "ogx_mmlux_da-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om professionel medicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_psychology": {
      "task": "ogx_mmlux_da-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om professionel psykologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-public_relations": {
      "task": "ogx_mmlux_da-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-security_studies": {
      "task": "ogx_mmlux_da-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om sikkerhedsstudier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-sociology": {
      "task": "ogx_mmlux_da-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om sociologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "task": "ogx_mmlux_da-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om amerikansk udenrigspolitik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-virology": {
      "task": "ogx_mmlux_da-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om virologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-world_religions": {
      "task": "ogx_mmlux_da-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det følgende er multiple choice-spørgsmål (med svar) om verdensreligioner.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-abstract_algebra": {
      "task": "ogx_mmlux_de-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur abstrakten Algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-anatomy": {
      "task": "ogx_mmlux_de-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-astronomy": {
      "task": "ogx_mmlux_de-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-business_ethics": {
      "task": "ogx_mmlux_de-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Unternehmensethik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "task": "ogx_mmlux_de-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu klinischen Kenntnissen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_biology": {
      "task": "ogx_mmlux_de-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Biologie an der Universität.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_chemistry": {
      "task": "ogx_mmlux_de-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Chemie an Hochschulen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_computer_science": {
      "task": "ogx_mmlux_de-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulinformatik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_mathematics": {
      "task": "ogx_mmlux_de-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulmathematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_medicine": {
      "task": "ogx_mmlux_de-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Hochschulmedizin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_physics": {
      "task": "ogx_mmlux_de-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulphysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-computer_security": {
      "task": "ogx_mmlux_de-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Computersicherheit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-conceptual_physics": {
      "task": "ogx_mmlux_de-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur konzeptionellen Physik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-econometrics": {
      "task": "ogx_mmlux_de-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Ökonometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-electrical_engineering": {
      "task": "ogx_mmlux_de-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Elektrotechnik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "task": "ogx_mmlux_de-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur elementaren Mathematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-formal_logic": {
      "task": "ogx_mmlux_de-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur formalen Logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-global_facts": {
      "task": "ogx_mmlux_de-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu globalen Fakten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_biology": {
      "task": "ogx_mmlux_de-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Biologie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "task": "ogx_mmlux_de-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Chemie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "task": "ogx_mmlux_de-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Informatik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_european_history": {
      "task": "ogx_mmlux_de-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur europäischen Geschichte in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_geography": {
      "task": "ogx_mmlux_de-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Geografie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "task": "ogx_mmlux_de-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Regierung und Politik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "task": "ogx_mmlux_de-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Makroökonomie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "task": "ogx_mmlux_de-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Mathematik in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "task": "ogx_mmlux_de-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Mikroökonomie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_physics": {
      "task": "ogx_mmlux_de-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Physik in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_psychology": {
      "task": "ogx_mmlux_de-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Schulpsychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_statistics": {
      "task": "ogx_mmlux_de-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Statistik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_us_history": {
      "task": "ogx_mmlux_de-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Geschichte der USA in der High School.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_world_history": {
      "task": "ogx_mmlux_de-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Weltgeschichte in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-human_aging": {
      "task": "ogx_mmlux_de-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum menschlichen Altern.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-human_sexuality": {
      "task": "ogx_mmlux_de-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur menschlichen Sexualität.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-international_law": {
      "task": "ogx_mmlux_de-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum internationalen Recht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-jurisprudence": {
      "task": "ogx_mmlux_de-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Rechtswissenschaft.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-logical_fallacies": {
      "task": "ogx_mmlux_de-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu logischen Fehlschlüssen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-machine_learning": {
      "task": "ogx_mmlux_de-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum maschinellen Lernen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-management": {
      "task": "ogx_mmlux_de-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-marketing": {
      "task": "ogx_mmlux_de-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-medical_genetics": {
      "task": "ogx_mmlux_de-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur medizinischen Genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-miscellaneous": {
      "task": "ogx_mmlux_de-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Verschiedenes.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-moral_disputes": {
      "task": "ogx_mmlux_de-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu moralischen Streitigkeiten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-moral_scenarios": {
      "task": "ogx_mmlux_de-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu moralischen Szenarien.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-nutrition": {
      "task": "ogx_mmlux_de-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Ernährung.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-philosophy": {
      "task": "ogx_mmlux_de-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Philosophie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-prehistory": {
      "task": "ogx_mmlux_de-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Vorgeschichte.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_accounting": {
      "task": "ogx_mmlux_de-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema professionelle Buchhaltung.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_law": {
      "task": "ogx_mmlux_de-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Berufsrecht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_medicine": {
      "task": "ogx_mmlux_de-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Berufsmedizin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_psychology": {
      "task": "ogx_mmlux_de-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Berufspsychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-public_relations": {
      "task": "ogx_mmlux_de-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Öffentlichkeitsarbeit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-security_studies": {
      "task": "ogx_mmlux_de-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Es folgen Multiple-Choice-Fragen (mit Antworten) zu Sicherheitsstudien.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-sociology": {
      "task": "ogx_mmlux_de-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Soziologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "task": "ogx_mmlux_de-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Außenpolitik der USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-virology": {
      "task": "ogx_mmlux_de-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-world_religions": {
      "task": "ogx_mmlux_de-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu den Weltreligionen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-abstract_algebra": {
      "task": "ogx_mmlux_el-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την αφηρημένη άλγεβρα.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-anatomy": {
      "task": "ogx_mmlux_el-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ανατομία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-astronomy": {
      "task": "ogx_mmlux_el-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την αστρονομία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-business_ethics": {
      "task": "ogx_mmlux_el-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επιχειρηματική ηθική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "task": "ogx_mmlux_el-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις κλινικές γνώσεις.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_biology": {
      "task": "ogx_mmlux_el-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη βιολογία του κολεγίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_chemistry": {
      "task": "ogx_mmlux_el-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη χημεία του πανεπιστημίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_computer_science": {
      "task": "ogx_mmlux_el-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επιστήμη των υπολογιστών στο κολέγιο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_mathematics": {
      "task": "ogx_mmlux_el-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα μαθηματικά του πανεπιστημίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_medicine": {
      "task": "ogx_mmlux_el-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ιατρική στο κολέγιο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_physics": {
      "task": "ogx_mmlux_el-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη φυσική του πανεπιστημίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-computer_security": {
      "task": "ogx_mmlux_el-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ασφάλεια των υπολογιστών.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-conceptual_physics": {
      "task": "ogx_mmlux_el-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την εννοιολογική φυσική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-econometrics": {
      "task": "ogx_mmlux_el-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την οικονομετρία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-electrical_engineering": {
      "task": "ogx_mmlux_el-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ηλεκτρολογική μηχανική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "task": "ogx_mmlux_el-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα στοιχειώδη μαθηματικά.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-formal_logic": {
      "task": "ogx_mmlux_el-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την τυπική λογική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-global_facts": {
      "task": "ogx_mmlux_el-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα παγκόσμια γεγονότα.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_biology": {
      "task": "ogx_mmlux_el-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη βιολογία γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "task": "ogx_mmlux_el-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη χημεία του γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "task": "ogx_mmlux_el-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επιστήμη των υπολογιστών στο λύκειο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_european_history": {
      "task": "ogx_mmlux_el-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ευρωπαϊκή ιστορία του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_geography": {
      "task": "ogx_mmlux_el-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη γεωγραφία του γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "task": "ogx_mmlux_el-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την κυβέρνηση και την πολιτική στο λύκειο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "task": "ogx_mmlux_el-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα μακροοικονομικά του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "task": "ogx_mmlux_el-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα μαθηματικά του γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "task": "ogx_mmlux_el-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη μικροοικονομία του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_physics": {
      "task": "ogx_mmlux_el-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη φυσική γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_psychology": {
      "task": "ogx_mmlux_el-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ψυχολογία του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_statistics": {
      "task": "ogx_mmlux_el-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη στατιστική του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_us_history": {
      "task": "ogx_mmlux_el-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ιστορία μας στο λύκειο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_world_history": {
      "task": "ogx_mmlux_el-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την παγκόσμια ιστορία του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-human_aging": {
      "task": "ogx_mmlux_el-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη γήρανση του ανθρώπου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-human_sexuality": {
      "task": "ogx_mmlux_el-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ανθρώπινη σεξουαλικότητα.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-international_law": {
      "task": "ogx_mmlux_el-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με το διεθνές δίκαιο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-jurisprudence": {
      "task": "ogx_mmlux_el-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη νομική επιστήμη.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-logical_fallacies": {
      "task": "ogx_mmlux_el-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις λογικές πλάνες.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-machine_learning": {
      "task": "ogx_mmlux_el-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη μηχανική μάθηση.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-management": {
      "task": "ogx_mmlux_el-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη διαχείριση.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-marketing": {
      "task": "ogx_mmlux_el-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με το μάρκετινγκ.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-medical_genetics": {
      "task": "ogx_mmlux_el-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ιατρική γενετική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-miscellaneous": {
      "task": "ogx_mmlux_el-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα διάφορα.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-moral_disputes": {
      "task": "ogx_mmlux_el-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις ηθικές διαμάχες.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-moral_scenarios": {
      "task": "ogx_mmlux_el-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με ηθικά σενάρια.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-nutrition": {
      "task": "ogx_mmlux_el-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη διατροφή.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-philosophy": {
      "task": "ogx_mmlux_el-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη φιλοσοφία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-prehistory": {
      "task": "ogx_mmlux_el-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την προϊστορία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_accounting": {
      "task": "ogx_mmlux_el-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επαγγελματική λογιστική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_law": {
      "task": "ogx_mmlux_el-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με το επαγγελματικό δίκαιο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_medicine": {
      "task": "ogx_mmlux_el-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επαγγελματική ιατρική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_psychology": {
      "task": "ogx_mmlux_el-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επαγγελματική ψυχολογία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-public_relations": {
      "task": "ogx_mmlux_el-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις δημόσιες σχέσεις.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-security_studies": {
      "task": "ogx_mmlux_el-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις μελέτες ασφάλειας.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-sociology": {
      "task": "ogx_mmlux_el-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την κοινωνιολογία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "task": "ogx_mmlux_el-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την εξωτερική πολιτική των ΗΠΑ.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-virology": {
      "task": "ogx_mmlux_el-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ιολογία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-world_religions": {
      "task": "ogx_mmlux_el-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις παγκόσμιες θρησκείες.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-abstract_algebra": {
      "task": "ogx_mmlux_es-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre álgebra abstracta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-anatomy": {
      "task": "ogx_mmlux_es-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre anatomía.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-astronomy": {
      "task": "ogx_mmlux_es-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre astronomía.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-business_ethics": {
      "task": "ogx_mmlux_es-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre ética empresarial.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "task": "ogx_mmlux_es-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A continuación se presentan preguntas tipo test (con respuesta) sobre conocimientos clínicos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_biology": {
      "task": "ogx_mmlux_es-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre biología universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_chemistry": {
      "task": "ogx_mmlux_es-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre química universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_computer_science": {
      "task": "ogx_mmlux_es-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre informática universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_mathematics": {
      "task": "ogx_mmlux_es-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemáticas universitarias.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_medicine": {
      "task": "ogx_mmlux_es-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre medicina universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_physics": {
      "task": "ogx_mmlux_es-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre física universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-computer_security": {
      "task": "ogx_mmlux_es-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre seguridad informática.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-conceptual_physics": {
      "task": "ogx_mmlux_es-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre física conceptual.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-econometrics": {
      "task": "ogx_mmlux_es-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre econometría.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-electrical_engineering": {
      "task": "ogx_mmlux_es-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre ingeniería eléctrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "task": "ogx_mmlux_es-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemáticas elementales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-formal_logic": {
      "task": "ogx_mmlux_es-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre lógica formal.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-global_facts": {
      "task": "ogx_mmlux_es-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre hechos globales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_biology": {
      "task": "ogx_mmlux_es-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre biología de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "task": "ogx_mmlux_es-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre química de bachillerato.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "task": "ogx_mmlux_es-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre informática en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_european_history": {
      "task": "ogx_mmlux_es-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre historia europea de bachillerato.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_geography": {
      "task": "ogx_mmlux_es-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre geografía de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "task": "ogx_mmlux_es-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre el gobierno y la política en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "task": "ogx_mmlux_es-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre macroeconomía en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "task": "ogx_mmlux_es-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemáticas de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "task": "ogx_mmlux_es-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre microeconomía en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_physics": {
      "task": "ogx_mmlux_es-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre física de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_psychology": {
      "task": "ogx_mmlux_es-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre psicología en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_statistics": {
      "task": "ogx_mmlux_es-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre estadística de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_us_history": {
      "task": "ogx_mmlux_es-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre la historia de EE.UU. en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_world_history": {
      "task": "ogx_mmlux_es-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre la historia mundial de la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-human_aging": {
      "task": "ogx_mmlux_es-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre el envejecimiento humano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-human_sexuality": {
      "task": "ogx_mmlux_es-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre la sexualidad humana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-international_law": {
      "task": "ogx_mmlux_es-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre Derecho internacional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-jurisprudence": {
      "task": "ogx_mmlux_es-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre jurisprudencia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-logical_fallacies": {
      "task": "ogx_mmlux_es-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre falacias lógicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-machine_learning": {
      "task": "ogx_mmlux_es-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre aprendizaje automático.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-management": {
      "task": "ogx_mmlux_es-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre gestión.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-marketing": {
      "task": "ogx_mmlux_es-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-medical_genetics": {
      "task": "ogx_mmlux_es-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre genética médica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-miscellaneous": {
      "task": "ogx_mmlux_es-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre miscelánea.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-moral_disputes": {
      "task": "ogx_mmlux_es-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre disputas morales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-moral_scenarios": {
      "task": "ogx_mmlux_es-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre escenarios morales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-nutrition": {
      "task": "ogx_mmlux_es-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre nutrición.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-philosophy": {
      "task": "ogx_mmlux_es-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre filosofía.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-prehistory": {
      "task": "ogx_mmlux_es-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre la prehistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_accounting": {
      "task": "ogx_mmlux_es-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre contabilidad profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_law": {
      "task": "ogx_mmlux_es-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A continuación se presentan preguntas tipo test (con respuesta) sobre Derecho profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_medicine": {
      "task": "ogx_mmlux_es-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre medicina profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_psychology": {
      "task": "ogx_mmlux_es-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre psicología profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-public_relations": {
      "task": "ogx_mmlux_es-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre relaciones públicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-security_studies": {
      "task": "ogx_mmlux_es-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre estudios de seguridad.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-sociology": {
      "task": "ogx_mmlux_es-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre sociología.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "task": "ogx_mmlux_es-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre la política exterior estadounidense.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-virology": {
      "task": "ogx_mmlux_es-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre virología.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-world_religions": {
      "task": "ogx_mmlux_es-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre las religiones del mundo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-abstract_algebra": {
      "task": "ogx_mmlux_et-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) abstraktse algebra kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-anatomy": {
      "task": "ogx_mmlux_et-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) anatoomia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-astronomy": {
      "task": "ogx_mmlux_et-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) astronoomia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-business_ethics": {
      "task": "ogx_mmlux_et-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) ärieetika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "task": "ogx_mmlux_et-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kliiniliste teadmiste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_biology": {
      "task": "ogx_mmlux_et-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži bioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_chemistry": {
      "task": "ogx_mmlux_et-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži keemia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_computer_science": {
      "task": "ogx_mmlux_et-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kõrgkooli informaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_mathematics": {
      "task": "ogx_mmlux_et-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži matemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_medicine": {
      "task": "ogx_mmlux_et-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži meditsiini kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_physics": {
      "task": "ogx_mmlux_et-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži füüsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-computer_security": {
      "task": "ogx_mmlux_et-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) arvutiturbe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-conceptual_physics": {
      "task": "ogx_mmlux_et-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kontseptuaalse füüsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-econometrics": {
      "task": "ogx_mmlux_et-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) ökonomeetria kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-electrical_engineering": {
      "task": "ogx_mmlux_et-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) elektrotehnika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "task": "ogx_mmlux_et-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) elementaarmatemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-formal_logic": {
      "task": "ogx_mmlux_et-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) formaalloogika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-global_facts": {
      "task": "ogx_mmlux_et-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) globaalsete faktide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_biology": {
      "task": "ogx_mmlux_et-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli bioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "task": "ogx_mmlux_et-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli keemia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "task": "ogx_mmlux_et-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli informaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_european_history": {
      "task": "ogx_mmlux_et-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli Euroopa ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_geography": {
      "task": "ogx_mmlux_et-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli geograafia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "task": "ogx_mmlux_et-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli valitsuse ja poliitika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "task": "ogx_mmlux_et-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli makromajanduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "task": "ogx_mmlux_et-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli matemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "task": "ogx_mmlux_et-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli mikroökonoomika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_physics": {
      "task": "ogx_mmlux_et-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkoolifüüsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_psychology": {
      "task": "ogx_mmlux_et-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkoolipsühholoogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_statistics": {
      "task": "ogx_mmlux_et-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli statistika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_us_history": {
      "task": "ogx_mmlux_et-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) meie keskkooli ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_world_history": {
      "task": "ogx_mmlux_et-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli maailma ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-human_aging": {
      "task": "ogx_mmlux_et-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) inimese vananemise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-human_sexuality": {
      "task": "ogx_mmlux_et-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) inimese seksuaalsuse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-international_law": {
      "task": "ogx_mmlux_et-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) rahvusvahelise õiguse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-jurisprudence": {
      "task": "ogx_mmlux_et-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) õigusteaduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-logical_fallacies": {
      "task": "ogx_mmlux_et-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) loogiliste eksituste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-machine_learning": {
      "task": "ogx_mmlux_et-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) masinõppe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-management": {
      "task": "ogx_mmlux_et-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) juhtimise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-marketing": {
      "task": "ogx_mmlux_et-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) turunduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-medical_genetics": {
      "task": "ogx_mmlux_et-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) meditsiinigeneetika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-miscellaneous": {
      "task": "ogx_mmlux_et-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) mitmesuguste küsimuste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-moral_disputes": {
      "task": "ogx_mmlux_et-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) moraalsete vaidluste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-moral_scenarios": {
      "task": "ogx_mmlux_et-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) moraalsete stsenaariumide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-nutrition": {
      "task": "ogx_mmlux_et-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) toitumise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-philosophy": {
      "task": "ogx_mmlux_et-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) filosoofia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-prehistory": {
      "task": "ogx_mmlux_et-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) eelajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_accounting": {
      "task": "ogx_mmlux_et-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kutsealase raamatupidamise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_law": {
      "task": "ogx_mmlux_et-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kutseõiguse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_medicine": {
      "task": "ogx_mmlux_et-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) erialase meditsiini kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_psychology": {
      "task": "ogx_mmlux_et-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) erialase psühholoogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-public_relations": {
      "task": "ogx_mmlux_et-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) avalike suhete kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-security_studies": {
      "task": "ogx_mmlux_et-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) julgeolekuõppe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-sociology": {
      "task": "ogx_mmlux_et-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) sotsioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "task": "ogx_mmlux_et-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) meie välispoliitika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-virology": {
      "task": "ogx_mmlux_et-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) viroloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-world_religions": {
      "task": "ogx_mmlux_et-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) maailmareligioonide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "task": "ogx_mmlux_fi-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) abstraktista algebrasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-anatomy": {
      "task": "ogx_mmlux_fi-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) anatomiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-astronomy": {
      "task": "ogx_mmlux_fi-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) tähtitieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-business_ethics": {
      "task": "ogx_mmlux_fi-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) liike-elämän etiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "task": "ogx_mmlux_fi-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) kliinisestä tietämyksestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_biology": {
      "task": "ogx_mmlux_fi-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistobiologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_chemistry": {
      "task": "ogx_mmlux_fi-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistokemiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_computer_science": {
      "task": "ogx_mmlux_fi-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistojen tietotekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_mathematics": {
      "task": "ogx_mmlux_fi-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistomatematiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_medicine": {
      "task": "ogx_mmlux_fi-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistolääketieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_physics": {
      "task": "ogx_mmlux_fi-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistofysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-computer_security": {
      "task": "ogx_mmlux_fi-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) tietoturvasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "task": "ogx_mmlux_fi-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) käsitteellisestä fysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-econometrics": {
      "task": "ogx_mmlux_fi-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ekonometriasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "task": "ogx_mmlux_fi-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) sähkötekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "task": "ogx_mmlux_fi-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) matematiikan alkeista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-formal_logic": {
      "task": "ogx_mmlux_fi-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) muodollisesta logiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-global_facts": {
      "task": "ogx_mmlux_fi-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) globaaleista tosiasioista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_biology": {
      "task": "ogx_mmlux_fi-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion biologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "task": "ogx_mmlux_fi-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion kemiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "task": "ogx_mmlux_fi-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion tietotekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "task": "ogx_mmlux_fi-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion Euroopan historiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_geography": {
      "task": "ogx_mmlux_fi-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion maantiedosta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "task": "ogx_mmlux_fi-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion hallituksesta ja politiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "task": "ogx_mmlux_fi-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion makrotaloudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "task": "ogx_mmlux_fi-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion matematiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "task": "ogx_mmlux_fi-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion mikrotaloustieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_physics": {
      "task": "ogx_mmlux_fi-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion fysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "task": "ogx_mmlux_fi-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion psykologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "task": "ogx_mmlux_fi-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion tilastoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "task": "ogx_mmlux_fi-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion historiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "task": "ogx_mmlux_fi-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion maailmanhistoriasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-human_aging": {
      "task": "ogx_mmlux_fi-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ihmisen ikääntymisestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-human_sexuality": {
      "task": "ogx_mmlux_fi-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ihmisen seksuaalisuudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-international_law": {
      "task": "ogx_mmlux_fi-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) kansainvälisestä oikeudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-jurisprudence": {
      "task": "ogx_mmlux_fi-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) oikeustieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "task": "ogx_mmlux_fi-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) loogisista virheistä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-machine_learning": {
      "task": "ogx_mmlux_fi-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) koneoppimisesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-management": {
      "task": "ogx_mmlux_fi-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) johtamisesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-marketing": {
      "task": "ogx_mmlux_fi-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) markkinoinnista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-medical_genetics": {
      "task": "ogx_mmlux_fi-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) lääketieteellisestä genetiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-miscellaneous": {
      "task": "ogx_mmlux_fi-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) aiheesta sekalaiset.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-moral_disputes": {
      "task": "ogx_mmlux_fi-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) moraalisista kiistoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "task": "ogx_mmlux_fi-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) moraalisista skenaarioista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-nutrition": {
      "task": "ogx_mmlux_fi-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ravitsemuksesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-philosophy": {
      "task": "ogx_mmlux_fi-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) filosofiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-prehistory": {
      "task": "ogx_mmlux_fi-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on esihistoriaa koskevia monivalintakysymyksiä (vastauksineen).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_accounting": {
      "task": "ogx_mmlux_fi-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ammattimaisesta kirjanpidosta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_law": {
      "task": "ogx_mmlux_fi-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ammattioikeudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_medicine": {
      "task": "ogx_mmlux_fi-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) ammatillisesta lääketieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_psychology": {
      "task": "ogx_mmlux_fi-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ammattipsykologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-public_relations": {
      "task": "ogx_mmlux_fi-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) suhdetoiminnasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-security_studies": {
      "task": "ogx_mmlux_fi-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) turvallisuustutkimuksesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-sociology": {
      "task": "ogx_mmlux_fi-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on sosiologiaa koskevia monivalintakysymyksiä (vastauksineen).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "task": "ogx_mmlux_fi-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavat ovat monivalintakysymyksiä (vastauksineen) Yhdysvaltojen ulkopolitiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-virology": {
      "task": "ogx_mmlux_fi-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) virologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-world_religions": {
      "task": "ogx_mmlux_fi-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) maailmanuskonnoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "task": "ogx_mmlux_fr-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'algèbre abstraite.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-anatomy": {
      "task": "ogx_mmlux_fr-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-astronomy": {
      "task": "ogx_mmlux_fr-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-business_ethics": {
      "task": "ogx_mmlux_fr-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'éthique des affaires.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "task": "ogx_mmlux_fr-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les connaissances cliniques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_biology": {
      "task": "ogx_mmlux_fr-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la biologie au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_chemistry": {
      "task": "ogx_mmlux_fr-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la chimie au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_computer_science": {
      "task": "ogx_mmlux_fr-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'informatique au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_mathematics": {
      "task": "ogx_mmlux_fr-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les mathématiques au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_medicine": {
      "task": "ogx_mmlux_fr-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la médecine universitaire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_physics": {
      "task": "ogx_mmlux_fr-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la physique au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-computer_security": {
      "task": "ogx_mmlux_fr-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la sécurité informatique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "task": "ogx_mmlux_fr-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la physique conceptuelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-econometrics": {
      "task": "ogx_mmlux_fr-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'économétrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "task": "ogx_mmlux_fr-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le génie électrique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "task": "ogx_mmlux_fr-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les mathématiques élémentaires.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-formal_logic": {
      "task": "ogx_mmlux_fr-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la logique formelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-global_facts": {
      "task": "ogx_mmlux_fr-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les faits mondiaux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_biology": {
      "task": "ogx_mmlux_fr-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la biologie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "task": "ogx_mmlux_fr-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la chimie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "task": "ogx_mmlux_fr-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'informatique au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "task": "ogx_mmlux_fr-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'histoire de l'Europe au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_geography": {
      "task": "ogx_mmlux_fr-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la géographie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "task": "ogx_mmlux_fr-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le gouvernement et la politique au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "task": "ogx_mmlux_fr-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la macroéconomie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "task": "ogx_mmlux_fr-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les mathématiques au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "task": "ogx_mmlux_fr-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la microéconomie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_physics": {
      "task": "ogx_mmlux_fr-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la physique au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "task": "ogx_mmlux_fr-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la psychologie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "task": "ogx_mmlux_fr-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les statistiques de l'enseignement secondaire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "task": "ogx_mmlux_fr-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'histoire des États-Unis au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "task": "ogx_mmlux_fr-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'histoire du monde au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-human_aging": {
      "task": "ogx_mmlux_fr-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le vieillissement humain.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-human_sexuality": {
      "task": "ogx_mmlux_fr-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la sexualité humaine.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-international_law": {
      "task": "ogx_mmlux_fr-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le droit international.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-jurisprudence": {
      "task": "ogx_mmlux_fr-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la jurisprudence.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "task": "ogx_mmlux_fr-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les sophismes logiques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-machine_learning": {
      "task": "ogx_mmlux_fr-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'apprentissage automatique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-management": {
      "task": "ogx_mmlux_fr-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-marketing": {
      "task": "ogx_mmlux_fr-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-medical_genetics": {
      "task": "ogx_mmlux_fr-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la génétique médicale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-miscellaneous": {
      "task": "ogx_mmlux_fr-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les divers.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-moral_disputes": {
      "task": "ogx_mmlux_fr-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les différends moraux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "task": "ogx_mmlux_fr-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur des scénarios moraux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-nutrition": {
      "task": "ogx_mmlux_fr-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la nutrition.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-philosophy": {
      "task": "ogx_mmlux_fr-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la philosophie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-prehistory": {
      "task": "ogx_mmlux_fr-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la préhistoire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_accounting": {
      "task": "ogx_mmlux_fr-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la comptabilité professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_law": {
      "task": "ogx_mmlux_fr-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le droit professionnel.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_medicine": {
      "task": "ogx_mmlux_fr-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la médecine professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_psychology": {
      "task": "ogx_mmlux_fr-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la psychologie professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-public_relations": {
      "task": "ogx_mmlux_fr-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les relations publiques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-security_studies": {
      "task": "ogx_mmlux_fr-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les études de sécurité.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-sociology": {
      "task": "ogx_mmlux_fr-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "task": "ogx_mmlux_fr-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Voici des questions à choix multiples (avec réponses) sur la politique étrangère des États-Unis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-virology": {
      "task": "ogx_mmlux_fr-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-world_religions": {
      "task": "ogx_mmlux_fr-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Voici des questions à choix multiples (avec réponses) sur les religions du monde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "task": "ogx_mmlux_hu-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) az absztrakt algebráról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-anatomy": {
      "task": "ogx_mmlux_hu-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) az anatómiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-astronomy": {
      "task": "ogx_mmlux_hu-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a csillagászatról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-business_ethics": {
      "task": "ogx_mmlux_hu-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az üzleti etikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "task": "ogx_mmlux_hu-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban a klinikai ismeretekkel kapcsolatos feleletválasztós kérdések (válaszokkal) következnek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_biology": {
      "task": "ogx_mmlux_hu-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai biológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_chemistry": {
      "task": "ogx_mmlux_hu-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai kémiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_computer_science": {
      "task": "ogx_mmlux_hu-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai informatikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_mathematics": {
      "task": "ogx_mmlux_hu-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai matematikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_medicine": {
      "task": "ogx_mmlux_hu-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai orvostudományról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_physics": {
      "task": "ogx_mmlux_hu-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) az egyetemi fizikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-computer_security": {
      "task": "ogx_mmlux_hu-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a számítógépes biztonságról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "task": "ogx_mmlux_hu-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a fogalmi fizikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-econometrics": {
      "task": "ogx_mmlux_hu-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban az ökonometriával kapcsolatos feleletválasztós kérdések (válaszokkal) következnek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "task": "ogx_mmlux_hu-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a villamosmérnöki tudományokról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "task": "ogx_mmlux_hu-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az elemi matematikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-formal_logic": {
      "task": "ogx_mmlux_hu-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a formális logikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-global_facts": {
      "task": "ogx_mmlux_hu-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a globális tényekről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_biology": {
      "task": "ogx_mmlux_hu-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai biológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "task": "ogx_mmlux_hu-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai kémiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "task": "ogx_mmlux_hu-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai informatikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "task": "ogx_mmlux_hu-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai európai történelemről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_geography": {
      "task": "ogx_mmlux_hu-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai földrajzról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "task": "ogx_mmlux_hu-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a középiskolai kormányzatról és politikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "task": "ogx_mmlux_hu-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai makroökonómiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "task": "ogx_mmlux_hu-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai matematikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "task": "ogx_mmlux_hu-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai mikroökonómiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_physics": {
      "task": "ogx_mmlux_hu-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai fizikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "task": "ogx_mmlux_hu-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a középiskolai pszichológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "task": "ogx_mmlux_hu-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban a középiskolai statisztikával kapcsolatos feleletválasztós kérdések (válaszokkal) találhatók.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "task": "ogx_mmlux_hu-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai történelemről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "task": "ogx_mmlux_hu-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai világtörténelemről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-human_aging": {
      "task": "ogx_mmlux_hu-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az emberi öregedéssel kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-human_sexuality": {
      "task": "ogx_mmlux_hu-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az emberi szexualitásról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-international_law": {
      "task": "ogx_mmlux_hu-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a nemzetközi jogról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-jurisprudence": {
      "task": "ogx_mmlux_hu-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a jogtudományról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "task": "ogx_mmlux_hu-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban a logikai tévedésekkel kapcsolatos feleletválasztós kérdések (válaszokkal) találhatók.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-machine_learning": {
      "task": "ogx_mmlux_hu-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a gépi tanulásról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-management": {
      "task": "ogx_mmlux_hu-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a menedzsmentről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-marketing": {
      "task": "ogx_mmlux_hu-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a marketingről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-medical_genetics": {
      "task": "ogx_mmlux_hu-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az orvosi genetikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-miscellaneous": {
      "task": "ogx_mmlux_hu-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a különféle kérdésekről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-moral_disputes": {
      "task": "ogx_mmlux_hu-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az erkölcsi vitákról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "task": "ogx_mmlux_hu-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban erkölcsi forgatókönyvekkel kapcsolatos feleletválasztós kérdések (válaszokkal) következnek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-nutrition": {
      "task": "ogx_mmlux_hu-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a táplálkozással kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-philosophy": {
      "task": "ogx_mmlux_hu-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a filozófiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-prehistory": {
      "task": "ogx_mmlux_hu-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az őstörténetről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_accounting": {
      "task": "ogx_mmlux_hu-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a szakmai számvitelről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_law": {
      "task": "ogx_mmlux_hu-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a szakmai joggal kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_medicine": {
      "task": "ogx_mmlux_hu-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a hivatásos orvoslásról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_psychology": {
      "task": "ogx_mmlux_hu-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a szakpszichológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-public_relations": {
      "task": "ogx_mmlux_hu-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a public relationsről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-security_studies": {
      "task": "ogx_mmlux_hu-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a biztonsági tanulmányokról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-sociology": {
      "task": "ogx_mmlux_hu-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a szociológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "task": "ogx_mmlux_hu-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) az amerikai külpolitikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-virology": {
      "task": "ogx_mmlux_hu-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a virológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-world_religions": {
      "task": "ogx_mmlux_hu-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a világvallásokról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-abstract_algebra": {
      "task": "ogx_mmlux_it-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'algebra astratta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-anatomy": {
      "task": "ogx_mmlux_it-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'anatomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-astronomy": {
      "task": "ogx_mmlux_it-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'astronomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-business_ethics": {
      "task": "ogx_mmlux_it-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'etica aziendale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "task": "ogx_mmlux_it-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla conoscenza clinica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_biology": {
      "task": "ogx_mmlux_it-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla biologia universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_chemistry": {
      "task": "ogx_mmlux_it-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla chimica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_computer_science": {
      "task": "ogx_mmlux_it-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'informatica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_mathematics": {
      "task": "ogx_mmlux_it-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_medicine": {
      "task": "ogx_mmlux_it-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla medicina universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_physics": {
      "task": "ogx_mmlux_it-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-computer_security": {
      "task": "ogx_mmlux_it-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sicurezza informatica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-conceptual_physics": {
      "task": "ogx_mmlux_it-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica concettuale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-econometrics": {
      "task": "ogx_mmlux_it-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'econometria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-electrical_engineering": {
      "task": "ogx_mmlux_it-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'ingegneria elettrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "task": "ogx_mmlux_it-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica elementare.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-formal_logic": {
      "task": "ogx_mmlux_it-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla logica formale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-global_facts": {
      "task": "ogx_mmlux_it-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sui fatti globali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_biology": {
      "task": "ogx_mmlux_it-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla biologia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "task": "ogx_mmlux_it-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla chimica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "task": "ogx_mmlux_it-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'informatica per le scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_european_history": {
      "task": "ogx_mmlux_it-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia europea delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_geography": {
      "task": "ogx_mmlux_it-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla geografia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "task": "ogx_mmlux_it-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul governo e la politica nelle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "task": "ogx_mmlux_it-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla macroeconomia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "task": "ogx_mmlux_it-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "task": "ogx_mmlux_it-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla microeconomia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_physics": {
      "task": "ogx_mmlux_it-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_psychology": {
      "task": "ogx_mmlux_it-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla psicologia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_statistics": {
      "task": "ogx_mmlux_it-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla statistica della scuola superiore.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_us_history": {
      "task": "ogx_mmlux_it-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia degli Stati Uniti al liceo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_world_history": {
      "task": "ogx_mmlux_it-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia mondiale delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-human_aging": {
      "task": "ogx_mmlux_it-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'invecchiamento umano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-human_sexuality": {
      "task": "ogx_mmlux_it-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sessualità umana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-international_law": {
      "task": "ogx_mmlux_it-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul diritto internazionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-jurisprudence": {
      "task": "ogx_mmlux_it-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla giurisprudenza.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-logical_fallacies": {
      "task": "ogx_mmlux_it-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle fallacie logiche.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-machine_learning": {
      "task": "ogx_mmlux_it-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'apprendimento automatico.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-management": {
      "task": "ogx_mmlux_it-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla gestione.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-marketing": {
      "task": "ogx_mmlux_it-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-medical_genetics": {
      "task": "ogx_mmlux_it-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla genetica medica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-miscellaneous": {
      "task": "ogx_mmlux_it-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) su varie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-moral_disputes": {
      "task": "ogx_mmlux_it-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle controversie morali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-moral_scenarios": {
      "task": "ogx_mmlux_it-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) su scenari morali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-nutrition": {
      "task": "ogx_mmlux_it-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'alimentazione.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-philosophy": {
      "task": "ogx_mmlux_it-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla filosofia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-prehistory": {
      "task": "ogx_mmlux_it-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla preistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_accounting": {
      "task": "ogx_mmlux_it-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla contabilità professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_law": {
      "task": "ogx_mmlux_it-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul diritto professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_medicine": {
      "task": "ogx_mmlux_it-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla medicina professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_psychology": {
      "task": "ogx_mmlux_it-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla psicologia professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-public_relations": {
      "task": "ogx_mmlux_it-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle relazioni pubbliche.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-security_studies": {
      "task": "ogx_mmlux_it-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sugli studi sulla sicurezza.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-sociology": {
      "task": "ogx_mmlux_it-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sociologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "task": "ogx_mmlux_it-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla politica estera degli Stati Uniti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-virology": {
      "task": "ogx_mmlux_it-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla virologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-world_religions": {
      "task": "ogx_mmlux_it-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle religioni del mondo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "task": "ogx_mmlux_lt-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie abstrakčiąją algebrą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-anatomy": {
      "task": "ogx_mmlux_lt-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie anatomiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-astronomy": {
      "task": "ogx_mmlux_lt-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie astronomiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-business_ethics": {
      "task": "ogx_mmlux_lt-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie verslo etiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "task": "ogx_mmlux_lt-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie klinikines žinias.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_biology": {
      "task": "ogx_mmlux_lt-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos biologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_chemistry": {
      "task": "ogx_mmlux_lt-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos chemiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_computer_science": {
      "task": "ogx_mmlux_lt-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos informatiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_mathematics": {
      "task": "ogx_mmlux_lt-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos matematiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_medicine": {
      "task": "ogx_mmlux_lt-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie koledžo mediciną.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_physics": {
      "task": "ogx_mmlux_lt-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos fiziką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-computer_security": {
      "task": "ogx_mmlux_lt-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kompiuterių saugumą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "task": "ogx_mmlux_lt-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie konceptualiąją fiziką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-econometrics": {
      "task": "ogx_mmlux_lt-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie ekonometriją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "task": "ogx_mmlux_lt-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie elektrotechniką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "task": "ogx_mmlux_lt-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai su atsakymais apie elementariąją matematiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-formal_logic": {
      "task": "ogx_mmlux_lt-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie formaliąją logiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-global_facts": {
      "task": "ogx_mmlux_lt-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie visuotinius faktus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_biology": {
      "task": "ogx_mmlux_lt-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurinės mokyklos biologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "task": "ogx_mmlux_lt-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie chemiją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "task": "ogx_mmlux_lt-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie informatiką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "task": "ogx_mmlux_lt-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie Europos istoriją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_geography": {
      "task": "ogx_mmlux_lt-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie geografiją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "task": "ogx_mmlux_lt-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vyriausybę ir politiką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "task": "ogx_mmlux_lt-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie makroekonomiką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "task": "ogx_mmlux_lt-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurinės mokyklos matematiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "task": "ogx_mmlux_lt-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mikroekonomiką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_physics": {
      "task": "ogx_mmlux_lt-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie fiziką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "task": "ogx_mmlux_lt-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie psichologiją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "task": "ogx_mmlux_lt-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurinės mokyklos statistiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "task": "ogx_mmlux_lt-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie JAV vidurinės mokyklos istoriją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "task": "ogx_mmlux_lt-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie pasaulio istoriją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-human_aging": {
      "task": "ogx_mmlux_lt-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie žmogaus senėjimą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-human_sexuality": {
      "task": "ogx_mmlux_lt-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie žmogaus lytiškumą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-international_law": {
      "task": "ogx_mmlux_lt-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie tarptautinę teisę.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-jurisprudence": {
      "task": "ogx_mmlux_lt-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie jurisprudenciją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "task": "ogx_mmlux_lt-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie logines klaidas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-machine_learning": {
      "task": "ogx_mmlux_lt-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mašininį mokymąsi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-management": {
      "task": "ogx_mmlux_lt-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie valdymą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-marketing": {
      "task": "ogx_mmlux_lt-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie rinkodarą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-medical_genetics": {
      "task": "ogx_mmlux_lt-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie medicininę genetiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-miscellaneous": {
      "task": "ogx_mmlux_lt-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie įvairius dalykus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-moral_disputes": {
      "task": "ogx_mmlux_lt-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie moralinius ginčus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "task": "ogx_mmlux_lt-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie moralinius scenarijus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-nutrition": {
      "task": "ogx_mmlux_lt-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mitybą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-philosophy": {
      "task": "ogx_mmlux_lt-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie filosofiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-prehistory": {
      "task": "ogx_mmlux_lt-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie priešistorę.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_accounting": {
      "task": "ogx_mmlux_lt-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesinę apskaitą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_law": {
      "task": "ogx_mmlux_lt-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesinę teisę.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_medicine": {
      "task": "ogx_mmlux_lt-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesinę mediciną.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_psychology": {
      "task": "ogx_mmlux_lt-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesinę psichologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-public_relations": {
      "task": "ogx_mmlux_lt-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie viešuosius ryšius.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-security_studies": {
      "task": "ogx_mmlux_lt-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie saugumo studijas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-sociology": {
      "task": "ogx_mmlux_lt-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie sociologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "task": "ogx_mmlux_lt-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie JAV užsienio politiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-virology": {
      "task": "ogx_mmlux_lt-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie virusologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-world_religions": {
      "task": "ogx_mmlux_lt-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie pasaulio religijas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "task": "ogx_mmlux_lv-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par abstrakto algebru.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-anatomy": {
      "task": "ogx_mmlux_lv-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem par anatomiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-astronomy": {
      "task": "ogx_mmlux_lv-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par astronomiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-business_ethics": {
      "task": "ogx_mmlux_lv-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par uzņēmējdarbības ētiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "task": "ogx_mmlux_lv-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par klīniskajām zināšanām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_biology": {
      "task": "ogx_mmlux_lv-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas bioloģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_chemistry": {
      "task": "ogx_mmlux_lv-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas ķīmiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_computer_science": {
      "task": "ogx_mmlux_lv-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par datorzinātnēm koledžā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_mathematics": {
      "task": "ogx_mmlux_lv-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas matemātiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_medicine": {
      "task": "ogx_mmlux_lv-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas medicīnu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_physics": {
      "task": "ogx_mmlux_lv-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-computer_security": {
      "task": "ogx_mmlux_lv-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par datoru drošību.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "task": "ogx_mmlux_lv-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par konceptuālo fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-econometrics": {
      "task": "ogx_mmlux_lv-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par ekonometriju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "task": "ogx_mmlux_lv-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par elektrotehniku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "task": "ogx_mmlux_lv-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par elementāro matemātiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-formal_logic": {
      "task": "ogx_mmlux_lv-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem par formālo loģiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-global_facts": {
      "task": "ogx_mmlux_lv-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par pasaules faktiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_biology": {
      "task": "ogx_mmlux_lv-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas bioloģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "task": "ogx_mmlux_lv-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas ķīmiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "task": "ogx_mmlux_lv-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas informātiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "task": "ogx_mmlux_lv-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas Eiropas vēsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_geography": {
      "task": "ogx_mmlux_lv-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas ģeogrāfiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "task": "ogx_mmlux_lv-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par valsts pārvaldi un politiku vidusskolā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "task": "ogx_mmlux_lv-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par makroekonomiku vidusskolā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "task": "ogx_mmlux_lv-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas matemātiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "task": "ogx_mmlux_lv-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par mikroekonomiku vidusskolā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_physics": {
      "task": "ogx_mmlux_lv-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "task": "ogx_mmlux_lv-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas psiholoģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "task": "ogx_mmlux_lv-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas statistiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "task": "ogx_mmlux_lv-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par ASV vidusskolas vēsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "task": "ogx_mmlux_lv-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par pasaules vēsturi vidusskolā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-human_aging": {
      "task": "ogx_mmlux_lv-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par cilvēka novecošanu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-human_sexuality": {
      "task": "ogx_mmlux_lv-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par cilvēka seksualitāti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-international_law": {
      "task": "ogx_mmlux_lv-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par starptautiskajām tiesībām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-jurisprudence": {
      "task": "ogx_mmlux_lv-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par jurisprudenci.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "task": "ogx_mmlux_lv-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par loģiskajām kļūdām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-machine_learning": {
      "task": "ogx_mmlux_lv-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par mašīnmācīšanos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-management": {
      "task": "ogx_mmlux_lv-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par vadību.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-marketing": {
      "task": "ogx_mmlux_lv-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par mārketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-medical_genetics": {
      "task": "ogx_mmlux_lv-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par medicīnas ģenētiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-miscellaneous": {
      "task": "ogx_mmlux_lv-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par dažādiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-moral_disputes": {
      "task": "ogx_mmlux_lv-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par morāles strīdiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "task": "ogx_mmlux_lv-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par morāles scenārijiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-nutrition": {
      "task": "ogx_mmlux_lv-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par uzturu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-philosophy": {
      "task": "ogx_mmlux_lv-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par filozofiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-prehistory": {
      "task": "ogx_mmlux_lv-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par aizvēsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_accounting": {
      "task": "ogx_mmlux_lv-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par profesionālo grāmatvedību.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_law": {
      "task": "ogx_mmlux_lv-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par profesionālajām tiesībām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_medicine": {
      "task": "ogx_mmlux_lv-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par profesionālo medicīnu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_psychology": {
      "task": "ogx_mmlux_lv-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par profesionālo psiholoģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-public_relations": {
      "task": "ogx_mmlux_lv-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par sabiedriskajām attiecībām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-security_studies": {
      "task": "ogx_mmlux_lv-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par drošības studijām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-sociology": {
      "task": "ogx_mmlux_lv-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmāk ir jautājumi ar atbilžu variantiem par socioloģiju (ar atbildēm).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "task": "ogx_mmlux_lv-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem par ASV ārpolitiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-virology": {
      "task": "ogx_mmlux_lv-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem par virusoloģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-world_religions": {
      "task": "ogx_mmlux_lv-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par pasaules reliģijām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "task": "ogx_mmlux_nl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over abstracte algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-anatomy": {
      "task": "ogx_mmlux_nl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-astronomy": {
      "task": "ogx_mmlux_nl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-business_ethics": {
      "task": "ogx_mmlux_nl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over bedrijfsethiek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "task": "ogx_mmlux_nl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over klinische kennis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_biology": {
      "task": "ogx_mmlux_nl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over biologie op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_chemistry": {
      "task": "ogx_mmlux_nl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over scheikunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_computer_science": {
      "task": "ogx_mmlux_nl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over informatica op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_mathematics": {
      "task": "ogx_mmlux_nl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wiskunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_medicine": {
      "task": "ogx_mmlux_nl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over geneeskunde aan de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_physics": {
      "task": "ogx_mmlux_nl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over natuurkunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-computer_security": {
      "task": "ogx_mmlux_nl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over computerbeveiliging.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "task": "ogx_mmlux_nl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over conceptuele fysica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-econometrics": {
      "task": "ogx_mmlux_nl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over econometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "task": "ogx_mmlux_nl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over elektrotechniek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "task": "ogx_mmlux_nl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over elementaire wiskunde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-formal_logic": {
      "task": "ogx_mmlux_nl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over formele logica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-global_facts": {
      "task": "ogx_mmlux_nl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over globale feiten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_biology": {
      "task": "ogx_mmlux_nl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over biologie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "task": "ogx_mmlux_nl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over scheikunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "task": "ogx_mmlux_nl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over informatica op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "task": "ogx_mmlux_nl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over Europese geschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_geography": {
      "task": "ogx_mmlux_nl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over aardrijkskunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "task": "ogx_mmlux_nl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over bestuur en politiek op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "task": "ogx_mmlux_nl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over macro-economie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "task": "ogx_mmlux_nl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wiskunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "task": "ogx_mmlux_nl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over micro-economie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_physics": {
      "task": "ogx_mmlux_nl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over natuurkunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "task": "ogx_mmlux_nl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over psychologie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "task": "ogx_mmlux_nl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over statistiek op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "task": "ogx_mmlux_nl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over geschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "task": "ogx_mmlux_nl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wereldgeschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-human_aging": {
      "task": "ogx_mmlux_nl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over menselijke veroudering.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-human_sexuality": {
      "task": "ogx_mmlux_nl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over menselijke seksualiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-international_law": {
      "task": "ogx_mmlux_nl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over internationaal recht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-jurisprudence": {
      "task": "ogx_mmlux_nl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over jurisprudentie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "task": "ogx_mmlux_nl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over logische drogredenen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-machine_learning": {
      "task": "ogx_mmlux_nl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over machinaal leren.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-management": {
      "task": "ogx_mmlux_nl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-marketing": {
      "task": "ogx_mmlux_nl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-medical_genetics": {
      "task": "ogx_mmlux_nl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over medische genetica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-miscellaneous": {
      "task": "ogx_mmlux_nl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over diversen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-moral_disputes": {
      "task": "ogx_mmlux_nl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over morele geschillen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "task": "ogx_mmlux_nl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over morele scenario's.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-nutrition": {
      "task": "ogx_mmlux_nl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over voeding.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-philosophy": {
      "task": "ogx_mmlux_nl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over filosofie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-prehistory": {
      "task": "ogx_mmlux_nl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over de prehistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_accounting": {
      "task": "ogx_mmlux_nl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over professioneel boekhouden.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_law": {
      "task": "ogx_mmlux_nl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over het beroepsrecht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_medicine": {
      "task": "ogx_mmlux_nl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over professionele geneeskunde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_psychology": {
      "task": "ogx_mmlux_nl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over professionele psychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-public_relations": {
      "task": "ogx_mmlux_nl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-security_studies": {
      "task": "ogx_mmlux_nl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over veiligheidsstudies.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-sociology": {
      "task": "ogx_mmlux_nl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "task": "ogx_mmlux_nl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over het buitenlands beleid van de Verenigde Staten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-virology": {
      "task": "ogx_mmlux_nl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-world_religions": {
      "task": "ogx_mmlux_nl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wereldreligies.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "task": "ogx_mmlux_pl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące algebry abstrakcyjnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-anatomy": {
      "task": "ogx_mmlux_pl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące anatomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-astronomy": {
      "task": "ogx_mmlux_pl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące astronomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-business_ethics": {
      "task": "ogx_mmlux_pl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące etyki biznesu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "task": "ogx_mmlux_pl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące wiedzy klinicznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_biology": {
      "task": "ogx_mmlux_pl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące biologii na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_chemistry": {
      "task": "ogx_mmlux_pl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące chemii na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_computer_science": {
      "task": "ogx_mmlux_pl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące informatyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_mathematics": {
      "task": "ogx_mmlux_pl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące matematyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_medicine": {
      "task": "ogx_mmlux_pl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące medycyny uniwersyteckiej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_physics": {
      "task": "ogx_mmlux_pl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące fizyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-computer_security": {
      "task": "ogx_mmlux_pl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące bezpieczeństwa komputerowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "task": "ogx_mmlux_pl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące fizyki konceptualnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-econometrics": {
      "task": "ogx_mmlux_pl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "task": "ogx_mmlux_pl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące inżynierii elektrycznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "task": "ogx_mmlux_pl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące matematyki elementarnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-formal_logic": {
      "task": "ogx_mmlux_pl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące logiki formalnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-global_facts": {
      "task": "ogx_mmlux_pl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące globalnych faktów.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_biology": {
      "task": "ogx_mmlux_pl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące biologii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "task": "ogx_mmlux_pl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące chemii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "task": "ogx_mmlux_pl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące informatyki w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "task": "ogx_mmlux_pl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące historii Europy w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_geography": {
      "task": "ogx_mmlux_pl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące geografii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "task": "ogx_mmlux_pl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące rządów i polityki w szkołach średnich.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "task": "ogx_mmlux_pl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące makroekonomii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "task": "ogx_mmlux_pl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące matematyki w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "task": "ogx_mmlux_pl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące mikroekonomii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_physics": {
      "task": "ogx_mmlux_pl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące fizyki w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "task": "ogx_mmlux_pl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące psychologii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "task": "ogx_mmlux_pl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące statystyki w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "task": "ogx_mmlux_pl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące historii Stanów Zjednoczonych w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "task": "ogx_mmlux_pl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące historii świata w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-human_aging": {
      "task": "ogx_mmlux_pl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące starzenia się człowieka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-human_sexuality": {
      "task": "ogx_mmlux_pl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące ludzkiej seksualności.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-international_law": {
      "task": "ogx_mmlux_pl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące prawa międzynarodowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-jurisprudence": {
      "task": "ogx_mmlux_pl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące orzecznictwa.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "task": "ogx_mmlux_pl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące błędów logicznych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-machine_learning": {
      "task": "ogx_mmlux_pl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące uczenia maszynowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-management": {
      "task": "ogx_mmlux_pl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące zarządzania.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-marketing": {
      "task": "ogx_mmlux_pl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-medical_genetics": {
      "task": "ogx_mmlux_pl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące genetyki medycznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-miscellaneous": {
      "task": "ogx_mmlux_pl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące różnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-moral_disputes": {
      "task": "ogx_mmlux_pl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące sporów moralnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "task": "ogx_mmlux_pl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące scenariuszy moralnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-nutrition": {
      "task": "ogx_mmlux_pl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące odżywiania.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-philosophy": {
      "task": "ogx_mmlux_pl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-prehistory": {
      "task": "ogx_mmlux_pl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące prehistorii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_accounting": {
      "task": "ogx_mmlux_pl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące profesjonalnej księgowości.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_law": {
      "task": "ogx_mmlux_pl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące prawa zawodowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_medicine": {
      "task": "ogx_mmlux_pl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące medycyny profesjonalnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_psychology": {
      "task": "ogx_mmlux_pl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące psychologii zawodowej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-public_relations": {
      "task": "ogx_mmlux_pl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-security_studies": {
      "task": "ogx_mmlux_pl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące studiów nad bezpieczeństwem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-sociology": {
      "task": "ogx_mmlux_pl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące socjologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "task": "ogx_mmlux_pl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące polityki zagranicznej Stanów Zjednoczonych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-virology": {
      "task": "ogx_mmlux_pl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące wirusologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-world_religions": {
      "task": "ogx_mmlux_pl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące religii świata.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "task": "ogx_mmlux_pt-pt-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre álgebra abstrata.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "task": "ogx_mmlux_pt-pt-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre anatomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "task": "ogx_mmlux_pt-pt-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre astronomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "task": "ogx_mmlux_pt-pt-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre ética empresarial.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "task": "ogx_mmlux_pt-pt-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre conhecimentos clínicos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "task": "ogx_mmlux_pt-pt-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes são de escolha múltipla (com respostas) sobre biologia universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "task": "ogx_mmlux_pt-pt-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes são de escolha múltipla (com respostas) sobre química universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "task": "ogx_mmlux_pt-pt-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre informática universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "task": "ogx_mmlux_pt-pt-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre matemática universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "task": "ogx_mmlux_pt-pt-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre medicina universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "task": "ogx_mmlux_pt-pt-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes são de escolha múltipla (com respostas) sobre física universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "task": "ogx_mmlux_pt-pt-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre segurança informática.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "task": "ogx_mmlux_pt-pt-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre física concetual.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "task": "ogx_mmlux_pt-pt-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre econometria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "task": "ogx_mmlux_pt-pt-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre engenharia eléctrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "task": "ogx_mmlux_pt-pt-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre matemática elementar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "task": "ogx_mmlux_pt-pt-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre lógica formal.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "task": "ogx_mmlux_pt-pt-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre factos globais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "task": "ogx_mmlux_pt-pt-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre biologia do ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "task": "ogx_mmlux_pt-pt-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre química no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "task": "ogx_mmlux_pt-pt-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre informática no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "task": "ogx_mmlux_pt-pt-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre história europeia no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "task": "ogx_mmlux_pt-pt-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre geografia do ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "task": "ogx_mmlux_pt-pt-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre governo e política no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "task": "ogx_mmlux_pt-pt-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre macroeconomia no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "task": "ogx_mmlux_pt-pt-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre matemática do ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "task": "ogx_mmlux_pt-pt-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre microeconomia no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "task": "ogx_mmlux_pt-pt-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre física do ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "task": "ogx_mmlux_pt-pt-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre psicologia no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "task": "ogx_mmlux_pt-pt-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre estatística no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "task": "ogx_mmlux_pt-pt-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre História dos EUA no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "task": "ogx_mmlux_pt-pt-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre história mundial no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "task": "ogx_mmlux_pt-pt-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre o envelhecimento humano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "task": "ogx_mmlux_pt-pt-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre a sexualidade humana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-international_law": {
      "task": "ogx_mmlux_pt-pt-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre direito internacional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "task": "ogx_mmlux_pt-pt-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre jurisprudência.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "task": "ogx_mmlux_pt-pt-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre falácias lógicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "task": "ogx_mmlux_pt-pt-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre aprendizagem automática.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-management": {
      "task": "ogx_mmlux_pt-pt-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre gestão.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-marketing": {
      "task": "ogx_mmlux_pt-pt-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "task": "ogx_mmlux_pt-pt-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre genética médica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "task": "ogx_mmlux_pt-pt-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre miscelânea.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "task": "ogx_mmlux_pt-pt-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre disputas morais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "task": "ogx_mmlux_pt-pt-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre cenários morais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "task": "ogx_mmlux_pt-pt-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre nutrição.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "task": "ogx_mmlux_pt-pt-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre filosofia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "task": "ogx_mmlux_pt-pt-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre a pré-história.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "task": "ogx_mmlux_pt-pt-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre contabilidade profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "task": "ogx_mmlux_pt-pt-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre direito profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "task": "ogx_mmlux_pt-pt-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre medicina profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "task": "ogx_mmlux_pt-pt-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre psicologia profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "task": "ogx_mmlux_pt-pt-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre relações públicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "task": "ogx_mmlux_pt-pt-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre estudos de segurança.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-sociology": {
      "task": "ogx_mmlux_pt-pt-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre sociologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "task": "ogx_mmlux_pt-pt-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes são de escolha múltipla (com respostas) sobre a política externa dos EUA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-virology": {
      "task": "ogx_mmlux_pt-pt-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre virologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "task": "ogx_mmlux_pt-pt-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre as religiões do mundo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "task": "ogx_mmlux_ro-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre algebra abstractă.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-anatomy": {
      "task": "ogx_mmlux_ro-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-astronomy": {
      "task": "ogx_mmlux_ro-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu răspunsuri multiple (cu răspunsuri) despre astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-business_ethics": {
      "task": "ogx_mmlux_ro-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre etica în afaceri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "task": "ogx_mmlux_ro-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre cunoștințele clinice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_biology": {
      "task": "ogx_mmlux_ro-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre biologia universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_chemistry": {
      "task": "ogx_mmlux_ro-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre chimia universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_computer_science": {
      "task": "ogx_mmlux_ro-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre informatică universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_mathematics": {
      "task": "ogx_mmlux_ro-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre matematica universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_medicine": {
      "task": "ogx_mmlux_ro-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre medicina universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_physics": {
      "task": "ogx_mmlux_ro-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre fizica universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-computer_security": {
      "task": "ogx_mmlux_ro-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre securitatea calculatoarelor.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "task": "ogx_mmlux_ro-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre fizica conceptuală.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-econometrics": {
      "task": "ogx_mmlux_ro-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre econometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "task": "ogx_mmlux_ro-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre inginerie electrică.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "task": "ogx_mmlux_ro-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre matematică elementară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-formal_logic": {
      "task": "ogx_mmlux_ro-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre logica formală.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-global_facts": {
      "task": "ogx_mmlux_ro-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre fapte globale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_biology": {
      "task": "ogx_mmlux_ro-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre biologia de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "task": "ogx_mmlux_ro-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre chimia de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "task": "ogx_mmlux_ro-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre informatică la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "task": "ogx_mmlux_ro-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre istoria europeană la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_geography": {
      "task": "ogx_mmlux_ro-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre geografia liceului.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "task": "ogx_mmlux_ro-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre guvernare și politică în liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "task": "ogx_mmlux_ro-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre macroeconomie la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "task": "ogx_mmlux_ro-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre matematica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "task": "ogx_mmlux_ro-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre microeconomie la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_physics": {
      "task": "ogx_mmlux_ro-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre fizica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "task": "ogx_mmlux_ro-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre psihologia liceului.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "task": "ogx_mmlux_ro-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre statistica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "task": "ogx_mmlux_ro-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre istoria noastră la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "task": "ogx_mmlux_ro-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre istoria universală de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-human_aging": {
      "task": "ogx_mmlux_ro-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre îmbătrânirea umană.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-human_sexuality": {
      "task": "ogx_mmlux_ro-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre sexualitatea umană.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-international_law": {
      "task": "ogx_mmlux_ro-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre dreptul internațional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-jurisprudence": {
      "task": "ogx_mmlux_ro-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre jurisprudență.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "task": "ogx_mmlux_ro-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre erori logice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-machine_learning": {
      "task": "ogx_mmlux_ro-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre învățarea automată.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-management": {
      "task": "ogx_mmlux_ro-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-marketing": {
      "task": "ogx_mmlux_ro-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-medical_genetics": {
      "task": "ogx_mmlux_ro-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre genetica medicală.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-miscellaneous": {
      "task": "ogx_mmlux_ro-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-moral_disputes": {
      "task": "ogx_mmlux_ro-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre disputele morale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "task": "ogx_mmlux_ro-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre scenarii morale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-nutrition": {
      "task": "ogx_mmlux_ro-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre nutriție.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-philosophy": {
      "task": "ogx_mmlux_ro-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre filosofie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-prehistory": {
      "task": "ogx_mmlux_ro-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre preistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_accounting": {
      "task": "ogx_mmlux_ro-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre contabilitatea profesională.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_law": {
      "task": "ogx_mmlux_ro-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre dreptul profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_medicine": {
      "task": "ogx_mmlux_ro-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre medicina profesională.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_psychology": {
      "task": "ogx_mmlux_ro-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre psihologia profesională.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-public_relations": {
      "task": "ogx_mmlux_ro-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre relațiile publice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-security_studies": {
      "task": "ogx_mmlux_ro-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre studiile de securitate.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-sociology": {
      "task": "ogx_mmlux_ro-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "task": "ogx_mmlux_ro-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre politica externă a SUA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-virology": {
      "task": "ogx_mmlux_ro-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre virusologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-world_religions": {
      "task": "ogx_mmlux_ro-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre religiile lumii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "task": "ogx_mmlux_sk-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o abstraktnej algebre.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-anatomy": {
      "task": "ogx_mmlux_sk-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o anatómii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-astronomy": {
      "task": "ogx_mmlux_sk-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o astronómii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-business_ethics": {
      "task": "ogx_mmlux_sk-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o etike v podnikaní.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "task": "ogx_mmlux_sk-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o klinických znalostiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_biology": {
      "task": "ogx_mmlux_sk-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o vysokoškolskej biológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_chemistry": {
      "task": "ogx_mmlux_sk-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o vysokoškolskej chémii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_computer_science": {
      "task": "ogx_mmlux_sk-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o informatike na vysokej škole.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_mathematics": {
      "task": "ogx_mmlux_sk-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o vysokoškolskej matematike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_medicine": {
      "task": "ogx_mmlux_sk-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o vysokoškolskej medicíne.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_physics": {
      "task": "ogx_mmlux_sk-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o vysokoškolskej fyzike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-computer_security": {
      "task": "ogx_mmlux_sk-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o počítačovej bezpečnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "task": "ogx_mmlux_sk-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o konceptuálnej fyzike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-econometrics": {
      "task": "ogx_mmlux_sk-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "task": "ogx_mmlux_sk-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o elektrotechnike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "task": "ogx_mmlux_sk-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o elementárnej matematike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-formal_logic": {
      "task": "ogx_mmlux_sk-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o formálnej logike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-global_facts": {
      "task": "ogx_mmlux_sk-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o globálnych faktoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_biology": {
      "task": "ogx_mmlux_sk-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolskej biológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "task": "ogx_mmlux_sk-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolskej chémii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "task": "ogx_mmlux_sk-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolskej informatike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "task": "ogx_mmlux_sk-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolských európskych dejinách.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_geography": {
      "task": "ogx_mmlux_sk-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o stredoškolskom zemepise.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "task": "ogx_mmlux_sk-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú vlády a politiky na stredných školách.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "task": "ogx_mmlux_sk-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o stredoškolskej makroekonómii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "task": "ogx_mmlux_sk-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú stredoškolskej matematiky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "task": "ogx_mmlux_sk-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) z mikroekonómie pre stredné školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_physics": {
      "task": "ogx_mmlux_sk-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) zo stredoškolskej fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "task": "ogx_mmlux_sk-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o stredoškolskej psychológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "task": "ogx_mmlux_sk-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú stredoškolskej štatistiky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "task": "ogx_mmlux_sk-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolskej histórii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "task": "ogx_mmlux_sk-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) zo svetových dejín na strednej škole.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-human_aging": {
      "task": "ogx_mmlux_sk-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o starnutí človeka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-human_sexuality": {
      "task": "ogx_mmlux_sk-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o ľudskej sexualite.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-international_law": {
      "task": "ogx_mmlux_sk-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o medzinárodnom práve.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-jurisprudence": {
      "task": "ogx_mmlux_sk-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú právnej vedy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "task": "ogx_mmlux_sk-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o logických klamoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-machine_learning": {
      "task": "ogx_mmlux_sk-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o strojovom učení.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-management": {
      "task": "ogx_mmlux_sk-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o manažmente.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-marketing": {
      "task": "ogx_mmlux_sk-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-medical_genetics": {
      "task": "ogx_mmlux_sk-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o lekárskej genetike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-miscellaneous": {
      "task": "ogx_mmlux_sk-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky s výberom odpovede sa týkajú rôzneho.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-moral_disputes": {
      "task": "ogx_mmlux_sk-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o morálnych sporoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "task": "ogx_mmlux_sk-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o morálnych scenároch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-nutrition": {
      "task": "ogx_mmlux_sk-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o výžive.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-philosophy": {
      "task": "ogx_mmlux_sk-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-prehistory": {
      "task": "ogx_mmlux_sk-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o prehistórii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_accounting": {
      "task": "ogx_mmlux_sk-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o odbornom účtovníctve.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_law": {
      "task": "ogx_mmlux_sk-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú profesijného práva.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_medicine": {
      "task": "ogx_mmlux_sk-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú profesionálnej medicíny.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_psychology": {
      "task": "ogx_mmlux_sk-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o profesionálnej psychológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-public_relations": {
      "task": "ogx_mmlux_sk-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o vzťahoch s verejnosťou.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-security_studies": {
      "task": "ogx_mmlux_sk-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o bezpečnostných štúdiách.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-sociology": {
      "task": "ogx_mmlux_sk-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o sociológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "task": "ogx_mmlux_sk-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky s výberom odpovede sa týkajú zahraničnej politiky USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-virology": {
      "task": "ogx_mmlux_sk-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o virológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-world_religions": {
      "task": "ogx_mmlux_sk-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o svetových náboženstvách.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "task": "ogx_mmlux_sl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o abstraktni algebri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-anatomy": {
      "task": "ogx_mmlux_sl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o anatomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-astronomy": {
      "task": "ogx_mmlux_sl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o astronomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-business_ethics": {
      "task": "ogx_mmlux_sl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o poslovni etiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "task": "ogx_mmlux_sl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o kliničnem znanju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_biology": {
      "task": "ogx_mmlux_sl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o biologiji na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_chemistry": {
      "task": "ogx_mmlux_sl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o kemiji na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_computer_science": {
      "task": "ogx_mmlux_sl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o računalništvu na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_mathematics": {
      "task": "ogx_mmlux_sl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o matematiki na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_medicine": {
      "task": "ogx_mmlux_sl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o univerzitetni medicini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_physics": {
      "task": "ogx_mmlux_sl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o fiziki na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-computer_security": {
      "task": "ogx_mmlux_sl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o računalniški varnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "task": "ogx_mmlux_sl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o konceptualni fiziki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-econometrics": {
      "task": "ogx_mmlux_sl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o ekonometriji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "task": "ogx_mmlux_sl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o elektrotehniki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "task": "ogx_mmlux_sl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o osnovni matematiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-formal_logic": {
      "task": "ogx_mmlux_sl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o formalni logiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-global_facts": {
      "task": "ogx_mmlux_sl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o globalnih dejstvih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_biology": {
      "task": "ogx_mmlux_sl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski biologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "task": "ogx_mmlux_sl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o kemiji v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "task": "ogx_mmlux_sl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o računalništvu v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "task": "ogx_mmlux_sl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o evropski zgodovini v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_geography": {
      "task": "ogx_mmlux_sl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o geografiji v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "task": "ogx_mmlux_sl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o vladi in politiki v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "task": "ogx_mmlux_sl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski makroekonomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "task": "ogx_mmlux_sl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o matematiki v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "task": "ogx_mmlux_sl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski mikroekonomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_physics": {
      "task": "ogx_mmlux_sl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) s področja srednješolske fizike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "task": "ogx_mmlux_sl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski psihologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "task": "ogx_mmlux_sl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski statistiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "task": "ogx_mmlux_sl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski zgodovini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "task": "ogx_mmlux_sl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o svetovni zgodovini v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-human_aging": {
      "task": "ogx_mmlux_sl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o staranju človeka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-human_sexuality": {
      "task": "ogx_mmlux_sl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o človeški spolnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-international_law": {
      "task": "ogx_mmlux_sl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o mednarodnem pravu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-jurisprudence": {
      "task": "ogx_mmlux_sl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o sodni praksi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "task": "ogx_mmlux_sl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o logičnih zmotah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-machine_learning": {
      "task": "ogx_mmlux_sl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o strojnem učenju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-management": {
      "task": "ogx_mmlux_sl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o upravljanju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-marketing": {
      "task": "ogx_mmlux_sl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o trženju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-medical_genetics": {
      "task": "ogx_mmlux_sl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o medicinski genetiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-miscellaneous": {
      "task": "ogx_mmlux_sl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o raznih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-moral_disputes": {
      "task": "ogx_mmlux_sl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o moralnih sporih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "task": "ogx_mmlux_sl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o moralnih scenarijih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-nutrition": {
      "task": "ogx_mmlux_sl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o prehrani.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-philosophy": {
      "task": "ogx_mmlux_sl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o filozofiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-prehistory": {
      "task": "ogx_mmlux_sl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o prazgodovini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_accounting": {
      "task": "ogx_mmlux_sl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o strokovnem računovodstvu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_law": {
      "task": "ogx_mmlux_sl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o poklicnem pravu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_medicine": {
      "task": "ogx_mmlux_sl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o poklicni medicini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_psychology": {
      "task": "ogx_mmlux_sl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o poklicni psihologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-public_relations": {
      "task": "ogx_mmlux_sl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o odnosih z javnostmi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-security_studies": {
      "task": "ogx_mmlux_sl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o varnostnih študijah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-sociology": {
      "task": "ogx_mmlux_sl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o sociologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "task": "ogx_mmlux_sl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o zunanji politiki ZDA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-virology": {
      "task": "ogx_mmlux_sl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o virologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-world_religions": {
      "task": "ogx_mmlux_sl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o svetovnih religijah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "task": "ogx_mmlux_sv-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om abstrakt algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-anatomy": {
      "task": "ogx_mmlux_sv-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om anatomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-astronomy": {
      "task": "ogx_mmlux_sv-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om astronomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-business_ethics": {
      "task": "ogx_mmlux_sv-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om affärsetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "task": "ogx_mmlux_sv-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om klinisk kunskap.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_biology": {
      "task": "ogx_mmlux_sv-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om biologi på högskolenivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_chemistry": {
      "task": "ogx_mmlux_sv-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om kemi på högskolenivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_computer_science": {
      "task": "ogx_mmlux_sv-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om datavetenskap på högskolenivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_mathematics": {
      "task": "ogx_mmlux_sv-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om matematik på högskolenivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_medicine": {
      "task": "ogx_mmlux_sv-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om universitetsmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_physics": {
      "task": "ogx_mmlux_sv-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om högskolefysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-computer_security": {
      "task": "ogx_mmlux_sv-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om datasäkerhet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "task": "ogx_mmlux_sv-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om konceptuell fysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-econometrics": {
      "task": "ogx_mmlux_sv-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om ekonometri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "task": "ogx_mmlux_sv-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om elektroteknik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "task": "ogx_mmlux_sv-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om elementär matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-formal_logic": {
      "task": "ogx_mmlux_sv-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om formell logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-global_facts": {
      "task": "ogx_mmlux_sv-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om globala fakta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_biology": {
      "task": "ogx_mmlux_sv-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om biologi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "task": "ogx_mmlux_sv-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om kemi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "task": "ogx_mmlux_sv-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om datavetenskap på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "task": "ogx_mmlux_sv-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om europeisk historia på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_geography": {
      "task": "ogx_mmlux_sv-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om geografi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "task": "ogx_mmlux_sv-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om regering och politik på gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "task": "ogx_mmlux_sv-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om makroekonomi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "task": "ogx_mmlux_sv-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om matematik på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "task": "ogx_mmlux_sv-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om mikroekonomi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_physics": {
      "task": "ogx_mmlux_sv-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om fysik på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "task": "ogx_mmlux_sv-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om psykologi på gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "task": "ogx_mmlux_sv-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om statistik på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "task": "ogx_mmlux_sv-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om historia i USA på gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "task": "ogx_mmlux_sv-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om världshistoria på gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-human_aging": {
      "task": "ogx_mmlux_sv-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om människans åldrande.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-human_sexuality": {
      "task": "ogx_mmlux_sv-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om mänsklig sexualitet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-international_law": {
      "task": "ogx_mmlux_sv-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om internationell rätt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-jurisprudence": {
      "task": "ogx_mmlux_sv-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om rättsvetenskap.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "task": "ogx_mmlux_sv-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om logiska felslut.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-machine_learning": {
      "task": "ogx_mmlux_sv-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om maskininlärning.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-management": {
      "task": "ogx_mmlux_sv-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-marketing": {
      "task": "ogx_mmlux_sv-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om marknadsföring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-medical_genetics": {
      "task": "ogx_mmlux_sv-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om medicinsk genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-miscellaneous": {
      "task": "ogx_mmlux_sv-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-moral_disputes": {
      "task": "ogx_mmlux_sv-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om moraliska tvister.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "task": "ogx_mmlux_sv-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om moraliska scenarier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-nutrition": {
      "task": "ogx_mmlux_sv-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om näringslära.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-philosophy": {
      "task": "ogx_mmlux_sv-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om filosofi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-prehistory": {
      "task": "ogx_mmlux_sv-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om förhistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_accounting": {
      "task": "ogx_mmlux_sv-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om professionell redovisning.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_law": {
      "task": "ogx_mmlux_sv-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om yrkesrätt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_medicine": {
      "task": "ogx_mmlux_sv-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om yrkesmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_psychology": {
      "task": "ogx_mmlux_sv-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om professionell psykologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-public_relations": {
      "task": "ogx_mmlux_sv-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-security_studies": {
      "task": "ogx_mmlux_sv-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om säkerhetsstudier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-sociology": {
      "task": "ogx_mmlux_sv-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om sociologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "task": "ogx_mmlux_sv-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om USA:s utrikespolitik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-virology": {
      "task": "ogx_mmlux_sv-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om virologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-world_religions": {
      "task": "ogx_mmlux_sv-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om världsreligioner.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    }
  },
  "versions": {
    "ogx_mmlux_bg-abstract_algebra": 0,
    "ogx_mmlux_bg-anatomy": 0,
    "ogx_mmlux_bg-astronomy": 0,
    "ogx_mmlux_bg-business_ethics": 0,
    "ogx_mmlux_bg-clinical_knowledge": 0,
    "ogx_mmlux_bg-college_biology": 0,
    "ogx_mmlux_bg-college_chemistry": 0,
    "ogx_mmlux_bg-college_computer_science": 0,
    "ogx_mmlux_bg-college_mathematics": 0,
    "ogx_mmlux_bg-college_medicine": 0,
    "ogx_mmlux_bg-college_physics": 0,
    "ogx_mmlux_bg-computer_security": 0,
    "ogx_mmlux_bg-conceptual_physics": 0,
    "ogx_mmlux_bg-econometrics": 0,
    "ogx_mmlux_bg-electrical_engineering": 0,
    "ogx_mmlux_bg-elementary_mathematics": 0,
    "ogx_mmlux_bg-formal_logic": 0,
    "ogx_mmlux_bg-global_facts": 0,
    "ogx_mmlux_bg-high_school_biology": 0,
    "ogx_mmlux_bg-high_school_chemistry": 0,
    "ogx_mmlux_bg-high_school_computer_science": 0,
    "ogx_mmlux_bg-high_school_european_history": 0,
    "ogx_mmlux_bg-high_school_geography": 0,
    "ogx_mmlux_bg-high_school_government_and_politics": 0,
    "ogx_mmlux_bg-high_school_macroeconomics": 0,
    "ogx_mmlux_bg-high_school_mathematics": 0,
    "ogx_mmlux_bg-high_school_microeconomics": 0,
    "ogx_mmlux_bg-high_school_physics": 0,
    "ogx_mmlux_bg-high_school_psychology": 0,
    "ogx_mmlux_bg-high_school_statistics": 0,
    "ogx_mmlux_bg-high_school_us_history": 0,
    "ogx_mmlux_bg-high_school_world_history": 0,
    "ogx_mmlux_bg-human_aging": 0,
    "ogx_mmlux_bg-human_sexuality": 0,
    "ogx_mmlux_bg-international_law": 0,
    "ogx_mmlux_bg-jurisprudence": 0,
    "ogx_mmlux_bg-logical_fallacies": 0,
    "ogx_mmlux_bg-machine_learning": 0,
    "ogx_mmlux_bg-management": 0,
    "ogx_mmlux_bg-marketing": 0,
    "ogx_mmlux_bg-medical_genetics": 0,
    "ogx_mmlux_bg-miscellaneous": 0,
    "ogx_mmlux_bg-moral_disputes": 0,
    "ogx_mmlux_bg-moral_scenarios": 0,
    "ogx_mmlux_bg-nutrition": 0,
    "ogx_mmlux_bg-philosophy": 0,
    "ogx_mmlux_bg-prehistory": 0,
    "ogx_mmlux_bg-professional_accounting": 0,
    "ogx_mmlux_bg-professional_law": 0,
    "ogx_mmlux_bg-professional_medicine": 0,
    "ogx_mmlux_bg-professional_psychology": 0,
    "ogx_mmlux_bg-public_relations": 0,
    "ogx_mmlux_bg-security_studies": 0,
    "ogx_mmlux_bg-sociology": 0,
    "ogx_mmlux_bg-us_foreign_policy": 0,
    "ogx_mmlux_bg-virology": 0,
    "ogx_mmlux_bg-world_religions": 0,
    "ogx_mmlux_cs-abstract_algebra": 0,
    "ogx_mmlux_cs-anatomy": 0,
    "ogx_mmlux_cs-astronomy": 0,
    "ogx_mmlux_cs-business_ethics": 0,
    "ogx_mmlux_cs-clinical_knowledge": 0,
    "ogx_mmlux_cs-college_biology": 0,
    "ogx_mmlux_cs-college_chemistry": 0,
    "ogx_mmlux_cs-college_computer_science": 0,
    "ogx_mmlux_cs-college_mathematics": 0,
    "ogx_mmlux_cs-college_medicine": 0,
    "ogx_mmlux_cs-college_physics": 0,
    "ogx_mmlux_cs-computer_security": 0,
    "ogx_mmlux_cs-conceptual_physics": 0,
    "ogx_mmlux_cs-econometrics": 0,
    "ogx_mmlux_cs-electrical_engineering": 0,
    "ogx_mmlux_cs-elementary_mathematics": 0,
    "ogx_mmlux_cs-formal_logic": 0,
    "ogx_mmlux_cs-global_facts": 0,
    "ogx_mmlux_cs-high_school_biology": 0,
    "ogx_mmlux_cs-high_school_chemistry": 0,
    "ogx_mmlux_cs-high_school_computer_science": 0,
    "ogx_mmlux_cs-high_school_european_history": 0,
    "ogx_mmlux_cs-high_school_geography": 0,
    "ogx_mmlux_cs-high_school_government_and_politics": 0,
    "ogx_mmlux_cs-high_school_macroeconomics": 0,
    "ogx_mmlux_cs-high_school_mathematics": 0,
    "ogx_mmlux_cs-high_school_microeconomics": 0,
    "ogx_mmlux_cs-high_school_physics": 0,
    "ogx_mmlux_cs-high_school_psychology": 0,
    "ogx_mmlux_cs-high_school_statistics": 0,
    "ogx_mmlux_cs-high_school_us_history": 0,
    "ogx_mmlux_cs-high_school_world_history": 0,
    "ogx_mmlux_cs-human_aging": 0,
    "ogx_mmlux_cs-human_sexuality": 0,
    "ogx_mmlux_cs-international_law": 0,
    "ogx_mmlux_cs-jurisprudence": 0,
    "ogx_mmlux_cs-logical_fallacies": 0,
    "ogx_mmlux_cs-machine_learning": 0,
    "ogx_mmlux_cs-management": 0,
    "ogx_mmlux_cs-marketing": 0,
    "ogx_mmlux_cs-medical_genetics": 0,
    "ogx_mmlux_cs-miscellaneous": 0,
    "ogx_mmlux_cs-moral_disputes": 0,
    "ogx_mmlux_cs-moral_scenarios": 0,
    "ogx_mmlux_cs-nutrition": 0,
    "ogx_mmlux_cs-philosophy": 0,
    "ogx_mmlux_cs-prehistory": 0,
    "ogx_mmlux_cs-professional_accounting": 0,
    "ogx_mmlux_cs-professional_law": 0,
    "ogx_mmlux_cs-professional_medicine": 0,
    "ogx_mmlux_cs-professional_psychology": 0,
    "ogx_mmlux_cs-public_relations": 0,
    "ogx_mmlux_cs-security_studies": 0,
    "ogx_mmlux_cs-sociology": 0,
    "ogx_mmlux_cs-us_foreign_policy": 0,
    "ogx_mmlux_cs-virology": 0,
    "ogx_mmlux_cs-world_religions": 0,
    "ogx_mmlux_da-abstract_algebra": 0,
    "ogx_mmlux_da-anatomy": 0,
    "ogx_mmlux_da-astronomy": 0,
    "ogx_mmlux_da-business_ethics": 0,
    "ogx_mmlux_da-clinical_knowledge": 0,
    "ogx_mmlux_da-college_biology": 0,
    "ogx_mmlux_da-college_chemistry": 0,
    "ogx_mmlux_da-college_computer_science": 0,
    "ogx_mmlux_da-college_mathematics": 0,
    "ogx_mmlux_da-college_medicine": 0,
    "ogx_mmlux_da-college_physics": 0,
    "ogx_mmlux_da-computer_security": 0,
    "ogx_mmlux_da-conceptual_physics": 0,
    "ogx_mmlux_da-econometrics": 0,
    "ogx_mmlux_da-electrical_engineering": 0,
    "ogx_mmlux_da-elementary_mathematics": 0,
    "ogx_mmlux_da-formal_logic": 0,
    "ogx_mmlux_da-global_facts": 0,
    "ogx_mmlux_da-high_school_biology": 0,
    "ogx_mmlux_da-high_school_chemistry": 0,
    "ogx_mmlux_da-high_school_computer_science": 0,
    "ogx_mmlux_da-high_school_european_history": 0,
    "ogx_mmlux_da-high_school_geography": 0,
    "ogx_mmlux_da-high_school_government_and_politics": 0,
    "ogx_mmlux_da-high_school_macroeconomics": 0,
    "ogx_mmlux_da-high_school_mathematics": 0,
    "ogx_mmlux_da-high_school_microeconomics": 0,
    "ogx_mmlux_da-high_school_physics": 0,
    "ogx_mmlux_da-high_school_psychology": 0,
    "ogx_mmlux_da-high_school_statistics": 0,
    "ogx_mmlux_da-high_school_us_history": 0,
    "ogx_mmlux_da-high_school_world_history": 0,
    "ogx_mmlux_da-human_aging": 0,
    "ogx_mmlux_da-human_sexuality": 0,
    "ogx_mmlux_da-international_law": 0,
    "ogx_mmlux_da-jurisprudence": 0,
    "ogx_mmlux_da-logical_fallacies": 0,
    "ogx_mmlux_da-machine_learning": 0,
    "ogx_mmlux_da-management": 0,
    "ogx_mmlux_da-marketing": 0,
    "ogx_mmlux_da-medical_genetics": 0,
    "ogx_mmlux_da-miscellaneous": 0,
    "ogx_mmlux_da-moral_disputes": 0,
    "ogx_mmlux_da-moral_scenarios": 0,
    "ogx_mmlux_da-nutrition": 0,
    "ogx_mmlux_da-philosophy": 0,
    "ogx_mmlux_da-prehistory": 0,
    "ogx_mmlux_da-professional_accounting": 0,
    "ogx_mmlux_da-professional_law": 0,
    "ogx_mmlux_da-professional_medicine": 0,
    "ogx_mmlux_da-professional_psychology": 0,
    "ogx_mmlux_da-public_relations": 0,
    "ogx_mmlux_da-security_studies": 0,
    "ogx_mmlux_da-sociology": 0,
    "ogx_mmlux_da-us_foreign_policy": 0,
    "ogx_mmlux_da-virology": 0,
    "ogx_mmlux_da-world_religions": 0,
    "ogx_mmlux_de-abstract_algebra": 0,
    "ogx_mmlux_de-anatomy": 0,
    "ogx_mmlux_de-astronomy": 0,
    "ogx_mmlux_de-business_ethics": 0,
    "ogx_mmlux_de-clinical_knowledge": 0,
    "ogx_mmlux_de-college_biology": 0,
    "ogx_mmlux_de-college_chemistry": 0,
    "ogx_mmlux_de-college_computer_science": 0,
    "ogx_mmlux_de-college_mathematics": 0,
    "ogx_mmlux_de-college_medicine": 0,
    "ogx_mmlux_de-college_physics": 0,
    "ogx_mmlux_de-computer_security": 0,
    "ogx_mmlux_de-conceptual_physics": 0,
    "ogx_mmlux_de-econometrics": 0,
    "ogx_mmlux_de-electrical_engineering": 0,
    "ogx_mmlux_de-elementary_mathematics": 0,
    "ogx_mmlux_de-formal_logic": 0,
    "ogx_mmlux_de-global_facts": 0,
    "ogx_mmlux_de-high_school_biology": 0,
    "ogx_mmlux_de-high_school_chemistry": 0,
    "ogx_mmlux_de-high_school_computer_science": 0,
    "ogx_mmlux_de-high_school_european_history": 0,
    "ogx_mmlux_de-high_school_geography": 0,
    "ogx_mmlux_de-high_school_government_and_politics": 0,
    "ogx_mmlux_de-high_school_macroeconomics": 0,
    "ogx_mmlux_de-high_school_mathematics": 0,
    "ogx_mmlux_de-high_school_microeconomics": 0,
    "ogx_mmlux_de-high_school_physics": 0,
    "ogx_mmlux_de-high_school_psychology": 0,
    "ogx_mmlux_de-high_school_statistics": 0,
    "ogx_mmlux_de-high_school_us_history": 0,
    "ogx_mmlux_de-high_school_world_history": 0,
    "ogx_mmlux_de-human_aging": 0,
    "ogx_mmlux_de-human_sexuality": 0,
    "ogx_mmlux_de-international_law": 0,
    "ogx_mmlux_de-jurisprudence": 0,
    "ogx_mmlux_de-logical_fallacies": 0,
    "ogx_mmlux_de-machine_learning": 0,
    "ogx_mmlux_de-management": 0,
    "ogx_mmlux_de-marketing": 0,
    "ogx_mmlux_de-medical_genetics": 0,
    "ogx_mmlux_de-miscellaneous": 0,
    "ogx_mmlux_de-moral_disputes": 0,
    "ogx_mmlux_de-moral_scenarios": 0,
    "ogx_mmlux_de-nutrition": 0,
    "ogx_mmlux_de-philosophy": 0,
    "ogx_mmlux_de-prehistory": 0,
    "ogx_mmlux_de-professional_accounting": 0,
    "ogx_mmlux_de-professional_law": 0,
    "ogx_mmlux_de-professional_medicine": 0,
    "ogx_mmlux_de-professional_psychology": 0,
    "ogx_mmlux_de-public_relations": 0,
    "ogx_mmlux_de-security_studies": 0,
    "ogx_mmlux_de-sociology": 0,
    "ogx_mmlux_de-us_foreign_policy": 0,
    "ogx_mmlux_de-virology": 0,
    "ogx_mmlux_de-world_religions": 0,
    "ogx_mmlux_el-abstract_algebra": 0,
    "ogx_mmlux_el-anatomy": 0,
    "ogx_mmlux_el-astronomy": 0,
    "ogx_mmlux_el-business_ethics": 0,
    "ogx_mmlux_el-clinical_knowledge": 0,
    "ogx_mmlux_el-college_biology": 0,
    "ogx_mmlux_el-college_chemistry": 0,
    "ogx_mmlux_el-college_computer_science": 0,
    "ogx_mmlux_el-college_mathematics": 0,
    "ogx_mmlux_el-college_medicine": 0,
    "ogx_mmlux_el-college_physics": 0,
    "ogx_mmlux_el-computer_security": 0,
    "ogx_mmlux_el-conceptual_physics": 0,
    "ogx_mmlux_el-econometrics": 0,
    "ogx_mmlux_el-electrical_engineering": 0,
    "ogx_mmlux_el-elementary_mathematics": 0,
    "ogx_mmlux_el-formal_logic": 0,
    "ogx_mmlux_el-global_facts": 0,
    "ogx_mmlux_el-high_school_biology": 0,
    "ogx_mmlux_el-high_school_chemistry": 0,
    "ogx_mmlux_el-high_school_computer_science": 0,
    "ogx_mmlux_el-high_school_european_history": 0,
    "ogx_mmlux_el-high_school_geography": 0,
    "ogx_mmlux_el-high_school_government_and_politics": 0,
    "ogx_mmlux_el-high_school_macroeconomics": 0,
    "ogx_mmlux_el-high_school_mathematics": 0,
    "ogx_mmlux_el-high_school_microeconomics": 0,
    "ogx_mmlux_el-high_school_physics": 0,
    "ogx_mmlux_el-high_school_psychology": 0,
    "ogx_mmlux_el-high_school_statistics": 0,
    "ogx_mmlux_el-high_school_us_history": 0,
    "ogx_mmlux_el-high_school_world_history": 0,
    "ogx_mmlux_el-human_aging": 0,
    "ogx_mmlux_el-human_sexuality": 0,
    "ogx_mmlux_el-international_law": 0,
    "ogx_mmlux_el-jurisprudence": 0,
    "ogx_mmlux_el-logical_fallacies": 0,
    "ogx_mmlux_el-machine_learning": 0,
    "ogx_mmlux_el-management": 0,
    "ogx_mmlux_el-marketing": 0,
    "ogx_mmlux_el-medical_genetics": 0,
    "ogx_mmlux_el-miscellaneous": 0,
    "ogx_mmlux_el-moral_disputes": 0,
    "ogx_mmlux_el-moral_scenarios": 0,
    "ogx_mmlux_el-nutrition": 0,
    "ogx_mmlux_el-philosophy": 0,
    "ogx_mmlux_el-prehistory": 0,
    "ogx_mmlux_el-professional_accounting": 0,
    "ogx_mmlux_el-professional_law": 0,
    "ogx_mmlux_el-professional_medicine": 0,
    "ogx_mmlux_el-professional_psychology": 0,
    "ogx_mmlux_el-public_relations": 0,
    "ogx_mmlux_el-security_studies": 0,
    "ogx_mmlux_el-sociology": 0,
    "ogx_mmlux_el-us_foreign_policy": 0,
    "ogx_mmlux_el-virology": 0,
    "ogx_mmlux_el-world_religions": 0,
    "ogx_mmlux_es-abstract_algebra": 0,
    "ogx_mmlux_es-anatomy": 0,
    "ogx_mmlux_es-astronomy": 0,
    "ogx_mmlux_es-business_ethics": 0,
    "ogx_mmlux_es-clinical_knowledge": 0,
    "ogx_mmlux_es-college_biology": 0,
    "ogx_mmlux_es-college_chemistry": 0,
    "ogx_mmlux_es-college_computer_science": 0,
    "ogx_mmlux_es-college_mathematics": 0,
    "ogx_mmlux_es-college_medicine": 0,
    "ogx_mmlux_es-college_physics": 0,
    "ogx_mmlux_es-computer_security": 0,
    "ogx_mmlux_es-conceptual_physics": 0,
    "ogx_mmlux_es-econometrics": 0,
    "ogx_mmlux_es-electrical_engineering": 0,
    "ogx_mmlux_es-elementary_mathematics": 0,
    "ogx_mmlux_es-formal_logic": 0,
    "ogx_mmlux_es-global_facts": 0,
    "ogx_mmlux_es-high_school_biology": 0,
    "ogx_mmlux_es-high_school_chemistry": 0,
    "ogx_mmlux_es-high_school_computer_science": 0,
    "ogx_mmlux_es-high_school_european_history": 0,
    "ogx_mmlux_es-high_school_geography": 0,
    "ogx_mmlux_es-high_school_government_and_politics": 0,
    "ogx_mmlux_es-high_school_macroeconomics": 0,
    "ogx_mmlux_es-high_school_mathematics": 0,
    "ogx_mmlux_es-high_school_microeconomics": 0,
    "ogx_mmlux_es-high_school_physics": 0,
    "ogx_mmlux_es-high_school_psychology": 0,
    "ogx_mmlux_es-high_school_statistics": 0,
    "ogx_mmlux_es-high_school_us_history": 0,
    "ogx_mmlux_es-high_school_world_history": 0,
    "ogx_mmlux_es-human_aging": 0,
    "ogx_mmlux_es-human_sexuality": 0,
    "ogx_mmlux_es-international_law": 0,
    "ogx_mmlux_es-jurisprudence": 0,
    "ogx_mmlux_es-logical_fallacies": 0,
    "ogx_mmlux_es-machine_learning": 0,
    "ogx_mmlux_es-management": 0,
    "ogx_mmlux_es-marketing": 0,
    "ogx_mmlux_es-medical_genetics": 0,
    "ogx_mmlux_es-miscellaneous": 0,
    "ogx_mmlux_es-moral_disputes": 0,
    "ogx_mmlux_es-moral_scenarios": 0,
    "ogx_mmlux_es-nutrition": 0,
    "ogx_mmlux_es-philosophy": 0,
    "ogx_mmlux_es-prehistory": 0,
    "ogx_mmlux_es-professional_accounting": 0,
    "ogx_mmlux_es-professional_law": 0,
    "ogx_mmlux_es-professional_medicine": 0,
    "ogx_mmlux_es-professional_psychology": 0,
    "ogx_mmlux_es-public_relations": 0,
    "ogx_mmlux_es-security_studies": 0,
    "ogx_mmlux_es-sociology": 0,
    "ogx_mmlux_es-us_foreign_policy": 0,
    "ogx_mmlux_es-virology": 0,
    "ogx_mmlux_es-world_religions": 0,
    "ogx_mmlux_et-abstract_algebra": 0,
    "ogx_mmlux_et-anatomy": 0,
    "ogx_mmlux_et-astronomy": 0,
    "ogx_mmlux_et-business_ethics": 0,
    "ogx_mmlux_et-clinical_knowledge": 0,
    "ogx_mmlux_et-college_biology": 0,
    "ogx_mmlux_et-college_chemistry": 0,
    "ogx_mmlux_et-college_computer_science": 0,
    "ogx_mmlux_et-college_mathematics": 0,
    "ogx_mmlux_et-college_medicine": 0,
    "ogx_mmlux_et-college_physics": 0,
    "ogx_mmlux_et-computer_security": 0,
    "ogx_mmlux_et-conceptual_physics": 0,
    "ogx_mmlux_et-econometrics": 0,
    "ogx_mmlux_et-electrical_engineering": 0,
    "ogx_mmlux_et-elementary_mathematics": 0,
    "ogx_mmlux_et-formal_logic": 0,
    "ogx_mmlux_et-global_facts": 0,
    "ogx_mmlux_et-high_school_biology": 0,
    "ogx_mmlux_et-high_school_chemistry": 0,
    "ogx_mmlux_et-high_school_computer_science": 0,
    "ogx_mmlux_et-high_school_european_history": 0,
    "ogx_mmlux_et-high_school_geography": 0,
    "ogx_mmlux_et-high_school_government_and_politics": 0,
    "ogx_mmlux_et-high_school_macroeconomics": 0,
    "ogx_mmlux_et-high_school_mathematics": 0,
    "ogx_mmlux_et-high_school_microeconomics": 0,
    "ogx_mmlux_et-high_school_physics": 0,
    "ogx_mmlux_et-high_school_psychology": 0,
    "ogx_mmlux_et-high_school_statistics": 0,
    "ogx_mmlux_et-high_school_us_history": 0,
    "ogx_mmlux_et-high_school_world_history": 0,
    "ogx_mmlux_et-human_aging": 0,
    "ogx_mmlux_et-human_sexuality": 0,
    "ogx_mmlux_et-international_law": 0,
    "ogx_mmlux_et-jurisprudence": 0,
    "ogx_mmlux_et-logical_fallacies": 0,
    "ogx_mmlux_et-machine_learning": 0,
    "ogx_mmlux_et-management": 0,
    "ogx_mmlux_et-marketing": 0,
    "ogx_mmlux_et-medical_genetics": 0,
    "ogx_mmlux_et-miscellaneous": 0,
    "ogx_mmlux_et-moral_disputes": 0,
    "ogx_mmlux_et-moral_scenarios": 0,
    "ogx_mmlux_et-nutrition": 0,
    "ogx_mmlux_et-philosophy": 0,
    "ogx_mmlux_et-prehistory": 0,
    "ogx_mmlux_et-professional_accounting": 0,
    "ogx_mmlux_et-professional_law": 0,
    "ogx_mmlux_et-professional_medicine": 0,
    "ogx_mmlux_et-professional_psychology": 0,
    "ogx_mmlux_et-public_relations": 0,
    "ogx_mmlux_et-security_studies": 0,
    "ogx_mmlux_et-sociology": 0,
    "ogx_mmlux_et-us_foreign_policy": 0,
    "ogx_mmlux_et-virology": 0,
    "ogx_mmlux_et-world_religions": 0,
    "ogx_mmlux_fi-abstract_algebra": 0,
    "ogx_mmlux_fi-anatomy": 0,
    "ogx_mmlux_fi-astronomy": 0,
    "ogx_mmlux_fi-business_ethics": 0,
    "ogx_mmlux_fi-clinical_knowledge": 0,
    "ogx_mmlux_fi-college_biology": 0,
    "ogx_mmlux_fi-college_chemistry": 0,
    "ogx_mmlux_fi-college_computer_science": 0,
    "ogx_mmlux_fi-college_mathematics": 0,
    "ogx_mmlux_fi-college_medicine": 0,
    "ogx_mmlux_fi-college_physics": 0,
    "ogx_mmlux_fi-computer_security": 0,
    "ogx_mmlux_fi-conceptual_physics": 0,
    "ogx_mmlux_fi-econometrics": 0,
    "ogx_mmlux_fi-electrical_engineering": 0,
    "ogx_mmlux_fi-elementary_mathematics": 0,
    "ogx_mmlux_fi-formal_logic": 0,
    "ogx_mmlux_fi-global_facts": 0,
    "ogx_mmlux_fi-high_school_biology": 0,
    "ogx_mmlux_fi-high_school_chemistry": 0,
    "ogx_mmlux_fi-high_school_computer_science": 0,
    "ogx_mmlux_fi-high_school_european_history": 0,
    "ogx_mmlux_fi-high_school_geography": 0,
    "ogx_mmlux_fi-high_school_government_and_politics": 0,
    "ogx_mmlux_fi-high_school_macroeconomics": 0,
    "ogx_mmlux_fi-high_school_mathematics": 0,
    "ogx_mmlux_fi-high_school_microeconomics": 0,
    "ogx_mmlux_fi-high_school_physics": 0,
    "ogx_mmlux_fi-high_school_psychology": 0,
    "ogx_mmlux_fi-high_school_statistics": 0,
    "ogx_mmlux_fi-high_school_us_history": 0,
    "ogx_mmlux_fi-high_school_world_history": 0,
    "ogx_mmlux_fi-human_aging": 0,
    "ogx_mmlux_fi-human_sexuality": 0,
    "ogx_mmlux_fi-international_law": 0,
    "ogx_mmlux_fi-jurisprudence": 0,
    "ogx_mmlux_fi-logical_fallacies": 0,
    "ogx_mmlux_fi-machine_learning": 0,
    "ogx_mmlux_fi-management": 0,
    "ogx_mmlux_fi-marketing": 0,
    "ogx_mmlux_fi-medical_genetics": 0,
    "ogx_mmlux_fi-miscellaneous": 0,
    "ogx_mmlux_fi-moral_disputes": 0,
    "ogx_mmlux_fi-moral_scenarios": 0,
    "ogx_mmlux_fi-nutrition": 0,
    "ogx_mmlux_fi-philosophy": 0,
    "ogx_mmlux_fi-prehistory": 0,
    "ogx_mmlux_fi-professional_accounting": 0,
    "ogx_mmlux_fi-professional_law": 0,
    "ogx_mmlux_fi-professional_medicine": 0,
    "ogx_mmlux_fi-professional_psychology": 0,
    "ogx_mmlux_fi-public_relations": 0,
    "ogx_mmlux_fi-security_studies": 0,
    "ogx_mmlux_fi-sociology": 0,
    "ogx_mmlux_fi-us_foreign_policy": 0,
    "ogx_mmlux_fi-virology": 0,
    "ogx_mmlux_fi-world_religions": 0,
    "ogx_mmlux_fr-abstract_algebra": 0,
    "ogx_mmlux_fr-anatomy": 0,
    "ogx_mmlux_fr-astronomy": 0,
    "ogx_mmlux_fr-business_ethics": 0,
    "ogx_mmlux_fr-clinical_knowledge": 0,
    "ogx_mmlux_fr-college_biology": 0,
    "ogx_mmlux_fr-college_chemistry": 0,
    "ogx_mmlux_fr-college_computer_science": 0,
    "ogx_mmlux_fr-college_mathematics": 0,
    "ogx_mmlux_fr-college_medicine": 0,
    "ogx_mmlux_fr-college_physics": 0,
    "ogx_mmlux_fr-computer_security": 0,
    "ogx_mmlux_fr-conceptual_physics": 0,
    "ogx_mmlux_fr-econometrics": 0,
    "ogx_mmlux_fr-electrical_engineering": 0,
    "ogx_mmlux_fr-elementary_mathematics": 0,
    "ogx_mmlux_fr-formal_logic": 0,
    "ogx_mmlux_fr-global_facts": 0,
    "ogx_mmlux_fr-high_school_biology": 0,
    "ogx_mmlux_fr-high_school_chemistry": 0,
    "ogx_mmlux_fr-high_school_computer_science": 0,
    "ogx_mmlux_fr-high_school_european_history": 0,
    "ogx_mmlux_fr-high_school_geography": 0,
    "ogx_mmlux_fr-high_school_government_and_politics": 0,
    "ogx_mmlux_fr-high_school_macroeconomics": 0,
    "ogx_mmlux_fr-high_school_mathematics": 0,
    "ogx_mmlux_fr-high_school_microeconomics": 0,
    "ogx_mmlux_fr-high_school_physics": 0,
    "ogx_mmlux_fr-high_school_psychology": 0,
    "ogx_mmlux_fr-high_school_statistics": 0,
    "ogx_mmlux_fr-high_school_us_history": 0,
    "ogx_mmlux_fr-high_school_world_history": 0,
    "ogx_mmlux_fr-human_aging": 0,
    "ogx_mmlux_fr-human_sexuality": 0,
    "ogx_mmlux_fr-international_law": 0,
    "ogx_mmlux_fr-jurisprudence": 0,
    "ogx_mmlux_fr-logical_fallacies": 0,
    "ogx_mmlux_fr-machine_learning": 0,
    "ogx_mmlux_fr-management": 0,
    "ogx_mmlux_fr-marketing": 0,
    "ogx_mmlux_fr-medical_genetics": 0,
    "ogx_mmlux_fr-miscellaneous": 0,
    "ogx_mmlux_fr-moral_disputes": 0,
    "ogx_mmlux_fr-moral_scenarios": 0,
    "ogx_mmlux_fr-nutrition": 0,
    "ogx_mmlux_fr-philosophy": 0,
    "ogx_mmlux_fr-prehistory": 0,
    "ogx_mmlux_fr-professional_accounting": 0,
    "ogx_mmlux_fr-professional_law": 0,
    "ogx_mmlux_fr-professional_medicine": 0,
    "ogx_mmlux_fr-professional_psychology": 0,
    "ogx_mmlux_fr-public_relations": 0,
    "ogx_mmlux_fr-security_studies": 0,
    "ogx_mmlux_fr-sociology": 0,
    "ogx_mmlux_fr-us_foreign_policy": 0,
    "ogx_mmlux_fr-virology": 0,
    "ogx_mmlux_fr-world_religions": 0,
    "ogx_mmlux_hu-abstract_algebra": 0,
    "ogx_mmlux_hu-anatomy": 0,
    "ogx_mmlux_hu-astronomy": 0,
    "ogx_mmlux_hu-business_ethics": 0,
    "ogx_mmlux_hu-clinical_knowledge": 0,
    "ogx_mmlux_hu-college_biology": 0,
    "ogx_mmlux_hu-college_chemistry": 0,
    "ogx_mmlux_hu-college_computer_science": 0,
    "ogx_mmlux_hu-college_mathematics": 0,
    "ogx_mmlux_hu-college_medicine": 0,
    "ogx_mmlux_hu-college_physics": 0,
    "ogx_mmlux_hu-computer_security": 0,
    "ogx_mmlux_hu-conceptual_physics": 0,
    "ogx_mmlux_hu-econometrics": 0,
    "ogx_mmlux_hu-electrical_engineering": 0,
    "ogx_mmlux_hu-elementary_mathematics": 0,
    "ogx_mmlux_hu-formal_logic": 0,
    "ogx_mmlux_hu-global_facts": 0,
    "ogx_mmlux_hu-high_school_biology": 0,
    "ogx_mmlux_hu-high_school_chemistry": 0,
    "ogx_mmlux_hu-high_school_computer_science": 0,
    "ogx_mmlux_hu-high_school_european_history": 0,
    "ogx_mmlux_hu-high_school_geography": 0,
    "ogx_mmlux_hu-high_school_government_and_politics": 0,
    "ogx_mmlux_hu-high_school_macroeconomics": 0,
    "ogx_mmlux_hu-high_school_mathematics": 0,
    "ogx_mmlux_hu-high_school_microeconomics": 0,
    "ogx_mmlux_hu-high_school_physics": 0,
    "ogx_mmlux_hu-high_school_psychology": 0,
    "ogx_mmlux_hu-high_school_statistics": 0,
    "ogx_mmlux_hu-high_school_us_history": 0,
    "ogx_mmlux_hu-high_school_world_history": 0,
    "ogx_mmlux_hu-human_aging": 0,
    "ogx_mmlux_hu-human_sexuality": 0,
    "ogx_mmlux_hu-international_law": 0,
    "ogx_mmlux_hu-jurisprudence": 0,
    "ogx_mmlux_hu-logical_fallacies": 0,
    "ogx_mmlux_hu-machine_learning": 0,
    "ogx_mmlux_hu-management": 0,
    "ogx_mmlux_hu-marketing": 0,
    "ogx_mmlux_hu-medical_genetics": 0,
    "ogx_mmlux_hu-miscellaneous": 0,
    "ogx_mmlux_hu-moral_disputes": 0,
    "ogx_mmlux_hu-moral_scenarios": 0,
    "ogx_mmlux_hu-nutrition": 0,
    "ogx_mmlux_hu-philosophy": 0,
    "ogx_mmlux_hu-prehistory": 0,
    "ogx_mmlux_hu-professional_accounting": 0,
    "ogx_mmlux_hu-professional_law": 0,
    "ogx_mmlux_hu-professional_medicine": 0,
    "ogx_mmlux_hu-professional_psychology": 0,
    "ogx_mmlux_hu-public_relations": 0,
    "ogx_mmlux_hu-security_studies": 0,
    "ogx_mmlux_hu-sociology": 0,
    "ogx_mmlux_hu-us_foreign_policy": 0,
    "ogx_mmlux_hu-virology": 0,
    "ogx_mmlux_hu-world_religions": 0,
    "ogx_mmlux_it-abstract_algebra": 0,
    "ogx_mmlux_it-anatomy": 0,
    "ogx_mmlux_it-astronomy": 0,
    "ogx_mmlux_it-business_ethics": 0,
    "ogx_mmlux_it-clinical_knowledge": 0,
    "ogx_mmlux_it-college_biology": 0,
    "ogx_mmlux_it-college_chemistry": 0,
    "ogx_mmlux_it-college_computer_science": 0,
    "ogx_mmlux_it-college_mathematics": 0,
    "ogx_mmlux_it-college_medicine": 0,
    "ogx_mmlux_it-college_physics": 0,
    "ogx_mmlux_it-computer_security": 0,
    "ogx_mmlux_it-conceptual_physics": 0,
    "ogx_mmlux_it-econometrics": 0,
    "ogx_mmlux_it-electrical_engineering": 0,
    "ogx_mmlux_it-elementary_mathematics": 0,
    "ogx_mmlux_it-formal_logic": 0,
    "ogx_mmlux_it-global_facts": 0,
    "ogx_mmlux_it-high_school_biology": 0,
    "ogx_mmlux_it-high_school_chemistry": 0,
    "ogx_mmlux_it-high_school_computer_science": 0,
    "ogx_mmlux_it-high_school_european_history": 0,
    "ogx_mmlux_it-high_school_geography": 0,
    "ogx_mmlux_it-high_school_government_and_politics": 0,
    "ogx_mmlux_it-high_school_macroeconomics": 0,
    "ogx_mmlux_it-high_school_mathematics": 0,
    "ogx_mmlux_it-high_school_microeconomics": 0,
    "ogx_mmlux_it-high_school_physics": 0,
    "ogx_mmlux_it-high_school_psychology": 0,
    "ogx_mmlux_it-high_school_statistics": 0,
    "ogx_mmlux_it-high_school_us_history": 0,
    "ogx_mmlux_it-high_school_world_history": 0,
    "ogx_mmlux_it-human_aging": 0,
    "ogx_mmlux_it-human_sexuality": 0,
    "ogx_mmlux_it-international_law": 0,
    "ogx_mmlux_it-jurisprudence": 0,
    "ogx_mmlux_it-logical_fallacies": 0,
    "ogx_mmlux_it-machine_learning": 0,
    "ogx_mmlux_it-management": 0,
    "ogx_mmlux_it-marketing": 0,
    "ogx_mmlux_it-medical_genetics": 0,
    "ogx_mmlux_it-miscellaneous": 0,
    "ogx_mmlux_it-moral_disputes": 0,
    "ogx_mmlux_it-moral_scenarios": 0,
    "ogx_mmlux_it-nutrition": 0,
    "ogx_mmlux_it-philosophy": 0,
    "ogx_mmlux_it-prehistory": 0,
    "ogx_mmlux_it-professional_accounting": 0,
    "ogx_mmlux_it-professional_law": 0,
    "ogx_mmlux_it-professional_medicine": 0,
    "ogx_mmlux_it-professional_psychology": 0,
    "ogx_mmlux_it-public_relations": 0,
    "ogx_mmlux_it-security_studies": 0,
    "ogx_mmlux_it-sociology": 0,
    "ogx_mmlux_it-us_foreign_policy": 0,
    "ogx_mmlux_it-virology": 0,
    "ogx_mmlux_it-world_religions": 0,
    "ogx_mmlux_lt-abstract_algebra": 0,
    "ogx_mmlux_lt-anatomy": 0,
    "ogx_mmlux_lt-astronomy": 0,
    "ogx_mmlux_lt-business_ethics": 0,
    "ogx_mmlux_lt-clinical_knowledge": 0,
    "ogx_mmlux_lt-college_biology": 0,
    "ogx_mmlux_lt-college_chemistry": 0,
    "ogx_mmlux_lt-college_computer_science": 0,
    "ogx_mmlux_lt-college_mathematics": 0,
    "ogx_mmlux_lt-college_medicine": 0,
    "ogx_mmlux_lt-college_physics": 0,
    "ogx_mmlux_lt-computer_security": 0,
    "ogx_mmlux_lt-conceptual_physics": 0,
    "ogx_mmlux_lt-econometrics": 0,
    "ogx_mmlux_lt-electrical_engineering": 0,
    "ogx_mmlux_lt-elementary_mathematics": 0,
    "ogx_mmlux_lt-formal_logic": 0,
    "ogx_mmlux_lt-global_facts": 0,
    "ogx_mmlux_lt-high_school_biology": 0,
    "ogx_mmlux_lt-high_school_chemistry": 0,
    "ogx_mmlux_lt-high_school_computer_science": 0,
    "ogx_mmlux_lt-high_school_european_history": 0,
    "ogx_mmlux_lt-high_school_geography": 0,
    "ogx_mmlux_lt-high_school_government_and_politics": 0,
    "ogx_mmlux_lt-high_school_macroeconomics": 0,
    "ogx_mmlux_lt-high_school_mathematics": 0,
    "ogx_mmlux_lt-high_school_microeconomics": 0,
    "ogx_mmlux_lt-high_school_physics": 0,
    "ogx_mmlux_lt-high_school_psychology": 0,
    "ogx_mmlux_lt-high_school_statistics": 0,
    "ogx_mmlux_lt-high_school_us_history": 0,
    "ogx_mmlux_lt-high_school_world_history": 0,
    "ogx_mmlux_lt-human_aging": 0,
    "ogx_mmlux_lt-human_sexuality": 0,
    "ogx_mmlux_lt-international_law": 0,
    "ogx_mmlux_lt-jurisprudence": 0,
    "ogx_mmlux_lt-logical_fallacies": 0,
    "ogx_mmlux_lt-machine_learning": 0,
    "ogx_mmlux_lt-management": 0,
    "ogx_mmlux_lt-marketing": 0,
    "ogx_mmlux_lt-medical_genetics": 0,
    "ogx_mmlux_lt-miscellaneous": 0,
    "ogx_mmlux_lt-moral_disputes": 0,
    "ogx_mmlux_lt-moral_scenarios": 0,
    "ogx_mmlux_lt-nutrition": 0,
    "ogx_mmlux_lt-philosophy": 0,
    "ogx_mmlux_lt-prehistory": 0,
    "ogx_mmlux_lt-professional_accounting": 0,
    "ogx_mmlux_lt-professional_law": 0,
    "ogx_mmlux_lt-professional_medicine": 0,
    "ogx_mmlux_lt-professional_psychology": 0,
    "ogx_mmlux_lt-public_relations": 0,
    "ogx_mmlux_lt-security_studies": 0,
    "ogx_mmlux_lt-sociology": 0,
    "ogx_mmlux_lt-us_foreign_policy": 0,
    "ogx_mmlux_lt-virology": 0,
    "ogx_mmlux_lt-world_religions": 0,
    "ogx_mmlux_lv-abstract_algebra": 0,
    "ogx_mmlux_lv-anatomy": 0,
    "ogx_mmlux_lv-astronomy": 0,
    "ogx_mmlux_lv-business_ethics": 0,
    "ogx_mmlux_lv-clinical_knowledge": 0,
    "ogx_mmlux_lv-college_biology": 0,
    "ogx_mmlux_lv-college_chemistry": 0,
    "ogx_mmlux_lv-college_computer_science": 0,
    "ogx_mmlux_lv-college_mathematics": 0,
    "ogx_mmlux_lv-college_medicine": 0,
    "ogx_mmlux_lv-college_physics": 0,
    "ogx_mmlux_lv-computer_security": 0,
    "ogx_mmlux_lv-conceptual_physics": 0,
    "ogx_mmlux_lv-econometrics": 0,
    "ogx_mmlux_lv-electrical_engineering": 0,
    "ogx_mmlux_lv-elementary_mathematics": 0,
    "ogx_mmlux_lv-formal_logic": 0,
    "ogx_mmlux_lv-global_facts": 0,
    "ogx_mmlux_lv-high_school_biology": 0,
    "ogx_mmlux_lv-high_school_chemistry": 0,
    "ogx_mmlux_lv-high_school_computer_science": 0,
    "ogx_mmlux_lv-high_school_european_history": 0,
    "ogx_mmlux_lv-high_school_geography": 0,
    "ogx_mmlux_lv-high_school_government_and_politics": 0,
    "ogx_mmlux_lv-high_school_macroeconomics": 0,
    "ogx_mmlux_lv-high_school_mathematics": 0,
    "ogx_mmlux_lv-high_school_microeconomics": 0,
    "ogx_mmlux_lv-high_school_physics": 0,
    "ogx_mmlux_lv-high_school_psychology": 0,
    "ogx_mmlux_lv-high_school_statistics": 0,
    "ogx_mmlux_lv-high_school_us_history": 0,
    "ogx_mmlux_lv-high_school_world_history": 0,
    "ogx_mmlux_lv-human_aging": 0,
    "ogx_mmlux_lv-human_sexuality": 0,
    "ogx_mmlux_lv-international_law": 0,
    "ogx_mmlux_lv-jurisprudence": 0,
    "ogx_mmlux_lv-logical_fallacies": 0,
    "ogx_mmlux_lv-machine_learning": 0,
    "ogx_mmlux_lv-management": 0,
    "ogx_mmlux_lv-marketing": 0,
    "ogx_mmlux_lv-medical_genetics": 0,
    "ogx_mmlux_lv-miscellaneous": 0,
    "ogx_mmlux_lv-moral_disputes": 0,
    "ogx_mmlux_lv-moral_scenarios": 0,
    "ogx_mmlux_lv-nutrition": 0,
    "ogx_mmlux_lv-philosophy": 0,
    "ogx_mmlux_lv-prehistory": 0,
    "ogx_mmlux_lv-professional_accounting": 0,
    "ogx_mmlux_lv-professional_law": 0,
    "ogx_mmlux_lv-professional_medicine": 0,
    "ogx_mmlux_lv-professional_psychology": 0,
    "ogx_mmlux_lv-public_relations": 0,
    "ogx_mmlux_lv-security_studies": 0,
    "ogx_mmlux_lv-sociology": 0,
    "ogx_mmlux_lv-us_foreign_policy": 0,
    "ogx_mmlux_lv-virology": 0,
    "ogx_mmlux_lv-world_religions": 0,
    "ogx_mmlux_nl-abstract_algebra": 0,
    "ogx_mmlux_nl-anatomy": 0,
    "ogx_mmlux_nl-astronomy": 0,
    "ogx_mmlux_nl-business_ethics": 0,
    "ogx_mmlux_nl-clinical_knowledge": 0,
    "ogx_mmlux_nl-college_biology": 0,
    "ogx_mmlux_nl-college_chemistry": 0,
    "ogx_mmlux_nl-college_computer_science": 0,
    "ogx_mmlux_nl-college_mathematics": 0,
    "ogx_mmlux_nl-college_medicine": 0,
    "ogx_mmlux_nl-college_physics": 0,
    "ogx_mmlux_nl-computer_security": 0,
    "ogx_mmlux_nl-conceptual_physics": 0,
    "ogx_mmlux_nl-econometrics": 0,
    "ogx_mmlux_nl-electrical_engineering": 0,
    "ogx_mmlux_nl-elementary_mathematics": 0,
    "ogx_mmlux_nl-formal_logic": 0,
    "ogx_mmlux_nl-global_facts": 0,
    "ogx_mmlux_nl-high_school_biology": 0,
    "ogx_mmlux_nl-high_school_chemistry": 0,
    "ogx_mmlux_nl-high_school_computer_science": 0,
    "ogx_mmlux_nl-high_school_european_history": 0,
    "ogx_mmlux_nl-high_school_geography": 0,
    "ogx_mmlux_nl-high_school_government_and_politics": 0,
    "ogx_mmlux_nl-high_school_macroeconomics": 0,
    "ogx_mmlux_nl-high_school_mathematics": 0,
    "ogx_mmlux_nl-high_school_microeconomics": 0,
    "ogx_mmlux_nl-high_school_physics": 0,
    "ogx_mmlux_nl-high_school_psychology": 0,
    "ogx_mmlux_nl-high_school_statistics": 0,
    "ogx_mmlux_nl-high_school_us_history": 0,
    "ogx_mmlux_nl-high_school_world_history": 0,
    "ogx_mmlux_nl-human_aging": 0,
    "ogx_mmlux_nl-human_sexuality": 0,
    "ogx_mmlux_nl-international_law": 0,
    "ogx_mmlux_nl-jurisprudence": 0,
    "ogx_mmlux_nl-logical_fallacies": 0,
    "ogx_mmlux_nl-machine_learning": 0,
    "ogx_mmlux_nl-management": 0,
    "ogx_mmlux_nl-marketing": 0,
    "ogx_mmlux_nl-medical_genetics": 0,
    "ogx_mmlux_nl-miscellaneous": 0,
    "ogx_mmlux_nl-moral_disputes": 0,
    "ogx_mmlux_nl-moral_scenarios": 0,
    "ogx_mmlux_nl-nutrition": 0,
    "ogx_mmlux_nl-philosophy": 0,
    "ogx_mmlux_nl-prehistory": 0,
    "ogx_mmlux_nl-professional_accounting": 0,
    "ogx_mmlux_nl-professional_law": 0,
    "ogx_mmlux_nl-professional_medicine": 0,
    "ogx_mmlux_nl-professional_psychology": 0,
    "ogx_mmlux_nl-public_relations": 0,
    "ogx_mmlux_nl-security_studies": 0,
    "ogx_mmlux_nl-sociology": 0,
    "ogx_mmlux_nl-us_foreign_policy": 0,
    "ogx_mmlux_nl-virology": 0,
    "ogx_mmlux_nl-world_religions": 0,
    "ogx_mmlux_pl-abstract_algebra": 0,
    "ogx_mmlux_pl-anatomy": 0,
    "ogx_mmlux_pl-astronomy": 0,
    "ogx_mmlux_pl-business_ethics": 0,
    "ogx_mmlux_pl-clinical_knowledge": 0,
    "ogx_mmlux_pl-college_biology": 0,
    "ogx_mmlux_pl-college_chemistry": 0,
    "ogx_mmlux_pl-college_computer_science": 0,
    "ogx_mmlux_pl-college_mathematics": 0,
    "ogx_mmlux_pl-college_medicine": 0,
    "ogx_mmlux_pl-college_physics": 0,
    "ogx_mmlux_pl-computer_security": 0,
    "ogx_mmlux_pl-conceptual_physics": 0,
    "ogx_mmlux_pl-econometrics": 0,
    "ogx_mmlux_pl-electrical_engineering": 0,
    "ogx_mmlux_pl-elementary_mathematics": 0,
    "ogx_mmlux_pl-formal_logic": 0,
    "ogx_mmlux_pl-global_facts": 0,
    "ogx_mmlux_pl-high_school_biology": 0,
    "ogx_mmlux_pl-high_school_chemistry": 0,
    "ogx_mmlux_pl-high_school_computer_science": 0,
    "ogx_mmlux_pl-high_school_european_history": 0,
    "ogx_mmlux_pl-high_school_geography": 0,
    "ogx_mmlux_pl-high_school_government_and_politics": 0,
    "ogx_mmlux_pl-high_school_macroeconomics": 0,
    "ogx_mmlux_pl-high_school_mathematics": 0,
    "ogx_mmlux_pl-high_school_microeconomics": 0,
    "ogx_mmlux_pl-high_school_physics": 0,
    "ogx_mmlux_pl-high_school_psychology": 0,
    "ogx_mmlux_pl-high_school_statistics": 0,
    "ogx_mmlux_pl-high_school_us_history": 0,
    "ogx_mmlux_pl-high_school_world_history": 0,
    "ogx_mmlux_pl-human_aging": 0,
    "ogx_mmlux_pl-human_sexuality": 0,
    "ogx_mmlux_pl-international_law": 0,
    "ogx_mmlux_pl-jurisprudence": 0,
    "ogx_mmlux_pl-logical_fallacies": 0,
    "ogx_mmlux_pl-machine_learning": 0,
    "ogx_mmlux_pl-management": 0,
    "ogx_mmlux_pl-marketing": 0,
    "ogx_mmlux_pl-medical_genetics": 0,
    "ogx_mmlux_pl-miscellaneous": 0,
    "ogx_mmlux_pl-moral_disputes": 0,
    "ogx_mmlux_pl-moral_scenarios": 0,
    "ogx_mmlux_pl-nutrition": 0,
    "ogx_mmlux_pl-philosophy": 0,
    "ogx_mmlux_pl-prehistory": 0,
    "ogx_mmlux_pl-professional_accounting": 0,
    "ogx_mmlux_pl-professional_law": 0,
    "ogx_mmlux_pl-professional_medicine": 0,
    "ogx_mmlux_pl-professional_psychology": 0,
    "ogx_mmlux_pl-public_relations": 0,
    "ogx_mmlux_pl-security_studies": 0,
    "ogx_mmlux_pl-sociology": 0,
    "ogx_mmlux_pl-us_foreign_policy": 0,
    "ogx_mmlux_pl-virology": 0,
    "ogx_mmlux_pl-world_religions": 0,
    "ogx_mmlux_pt-pt-abstract_algebra": 0,
    "ogx_mmlux_pt-pt-anatomy": 0,
    "ogx_mmlux_pt-pt-astronomy": 0,
    "ogx_mmlux_pt-pt-business_ethics": 0,
    "ogx_mmlux_pt-pt-clinical_knowledge": 0,
    "ogx_mmlux_pt-pt-college_biology": 0,
    "ogx_mmlux_pt-pt-college_chemistry": 0,
    "ogx_mmlux_pt-pt-college_computer_science": 0,
    "ogx_mmlux_pt-pt-college_mathematics": 0,
    "ogx_mmlux_pt-pt-college_medicine": 0,
    "ogx_mmlux_pt-pt-college_physics": 0,
    "ogx_mmlux_pt-pt-computer_security": 0,
    "ogx_mmlux_pt-pt-conceptual_physics": 0,
    "ogx_mmlux_pt-pt-econometrics": 0,
    "ogx_mmlux_pt-pt-electrical_engineering": 0,
    "ogx_mmlux_pt-pt-elementary_mathematics": 0,
    "ogx_mmlux_pt-pt-formal_logic": 0,
    "ogx_mmlux_pt-pt-global_facts": 0,
    "ogx_mmlux_pt-pt-high_school_biology": 0,
    "ogx_mmlux_pt-pt-high_school_chemistry": 0,
    "ogx_mmlux_pt-pt-high_school_computer_science": 0,
    "ogx_mmlux_pt-pt-high_school_european_history": 0,
    "ogx_mmlux_pt-pt-high_school_geography": 0,
    "ogx_mmlux_pt-pt-high_school_government_and_politics": 0,
    "ogx_mmlux_pt-pt-high_school_macroeconomics": 0,
    "ogx_mmlux_pt-pt-high_school_mathematics": 0,
    "ogx_mmlux_pt-pt-high_school_microeconomics": 0,
    "ogx_mmlux_pt-pt-high_school_physics": 0,
    "ogx_mmlux_pt-pt-high_school_psychology": 0,
    "ogx_mmlux_pt-pt-high_school_statistics": 0,
    "ogx_mmlux_pt-pt-high_school_us_history": 0,
    "ogx_mmlux_pt-pt-high_school_world_history": 0,
    "ogx_mmlux_pt-pt-human_aging": 0,
    "ogx_mmlux_pt-pt-human_sexuality": 0,
    "ogx_mmlux_pt-pt-international_law": 0,
    "ogx_mmlux_pt-pt-jurisprudence": 0,
    "ogx_mmlux_pt-pt-logical_fallacies": 0,
    "ogx_mmlux_pt-pt-machine_learning": 0,
    "ogx_mmlux_pt-pt-management": 0,
    "ogx_mmlux_pt-pt-marketing": 0,
    "ogx_mmlux_pt-pt-medical_genetics": 0,
    "ogx_mmlux_pt-pt-miscellaneous": 0,
    "ogx_mmlux_pt-pt-moral_disputes": 0,
    "ogx_mmlux_pt-pt-moral_scenarios": 0,
    "ogx_mmlux_pt-pt-nutrition": 0,
    "ogx_mmlux_pt-pt-philosophy": 0,
    "ogx_mmlux_pt-pt-prehistory": 0,
    "ogx_mmlux_pt-pt-professional_accounting": 0,
    "ogx_mmlux_pt-pt-professional_law": 0,
    "ogx_mmlux_pt-pt-professional_medicine": 0,
    "ogx_mmlux_pt-pt-professional_psychology": 0,
    "ogx_mmlux_pt-pt-public_relations": 0,
    "ogx_mmlux_pt-pt-security_studies": 0,
    "ogx_mmlux_pt-pt-sociology": 0,
    "ogx_mmlux_pt-pt-us_foreign_policy": 0,
    "ogx_mmlux_pt-pt-virology": 0,
    "ogx_mmlux_pt-pt-world_religions": 0,
    "ogx_mmlux_ro-abstract_algebra": 0,
    "ogx_mmlux_ro-anatomy": 0,
    "ogx_mmlux_ro-astronomy": 0,
    "ogx_mmlux_ro-business_ethics": 0,
    "ogx_mmlux_ro-clinical_knowledge": 0,
    "ogx_mmlux_ro-college_biology": 0,
    "ogx_mmlux_ro-college_chemistry": 0,
    "ogx_mmlux_ro-college_computer_science": 0,
    "ogx_mmlux_ro-college_mathematics": 0,
    "ogx_mmlux_ro-college_medicine": 0,
    "ogx_mmlux_ro-college_physics": 0,
    "ogx_mmlux_ro-computer_security": 0,
    "ogx_mmlux_ro-conceptual_physics": 0,
    "ogx_mmlux_ro-econometrics": 0,
    "ogx_mmlux_ro-electrical_engineering": 0,
    "ogx_mmlux_ro-elementary_mathematics": 0,
    "ogx_mmlux_ro-formal_logic": 0,
    "ogx_mmlux_ro-global_facts": 0,
    "ogx_mmlux_ro-high_school_biology": 0,
    "ogx_mmlux_ro-high_school_chemistry": 0,
    "ogx_mmlux_ro-high_school_computer_science": 0,
    "ogx_mmlux_ro-high_school_european_history": 0,
    "ogx_mmlux_ro-high_school_geography": 0,
    "ogx_mmlux_ro-high_school_government_and_politics": 0,
    "ogx_mmlux_ro-high_school_macroeconomics": 0,
    "ogx_mmlux_ro-high_school_mathematics": 0,
    "ogx_mmlux_ro-high_school_microeconomics": 0,
    "ogx_mmlux_ro-high_school_physics": 0,
    "ogx_mmlux_ro-high_school_psychology": 0,
    "ogx_mmlux_ro-high_school_statistics": 0,
    "ogx_mmlux_ro-high_school_us_history": 0,
    "ogx_mmlux_ro-high_school_world_history": 0,
    "ogx_mmlux_ro-human_aging": 0,
    "ogx_mmlux_ro-human_sexuality": 0,
    "ogx_mmlux_ro-international_law": 0,
    "ogx_mmlux_ro-jurisprudence": 0,
    "ogx_mmlux_ro-logical_fallacies": 0,
    "ogx_mmlux_ro-machine_learning": 0,
    "ogx_mmlux_ro-management": 0,
    "ogx_mmlux_ro-marketing": 0,
    "ogx_mmlux_ro-medical_genetics": 0,
    "ogx_mmlux_ro-miscellaneous": 0,
    "ogx_mmlux_ro-moral_disputes": 0,
    "ogx_mmlux_ro-moral_scenarios": 0,
    "ogx_mmlux_ro-nutrition": 0,
    "ogx_mmlux_ro-philosophy": 0,
    "ogx_mmlux_ro-prehistory": 0,
    "ogx_mmlux_ro-professional_accounting": 0,
    "ogx_mmlux_ro-professional_law": 0,
    "ogx_mmlux_ro-professional_medicine": 0,
    "ogx_mmlux_ro-professional_psychology": 0,
    "ogx_mmlux_ro-public_relations": 0,
    "ogx_mmlux_ro-security_studies": 0,
    "ogx_mmlux_ro-sociology": 0,
    "ogx_mmlux_ro-us_foreign_policy": 0,
    "ogx_mmlux_ro-virology": 0,
    "ogx_mmlux_ro-world_religions": 0,
    "ogx_mmlux_sk-abstract_algebra": 0,
    "ogx_mmlux_sk-anatomy": 0,
    "ogx_mmlux_sk-astronomy": 0,
    "ogx_mmlux_sk-business_ethics": 0,
    "ogx_mmlux_sk-clinical_knowledge": 0,
    "ogx_mmlux_sk-college_biology": 0,
    "ogx_mmlux_sk-college_chemistry": 0,
    "ogx_mmlux_sk-college_computer_science": 0,
    "ogx_mmlux_sk-college_mathematics": 0,
    "ogx_mmlux_sk-college_medicine": 0,
    "ogx_mmlux_sk-college_physics": 0,
    "ogx_mmlux_sk-computer_security": 0,
    "ogx_mmlux_sk-conceptual_physics": 0,
    "ogx_mmlux_sk-econometrics": 0,
    "ogx_mmlux_sk-electrical_engineering": 0,
    "ogx_mmlux_sk-elementary_mathematics": 0,
    "ogx_mmlux_sk-formal_logic": 0,
    "ogx_mmlux_sk-global_facts": 0,
    "ogx_mmlux_sk-high_school_biology": 0,
    "ogx_mmlux_sk-high_school_chemistry": 0,
    "ogx_mmlux_sk-high_school_computer_science": 0,
    "ogx_mmlux_sk-high_school_european_history": 0,
    "ogx_mmlux_sk-high_school_geography": 0,
    "ogx_mmlux_sk-high_school_government_and_politics": 0,
    "ogx_mmlux_sk-high_school_macroeconomics": 0,
    "ogx_mmlux_sk-high_school_mathematics": 0,
    "ogx_mmlux_sk-high_school_microeconomics": 0,
    "ogx_mmlux_sk-high_school_physics": 0,
    "ogx_mmlux_sk-high_school_psychology": 0,
    "ogx_mmlux_sk-high_school_statistics": 0,
    "ogx_mmlux_sk-high_school_us_history": 0,
    "ogx_mmlux_sk-high_school_world_history": 0,
    "ogx_mmlux_sk-human_aging": 0,
    "ogx_mmlux_sk-human_sexuality": 0,
    "ogx_mmlux_sk-international_law": 0,
    "ogx_mmlux_sk-jurisprudence": 0,
    "ogx_mmlux_sk-logical_fallacies": 0,
    "ogx_mmlux_sk-machine_learning": 0,
    "ogx_mmlux_sk-management": 0,
    "ogx_mmlux_sk-marketing": 0,
    "ogx_mmlux_sk-medical_genetics": 0,
    "ogx_mmlux_sk-miscellaneous": 0,
    "ogx_mmlux_sk-moral_disputes": 0,
    "ogx_mmlux_sk-moral_scenarios": 0,
    "ogx_mmlux_sk-nutrition": 0,
    "ogx_mmlux_sk-philosophy": 0,
    "ogx_mmlux_sk-prehistory": 0,
    "ogx_mmlux_sk-professional_accounting": 0,
    "ogx_mmlux_sk-professional_law": 0,
    "ogx_mmlux_sk-professional_medicine": 0,
    "ogx_mmlux_sk-professional_psychology": 0,
    "ogx_mmlux_sk-public_relations": 0,
    "ogx_mmlux_sk-security_studies": 0,
    "ogx_mmlux_sk-sociology": 0,
    "ogx_mmlux_sk-us_foreign_policy": 0,
    "ogx_mmlux_sk-virology": 0,
    "ogx_mmlux_sk-world_religions": 0,
    "ogx_mmlux_sl-abstract_algebra": 0,
    "ogx_mmlux_sl-anatomy": 0,
    "ogx_mmlux_sl-astronomy": 0,
    "ogx_mmlux_sl-business_ethics": 0,
    "ogx_mmlux_sl-clinical_knowledge": 0,
    "ogx_mmlux_sl-college_biology": 0,
    "ogx_mmlux_sl-college_chemistry": 0,
    "ogx_mmlux_sl-college_computer_science": 0,
    "ogx_mmlux_sl-college_mathematics": 0,
    "ogx_mmlux_sl-college_medicine": 0,
    "ogx_mmlux_sl-college_physics": 0,
    "ogx_mmlux_sl-computer_security": 0,
    "ogx_mmlux_sl-conceptual_physics": 0,
    "ogx_mmlux_sl-econometrics": 0,
    "ogx_mmlux_sl-electrical_engineering": 0,
    "ogx_mmlux_sl-elementary_mathematics": 0,
    "ogx_mmlux_sl-formal_logic": 0,
    "ogx_mmlux_sl-global_facts": 0,
    "ogx_mmlux_sl-high_school_biology": 0,
    "ogx_mmlux_sl-high_school_chemistry": 0,
    "ogx_mmlux_sl-high_school_computer_science": 0,
    "ogx_mmlux_sl-high_school_european_history": 0,
    "ogx_mmlux_sl-high_school_geography": 0,
    "ogx_mmlux_sl-high_school_government_and_politics": 0,
    "ogx_mmlux_sl-high_school_macroeconomics": 0,
    "ogx_mmlux_sl-high_school_mathematics": 0,
    "ogx_mmlux_sl-high_school_microeconomics": 0,
    "ogx_mmlux_sl-high_school_physics": 0,
    "ogx_mmlux_sl-high_school_psychology": 0,
    "ogx_mmlux_sl-high_school_statistics": 0,
    "ogx_mmlux_sl-high_school_us_history": 0,
    "ogx_mmlux_sl-high_school_world_history": 0,
    "ogx_mmlux_sl-human_aging": 0,
    "ogx_mmlux_sl-human_sexuality": 0,
    "ogx_mmlux_sl-international_law": 0,
    "ogx_mmlux_sl-jurisprudence": 0,
    "ogx_mmlux_sl-logical_fallacies": 0,
    "ogx_mmlux_sl-machine_learning": 0,
    "ogx_mmlux_sl-management": 0,
    "ogx_mmlux_sl-marketing": 0,
    "ogx_mmlux_sl-medical_genetics": 0,
    "ogx_mmlux_sl-miscellaneous": 0,
    "ogx_mmlux_sl-moral_disputes": 0,
    "ogx_mmlux_sl-moral_scenarios": 0,
    "ogx_mmlux_sl-nutrition": 0,
    "ogx_mmlux_sl-philosophy": 0,
    "ogx_mmlux_sl-prehistory": 0,
    "ogx_mmlux_sl-professional_accounting": 0,
    "ogx_mmlux_sl-professional_law": 0,
    "ogx_mmlux_sl-professional_medicine": 0,
    "ogx_mmlux_sl-professional_psychology": 0,
    "ogx_mmlux_sl-public_relations": 0,
    "ogx_mmlux_sl-security_studies": 0,
    "ogx_mmlux_sl-sociology": 0,
    "ogx_mmlux_sl-us_foreign_policy": 0,
    "ogx_mmlux_sl-virology": 0,
    "ogx_mmlux_sl-world_religions": 0,
    "ogx_mmlux_sv-abstract_algebra": 0,
    "ogx_mmlux_sv-anatomy": 0,
    "ogx_mmlux_sv-astronomy": 0,
    "ogx_mmlux_sv-business_ethics": 0,
    "ogx_mmlux_sv-clinical_knowledge": 0,
    "ogx_mmlux_sv-college_biology": 0,
    "ogx_mmlux_sv-college_chemistry": 0,
    "ogx_mmlux_sv-college_computer_science": 0,
    "ogx_mmlux_sv-college_mathematics": 0,
    "ogx_mmlux_sv-college_medicine": 0,
    "ogx_mmlux_sv-college_physics": 0,
    "ogx_mmlux_sv-computer_security": 0,
    "ogx_mmlux_sv-conceptual_physics": 0,
    "ogx_mmlux_sv-econometrics": 0,
    "ogx_mmlux_sv-electrical_engineering": 0,
    "ogx_mmlux_sv-elementary_mathematics": 0,
    "ogx_mmlux_sv-formal_logic": 0,
    "ogx_mmlux_sv-global_facts": 0,
    "ogx_mmlux_sv-high_school_biology": 0,
    "ogx_mmlux_sv-high_school_chemistry": 0,
    "ogx_mmlux_sv-high_school_computer_science": 0,
    "ogx_mmlux_sv-high_school_european_history": 0,
    "ogx_mmlux_sv-high_school_geography": 0,
    "ogx_mmlux_sv-high_school_government_and_politics": 0,
    "ogx_mmlux_sv-high_school_macroeconomics": 0,
    "ogx_mmlux_sv-high_school_mathematics": 0,
    "ogx_mmlux_sv-high_school_microeconomics": 0,
    "ogx_mmlux_sv-high_school_physics": 0,
    "ogx_mmlux_sv-high_school_psychology": 0,
    "ogx_mmlux_sv-high_school_statistics": 0,
    "ogx_mmlux_sv-high_school_us_history": 0,
    "ogx_mmlux_sv-high_school_world_history": 0,
    "ogx_mmlux_sv-human_aging": 0,
    "ogx_mmlux_sv-human_sexuality": 0,
    "ogx_mmlux_sv-international_law": 0,
    "ogx_mmlux_sv-jurisprudence": 0,
    "ogx_mmlux_sv-logical_fallacies": 0,
    "ogx_mmlux_sv-machine_learning": 0,
    "ogx_mmlux_sv-management": 0,
    "ogx_mmlux_sv-marketing": 0,
    "ogx_mmlux_sv-medical_genetics": 0,
    "ogx_mmlux_sv-miscellaneous": 0,
    "ogx_mmlux_sv-moral_disputes": 0,
    "ogx_mmlux_sv-moral_scenarios": 0,
    "ogx_mmlux_sv-nutrition": 0,
    "ogx_mmlux_sv-philosophy": 0,
    "ogx_mmlux_sv-prehistory": 0,
    "ogx_mmlux_sv-professional_accounting": 0,
    "ogx_mmlux_sv-professional_law": 0,
    "ogx_mmlux_sv-professional_medicine": 0,
    "ogx_mmlux_sv-professional_psychology": 0,
    "ogx_mmlux_sv-public_relations": 0,
    "ogx_mmlux_sv-security_studies": 0,
    "ogx_mmlux_sv-sociology": 0,
    "ogx_mmlux_sv-us_foreign_policy": 0,
    "ogx_mmlux_sv-virology": 0,
    "ogx_mmlux_sv-world_religions": 0
  },
  "n-shot": {
    "ogx_mmlux_bg-abstract_algebra": 5,
    "ogx_mmlux_bg-anatomy": 5,
    "ogx_mmlux_bg-astronomy": 5,
    "ogx_mmlux_bg-business_ethics": 5,
    "ogx_mmlux_bg-clinical_knowledge": 5,
    "ogx_mmlux_bg-college_biology": 5,
    "ogx_mmlux_bg-college_chemistry": 5,
    "ogx_mmlux_bg-college_computer_science": 5,
    "ogx_mmlux_bg-college_mathematics": 5,
    "ogx_mmlux_bg-college_medicine": 5,
    "ogx_mmlux_bg-college_physics": 5,
    "ogx_mmlux_bg-computer_security": 5,
    "ogx_mmlux_bg-conceptual_physics": 5,
    "ogx_mmlux_bg-econometrics": 5,
    "ogx_mmlux_bg-electrical_engineering": 5,
    "ogx_mmlux_bg-elementary_mathematics": 5,
    "ogx_mmlux_bg-formal_logic": 5,
    "ogx_mmlux_bg-global_facts": 5,
    "ogx_mmlux_bg-high_school_biology": 5,
    "ogx_mmlux_bg-high_school_chemistry": 5,
    "ogx_mmlux_bg-high_school_computer_science": 5,
    "ogx_mmlux_bg-high_school_european_history": 5,
    "ogx_mmlux_bg-high_school_geography": 5,
    "ogx_mmlux_bg-high_school_government_and_politics": 5,
    "ogx_mmlux_bg-high_school_macroeconomics": 5,
    "ogx_mmlux_bg-high_school_mathematics": 5,
    "ogx_mmlux_bg-high_school_microeconomics": 5,
    "ogx_mmlux_bg-high_school_physics": 5,
    "ogx_mmlux_bg-high_school_psychology": 5,
    "ogx_mmlux_bg-high_school_statistics": 5,
    "ogx_mmlux_bg-high_school_us_history": 5,
    "ogx_mmlux_bg-high_school_world_history": 5,
    "ogx_mmlux_bg-human_aging": 5,
    "ogx_mmlux_bg-human_sexuality": 5,
    "ogx_mmlux_bg-international_law": 5,
    "ogx_mmlux_bg-jurisprudence": 5,
    "ogx_mmlux_bg-logical_fallacies": 5,
    "ogx_mmlux_bg-machine_learning": 5,
    "ogx_mmlux_bg-management": 5,
    "ogx_mmlux_bg-marketing": 5,
    "ogx_mmlux_bg-medical_genetics": 5,
    "ogx_mmlux_bg-miscellaneous": 5,
    "ogx_mmlux_bg-moral_disputes": 5,
    "ogx_mmlux_bg-moral_scenarios": 5,
    "ogx_mmlux_bg-nutrition": 5,
    "ogx_mmlux_bg-philosophy": 5,
    "ogx_mmlux_bg-prehistory": 5,
    "ogx_mmlux_bg-professional_accounting": 5,
    "ogx_mmlux_bg-professional_law": 5,
    "ogx_mmlux_bg-professional_medicine": 5,
    "ogx_mmlux_bg-professional_psychology": 5,
    "ogx_mmlux_bg-public_relations": 5,
    "ogx_mmlux_bg-security_studies": 5,
    "ogx_mmlux_bg-sociology": 5,
    "ogx_mmlux_bg-us_foreign_policy": 5,
    "ogx_mmlux_bg-virology": 5,
    "ogx_mmlux_bg-world_religions": 5,
    "ogx_mmlux_cs-abstract_algebra": 5,
    "ogx_mmlux_cs-anatomy": 5,
    "ogx_mmlux_cs-astronomy": 5,
    "ogx_mmlux_cs-business_ethics": 5,
    "ogx_mmlux_cs-clinical_knowledge": 5,
    "ogx_mmlux_cs-college_biology": 5,
    "ogx_mmlux_cs-college_chemistry": 5,
    "ogx_mmlux_cs-college_computer_science": 5,
    "ogx_mmlux_cs-college_mathematics": 5,
    "ogx_mmlux_cs-college_medicine": 5,
    "ogx_mmlux_cs-college_physics": 5,
    "ogx_mmlux_cs-computer_security": 5,
    "ogx_mmlux_cs-conceptual_physics": 5,
    "ogx_mmlux_cs-econometrics": 5,
    "ogx_mmlux_cs-electrical_engineering": 5,
    "ogx_mmlux_cs-elementary_mathematics": 5,
    "ogx_mmlux_cs-formal_logic": 5,
    "ogx_mmlux_cs-global_facts": 5,
    "ogx_mmlux_cs-high_school_biology": 5,
    "ogx_mmlux_cs-high_school_chemistry": 5,
    "ogx_mmlux_cs-high_school_computer_science": 5,
    "ogx_mmlux_cs-high_school_european_history": 5,
    "ogx_mmlux_cs-high_school_geography": 5,
    "ogx_mmlux_cs-high_school_government_and_politics": 5,
    "ogx_mmlux_cs-high_school_macroeconomics": 5,
    "ogx_mmlux_cs-high_school_mathematics": 5,
    "ogx_mmlux_cs-high_school_microeconomics": 5,
    "ogx_mmlux_cs-high_school_physics": 5,
    "ogx_mmlux_cs-high_school_psychology": 5,
    "ogx_mmlux_cs-high_school_statistics": 5,
    "ogx_mmlux_cs-high_school_us_history": 5,
    "ogx_mmlux_cs-high_school_world_history": 5,
    "ogx_mmlux_cs-human_aging": 5,
    "ogx_mmlux_cs-human_sexuality": 5,
    "ogx_mmlux_cs-international_law": 5,
    "ogx_mmlux_cs-jurisprudence": 5,
    "ogx_mmlux_cs-logical_fallacies": 5,
    "ogx_mmlux_cs-machine_learning": 5,
    "ogx_mmlux_cs-management": 5,
    "ogx_mmlux_cs-marketing": 5,
    "ogx_mmlux_cs-medical_genetics": 5,
    "ogx_mmlux_cs-miscellaneous": 5,
    "ogx_mmlux_cs-moral_disputes": 5,
    "ogx_mmlux_cs-moral_scenarios": 5,
    "ogx_mmlux_cs-nutrition": 5,
    "ogx_mmlux_cs-philosophy": 5,
    "ogx_mmlux_cs-prehistory": 5,
    "ogx_mmlux_cs-professional_accounting": 5,
    "ogx_mmlux_cs-professional_law": 5,
    "ogx_mmlux_cs-professional_medicine": 5,
    "ogx_mmlux_cs-professional_psychology": 5,
    "ogx_mmlux_cs-public_relations": 5,
    "ogx_mmlux_cs-security_studies": 5,
    "ogx_mmlux_cs-sociology": 5,
    "ogx_mmlux_cs-us_foreign_policy": 5,
    "ogx_mmlux_cs-virology": 5,
    "ogx_mmlux_cs-world_religions": 5,
    "ogx_mmlux_da-abstract_algebra": 5,
    "ogx_mmlux_da-anatomy": 5,
    "ogx_mmlux_da-astronomy": 5,
    "ogx_mmlux_da-business_ethics": 5,
    "ogx_mmlux_da-clinical_knowledge": 5,
    "ogx_mmlux_da-college_biology": 5,
    "ogx_mmlux_da-college_chemistry": 5,
    "ogx_mmlux_da-college_computer_science": 5,
    "ogx_mmlux_da-college_mathematics": 5,
    "ogx_mmlux_da-college_medicine": 5,
    "ogx_mmlux_da-college_physics": 5,
    "ogx_mmlux_da-computer_security": 5,
    "ogx_mmlux_da-conceptual_physics": 5,
    "ogx_mmlux_da-econometrics": 5,
    "ogx_mmlux_da-electrical_engineering": 5,
    "ogx_mmlux_da-elementary_mathematics": 5,
    "ogx_mmlux_da-formal_logic": 5,
    "ogx_mmlux_da-global_facts": 5,
    "ogx_mmlux_da-high_school_biology": 5,
    "ogx_mmlux_da-high_school_chemistry": 5,
    "ogx_mmlux_da-high_school_computer_science": 5,
    "ogx_mmlux_da-high_school_european_history": 5,
    "ogx_mmlux_da-high_school_geography": 5,
    "ogx_mmlux_da-high_school_government_and_politics": 5,
    "ogx_mmlux_da-high_school_macroeconomics": 5,
    "ogx_mmlux_da-high_school_mathematics": 5,
    "ogx_mmlux_da-high_school_microeconomics": 5,
    "ogx_mmlux_da-high_school_physics": 5,
    "ogx_mmlux_da-high_school_psychology": 5,
    "ogx_mmlux_da-high_school_statistics": 5,
    "ogx_mmlux_da-high_school_us_history": 5,
    "ogx_mmlux_da-high_school_world_history": 5,
    "ogx_mmlux_da-human_aging": 5,
    "ogx_mmlux_da-human_sexuality": 5,
    "ogx_mmlux_da-international_law": 5,
    "ogx_mmlux_da-jurisprudence": 5,
    "ogx_mmlux_da-logical_fallacies": 5,
    "ogx_mmlux_da-machine_learning": 5,
    "ogx_mmlux_da-management": 5,
    "ogx_mmlux_da-marketing": 5,
    "ogx_mmlux_da-medical_genetics": 5,
    "ogx_mmlux_da-miscellaneous": 5,
    "ogx_mmlux_da-moral_disputes": 5,
    "ogx_mmlux_da-moral_scenarios": 5,
    "ogx_mmlux_da-nutrition": 5,
    "ogx_mmlux_da-philosophy": 5,
    "ogx_mmlux_da-prehistory": 5,
    "ogx_mmlux_da-professional_accounting": 5,
    "ogx_mmlux_da-professional_law": 5,
    "ogx_mmlux_da-professional_medicine": 5,
    "ogx_mmlux_da-professional_psychology": 5,
    "ogx_mmlux_da-public_relations": 5,
    "ogx_mmlux_da-security_studies": 5,
    "ogx_mmlux_da-sociology": 5,
    "ogx_mmlux_da-us_foreign_policy": 5,
    "ogx_mmlux_da-virology": 5,
    "ogx_mmlux_da-world_religions": 5,
    "ogx_mmlux_de-abstract_algebra": 5,
    "ogx_mmlux_de-anatomy": 5,
    "ogx_mmlux_de-astronomy": 5,
    "ogx_mmlux_de-business_ethics": 5,
    "ogx_mmlux_de-clinical_knowledge": 5,
    "ogx_mmlux_de-college_biology": 5,
    "ogx_mmlux_de-college_chemistry": 5,
    "ogx_mmlux_de-college_computer_science": 5,
    "ogx_mmlux_de-college_mathematics": 5,
    "ogx_mmlux_de-college_medicine": 5,
    "ogx_mmlux_de-college_physics": 5,
    "ogx_mmlux_de-computer_security": 5,
    "ogx_mmlux_de-conceptual_physics": 5,
    "ogx_mmlux_de-econometrics": 5,
    "ogx_mmlux_de-electrical_engineering": 5,
    "ogx_mmlux_de-elementary_mathematics": 5,
    "ogx_mmlux_de-formal_logic": 5,
    "ogx_mmlux_de-global_facts": 5,
    "ogx_mmlux_de-high_school_biology": 5,
    "ogx_mmlux_de-high_school_chemistry": 5,
    "ogx_mmlux_de-high_school_computer_science": 5,
    "ogx_mmlux_de-high_school_european_history": 5,
    "ogx_mmlux_de-high_school_geography": 5,
    "ogx_mmlux_de-high_school_government_and_politics": 5,
    "ogx_mmlux_de-high_school_macroeconomics": 5,
    "ogx_mmlux_de-high_school_mathematics": 5,
    "ogx_mmlux_de-high_school_microeconomics": 5,
    "ogx_mmlux_de-high_school_physics": 5,
    "ogx_mmlux_de-high_school_psychology": 5,
    "ogx_mmlux_de-high_school_statistics": 5,
    "ogx_mmlux_de-high_school_us_history": 5,
    "ogx_mmlux_de-high_school_world_history": 5,
    "ogx_mmlux_de-human_aging": 5,
    "ogx_mmlux_de-human_sexuality": 5,
    "ogx_mmlux_de-international_law": 5,
    "ogx_mmlux_de-jurisprudence": 5,
    "ogx_mmlux_de-logical_fallacies": 5,
    "ogx_mmlux_de-machine_learning": 5,
    "ogx_mmlux_de-management": 5,
    "ogx_mmlux_de-marketing": 5,
    "ogx_mmlux_de-medical_genetics": 5,
    "ogx_mmlux_de-miscellaneous": 5,
    "ogx_mmlux_de-moral_disputes": 5,
    "ogx_mmlux_de-moral_scenarios": 5,
    "ogx_mmlux_de-nutrition": 5,
    "ogx_mmlux_de-philosophy": 5,
    "ogx_mmlux_de-prehistory": 5,
    "ogx_mmlux_de-professional_accounting": 5,
    "ogx_mmlux_de-professional_law": 5,
    "ogx_mmlux_de-professional_medicine": 5,
    "ogx_mmlux_de-professional_psychology": 5,
    "ogx_mmlux_de-public_relations": 5,
    "ogx_mmlux_de-security_studies": 5,
    "ogx_mmlux_de-sociology": 5,
    "ogx_mmlux_de-us_foreign_policy": 5,
    "ogx_mmlux_de-virology": 5,
    "ogx_mmlux_de-world_religions": 5,
    "ogx_mmlux_el-abstract_algebra": 5,
    "ogx_mmlux_el-anatomy": 5,
    "ogx_mmlux_el-astronomy": 5,
    "ogx_mmlux_el-business_ethics": 5,
    "ogx_mmlux_el-clinical_knowledge": 5,
    "ogx_mmlux_el-college_biology": 5,
    "ogx_mmlux_el-college_chemistry": 5,
    "ogx_mmlux_el-college_computer_science": 5,
    "ogx_mmlux_el-college_mathematics": 5,
    "ogx_mmlux_el-college_medicine": 5,
    "ogx_mmlux_el-college_physics": 5,
    "ogx_mmlux_el-computer_security": 5,
    "ogx_mmlux_el-conceptual_physics": 5,
    "ogx_mmlux_el-econometrics": 5,
    "ogx_mmlux_el-electrical_engineering": 5,
    "ogx_mmlux_el-elementary_mathematics": 5,
    "ogx_mmlux_el-formal_logic": 5,
    "ogx_mmlux_el-global_facts": 5,
    "ogx_mmlux_el-high_school_biology": 5,
    "ogx_mmlux_el-high_school_chemistry": 5,
    "ogx_mmlux_el-high_school_computer_science": 5,
    "ogx_mmlux_el-high_school_european_history": 5,
    "ogx_mmlux_el-high_school_geography": 5,
    "ogx_mmlux_el-high_school_government_and_politics": 5,
    "ogx_mmlux_el-high_school_macroeconomics": 5,
    "ogx_mmlux_el-high_school_mathematics": 5,
    "ogx_mmlux_el-high_school_microeconomics": 5,
    "ogx_mmlux_el-high_school_physics": 5,
    "ogx_mmlux_el-high_school_psychology": 5,
    "ogx_mmlux_el-high_school_statistics": 5,
    "ogx_mmlux_el-high_school_us_history": 5,
    "ogx_mmlux_el-high_school_world_history": 5,
    "ogx_mmlux_el-human_aging": 5,
    "ogx_mmlux_el-human_sexuality": 5,
    "ogx_mmlux_el-international_law": 5,
    "ogx_mmlux_el-jurisprudence": 5,
    "ogx_mmlux_el-logical_fallacies": 5,
    "ogx_mmlux_el-machine_learning": 5,
    "ogx_mmlux_el-management": 5,
    "ogx_mmlux_el-marketing": 5,
    "ogx_mmlux_el-medical_genetics": 5,
    "ogx_mmlux_el-miscellaneous": 5,
    "ogx_mmlux_el-moral_disputes": 5,
    "ogx_mmlux_el-moral_scenarios": 5,
    "ogx_mmlux_el-nutrition": 5,
    "ogx_mmlux_el-philosophy": 5,
    "ogx_mmlux_el-prehistory": 5,
    "ogx_mmlux_el-professional_accounting": 5,
    "ogx_mmlux_el-professional_law": 5,
    "ogx_mmlux_el-professional_medicine": 5,
    "ogx_mmlux_el-professional_psychology": 5,
    "ogx_mmlux_el-public_relations": 5,
    "ogx_mmlux_el-security_studies": 5,
    "ogx_mmlux_el-sociology": 5,
    "ogx_mmlux_el-us_foreign_policy": 5,
    "ogx_mmlux_el-virology": 5,
    "ogx_mmlux_el-world_religions": 5,
    "ogx_mmlux_es-abstract_algebra": 5,
    "ogx_mmlux_es-anatomy": 5,
    "ogx_mmlux_es-astronomy": 5,
    "ogx_mmlux_es-business_ethics": 5,
    "ogx_mmlux_es-clinical_knowledge": 5,
    "ogx_mmlux_es-college_biology": 5,
    "ogx_mmlux_es-college_chemistry": 5,
    "ogx_mmlux_es-college_computer_science": 5,
    "ogx_mmlux_es-college_mathematics": 5,
    "ogx_mmlux_es-college_medicine": 5,
    "ogx_mmlux_es-college_physics": 5,
    "ogx_mmlux_es-computer_security": 5,
    "ogx_mmlux_es-conceptual_physics": 5,
    "ogx_mmlux_es-econometrics": 5,
    "ogx_mmlux_es-electrical_engineering": 5,
    "ogx_mmlux_es-elementary_mathematics": 5,
    "ogx_mmlux_es-formal_logic": 5,
    "ogx_mmlux_es-global_facts": 5,
    "ogx_mmlux_es-high_school_biology": 5,
    "ogx_mmlux_es-high_school_chemistry": 5,
    "ogx_mmlux_es-high_school_computer_science": 5,
    "ogx_mmlux_es-high_school_european_history": 5,
    "ogx_mmlux_es-high_school_geography": 5,
    "ogx_mmlux_es-high_school_government_and_politics": 5,
    "ogx_mmlux_es-high_school_macroeconomics": 5,
    "ogx_mmlux_es-high_school_mathematics": 5,
    "ogx_mmlux_es-high_school_microeconomics": 5,
    "ogx_mmlux_es-high_school_physics": 5,
    "ogx_mmlux_es-high_school_psychology": 5,
    "ogx_mmlux_es-high_school_statistics": 5,
    "ogx_mmlux_es-high_school_us_history": 5,
    "ogx_mmlux_es-high_school_world_history": 5,
    "ogx_mmlux_es-human_aging": 5,
    "ogx_mmlux_es-human_sexuality": 5,
    "ogx_mmlux_es-international_law": 5,
    "ogx_mmlux_es-jurisprudence": 5,
    "ogx_mmlux_es-logical_fallacies": 5,
    "ogx_mmlux_es-machine_learning": 5,
    "ogx_mmlux_es-management": 5,
    "ogx_mmlux_es-marketing": 5,
    "ogx_mmlux_es-medical_genetics": 5,
    "ogx_mmlux_es-miscellaneous": 5,
    "ogx_mmlux_es-moral_disputes": 5,
    "ogx_mmlux_es-moral_scenarios": 5,
    "ogx_mmlux_es-nutrition": 5,
    "ogx_mmlux_es-philosophy": 5,
    "ogx_mmlux_es-prehistory": 5,
    "ogx_mmlux_es-professional_accounting": 5,
    "ogx_mmlux_es-professional_law": 5,
    "ogx_mmlux_es-professional_medicine": 5,
    "ogx_mmlux_es-professional_psychology": 5,
    "ogx_mmlux_es-public_relations": 5,
    "ogx_mmlux_es-security_studies": 5,
    "ogx_mmlux_es-sociology": 5,
    "ogx_mmlux_es-us_foreign_policy": 5,
    "ogx_mmlux_es-virology": 5,
    "ogx_mmlux_es-world_religions": 5,
    "ogx_mmlux_et-abstract_algebra": 5,
    "ogx_mmlux_et-anatomy": 5,
    "ogx_mmlux_et-astronomy": 5,
    "ogx_mmlux_et-business_ethics": 5,
    "ogx_mmlux_et-clinical_knowledge": 5,
    "ogx_mmlux_et-college_biology": 5,
    "ogx_mmlux_et-college_chemistry": 5,
    "ogx_mmlux_et-college_computer_science": 5,
    "ogx_mmlux_et-college_mathematics": 5,
    "ogx_mmlux_et-college_medicine": 5,
    "ogx_mmlux_et-college_physics": 5,
    "ogx_mmlux_et-computer_security": 5,
    "ogx_mmlux_et-conceptual_physics": 5,
    "ogx_mmlux_et-econometrics": 5,
    "ogx_mmlux_et-electrical_engineering": 5,
    "ogx_mmlux_et-elementary_mathematics": 5,
    "ogx_mmlux_et-formal_logic": 5,
    "ogx_mmlux_et-global_facts": 5,
    "ogx_mmlux_et-high_school_biology": 5,
    "ogx_mmlux_et-high_school_chemistry": 5,
    "ogx_mmlux_et-high_school_computer_science": 5,
    "ogx_mmlux_et-high_school_european_history": 5,
    "ogx_mmlux_et-high_school_geography": 5,
    "ogx_mmlux_et-high_school_government_and_politics": 5,
    "ogx_mmlux_et-high_school_macroeconomics": 5,
    "ogx_mmlux_et-high_school_mathematics": 5,
    "ogx_mmlux_et-high_school_microeconomics": 5,
    "ogx_mmlux_et-high_school_physics": 5,
    "ogx_mmlux_et-high_school_psychology": 5,
    "ogx_mmlux_et-high_school_statistics": 5,
    "ogx_mmlux_et-high_school_us_history": 5,
    "ogx_mmlux_et-high_school_world_history": 5,
    "ogx_mmlux_et-human_aging": 5,
    "ogx_mmlux_et-human_sexuality": 5,
    "ogx_mmlux_et-international_law": 5,
    "ogx_mmlux_et-jurisprudence": 5,
    "ogx_mmlux_et-logical_fallacies": 5,
    "ogx_mmlux_et-machine_learning": 5,
    "ogx_mmlux_et-management": 5,
    "ogx_mmlux_et-marketing": 5,
    "ogx_mmlux_et-medical_genetics": 5,
    "ogx_mmlux_et-miscellaneous": 5,
    "ogx_mmlux_et-moral_disputes": 5,
    "ogx_mmlux_et-moral_scenarios": 5,
    "ogx_mmlux_et-nutrition": 5,
    "ogx_mmlux_et-philosophy": 5,
    "ogx_mmlux_et-prehistory": 5,
    "ogx_mmlux_et-professional_accounting": 5,
    "ogx_mmlux_et-professional_law": 5,
    "ogx_mmlux_et-professional_medicine": 5,
    "ogx_mmlux_et-professional_psychology": 5,
    "ogx_mmlux_et-public_relations": 5,
    "ogx_mmlux_et-security_studies": 5,
    "ogx_mmlux_et-sociology": 5,
    "ogx_mmlux_et-us_foreign_policy": 5,
    "ogx_mmlux_et-virology": 5,
    "ogx_mmlux_et-world_religions": 5,
    "ogx_mmlux_fi-abstract_algebra": 5,
    "ogx_mmlux_fi-anatomy": 5,
    "ogx_mmlux_fi-astronomy": 5,
    "ogx_mmlux_fi-business_ethics": 5,
    "ogx_mmlux_fi-clinical_knowledge": 5,
    "ogx_mmlux_fi-college_biology": 5,
    "ogx_mmlux_fi-college_chemistry": 5,
    "ogx_mmlux_fi-college_computer_science": 5,
    "ogx_mmlux_fi-college_mathematics": 5,
    "ogx_mmlux_fi-college_medicine": 5,
    "ogx_mmlux_fi-college_physics": 5,
    "ogx_mmlux_fi-computer_security": 5,
    "ogx_mmlux_fi-conceptual_physics": 5,
    "ogx_mmlux_fi-econometrics": 5,
    "ogx_mmlux_fi-electrical_engineering": 5,
    "ogx_mmlux_fi-elementary_mathematics": 5,
    "ogx_mmlux_fi-formal_logic": 5,
    "ogx_mmlux_fi-global_facts": 5,
    "ogx_mmlux_fi-high_school_biology": 5,
    "ogx_mmlux_fi-high_school_chemistry": 5,
    "ogx_mmlux_fi-high_school_computer_science": 5,
    "ogx_mmlux_fi-high_school_european_history": 5,
    "ogx_mmlux_fi-high_school_geography": 5,
    "ogx_mmlux_fi-high_school_government_and_politics": 5,
    "ogx_mmlux_fi-high_school_macroeconomics": 5,
    "ogx_mmlux_fi-high_school_mathematics": 5,
    "ogx_mmlux_fi-high_school_microeconomics": 5,
    "ogx_mmlux_fi-high_school_physics": 5,
    "ogx_mmlux_fi-high_school_psychology": 5,
    "ogx_mmlux_fi-high_school_statistics": 5,
    "ogx_mmlux_fi-high_school_us_history": 5,
    "ogx_mmlux_fi-high_school_world_history": 5,
    "ogx_mmlux_fi-human_aging": 5,
    "ogx_mmlux_fi-human_sexuality": 5,
    "ogx_mmlux_fi-international_law": 5,
    "ogx_mmlux_fi-jurisprudence": 5,
    "ogx_mmlux_fi-logical_fallacies": 5,
    "ogx_mmlux_fi-machine_learning": 5,
    "ogx_mmlux_fi-management": 5,
    "ogx_mmlux_fi-marketing": 5,
    "ogx_mmlux_fi-medical_genetics": 5,
    "ogx_mmlux_fi-miscellaneous": 5,
    "ogx_mmlux_fi-moral_disputes": 5,
    "ogx_mmlux_fi-moral_scenarios": 5,
    "ogx_mmlux_fi-nutrition": 5,
    "ogx_mmlux_fi-philosophy": 5,
    "ogx_mmlux_fi-prehistory": 5,
    "ogx_mmlux_fi-professional_accounting": 5,
    "ogx_mmlux_fi-professional_law": 5,
    "ogx_mmlux_fi-professional_medicine": 5,
    "ogx_mmlux_fi-professional_psychology": 5,
    "ogx_mmlux_fi-public_relations": 5,
    "ogx_mmlux_fi-security_studies": 5,
    "ogx_mmlux_fi-sociology": 5,
    "ogx_mmlux_fi-us_foreign_policy": 5,
    "ogx_mmlux_fi-virology": 5,
    "ogx_mmlux_fi-world_religions": 5,
    "ogx_mmlux_fr-abstract_algebra": 5,
    "ogx_mmlux_fr-anatomy": 5,
    "ogx_mmlux_fr-astronomy": 5,
    "ogx_mmlux_fr-business_ethics": 5,
    "ogx_mmlux_fr-clinical_knowledge": 5,
    "ogx_mmlux_fr-college_biology": 5,
    "ogx_mmlux_fr-college_chemistry": 5,
    "ogx_mmlux_fr-college_computer_science": 5,
    "ogx_mmlux_fr-college_mathematics": 5,
    "ogx_mmlux_fr-college_medicine": 5,
    "ogx_mmlux_fr-college_physics": 5,
    "ogx_mmlux_fr-computer_security": 5,
    "ogx_mmlux_fr-conceptual_physics": 5,
    "ogx_mmlux_fr-econometrics": 5,
    "ogx_mmlux_fr-electrical_engineering": 5,
    "ogx_mmlux_fr-elementary_mathematics": 5,
    "ogx_mmlux_fr-formal_logic": 5,
    "ogx_mmlux_fr-global_facts": 5,
    "ogx_mmlux_fr-high_school_biology": 5,
    "ogx_mmlux_fr-high_school_chemistry": 5,
    "ogx_mmlux_fr-high_school_computer_science": 5,
    "ogx_mmlux_fr-high_school_european_history": 5,
    "ogx_mmlux_fr-high_school_geography": 5,
    "ogx_mmlux_fr-high_school_government_and_politics": 5,
    "ogx_mmlux_fr-high_school_macroeconomics": 5,
    "ogx_mmlux_fr-high_school_mathematics": 5,
    "ogx_mmlux_fr-high_school_microeconomics": 5,
    "ogx_mmlux_fr-high_school_physics": 5,
    "ogx_mmlux_fr-high_school_psychology": 5,
    "ogx_mmlux_fr-high_school_statistics": 5,
    "ogx_mmlux_fr-high_school_us_history": 5,
    "ogx_mmlux_fr-high_school_world_history": 5,
    "ogx_mmlux_fr-human_aging": 5,
    "ogx_mmlux_fr-human_sexuality": 5,
    "ogx_mmlux_fr-international_law": 5,
    "ogx_mmlux_fr-jurisprudence": 5,
    "ogx_mmlux_fr-logical_fallacies": 5,
    "ogx_mmlux_fr-machine_learning": 5,
    "ogx_mmlux_fr-management": 5,
    "ogx_mmlux_fr-marketing": 5,
    "ogx_mmlux_fr-medical_genetics": 5,
    "ogx_mmlux_fr-miscellaneous": 5,
    "ogx_mmlux_fr-moral_disputes": 5,
    "ogx_mmlux_fr-moral_scenarios": 5,
    "ogx_mmlux_fr-nutrition": 5,
    "ogx_mmlux_fr-philosophy": 5,
    "ogx_mmlux_fr-prehistory": 5,
    "ogx_mmlux_fr-professional_accounting": 5,
    "ogx_mmlux_fr-professional_law": 5,
    "ogx_mmlux_fr-professional_medicine": 5,
    "ogx_mmlux_fr-professional_psychology": 5,
    "ogx_mmlux_fr-public_relations": 5,
    "ogx_mmlux_fr-security_studies": 5,
    "ogx_mmlux_fr-sociology": 5,
    "ogx_mmlux_fr-us_foreign_policy": 5,
    "ogx_mmlux_fr-virology": 5,
    "ogx_mmlux_fr-world_religions": 5,
    "ogx_mmlux_hu-abstract_algebra": 5,
    "ogx_mmlux_hu-anatomy": 5,
    "ogx_mmlux_hu-astronomy": 5,
    "ogx_mmlux_hu-business_ethics": 5,
    "ogx_mmlux_hu-clinical_knowledge": 5,
    "ogx_mmlux_hu-college_biology": 5,
    "ogx_mmlux_hu-college_chemistry": 5,
    "ogx_mmlux_hu-college_computer_science": 5,
    "ogx_mmlux_hu-college_mathematics": 5,
    "ogx_mmlux_hu-college_medicine": 5,
    "ogx_mmlux_hu-college_physics": 5,
    "ogx_mmlux_hu-computer_security": 5,
    "ogx_mmlux_hu-conceptual_physics": 5,
    "ogx_mmlux_hu-econometrics": 5,
    "ogx_mmlux_hu-electrical_engineering": 5,
    "ogx_mmlux_hu-elementary_mathematics": 5,
    "ogx_mmlux_hu-formal_logic": 5,
    "ogx_mmlux_hu-global_facts": 5,
    "ogx_mmlux_hu-high_school_biology": 5,
    "ogx_mmlux_hu-high_school_chemistry": 5,
    "ogx_mmlux_hu-high_school_computer_science": 5,
    "ogx_mmlux_hu-high_school_european_history": 5,
    "ogx_mmlux_hu-high_school_geography": 5,
    "ogx_mmlux_hu-high_school_government_and_politics": 5,
    "ogx_mmlux_hu-high_school_macroeconomics": 5,
    "ogx_mmlux_hu-high_school_mathematics": 5,
    "ogx_mmlux_hu-high_school_microeconomics": 5,
    "ogx_mmlux_hu-high_school_physics": 5,
    "ogx_mmlux_hu-high_school_psychology": 5,
    "ogx_mmlux_hu-high_school_statistics": 5,
    "ogx_mmlux_hu-high_school_us_history": 5,
    "ogx_mmlux_hu-high_school_world_history": 5,
    "ogx_mmlux_hu-human_aging": 5,
    "ogx_mmlux_hu-human_sexuality": 5,
    "ogx_mmlux_hu-international_law": 5,
    "ogx_mmlux_hu-jurisprudence": 5,
    "ogx_mmlux_hu-logical_fallacies": 5,
    "ogx_mmlux_hu-machine_learning": 5,
    "ogx_mmlux_hu-management": 5,
    "ogx_mmlux_hu-marketing": 5,
    "ogx_mmlux_hu-medical_genetics": 5,
    "ogx_mmlux_hu-miscellaneous": 5,
    "ogx_mmlux_hu-moral_disputes": 5,
    "ogx_mmlux_hu-moral_scenarios": 5,
    "ogx_mmlux_hu-nutrition": 5,
    "ogx_mmlux_hu-philosophy": 5,
    "ogx_mmlux_hu-prehistory": 5,
    "ogx_mmlux_hu-professional_accounting": 5,
    "ogx_mmlux_hu-professional_law": 5,
    "ogx_mmlux_hu-professional_medicine": 5,
    "ogx_mmlux_hu-professional_psychology": 5,
    "ogx_mmlux_hu-public_relations": 5,
    "ogx_mmlux_hu-security_studies": 5,
    "ogx_mmlux_hu-sociology": 5,
    "ogx_mmlux_hu-us_foreign_policy": 5,
    "ogx_mmlux_hu-virology": 5,
    "ogx_mmlux_hu-world_religions": 5,
    "ogx_mmlux_it-abstract_algebra": 5,
    "ogx_mmlux_it-anatomy": 5,
    "ogx_mmlux_it-astronomy": 5,
    "ogx_mmlux_it-business_ethics": 5,
    "ogx_mmlux_it-clinical_knowledge": 5,
    "ogx_mmlux_it-college_biology": 5,
    "ogx_mmlux_it-college_chemistry": 5,
    "ogx_mmlux_it-college_computer_science": 5,
    "ogx_mmlux_it-college_mathematics": 5,
    "ogx_mmlux_it-college_medicine": 5,
    "ogx_mmlux_it-college_physics": 5,
    "ogx_mmlux_it-computer_security": 5,
    "ogx_mmlux_it-conceptual_physics": 5,
    "ogx_mmlux_it-econometrics": 5,
    "ogx_mmlux_it-electrical_engineering": 5,
    "ogx_mmlux_it-elementary_mathematics": 5,
    "ogx_mmlux_it-formal_logic": 5,
    "ogx_mmlux_it-global_facts": 5,
    "ogx_mmlux_it-high_school_biology": 5,
    "ogx_mmlux_it-high_school_chemistry": 5,
    "ogx_mmlux_it-high_school_computer_science": 5,
    "ogx_mmlux_it-high_school_european_history": 5,
    "ogx_mmlux_it-high_school_geography": 5,
    "ogx_mmlux_it-high_school_government_and_politics": 5,
    "ogx_mmlux_it-high_school_macroeconomics": 5,
    "ogx_mmlux_it-high_school_mathematics": 5,
    "ogx_mmlux_it-high_school_microeconomics": 5,
    "ogx_mmlux_it-high_school_physics": 5,
    "ogx_mmlux_it-high_school_psychology": 5,
    "ogx_mmlux_it-high_school_statistics": 5,
    "ogx_mmlux_it-high_school_us_history": 5,
    "ogx_mmlux_it-high_school_world_history": 5,
    "ogx_mmlux_it-human_aging": 5,
    "ogx_mmlux_it-human_sexuality": 5,
    "ogx_mmlux_it-international_law": 5,
    "ogx_mmlux_it-jurisprudence": 5,
    "ogx_mmlux_it-logical_fallacies": 5,
    "ogx_mmlux_it-machine_learning": 5,
    "ogx_mmlux_it-management": 5,
    "ogx_mmlux_it-marketing": 5,
    "ogx_mmlux_it-medical_genetics": 5,
    "ogx_mmlux_it-miscellaneous": 5,
    "ogx_mmlux_it-moral_disputes": 5,
    "ogx_mmlux_it-moral_scenarios": 5,
    "ogx_mmlux_it-nutrition": 5,
    "ogx_mmlux_it-philosophy": 5,
    "ogx_mmlux_it-prehistory": 5,
    "ogx_mmlux_it-professional_accounting": 5,
    "ogx_mmlux_it-professional_law": 5,
    "ogx_mmlux_it-professional_medicine": 5,
    "ogx_mmlux_it-professional_psychology": 5,
    "ogx_mmlux_it-public_relations": 5,
    "ogx_mmlux_it-security_studies": 5,
    "ogx_mmlux_it-sociology": 5,
    "ogx_mmlux_it-us_foreign_policy": 5,
    "ogx_mmlux_it-virology": 5,
    "ogx_mmlux_it-world_religions": 5,
    "ogx_mmlux_lt-abstract_algebra": 5,
    "ogx_mmlux_lt-anatomy": 5,
    "ogx_mmlux_lt-astronomy": 5,
    "ogx_mmlux_lt-business_ethics": 5,
    "ogx_mmlux_lt-clinical_knowledge": 5,
    "ogx_mmlux_lt-college_biology": 5,
    "ogx_mmlux_lt-college_chemistry": 5,
    "ogx_mmlux_lt-college_computer_science": 5,
    "ogx_mmlux_lt-college_mathematics": 5,
    "ogx_mmlux_lt-college_medicine": 5,
    "ogx_mmlux_lt-college_physics": 5,
    "ogx_mmlux_lt-computer_security": 5,
    "ogx_mmlux_lt-conceptual_physics": 5,
    "ogx_mmlux_lt-econometrics": 5,
    "ogx_mmlux_lt-electrical_engineering": 5,
    "ogx_mmlux_lt-elementary_mathematics": 5,
    "ogx_mmlux_lt-formal_logic": 5,
    "ogx_mmlux_lt-global_facts": 5,
    "ogx_mmlux_lt-high_school_biology": 5,
    "ogx_mmlux_lt-high_school_chemistry": 5,
    "ogx_mmlux_lt-high_school_computer_science": 5,
    "ogx_mmlux_lt-high_school_european_history": 5,
    "ogx_mmlux_lt-high_school_geography": 5,
    "ogx_mmlux_lt-high_school_government_and_politics": 5,
    "ogx_mmlux_lt-high_school_macroeconomics": 5,
    "ogx_mmlux_lt-high_school_mathematics": 5,
    "ogx_mmlux_lt-high_school_microeconomics": 5,
    "ogx_mmlux_lt-high_school_physics": 5,
    "ogx_mmlux_lt-high_school_psychology": 5,
    "ogx_mmlux_lt-high_school_statistics": 5,
    "ogx_mmlux_lt-high_school_us_history": 5,
    "ogx_mmlux_lt-high_school_world_history": 5,
    "ogx_mmlux_lt-human_aging": 5,
    "ogx_mmlux_lt-human_sexuality": 5,
    "ogx_mmlux_lt-international_law": 5,
    "ogx_mmlux_lt-jurisprudence": 5,
    "ogx_mmlux_lt-logical_fallacies": 5,
    "ogx_mmlux_lt-machine_learning": 5,
    "ogx_mmlux_lt-management": 5,
    "ogx_mmlux_lt-marketing": 5,
    "ogx_mmlux_lt-medical_genetics": 5,
    "ogx_mmlux_lt-miscellaneous": 5,
    "ogx_mmlux_lt-moral_disputes": 5,
    "ogx_mmlux_lt-moral_scenarios": 5,
    "ogx_mmlux_lt-nutrition": 5,
    "ogx_mmlux_lt-philosophy": 5,
    "ogx_mmlux_lt-prehistory": 5,
    "ogx_mmlux_lt-professional_accounting": 5,
    "ogx_mmlux_lt-professional_law": 5,
    "ogx_mmlux_lt-professional_medicine": 5,
    "ogx_mmlux_lt-professional_psychology": 5,
    "ogx_mmlux_lt-public_relations": 5,
    "ogx_mmlux_lt-security_studies": 5,
    "ogx_mmlux_lt-sociology": 5,
    "ogx_mmlux_lt-us_foreign_policy": 5,
    "ogx_mmlux_lt-virology": 5,
    "ogx_mmlux_lt-world_religions": 5,
    "ogx_mmlux_lv-abstract_algebra": 5,
    "ogx_mmlux_lv-anatomy": 5,
    "ogx_mmlux_lv-astronomy": 5,
    "ogx_mmlux_lv-business_ethics": 5,
    "ogx_mmlux_lv-clinical_knowledge": 5,
    "ogx_mmlux_lv-college_biology": 5,
    "ogx_mmlux_lv-college_chemistry": 5,
    "ogx_mmlux_lv-college_computer_science": 5,
    "ogx_mmlux_lv-college_mathematics": 5,
    "ogx_mmlux_lv-college_medicine": 5,
    "ogx_mmlux_lv-college_physics": 5,
    "ogx_mmlux_lv-computer_security": 5,
    "ogx_mmlux_lv-conceptual_physics": 5,
    "ogx_mmlux_lv-econometrics": 5,
    "ogx_mmlux_lv-electrical_engineering": 5,
    "ogx_mmlux_lv-elementary_mathematics": 5,
    "ogx_mmlux_lv-formal_logic": 5,
    "ogx_mmlux_lv-global_facts": 5,
    "ogx_mmlux_lv-high_school_biology": 5,
    "ogx_mmlux_lv-high_school_chemistry": 5,
    "ogx_mmlux_lv-high_school_computer_science": 5,
    "ogx_mmlux_lv-high_school_european_history": 5,
    "ogx_mmlux_lv-high_school_geography": 5,
    "ogx_mmlux_lv-high_school_government_and_politics": 5,
    "ogx_mmlux_lv-high_school_macroeconomics": 5,
    "ogx_mmlux_lv-high_school_mathematics": 5,
    "ogx_mmlux_lv-high_school_microeconomics": 5,
    "ogx_mmlux_lv-high_school_physics": 5,
    "ogx_mmlux_lv-high_school_psychology": 5,
    "ogx_mmlux_lv-high_school_statistics": 5,
    "ogx_mmlux_lv-high_school_us_history": 5,
    "ogx_mmlux_lv-high_school_world_history": 5,
    "ogx_mmlux_lv-human_aging": 5,
    "ogx_mmlux_lv-human_sexuality": 5,
    "ogx_mmlux_lv-international_law": 5,
    "ogx_mmlux_lv-jurisprudence": 5,
    "ogx_mmlux_lv-logical_fallacies": 5,
    "ogx_mmlux_lv-machine_learning": 5,
    "ogx_mmlux_lv-management": 5,
    "ogx_mmlux_lv-marketing": 5,
    "ogx_mmlux_lv-medical_genetics": 5,
    "ogx_mmlux_lv-miscellaneous": 5,
    "ogx_mmlux_lv-moral_disputes": 5,
    "ogx_mmlux_lv-moral_scenarios": 5,
    "ogx_mmlux_lv-nutrition": 5,
    "ogx_mmlux_lv-philosophy": 5,
    "ogx_mmlux_lv-prehistory": 5,
    "ogx_mmlux_lv-professional_accounting": 5,
    "ogx_mmlux_lv-professional_law": 5,
    "ogx_mmlux_lv-professional_medicine": 5,
    "ogx_mmlux_lv-professional_psychology": 5,
    "ogx_mmlux_lv-public_relations": 5,
    "ogx_mmlux_lv-security_studies": 5,
    "ogx_mmlux_lv-sociology": 5,
    "ogx_mmlux_lv-us_foreign_policy": 5,
    "ogx_mmlux_lv-virology": 5,
    "ogx_mmlux_lv-world_religions": 5,
    "ogx_mmlux_nl-abstract_algebra": 5,
    "ogx_mmlux_nl-anatomy": 5,
    "ogx_mmlux_nl-astronomy": 5,
    "ogx_mmlux_nl-business_ethics": 5,
    "ogx_mmlux_nl-clinical_knowledge": 5,
    "ogx_mmlux_nl-college_biology": 5,
    "ogx_mmlux_nl-college_chemistry": 5,
    "ogx_mmlux_nl-college_computer_science": 5,
    "ogx_mmlux_nl-college_mathematics": 5,
    "ogx_mmlux_nl-college_medicine": 5,
    "ogx_mmlux_nl-college_physics": 5,
    "ogx_mmlux_nl-computer_security": 5,
    "ogx_mmlux_nl-conceptual_physics": 5,
    "ogx_mmlux_nl-econometrics": 5,
    "ogx_mmlux_nl-electrical_engineering": 5,
    "ogx_mmlux_nl-elementary_mathematics": 5,
    "ogx_mmlux_nl-formal_logic": 5,
    "ogx_mmlux_nl-global_facts": 5,
    "ogx_mmlux_nl-high_school_biology": 5,
    "ogx_mmlux_nl-high_school_chemistry": 5,
    "ogx_mmlux_nl-high_school_computer_science": 5,
    "ogx_mmlux_nl-high_school_european_history": 5,
    "ogx_mmlux_nl-high_school_geography": 5,
    "ogx_mmlux_nl-high_school_government_and_politics": 5,
    "ogx_mmlux_nl-high_school_macroeconomics": 5,
    "ogx_mmlux_nl-high_school_mathematics": 5,
    "ogx_mmlux_nl-high_school_microeconomics": 5,
    "ogx_mmlux_nl-high_school_physics": 5,
    "ogx_mmlux_nl-high_school_psychology": 5,
    "ogx_mmlux_nl-high_school_statistics": 5,
    "ogx_mmlux_nl-high_school_us_history": 5,
    "ogx_mmlux_nl-high_school_world_history": 5,
    "ogx_mmlux_nl-human_aging": 5,
    "ogx_mmlux_nl-human_sexuality": 5,
    "ogx_mmlux_nl-international_law": 5,
    "ogx_mmlux_nl-jurisprudence": 5,
    "ogx_mmlux_nl-logical_fallacies": 5,
    "ogx_mmlux_nl-machine_learning": 5,
    "ogx_mmlux_nl-management": 5,
    "ogx_mmlux_nl-marketing": 5,
    "ogx_mmlux_nl-medical_genetics": 5,
    "ogx_mmlux_nl-miscellaneous": 5,
    "ogx_mmlux_nl-moral_disputes": 5,
    "ogx_mmlux_nl-moral_scenarios": 5,
    "ogx_mmlux_nl-nutrition": 5,
    "ogx_mmlux_nl-philosophy": 5,
    "ogx_mmlux_nl-prehistory": 5,
    "ogx_mmlux_nl-professional_accounting": 5,
    "ogx_mmlux_nl-professional_law": 5,
    "ogx_mmlux_nl-professional_medicine": 5,
    "ogx_mmlux_nl-professional_psychology": 5,
    "ogx_mmlux_nl-public_relations": 5,
    "ogx_mmlux_nl-security_studies": 5,
    "ogx_mmlux_nl-sociology": 5,
    "ogx_mmlux_nl-us_foreign_policy": 5,
    "ogx_mmlux_nl-virology": 5,
    "ogx_mmlux_nl-world_religions": 5,
    "ogx_mmlux_pl-abstract_algebra": 5,
    "ogx_mmlux_pl-anatomy": 5,
    "ogx_mmlux_pl-astronomy": 5,
    "ogx_mmlux_pl-business_ethics": 5,
    "ogx_mmlux_pl-clinical_knowledge": 5,
    "ogx_mmlux_pl-college_biology": 5,
    "ogx_mmlux_pl-college_chemistry": 5,
    "ogx_mmlux_pl-college_computer_science": 5,
    "ogx_mmlux_pl-college_mathematics": 5,
    "ogx_mmlux_pl-college_medicine": 5,
    "ogx_mmlux_pl-college_physics": 5,
    "ogx_mmlux_pl-computer_security": 5,
    "ogx_mmlux_pl-conceptual_physics": 5,
    "ogx_mmlux_pl-econometrics": 5,
    "ogx_mmlux_pl-electrical_engineering": 5,
    "ogx_mmlux_pl-elementary_mathematics": 5,
    "ogx_mmlux_pl-formal_logic": 5,
    "ogx_mmlux_pl-global_facts": 5,
    "ogx_mmlux_pl-high_school_biology": 5,
    "ogx_mmlux_pl-high_school_chemistry": 5,
    "ogx_mmlux_pl-high_school_computer_science": 5,
    "ogx_mmlux_pl-high_school_european_history": 5,
    "ogx_mmlux_pl-high_school_geography": 5,
    "ogx_mmlux_pl-high_school_government_and_politics": 5,
    "ogx_mmlux_pl-high_school_macroeconomics": 5,
    "ogx_mmlux_pl-high_school_mathematics": 5,
    "ogx_mmlux_pl-high_school_microeconomics": 5,
    "ogx_mmlux_pl-high_school_physics": 5,
    "ogx_mmlux_pl-high_school_psychology": 5,
    "ogx_mmlux_pl-high_school_statistics": 5,
    "ogx_mmlux_pl-high_school_us_history": 5,
    "ogx_mmlux_pl-high_school_world_history": 5,
    "ogx_mmlux_pl-human_aging": 5,
    "ogx_mmlux_pl-human_sexuality": 5,
    "ogx_mmlux_pl-international_law": 5,
    "ogx_mmlux_pl-jurisprudence": 5,
    "ogx_mmlux_pl-logical_fallacies": 5,
    "ogx_mmlux_pl-machine_learning": 5,
    "ogx_mmlux_pl-management": 5,
    "ogx_mmlux_pl-marketing": 5,
    "ogx_mmlux_pl-medical_genetics": 5,
    "ogx_mmlux_pl-miscellaneous": 5,
    "ogx_mmlux_pl-moral_disputes": 5,
    "ogx_mmlux_pl-moral_scenarios": 5,
    "ogx_mmlux_pl-nutrition": 5,
    "ogx_mmlux_pl-philosophy": 5,
    "ogx_mmlux_pl-prehistory": 5,
    "ogx_mmlux_pl-professional_accounting": 5,
    "ogx_mmlux_pl-professional_law": 5,
    "ogx_mmlux_pl-professional_medicine": 5,
    "ogx_mmlux_pl-professional_psychology": 5,
    "ogx_mmlux_pl-public_relations": 5,
    "ogx_mmlux_pl-security_studies": 5,
    "ogx_mmlux_pl-sociology": 5,
    "ogx_mmlux_pl-us_foreign_policy": 5,
    "ogx_mmlux_pl-virology": 5,
    "ogx_mmlux_pl-world_religions": 5,
    "ogx_mmlux_pt-pt-abstract_algebra": 5,
    "ogx_mmlux_pt-pt-anatomy": 5,
    "ogx_mmlux_pt-pt-astronomy": 5,
    "ogx_mmlux_pt-pt-business_ethics": 5,
    "ogx_mmlux_pt-pt-clinical_knowledge": 5,
    "ogx_mmlux_pt-pt-college_biology": 5,
    "ogx_mmlux_pt-pt-college_chemistry": 5,
    "ogx_mmlux_pt-pt-college_computer_science": 5,
    "ogx_mmlux_pt-pt-college_mathematics": 5,
    "ogx_mmlux_pt-pt-college_medicine": 5,
    "ogx_mmlux_pt-pt-college_physics": 5,
    "ogx_mmlux_pt-pt-computer_security": 5,
    "ogx_mmlux_pt-pt-conceptual_physics": 5,
    "ogx_mmlux_pt-pt-econometrics": 5,
    "ogx_mmlux_pt-pt-electrical_engineering": 5,
    "ogx_mmlux_pt-pt-elementary_mathematics": 5,
    "ogx_mmlux_pt-pt-formal_logic": 5,
    "ogx_mmlux_pt-pt-global_facts": 5,
    "ogx_mmlux_pt-pt-high_school_biology": 5,
    "ogx_mmlux_pt-pt-high_school_chemistry": 5,
    "ogx_mmlux_pt-pt-high_school_computer_science": 5,
    "ogx_mmlux_pt-pt-high_school_european_history": 5,
    "ogx_mmlux_pt-pt-high_school_geography": 5,
    "ogx_mmlux_pt-pt-high_school_government_and_politics": 5,
    "ogx_mmlux_pt-pt-high_school_macroeconomics": 5,
    "ogx_mmlux_pt-pt-high_school_mathematics": 5,
    "ogx_mmlux_pt-pt-high_school_microeconomics": 5,
    "ogx_mmlux_pt-pt-high_school_physics": 5,
    "ogx_mmlux_pt-pt-high_school_psychology": 5,
    "ogx_mmlux_pt-pt-high_school_statistics": 5,
    "ogx_mmlux_pt-pt-high_school_us_history": 5,
    "ogx_mmlux_pt-pt-high_school_world_history": 5,
    "ogx_mmlux_pt-pt-human_aging": 5,
    "ogx_mmlux_pt-pt-human_sexuality": 5,
    "ogx_mmlux_pt-pt-international_law": 5,
    "ogx_mmlux_pt-pt-jurisprudence": 5,
    "ogx_mmlux_pt-pt-logical_fallacies": 5,
    "ogx_mmlux_pt-pt-machine_learning": 5,
    "ogx_mmlux_pt-pt-management": 5,
    "ogx_mmlux_pt-pt-marketing": 5,
    "ogx_mmlux_pt-pt-medical_genetics": 5,
    "ogx_mmlux_pt-pt-miscellaneous": 5,
    "ogx_mmlux_pt-pt-moral_disputes": 5,
    "ogx_mmlux_pt-pt-moral_scenarios": 5,
    "ogx_mmlux_pt-pt-nutrition": 5,
    "ogx_mmlux_pt-pt-philosophy": 5,
    "ogx_mmlux_pt-pt-prehistory": 5,
    "ogx_mmlux_pt-pt-professional_accounting": 5,
    "ogx_mmlux_pt-pt-professional_law": 5,
    "ogx_mmlux_pt-pt-professional_medicine": 5,
    "ogx_mmlux_pt-pt-professional_psychology": 5,
    "ogx_mmlux_pt-pt-public_relations": 5,
    "ogx_mmlux_pt-pt-security_studies": 5,
    "ogx_mmlux_pt-pt-sociology": 5,
    "ogx_mmlux_pt-pt-us_foreign_policy": 5,
    "ogx_mmlux_pt-pt-virology": 5,
    "ogx_mmlux_pt-pt-world_religions": 5,
    "ogx_mmlux_ro-abstract_algebra": 5,
    "ogx_mmlux_ro-anatomy": 5,
    "ogx_mmlux_ro-astronomy": 5,
    "ogx_mmlux_ro-business_ethics": 5,
    "ogx_mmlux_ro-clinical_knowledge": 5,
    "ogx_mmlux_ro-college_biology": 5,
    "ogx_mmlux_ro-college_chemistry": 5,
    "ogx_mmlux_ro-college_computer_science": 5,
    "ogx_mmlux_ro-college_mathematics": 5,
    "ogx_mmlux_ro-college_medicine": 5,
    "ogx_mmlux_ro-college_physics": 5,
    "ogx_mmlux_ro-computer_security": 5,
    "ogx_mmlux_ro-conceptual_physics": 5,
    "ogx_mmlux_ro-econometrics": 5,
    "ogx_mmlux_ro-electrical_engineering": 5,
    "ogx_mmlux_ro-elementary_mathematics": 5,
    "ogx_mmlux_ro-formal_logic": 5,
    "ogx_mmlux_ro-global_facts": 5,
    "ogx_mmlux_ro-high_school_biology": 5,
    "ogx_mmlux_ro-high_school_chemistry": 5,
    "ogx_mmlux_ro-high_school_computer_science": 5,
    "ogx_mmlux_ro-high_school_european_history": 5,
    "ogx_mmlux_ro-high_school_geography": 5,
    "ogx_mmlux_ro-high_school_government_and_politics": 5,
    "ogx_mmlux_ro-high_school_macroeconomics": 5,
    "ogx_mmlux_ro-high_school_mathematics": 5,
    "ogx_mmlux_ro-high_school_microeconomics": 5,
    "ogx_mmlux_ro-high_school_physics": 5,
    "ogx_mmlux_ro-high_school_psychology": 5,
    "ogx_mmlux_ro-high_school_statistics": 5,
    "ogx_mmlux_ro-high_school_us_history": 5,
    "ogx_mmlux_ro-high_school_world_history": 5,
    "ogx_mmlux_ro-human_aging": 5,
    "ogx_mmlux_ro-human_sexuality": 5,
    "ogx_mmlux_ro-international_law": 5,
    "ogx_mmlux_ro-jurisprudence": 5,
    "ogx_mmlux_ro-logical_fallacies": 5,
    "ogx_mmlux_ro-machine_learning": 5,
    "ogx_mmlux_ro-management": 5,
    "ogx_mmlux_ro-marketing": 5,
    "ogx_mmlux_ro-medical_genetics": 5,
    "ogx_mmlux_ro-miscellaneous": 5,
    "ogx_mmlux_ro-moral_disputes": 5,
    "ogx_mmlux_ro-moral_scenarios": 5,
    "ogx_mmlux_ro-nutrition": 5,
    "ogx_mmlux_ro-philosophy": 5,
    "ogx_mmlux_ro-prehistory": 5,
    "ogx_mmlux_ro-professional_accounting": 5,
    "ogx_mmlux_ro-professional_law": 5,
    "ogx_mmlux_ro-professional_medicine": 5,
    "ogx_mmlux_ro-professional_psychology": 5,
    "ogx_mmlux_ro-public_relations": 5,
    "ogx_mmlux_ro-security_studies": 5,
    "ogx_mmlux_ro-sociology": 5,
    "ogx_mmlux_ro-us_foreign_policy": 5,
    "ogx_mmlux_ro-virology": 5,
    "ogx_mmlux_ro-world_religions": 5,
    "ogx_mmlux_sk-abstract_algebra": 5,
    "ogx_mmlux_sk-anatomy": 5,
    "ogx_mmlux_sk-astronomy": 5,
    "ogx_mmlux_sk-business_ethics": 5,
    "ogx_mmlux_sk-clinical_knowledge": 5,
    "ogx_mmlux_sk-college_biology": 5,
    "ogx_mmlux_sk-college_chemistry": 5,
    "ogx_mmlux_sk-college_computer_science": 5,
    "ogx_mmlux_sk-college_mathematics": 5,
    "ogx_mmlux_sk-college_medicine": 5,
    "ogx_mmlux_sk-college_physics": 5,
    "ogx_mmlux_sk-computer_security": 5,
    "ogx_mmlux_sk-conceptual_physics": 5,
    "ogx_mmlux_sk-econometrics": 5,
    "ogx_mmlux_sk-electrical_engineering": 5,
    "ogx_mmlux_sk-elementary_mathematics": 5,
    "ogx_mmlux_sk-formal_logic": 5,
    "ogx_mmlux_sk-global_facts": 5,
    "ogx_mmlux_sk-high_school_biology": 5,
    "ogx_mmlux_sk-high_school_chemistry": 5,
    "ogx_mmlux_sk-high_school_computer_science": 5,
    "ogx_mmlux_sk-high_school_european_history": 5,
    "ogx_mmlux_sk-high_school_geography": 5,
    "ogx_mmlux_sk-high_school_government_and_politics": 5,
    "ogx_mmlux_sk-high_school_macroeconomics": 5,
    "ogx_mmlux_sk-high_school_mathematics": 5,
    "ogx_mmlux_sk-high_school_microeconomics": 5,
    "ogx_mmlux_sk-high_school_physics": 5,
    "ogx_mmlux_sk-high_school_psychology": 5,
    "ogx_mmlux_sk-high_school_statistics": 5,
    "ogx_mmlux_sk-high_school_us_history": 5,
    "ogx_mmlux_sk-high_school_world_history": 5,
    "ogx_mmlux_sk-human_aging": 5,
    "ogx_mmlux_sk-human_sexuality": 5,
    "ogx_mmlux_sk-international_law": 5,
    "ogx_mmlux_sk-jurisprudence": 5,
    "ogx_mmlux_sk-logical_fallacies": 5,
    "ogx_mmlux_sk-machine_learning": 5,
    "ogx_mmlux_sk-management": 5,
    "ogx_mmlux_sk-marketing": 5,
    "ogx_mmlux_sk-medical_genetics": 5,
    "ogx_mmlux_sk-miscellaneous": 5,
    "ogx_mmlux_sk-moral_disputes": 5,
    "ogx_mmlux_sk-moral_scenarios": 5,
    "ogx_mmlux_sk-nutrition": 5,
    "ogx_mmlux_sk-philosophy": 5,
    "ogx_mmlux_sk-prehistory": 5,
    "ogx_mmlux_sk-professional_accounting": 5,
    "ogx_mmlux_sk-professional_law": 5,
    "ogx_mmlux_sk-professional_medicine": 5,
    "ogx_mmlux_sk-professional_psychology": 5,
    "ogx_mmlux_sk-public_relations": 5,
    "ogx_mmlux_sk-security_studies": 5,
    "ogx_mmlux_sk-sociology": 5,
    "ogx_mmlux_sk-us_foreign_policy": 5,
    "ogx_mmlux_sk-virology": 5,
    "ogx_mmlux_sk-world_religions": 5,
    "ogx_mmlux_sl-abstract_algebra": 5,
    "ogx_mmlux_sl-anatomy": 5,
    "ogx_mmlux_sl-astronomy": 5,
    "ogx_mmlux_sl-business_ethics": 5,
    "ogx_mmlux_sl-clinical_knowledge": 5,
    "ogx_mmlux_sl-college_biology": 5,
    "ogx_mmlux_sl-college_chemistry": 5,
    "ogx_mmlux_sl-college_computer_science": 5,
    "ogx_mmlux_sl-college_mathematics": 5,
    "ogx_mmlux_sl-college_medicine": 5,
    "ogx_mmlux_sl-college_physics": 5,
    "ogx_mmlux_sl-computer_security": 5,
    "ogx_mmlux_sl-conceptual_physics": 5,
    "ogx_mmlux_sl-econometrics": 5,
    "ogx_mmlux_sl-electrical_engineering": 5,
    "ogx_mmlux_sl-elementary_mathematics": 5,
    "ogx_mmlux_sl-formal_logic": 5,
    "ogx_mmlux_sl-global_facts": 5,
    "ogx_mmlux_sl-high_school_biology": 5,
    "ogx_mmlux_sl-high_school_chemistry": 5,
    "ogx_mmlux_sl-high_school_computer_science": 5,
    "ogx_mmlux_sl-high_school_european_history": 5,
    "ogx_mmlux_sl-high_school_geography": 5,
    "ogx_mmlux_sl-high_school_government_and_politics": 5,
    "ogx_mmlux_sl-high_school_macroeconomics": 5,
    "ogx_mmlux_sl-high_school_mathematics": 5,
    "ogx_mmlux_sl-high_school_microeconomics": 5,
    "ogx_mmlux_sl-high_school_physics": 5,
    "ogx_mmlux_sl-high_school_psychology": 5,
    "ogx_mmlux_sl-high_school_statistics": 5,
    "ogx_mmlux_sl-high_school_us_history": 5,
    "ogx_mmlux_sl-high_school_world_history": 5,
    "ogx_mmlux_sl-human_aging": 5,
    "ogx_mmlux_sl-human_sexuality": 5,
    "ogx_mmlux_sl-international_law": 5,
    "ogx_mmlux_sl-jurisprudence": 5,
    "ogx_mmlux_sl-logical_fallacies": 5,
    "ogx_mmlux_sl-machine_learning": 5,
    "ogx_mmlux_sl-management": 5,
    "ogx_mmlux_sl-marketing": 5,
    "ogx_mmlux_sl-medical_genetics": 5,
    "ogx_mmlux_sl-miscellaneous": 5,
    "ogx_mmlux_sl-moral_disputes": 5,
    "ogx_mmlux_sl-moral_scenarios": 5,
    "ogx_mmlux_sl-nutrition": 5,
    "ogx_mmlux_sl-philosophy": 5,
    "ogx_mmlux_sl-prehistory": 5,
    "ogx_mmlux_sl-professional_accounting": 5,
    "ogx_mmlux_sl-professional_law": 5,
    "ogx_mmlux_sl-professional_medicine": 5,
    "ogx_mmlux_sl-professional_psychology": 5,
    "ogx_mmlux_sl-public_relations": 5,
    "ogx_mmlux_sl-security_studies": 5,
    "ogx_mmlux_sl-sociology": 5,
    "ogx_mmlux_sl-us_foreign_policy": 5,
    "ogx_mmlux_sl-virology": 5,
    "ogx_mmlux_sl-world_religions": 5,
    "ogx_mmlux_sv-abstract_algebra": 5,
    "ogx_mmlux_sv-anatomy": 5,
    "ogx_mmlux_sv-astronomy": 5,
    "ogx_mmlux_sv-business_ethics": 5,
    "ogx_mmlux_sv-clinical_knowledge": 5,
    "ogx_mmlux_sv-college_biology": 5,
    "ogx_mmlux_sv-college_chemistry": 5,
    "ogx_mmlux_sv-college_computer_science": 5,
    "ogx_mmlux_sv-college_mathematics": 5,
    "ogx_mmlux_sv-college_medicine": 5,
    "ogx_mmlux_sv-college_physics": 5,
    "ogx_mmlux_sv-computer_security": 5,
    "ogx_mmlux_sv-conceptual_physics": 5,
    "ogx_mmlux_sv-econometrics": 5,
    "ogx_mmlux_sv-electrical_engineering": 5,
    "ogx_mmlux_sv-elementary_mathematics": 5,
    "ogx_mmlux_sv-formal_logic": 5,
    "ogx_mmlux_sv-global_facts": 5,
    "ogx_mmlux_sv-high_school_biology": 5,
    "ogx_mmlux_sv-high_school_chemistry": 5,
    "ogx_mmlux_sv-high_school_computer_science": 5,
    "ogx_mmlux_sv-high_school_european_history": 5,
    "ogx_mmlux_sv-high_school_geography": 5,
    "ogx_mmlux_sv-high_school_government_and_politics": 5,
    "ogx_mmlux_sv-high_school_macroeconomics": 5,
    "ogx_mmlux_sv-high_school_mathematics": 5,
    "ogx_mmlux_sv-high_school_microeconomics": 5,
    "ogx_mmlux_sv-high_school_physics": 5,
    "ogx_mmlux_sv-high_school_psychology": 5,
    "ogx_mmlux_sv-high_school_statistics": 5,
    "ogx_mmlux_sv-high_school_us_history": 5,
    "ogx_mmlux_sv-high_school_world_history": 5,
    "ogx_mmlux_sv-human_aging": 5,
    "ogx_mmlux_sv-human_sexuality": 5,
    "ogx_mmlux_sv-international_law": 5,
    "ogx_mmlux_sv-jurisprudence": 5,
    "ogx_mmlux_sv-logical_fallacies": 5,
    "ogx_mmlux_sv-machine_learning": 5,
    "ogx_mmlux_sv-management": 5,
    "ogx_mmlux_sv-marketing": 5,
    "ogx_mmlux_sv-medical_genetics": 5,
    "ogx_mmlux_sv-miscellaneous": 5,
    "ogx_mmlux_sv-moral_disputes": 5,
    "ogx_mmlux_sv-moral_scenarios": 5,
    "ogx_mmlux_sv-nutrition": 5,
    "ogx_mmlux_sv-philosophy": 5,
    "ogx_mmlux_sv-prehistory": 5,
    "ogx_mmlux_sv-professional_accounting": 5,
    "ogx_mmlux_sv-professional_law": 5,
    "ogx_mmlux_sv-professional_medicine": 5,
    "ogx_mmlux_sv-professional_psychology": 5,
    "ogx_mmlux_sv-public_relations": 5,
    "ogx_mmlux_sv-security_studies": 5,
    "ogx_mmlux_sv-sociology": 5,
    "ogx_mmlux_sv-us_foreign_policy": 5,
    "ogx_mmlux_sv-virology": 5,
    "ogx_mmlux_sv-world_religions": 5
  },
  "higher_is_better": {
    "ogx_mmlux_bg-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_bg-anatomy": {
      "acc": true
    },
    "ogx_mmlux_bg-astronomy": {
      "acc": true
    },
    "ogx_mmlux_bg-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_bg-college_biology": {
      "acc": true
    },
    "ogx_mmlux_bg-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_bg-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_bg-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_bg-college_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-computer_security": {
      "acc": true
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-econometrics": {
      "acc": true
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_bg-global_facts": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_bg-human_aging": {
      "acc": true
    },
    "ogx_mmlux_bg-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_bg-international_law": {
      "acc": true
    },
    "ogx_mmlux_bg-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_bg-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_bg-management": {
      "acc": true
    },
    "ogx_mmlux_bg-marketing": {
      "acc": true
    },
    "ogx_mmlux_bg-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_bg-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_bg-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_bg-nutrition": {
      "acc": true
    },
    "ogx_mmlux_bg-philosophy": {
      "acc": true
    },
    "ogx_mmlux_bg-prehistory": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_law": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_bg-public_relations": {
      "acc": true
    },
    "ogx_mmlux_bg-security_studies": {
      "acc": true
    },
    "ogx_mmlux_bg-sociology": {
      "acc": true
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_bg-virology": {
      "acc": true
    },
    "ogx_mmlux_bg-world_religions": {
      "acc": true
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_cs-anatomy": {
      "acc": true
    },
    "ogx_mmlux_cs-astronomy": {
      "acc": true
    },
    "ogx_mmlux_cs-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_cs-college_biology": {
      "acc": true
    },
    "ogx_mmlux_cs-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_cs-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_cs-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_cs-college_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-computer_security": {
      "acc": true
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-econometrics": {
      "acc": true
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_cs-global_facts": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_cs-human_aging": {
      "acc": true
    },
    "ogx_mmlux_cs-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_cs-international_law": {
      "acc": true
    },
    "ogx_mmlux_cs-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_cs-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_cs-management": {
      "acc": true
    },
    "ogx_mmlux_cs-marketing": {
      "acc": true
    },
    "ogx_mmlux_cs-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_cs-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_cs-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_cs-nutrition": {
      "acc": true
    },
    "ogx_mmlux_cs-philosophy": {
      "acc": true
    },
    "ogx_mmlux_cs-prehistory": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_law": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_cs-public_relations": {
      "acc": true
    },
    "ogx_mmlux_cs-security_studies": {
      "acc": true
    },
    "ogx_mmlux_cs-sociology": {
      "acc": true
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_cs-virology": {
      "acc": true
    },
    "ogx_mmlux_cs-world_religions": {
      "acc": true
    },
    "ogx_mmlux_da-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_da-anatomy": {
      "acc": true
    },
    "ogx_mmlux_da-astronomy": {
      "acc": true
    },
    "ogx_mmlux_da-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_da-college_biology": {
      "acc": true
    },
    "ogx_mmlux_da-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_da-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_da-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_da-college_physics": {
      "acc": true
    },
    "ogx_mmlux_da-computer_security": {
      "acc": true
    },
    "ogx_mmlux_da-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_da-econometrics": {
      "acc": true
    },
    "ogx_mmlux_da-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_da-global_facts": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_da-human_aging": {
      "acc": true
    },
    "ogx_mmlux_da-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_da-international_law": {
      "acc": true
    },
    "ogx_mmlux_da-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_da-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_da-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_da-management": {
      "acc": true
    },
    "ogx_mmlux_da-marketing": {
      "acc": true
    },
    "ogx_mmlux_da-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_da-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_da-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_da-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_da-nutrition": {
      "acc": true
    },
    "ogx_mmlux_da-philosophy": {
      "acc": true
    },
    "ogx_mmlux_da-prehistory": {
      "acc": true
    },
    "ogx_mmlux_da-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_da-professional_law": {
      "acc": true
    },
    "ogx_mmlux_da-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_da-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_da-public_relations": {
      "acc": true
    },
    "ogx_mmlux_da-security_studies": {
      "acc": true
    },
    "ogx_mmlux_da-sociology": {
      "acc": true
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_da-virology": {
      "acc": true
    },
    "ogx_mmlux_da-world_religions": {
      "acc": true
    },
    "ogx_mmlux_de-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_de-anatomy": {
      "acc": true
    },
    "ogx_mmlux_de-astronomy": {
      "acc": true
    },
    "ogx_mmlux_de-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_de-college_biology": {
      "acc": true
    },
    "ogx_mmlux_de-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_de-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_de-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_de-college_physics": {
      "acc": true
    },
    "ogx_mmlux_de-computer_security": {
      "acc": true
    },
    "ogx_mmlux_de-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_de-econometrics": {
      "acc": true
    },
    "ogx_mmlux_de-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_de-global_facts": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_de-human_aging": {
      "acc": true
    },
    "ogx_mmlux_de-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_de-international_law": {
      "acc": true
    },
    "ogx_mmlux_de-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_de-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_de-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_de-management": {
      "acc": true
    },
    "ogx_mmlux_de-marketing": {
      "acc": true
    },
    "ogx_mmlux_de-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_de-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_de-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_de-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_de-nutrition": {
      "acc": true
    },
    "ogx_mmlux_de-philosophy": {
      "acc": true
    },
    "ogx_mmlux_de-prehistory": {
      "acc": true
    },
    "ogx_mmlux_de-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_de-professional_law": {
      "acc": true
    },
    "ogx_mmlux_de-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_de-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_de-public_relations": {
      "acc": true
    },
    "ogx_mmlux_de-security_studies": {
      "acc": true
    },
    "ogx_mmlux_de-sociology": {
      "acc": true
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_de-virology": {
      "acc": true
    },
    "ogx_mmlux_de-world_religions": {
      "acc": true
    },
    "ogx_mmlux_el-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_el-anatomy": {
      "acc": true
    },
    "ogx_mmlux_el-astronomy": {
      "acc": true
    },
    "ogx_mmlux_el-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_el-college_biology": {
      "acc": true
    },
    "ogx_mmlux_el-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_el-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_el-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_el-college_physics": {
      "acc": true
    },
    "ogx_mmlux_el-computer_security": {
      "acc": true
    },
    "ogx_mmlux_el-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_el-econometrics": {
      "acc": true
    },
    "ogx_mmlux_el-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_el-global_facts": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_el-human_aging": {
      "acc": true
    },
    "ogx_mmlux_el-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_el-international_law": {
      "acc": true
    },
    "ogx_mmlux_el-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_el-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_el-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_el-management": {
      "acc": true
    },
    "ogx_mmlux_el-marketing": {
      "acc": true
    },
    "ogx_mmlux_el-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_el-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_el-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_el-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_el-nutrition": {
      "acc": true
    },
    "ogx_mmlux_el-philosophy": {
      "acc": true
    },
    "ogx_mmlux_el-prehistory": {
      "acc": true
    },
    "ogx_mmlux_el-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_el-professional_law": {
      "acc": true
    },
    "ogx_mmlux_el-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_el-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_el-public_relations": {
      "acc": true
    },
    "ogx_mmlux_el-security_studies": {
      "acc": true
    },
    "ogx_mmlux_el-sociology": {
      "acc": true
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_el-virology": {
      "acc": true
    },
    "ogx_mmlux_el-world_religions": {
      "acc": true
    },
    "ogx_mmlux_es-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_es-anatomy": {
      "acc": true
    },
    "ogx_mmlux_es-astronomy": {
      "acc": true
    },
    "ogx_mmlux_es-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_es-college_biology": {
      "acc": true
    },
    "ogx_mmlux_es-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_es-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_es-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_es-college_physics": {
      "acc": true
    },
    "ogx_mmlux_es-computer_security": {
      "acc": true
    },
    "ogx_mmlux_es-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_es-econometrics": {
      "acc": true
    },
    "ogx_mmlux_es-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_es-global_facts": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_es-human_aging": {
      "acc": true
    },
    "ogx_mmlux_es-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_es-international_law": {
      "acc": true
    },
    "ogx_mmlux_es-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_es-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_es-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_es-management": {
      "acc": true
    },
    "ogx_mmlux_es-marketing": {
      "acc": true
    },
    "ogx_mmlux_es-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_es-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_es-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_es-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_es-nutrition": {
      "acc": true
    },
    "ogx_mmlux_es-philosophy": {
      "acc": true
    },
    "ogx_mmlux_es-prehistory": {
      "acc": true
    },
    "ogx_mmlux_es-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_es-professional_law": {
      "acc": true
    },
    "ogx_mmlux_es-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_es-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_es-public_relations": {
      "acc": true
    },
    "ogx_mmlux_es-security_studies": {
      "acc": true
    },
    "ogx_mmlux_es-sociology": {
      "acc": true
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_es-virology": {
      "acc": true
    },
    "ogx_mmlux_es-world_religions": {
      "acc": true
    },
    "ogx_mmlux_et-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_et-anatomy": {
      "acc": true
    },
    "ogx_mmlux_et-astronomy": {
      "acc": true
    },
    "ogx_mmlux_et-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_et-college_biology": {
      "acc": true
    },
    "ogx_mmlux_et-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_et-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_et-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_et-college_physics": {
      "acc": true
    },
    "ogx_mmlux_et-computer_security": {
      "acc": true
    },
    "ogx_mmlux_et-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_et-econometrics": {
      "acc": true
    },
    "ogx_mmlux_et-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_et-global_facts": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_et-human_aging": {
      "acc": true
    },
    "ogx_mmlux_et-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_et-international_law": {
      "acc": true
    },
    "ogx_mmlux_et-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_et-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_et-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_et-management": {
      "acc": true
    },
    "ogx_mmlux_et-marketing": {
      "acc": true
    },
    "ogx_mmlux_et-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_et-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_et-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_et-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_et-nutrition": {
      "acc": true
    },
    "ogx_mmlux_et-philosophy": {
      "acc": true
    },
    "ogx_mmlux_et-prehistory": {
      "acc": true
    },
    "ogx_mmlux_et-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_et-professional_law": {
      "acc": true
    },
    "ogx_mmlux_et-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_et-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_et-public_relations": {
      "acc": true
    },
    "ogx_mmlux_et-security_studies": {
      "acc": true
    },
    "ogx_mmlux_et-sociology": {
      "acc": true
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_et-virology": {
      "acc": true
    },
    "ogx_mmlux_et-world_religions": {
      "acc": true
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_fi-anatomy": {
      "acc": true
    },
    "ogx_mmlux_fi-astronomy": {
      "acc": true
    },
    "ogx_mmlux_fi-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_fi-college_biology": {
      "acc": true
    },
    "ogx_mmlux_fi-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fi-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fi-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_fi-college_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-computer_security": {
      "acc": true
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-econometrics": {
      "acc": true
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_fi-global_facts": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_fi-human_aging": {
      "acc": true
    },
    "ogx_mmlux_fi-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_fi-international_law": {
      "acc": true
    },
    "ogx_mmlux_fi-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_fi-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_fi-management": {
      "acc": true
    },
    "ogx_mmlux_fi-marketing": {
      "acc": true
    },
    "ogx_mmlux_fi-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_fi-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_fi-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_fi-nutrition": {
      "acc": true
    },
    "ogx_mmlux_fi-philosophy": {
      "acc": true
    },
    "ogx_mmlux_fi-prehistory": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_law": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_fi-public_relations": {
      "acc": true
    },
    "ogx_mmlux_fi-security_studies": {
      "acc": true
    },
    "ogx_mmlux_fi-sociology": {
      "acc": true
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_fi-virology": {
      "acc": true
    },
    "ogx_mmlux_fi-world_religions": {
      "acc": true
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_fr-anatomy": {
      "acc": true
    },
    "ogx_mmlux_fr-astronomy": {
      "acc": true
    },
    "ogx_mmlux_fr-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_fr-college_biology": {
      "acc": true
    },
    "ogx_mmlux_fr-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fr-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fr-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_fr-college_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-computer_security": {
      "acc": true
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-econometrics": {
      "acc": true
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_fr-global_facts": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_fr-human_aging": {
      "acc": true
    },
    "ogx_mmlux_fr-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_fr-international_law": {
      "acc": true
    },
    "ogx_mmlux_fr-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_fr-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_fr-management": {
      "acc": true
    },
    "ogx_mmlux_fr-marketing": {
      "acc": true
    },
    "ogx_mmlux_fr-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_fr-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_fr-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_fr-nutrition": {
      "acc": true
    },
    "ogx_mmlux_fr-philosophy": {
      "acc": true
    },
    "ogx_mmlux_fr-prehistory": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_law": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_fr-public_relations": {
      "acc": true
    },
    "ogx_mmlux_fr-security_studies": {
      "acc": true
    },
    "ogx_mmlux_fr-sociology": {
      "acc": true
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_fr-virology": {
      "acc": true
    },
    "ogx_mmlux_fr-world_religions": {
      "acc": true
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_hu-anatomy": {
      "acc": true
    },
    "ogx_mmlux_hu-astronomy": {
      "acc": true
    },
    "ogx_mmlux_hu-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_hu-college_biology": {
      "acc": true
    },
    "ogx_mmlux_hu-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_hu-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_hu-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_hu-college_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-computer_security": {
      "acc": true
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-econometrics": {
      "acc": true
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_hu-global_facts": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_hu-human_aging": {
      "acc": true
    },
    "ogx_mmlux_hu-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_hu-international_law": {
      "acc": true
    },
    "ogx_mmlux_hu-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_hu-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_hu-management": {
      "acc": true
    },
    "ogx_mmlux_hu-marketing": {
      "acc": true
    },
    "ogx_mmlux_hu-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_hu-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_hu-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_hu-nutrition": {
      "acc": true
    },
    "ogx_mmlux_hu-philosophy": {
      "acc": true
    },
    "ogx_mmlux_hu-prehistory": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_law": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_hu-public_relations": {
      "acc": true
    },
    "ogx_mmlux_hu-security_studies": {
      "acc": true
    },
    "ogx_mmlux_hu-sociology": {
      "acc": true
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_hu-virology": {
      "acc": true
    },
    "ogx_mmlux_hu-world_religions": {
      "acc": true
    },
    "ogx_mmlux_it-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_it-anatomy": {
      "acc": true
    },
    "ogx_mmlux_it-astronomy": {
      "acc": true
    },
    "ogx_mmlux_it-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_it-college_biology": {
      "acc": true
    },
    "ogx_mmlux_it-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_it-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_it-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_it-college_physics": {
      "acc": true
    },
    "ogx_mmlux_it-computer_security": {
      "acc": true
    },
    "ogx_mmlux_it-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_it-econometrics": {
      "acc": true
    },
    "ogx_mmlux_it-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_it-global_facts": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_it-human_aging": {
      "acc": true
    },
    "ogx_mmlux_it-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_it-international_law": {
      "acc": true
    },
    "ogx_mmlux_it-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_it-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_it-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_it-management": {
      "acc": true
    },
    "ogx_mmlux_it-marketing": {
      "acc": true
    },
    "ogx_mmlux_it-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_it-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_it-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_it-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_it-nutrition": {
      "acc": true
    },
    "ogx_mmlux_it-philosophy": {
      "acc": true
    },
    "ogx_mmlux_it-prehistory": {
      "acc": true
    },
    "ogx_mmlux_it-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_it-professional_law": {
      "acc": true
    },
    "ogx_mmlux_it-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_it-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_it-public_relations": {
      "acc": true
    },
    "ogx_mmlux_it-security_studies": {
      "acc": true
    },
    "ogx_mmlux_it-sociology": {
      "acc": true
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_it-virology": {
      "acc": true
    },
    "ogx_mmlux_it-world_religions": {
      "acc": true
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_lt-anatomy": {
      "acc": true
    },
    "ogx_mmlux_lt-astronomy": {
      "acc": true
    },
    "ogx_mmlux_lt-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_lt-college_biology": {
      "acc": true
    },
    "ogx_mmlux_lt-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lt-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lt-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_lt-college_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-computer_security": {
      "acc": true
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-econometrics": {
      "acc": true
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_lt-global_facts": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_lt-human_aging": {
      "acc": true
    },
    "ogx_mmlux_lt-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_lt-international_law": {
      "acc": true
    },
    "ogx_mmlux_lt-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_lt-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_lt-management": {
      "acc": true
    },
    "ogx_mmlux_lt-marketing": {
      "acc": true
    },
    "ogx_mmlux_lt-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_lt-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_lt-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_lt-nutrition": {
      "acc": true
    },
    "ogx_mmlux_lt-philosophy": {
      "acc": true
    },
    "ogx_mmlux_lt-prehistory": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_law": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_lt-public_relations": {
      "acc": true
    },
    "ogx_mmlux_lt-security_studies": {
      "acc": true
    },
    "ogx_mmlux_lt-sociology": {
      "acc": true
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_lt-virology": {
      "acc": true
    },
    "ogx_mmlux_lt-world_religions": {
      "acc": true
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_lv-anatomy": {
      "acc": true
    },
    "ogx_mmlux_lv-astronomy": {
      "acc": true
    },
    "ogx_mmlux_lv-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_lv-college_biology": {
      "acc": true
    },
    "ogx_mmlux_lv-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lv-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lv-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_lv-college_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-computer_security": {
      "acc": true
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-econometrics": {
      "acc": true
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_lv-global_facts": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_lv-human_aging": {
      "acc": true
    },
    "ogx_mmlux_lv-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_lv-international_law": {
      "acc": true
    },
    "ogx_mmlux_lv-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_lv-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_lv-management": {
      "acc": true
    },
    "ogx_mmlux_lv-marketing": {
      "acc": true
    },
    "ogx_mmlux_lv-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_lv-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_lv-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_lv-nutrition": {
      "acc": true
    },
    "ogx_mmlux_lv-philosophy": {
      "acc": true
    },
    "ogx_mmlux_lv-prehistory": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_law": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_lv-public_relations": {
      "acc": true
    },
    "ogx_mmlux_lv-security_studies": {
      "acc": true
    },
    "ogx_mmlux_lv-sociology": {
      "acc": true
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_lv-virology": {
      "acc": true
    },
    "ogx_mmlux_lv-world_religions": {
      "acc": true
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_nl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_nl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_nl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_nl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_nl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_nl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_nl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_nl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_nl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_nl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_nl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_nl-international_law": {
      "acc": true
    },
    "ogx_mmlux_nl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_nl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_nl-management": {
      "acc": true
    },
    "ogx_mmlux_nl-marketing": {
      "acc": true
    },
    "ogx_mmlux_nl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_nl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_nl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_nl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_nl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_nl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_nl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_nl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_nl-sociology": {
      "acc": true
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_nl-virology": {
      "acc": true
    },
    "ogx_mmlux_nl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_pl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_pl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_pl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_pl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_pl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_pl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_pl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_pl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_pl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_pl-international_law": {
      "acc": true
    },
    "ogx_mmlux_pl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_pl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_pl-management": {
      "acc": true
    },
    "ogx_mmlux_pl-marketing": {
      "acc": true
    },
    "ogx_mmlux_pl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_pl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_pl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_pl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_pl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_pl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_pl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_pl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_pl-sociology": {
      "acc": true
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_pl-virology": {
      "acc": true
    },
    "ogx_mmlux_pl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-international_law": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-management": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-marketing": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-sociology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-virology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "acc": true
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_ro-anatomy": {
      "acc": true
    },
    "ogx_mmlux_ro-astronomy": {
      "acc": true
    },
    "ogx_mmlux_ro-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_ro-college_biology": {
      "acc": true
    },
    "ogx_mmlux_ro-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_ro-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_ro-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_ro-college_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-computer_security": {
      "acc": true
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-econometrics": {
      "acc": true
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_ro-global_facts": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_ro-human_aging": {
      "acc": true
    },
    "ogx_mmlux_ro-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_ro-international_law": {
      "acc": true
    },
    "ogx_mmlux_ro-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_ro-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_ro-management": {
      "acc": true
    },
    "ogx_mmlux_ro-marketing": {
      "acc": true
    },
    "ogx_mmlux_ro-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_ro-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_ro-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_ro-nutrition": {
      "acc": true
    },
    "ogx_mmlux_ro-philosophy": {
      "acc": true
    },
    "ogx_mmlux_ro-prehistory": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_law": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_ro-public_relations": {
      "acc": true
    },
    "ogx_mmlux_ro-security_studies": {
      "acc": true
    },
    "ogx_mmlux_ro-sociology": {
      "acc": true
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_ro-virology": {
      "acc": true
    },
    "ogx_mmlux_ro-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sk-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sk-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sk-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sk-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sk-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sk-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sk-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sk-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sk-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sk-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sk-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sk-international_law": {
      "acc": true
    },
    "ogx_mmlux_sk-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sk-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sk-management": {
      "acc": true
    },
    "ogx_mmlux_sk-marketing": {
      "acc": true
    },
    "ogx_mmlux_sk-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sk-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sk-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sk-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sk-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sk-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sk-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sk-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sk-sociology": {
      "acc": true
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sk-virology": {
      "acc": true
    },
    "ogx_mmlux_sk-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sl-international_law": {
      "acc": true
    },
    "ogx_mmlux_sl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sl-management": {
      "acc": true
    },
    "ogx_mmlux_sl-marketing": {
      "acc": true
    },
    "ogx_mmlux_sl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sl-sociology": {
      "acc": true
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sl-virology": {
      "acc": true
    },
    "ogx_mmlux_sl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sv-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sv-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sv-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sv-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sv-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sv-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sv-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sv-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sv-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sv-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sv-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sv-international_law": {
      "acc": true
    },
    "ogx_mmlux_sv-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sv-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sv-management": {
      "acc": true
    },
    "ogx_mmlux_sv-marketing": {
      "acc": true
    },
    "ogx_mmlux_sv-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sv-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sv-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sv-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sv-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sv-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sv-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sv-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sv-sociology": {
      "acc": true
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sv-virology": {
      "acc": true
    },
    "ogx_mmlux_sv-world_religions": {
      "acc": true
    }
  },
  "n-samples": {
    "ogx_mmlux_sv-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sv-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sv-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sv-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sv-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sv-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sv-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sv-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sv-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sv-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sv-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sv-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sv-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sv-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sv-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sv-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sv-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sv-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sv-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sv-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sv-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sv-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sv-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sv-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sv-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sv-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sv-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sv-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sv-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sv-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sk-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sk-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sk-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sk-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sk-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sk-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sk-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sk-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sk-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sk-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sk-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sk-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sk-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sk-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sk-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sk-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sk-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sk-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sk-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sk-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sk-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sk-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sk-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sk-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sk-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sk-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sk-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sk-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sk-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_ro-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_ro-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_ro-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_ro-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_ro-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_ro-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_ro-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_ro-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_ro-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_ro-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_ro-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_ro-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_ro-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_ro-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_ro-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_ro-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_ro-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_ro-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_ro-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_ro-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_ro-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_ro-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_ro-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_ro-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_ro-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_ro-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_ro-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_ro-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_ro-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_pt-pt-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_pt-pt-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_pt-pt-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_pl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_pl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_pl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_pl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_pl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_pl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_pl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_pl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_pl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_pl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_pl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_pl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_pl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_pl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_pl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_pl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_pl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_pl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_pl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_pl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_pl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_pl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_pl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_pl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_pl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_pl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_pl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_pl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_pl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_nl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_nl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_nl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_nl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_nl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_nl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_nl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_nl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_nl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_nl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_nl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_nl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_nl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_nl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_nl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_nl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_nl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_nl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_nl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_nl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_nl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_nl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_nl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_nl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_nl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_nl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_nl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_nl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_nl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_lv-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_lv-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_lv-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_lv-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_lv-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_lv-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_lv-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_lv-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_lv-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_lv-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_lv-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_lv-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_lv-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_lv-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_lv-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_lv-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_lv-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_lv-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_lv-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_lv-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_lv-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_lv-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_lv-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_lv-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_lv-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_lv-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_lv-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_lv-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_lv-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_lt-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_lt-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_lt-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_lt-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_lt-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_lt-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_lt-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_lt-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_lt-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_lt-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_lt-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_lt-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_lt-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_lt-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_lt-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_lt-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_lt-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_lt-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_lt-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_lt-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_lt-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_lt-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_lt-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_lt-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_lt-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_lt-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_lt-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_lt-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_lt-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_it-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_it-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_it-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_it-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_it-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_it-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_it-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_it-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_it-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_it-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_it-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_it-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_it-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_it-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_it-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_it-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_it-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_it-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_it-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_it-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_it-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_it-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_it-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_it-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_it-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_it-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_it-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_it-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_it-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_it-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_it-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_it-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_it-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_it-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_it-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_it-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_it-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_it-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_it-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_hu-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_hu-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_hu-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_hu-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_hu-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_hu-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_hu-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_hu-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_hu-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_hu-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_hu-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_hu-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_hu-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_hu-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_hu-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_hu-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_hu-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_hu-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_hu-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_hu-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_hu-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_hu-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_hu-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_hu-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_hu-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_hu-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_hu-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_hu-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_hu-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_fr-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_fr-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_fr-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_fr-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_fr-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_fr-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_fr-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_fr-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_fr-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_fr-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_fr-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_fr-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_fr-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_fr-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_fr-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_fr-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_fr-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_fr-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_fr-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_fr-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_fr-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_fr-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_fr-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_fr-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_fr-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_fr-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_fr-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_fr-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_fr-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_fi-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_fi-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_fi-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_fi-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_fi-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_fi-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_fi-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_fi-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_fi-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_fi-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_fi-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_fi-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_fi-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_fi-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_fi-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_fi-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_fi-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_fi-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_fi-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_fi-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_fi-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_fi-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_fi-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_fi-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_fi-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_fi-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_fi-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_fi-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_fi-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_et-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_et-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_et-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_et-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_et-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_et-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_et-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_et-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_et-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_et-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_et-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_et-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_et-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_et-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_et-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_et-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_et-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_et-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_et-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_et-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_et-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_et-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_et-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_et-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_et-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_et-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_et-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_et-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_et-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_et-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_et-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_et-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_et-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_et-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_et-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_et-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_et-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_et-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_et-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_es-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_es-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_es-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_es-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_es-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_es-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_es-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_es-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_es-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_es-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_es-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_es-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_es-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_es-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_es-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_es-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_es-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_es-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_es-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_es-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_es-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_es-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_es-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_es-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_es-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_es-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_es-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_es-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_es-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_es-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_es-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_es-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_es-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_es-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_es-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_es-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_es-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_es-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_es-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_el-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_el-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_el-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_el-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_el-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_el-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_el-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_el-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_el-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_el-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_el-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_el-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_el-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_el-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_el-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_el-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_el-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_el-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_el-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_el-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_el-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_el-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_el-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_el-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_el-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_el-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_el-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_el-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_el-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_el-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_el-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_el-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_el-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_el-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_el-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_el-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_el-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_el-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_el-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_de-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_de-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_de-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_de-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_de-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_de-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_de-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_de-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_de-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_de-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_de-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_de-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_de-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_de-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_de-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_de-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_de-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_de-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_de-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_de-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_de-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_de-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_de-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_de-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_de-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_de-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_de-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_de-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_de-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_de-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_de-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_de-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_de-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_de-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_de-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_de-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_de-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_de-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_de-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_da-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_da-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_da-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_da-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_da-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_da-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_da-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_da-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_da-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_da-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_da-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_da-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_da-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_da-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_da-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_da-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_da-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_da-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_da-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_da-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_da-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_da-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_da-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_da-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_da-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_da-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_da-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_da-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_da-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_da-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_da-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_da-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_da-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_da-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_da-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_da-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_da-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_da-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_da-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_cs-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_cs-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_cs-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_cs-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_cs-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_cs-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_cs-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_cs-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_cs-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_cs-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_cs-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_cs-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_cs-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_cs-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_cs-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_cs-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_cs-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_cs-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_cs-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_cs-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_cs-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_cs-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_cs-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_cs-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_cs-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_cs-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_cs-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_cs-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_cs-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_bg-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_bg-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_bg-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_bg-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_bg-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_bg-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_bg-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_bg-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_bg-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_bg-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_bg-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_bg-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_bg-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_bg-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_bg-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_bg-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_bg-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_bg-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_bg-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_bg-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_bg-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_bg-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_bg-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_bg-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_bg-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_bg-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_bg-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_bg-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_bg-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_bg-abstract_algebra": {
      "original": 100,
      "effective": 100
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=CohereForAI/aya-23-8B,dtype=bfloat16,trust_remote_code=True,nccl_timeout=3600,trust_remote_code=True",
    "model_num_parameters": 8028033024,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "f7c0f53641e86ef2e39c62461e6f0f54ff904eba",
    "batch_size": "auto",
    "batch_sizes": [
      4
    ],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "43468b99",
  "date": 1740576987.8439455,
  "pretty_env_info": "PyTorch version: 2.5.1\nIs debug build: False\nCUDA used to build PyTorch: 12.1\nROCM used to build PyTorch: N/A\n\nOS: Red Hat Enterprise Linux release 8.10 (Ootpa) (x86_64)\nGCC version: (GCC) 8.5.0 20210514 (Red Hat 8.5.0-23)\nClang version: Could not collect\nCMake version: version 3.26.5\nLibc version: glibc-2.28\n\nPython version: 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0] (64-bit runtime)\nPython platform: Linux-4.18.0-553.el8_10.x86_64-x86_64-with-glibc2.28\nIs CUDA available: True\nCUDA runtime version: 12.1.105\nCUDA_MODULE_LOADING set to: LAZY\nGPU models and configuration: \nGPU 0: NVIDIA A100-SXM4-80GB\nGPU 1: NVIDIA A100-SXM4-80GB\n\nNvidia driver version: 560.35.05\ncuDNN version: Could not collect\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nArchitecture:        x86_64\nCPU op-mode(s):      32-bit, 64-bit\nByte Order:          Little Endian\nCPU(s):              144\nOn-line CPU(s) list: 0-143\nThread(s) per core:  2\nCore(s) per socket:  36\nSocket(s):           2\nNUMA node(s):        2\nVendor ID:           GenuineIntel\nCPU family:          6\nModel:               106\nModel name:          Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz\nStepping:            6\nCPU MHz:             2400.000\nBogoMIPS:            4800.00\nVirtualization:      VT-x\nL1d cache:           48K\nL1i cache:           32K\nL2 cache:            1280K\nL3 cache:            55296K\nNUMA node0 CPU(s):   0-35,72-107\nNUMA node1 CPU(s):   36-71,108-143\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 invpcid_single intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb intel_pt avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local split_lock_detect wbnoinvd dtherm ida arat pln pts hwp_epp avx512vbmi umip pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq rdpid fsrm md_clear pconfig flush_l1d arch_capabilities\n\nVersions of relevant libraries:\n[pip3] numpy==2.0.1\n[pip3] torch==2.5.1\n[pip3] torchaudio==2.5.1\n[pip3] torchvision==0.20.1\n[pip3] triton==3.1.0\n[conda] blas                      1.0                         mkl  \n[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch\n[conda] libjpeg-turbo             2.0.0                h9bf148f_0    pytorch\n[conda] mkl                       2023.1.0         h213fc3f_46344  \n[conda] mkl-service               2.4.0           py310h5eee18b_1  \n[conda] mkl_fft                   1.3.11          py310h5eee18b_0  \n[conda] mkl_random                1.2.8           py310h1128e8f_0  \n[conda] numpy                     2.0.1           py310h5f9d8c6_1  \n[conda] numpy-base                2.0.1           py310hb5e798b_1  \n[conda] pytorch                   2.5.1           py3.10_cuda12.1_cudnn9.1.0_0    pytorch\n[conda] pytorch-cuda              12.1                 ha16c6d3_6    pytorch\n[conda] pytorch-mutex             1.0                        cuda    pytorch\n[conda] torchaudio                2.5.1               py310_cu121    pytorch\n[conda] torchtriton               3.1.0                     py310    pytorch\n[conda] torchvision               0.20.1              py310_cu121    pytorch",
  "transformers_version": "4.49.0",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<PAD>",
    0
  ],
  "tokenizer_eos_token": [
    "<|END_OF_TURN_TOKEN|>",
    255001
  ],
  "tokenizer_bos_token": [
    "<BOS_TOKEN>",
    5
  ],
  "eot_token_id": 255001,
  "max_length": 8192,
  "task_hashes": {},
  "model_source": "hf",
  "model_name": "CohereForAI/aya-23-8B",
  "model_name_sanitized": "CohereForAI__aya-23-8B",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": false,
  "chat_template": null,
  "chat_template_sha": null,
  "start_time": 4224261.823485212,
  "end_time": 4242573.936615112,
  "total_evaluation_time_seconds": "18312.113129899837"
}