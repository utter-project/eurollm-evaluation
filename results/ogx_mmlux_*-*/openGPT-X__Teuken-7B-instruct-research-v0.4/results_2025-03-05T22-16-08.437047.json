{
  "results": {
    "ogx_mmlux_sv-world_religions": {
      "acc,none": 0.6374269005847953,
      "acc_stderr,none": 0.0368713061556206,
      "alias": "ogx_mmlux_sv-world_religions"
    },
    "ogx_mmlux_sv-virology": {
      "acc,none": 0.3855421686746988,
      "acc_stderr,none": 0.037891344246115496,
      "alias": "ogx_mmlux_sv-virology"
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "acc,none": 0.61,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_sv-us_foreign_policy"
    },
    "ogx_mmlux_sv-sociology": {
      "acc,none": 0.5074626865671642,
      "acc_stderr,none": 0.03535140084276719,
      "alias": "ogx_mmlux_sv-sociology"
    },
    "ogx_mmlux_sv-security_studies": {
      "acc,none": 0.2897959183673469,
      "acc_stderr,none": 0.029043088683304342,
      "alias": "ogx_mmlux_sv-security_studies"
    },
    "ogx_mmlux_sv-public_relations": {
      "acc,none": 0.5636363636363636,
      "acc_stderr,none": 0.04750185058907297,
      "alias": "ogx_mmlux_sv-public_relations"
    },
    "ogx_mmlux_sv-professional_psychology": {
      "acc,none": 0.39705882352941174,
      "acc_stderr,none": 0.019794488900024113,
      "alias": "ogx_mmlux_sv-professional_psychology"
    },
    "ogx_mmlux_sv-professional_medicine": {
      "acc,none": 0.3014705882352941,
      "acc_stderr,none": 0.027875982114273168,
      "alias": "ogx_mmlux_sv-professional_medicine"
    },
    "ogx_mmlux_sv-professional_law": {
      "acc,none": 0.31290743155149936,
      "acc_stderr,none": 0.011842529823062995,
      "alias": "ogx_mmlux_sv-professional_law"
    },
    "ogx_mmlux_sv-professional_accounting": {
      "acc,none": 0.26595744680851063,
      "acc_stderr,none": 0.026358065698880585,
      "alias": "ogx_mmlux_sv-professional_accounting"
    },
    "ogx_mmlux_sv-prehistory": {
      "acc,none": 0.4567901234567901,
      "acc_stderr,none": 0.02771666165019404,
      "alias": "ogx_mmlux_sv-prehistory"
    },
    "ogx_mmlux_sv-philosophy": {
      "acc,none": 0.40836012861736337,
      "acc_stderr,none": 0.027917050748484624,
      "alias": "ogx_mmlux_sv-philosophy"
    },
    "ogx_mmlux_sv-nutrition": {
      "acc,none": 0.4411764705882353,
      "acc_stderr,none": 0.028431095444176643,
      "alias": "ogx_mmlux_sv-nutrition"
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "acc,none": 0.23798882681564246,
      "acc_stderr,none": 0.014242630070574885,
      "alias": "ogx_mmlux_sv-moral_scenarios"
    },
    "ogx_mmlux_sv-moral_disputes": {
      "acc,none": 0.43641618497109824,
      "acc_stderr,none": 0.026700545424943687,
      "alias": "ogx_mmlux_sv-moral_disputes"
    },
    "ogx_mmlux_sv-miscellaneous": {
      "acc,none": 0.5440613026819924,
      "acc_stderr,none": 0.01781040392543536,
      "alias": "ogx_mmlux_sv-miscellaneous"
    },
    "ogx_mmlux_sv-medical_genetics": {
      "acc,none": 0.56,
      "acc_stderr,none": 0.049888765156985884,
      "alias": "ogx_mmlux_sv-medical_genetics"
    },
    "ogx_mmlux_sv-marketing": {
      "acc,none": 0.6196581196581197,
      "acc_stderr,none": 0.03180425204384099,
      "alias": "ogx_mmlux_sv-marketing"
    },
    "ogx_mmlux_sv-management": {
      "acc,none": 0.3300970873786408,
      "acc_stderr,none": 0.0465614711001235,
      "alias": "ogx_mmlux_sv-management"
    },
    "ogx_mmlux_sv-machine_learning": {
      "acc,none": 0.3392857142857143,
      "acc_stderr,none": 0.04493949068613539,
      "alias": "ogx_mmlux_sv-machine_learning"
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "acc,none": 0.37423312883435583,
      "acc_stderr,none": 0.03802068102899615,
      "alias": "ogx_mmlux_sv-logical_fallacies"
    },
    "ogx_mmlux_sv-jurisprudence": {
      "acc,none": 0.37962962962962965,
      "acc_stderr,none": 0.04691521224077742,
      "alias": "ogx_mmlux_sv-jurisprudence"
    },
    "ogx_mmlux_sv-international_law": {
      "acc,none": 0.6033057851239669,
      "acc_stderr,none": 0.044658697805310094,
      "alias": "ogx_mmlux_sv-international_law"
    },
    "ogx_mmlux_sv-human_sexuality": {
      "acc,none": 0.48091603053435117,
      "acc_stderr,none": 0.04382094705550988,
      "alias": "ogx_mmlux_sv-human_sexuality"
    },
    "ogx_mmlux_sv-human_aging": {
      "acc,none": 0.47533632286995514,
      "acc_stderr,none": 0.03351695167652628,
      "alias": "ogx_mmlux_sv-human_aging"
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "acc,none": 0.4936708860759494,
      "acc_stderr,none": 0.03254462010767859,
      "alias": "ogx_mmlux_sv-high_school_world_history"
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "acc,none": 0.45098039215686275,
      "acc_stderr,none": 0.03492406104163613,
      "alias": "ogx_mmlux_sv-high_school_us_history"
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "acc,none": 0.18981481481481483,
      "acc_stderr,none": 0.026744714834691936,
      "alias": "ogx_mmlux_sv-high_school_statistics"
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "acc,none": 0.47155963302752296,
      "acc_stderr,none": 0.021402615697348047,
      "alias": "ogx_mmlux_sv-high_school_psychology"
    },
    "ogx_mmlux_sv-high_school_physics": {
      "acc,none": 0.2582781456953642,
      "acc_stderr,none": 0.035737053147634576,
      "alias": "ogx_mmlux_sv-high_school_physics"
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "acc,none": 0.3403361344537815,
      "acc_stderr,none": 0.030778057422931673,
      "alias": "ogx_mmlux_sv-high_school_microeconomics"
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "acc,none": 0.2777777777777778,
      "acc_stderr,none": 0.027309140588230182,
      "alias": "ogx_mmlux_sv-high_school_mathematics"
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "acc,none": 0.3153846153846154,
      "acc_stderr,none": 0.02355964698318994,
      "alias": "ogx_mmlux_sv-high_school_macroeconomics"
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "acc,none": 0.36787564766839376,
      "acc_stderr,none": 0.03480175668466036,
      "alias": "ogx_mmlux_sv-high_school_government_and_politics"
    },
    "ogx_mmlux_sv-high_school_geography": {
      "acc,none": 0.4595959595959596,
      "acc_stderr,none": 0.035507024651313425,
      "alias": "ogx_mmlux_sv-high_school_geography"
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "acc,none": 0.5272727272727272,
      "acc_stderr,none": 0.03898531605579419,
      "alias": "ogx_mmlux_sv-high_school_european_history"
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.04878317312145633,
      "alias": "ogx_mmlux_sv-high_school_computer_science"
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "acc,none": 0.23645320197044334,
      "acc_stderr,none": 0.029896114291733552,
      "alias": "ogx_mmlux_sv-high_school_chemistry"
    },
    "ogx_mmlux_sv-high_school_biology": {
      "acc,none": 0.4064516129032258,
      "acc_stderr,none": 0.0279417273462563,
      "alias": "ogx_mmlux_sv-high_school_biology"
    },
    "ogx_mmlux_sv-global_facts": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.04878317312145633,
      "alias": "ogx_mmlux_sv-global_facts"
    },
    "ogx_mmlux_sv-formal_logic": {
      "acc,none": 0.2698412698412698,
      "acc_stderr,none": 0.03970158273235171,
      "alias": "ogx_mmlux_sv-formal_logic"
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "acc,none": 0.2698412698412698,
      "acc_stderr,none": 0.022860838309232072,
      "alias": "ogx_mmlux_sv-elementary_mathematics"
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "acc,none": 0.3586206896551724,
      "acc_stderr,none": 0.039966295748767186,
      "alias": "ogx_mmlux_sv-electrical_engineering"
    },
    "ogx_mmlux_sv-econometrics": {
      "acc,none": 0.2631578947368421,
      "acc_stderr,none": 0.0414243971948936,
      "alias": "ogx_mmlux_sv-econometrics"
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "acc,none": 0.3574468085106383,
      "acc_stderr,none": 0.03132941789476425,
      "alias": "ogx_mmlux_sv-conceptual_physics"
    },
    "ogx_mmlux_sv-computer_security": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_sv-computer_security"
    },
    "ogx_mmlux_sv-college_physics": {
      "acc,none": 0.17647058823529413,
      "acc_stderr,none": 0.037932811853078084,
      "alias": "ogx_mmlux_sv-college_physics"
    },
    "ogx_mmlux_sv-college_medicine": {
      "acc,none": 0.3468208092485549,
      "acc_stderr,none": 0.036291466701596636,
      "alias": "ogx_mmlux_sv-college_medicine"
    },
    "ogx_mmlux_sv-college_mathematics": {
      "acc,none": 0.21,
      "acc_stderr,none": 0.040936018074033256,
      "alias": "ogx_mmlux_sv-college_mathematics"
    },
    "ogx_mmlux_sv-college_computer_science": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_sv-college_computer_science"
    },
    "ogx_mmlux_sv-college_chemistry": {
      "acc,none": 0.18,
      "acc_stderr,none": 0.038612291966536955,
      "alias": "ogx_mmlux_sv-college_chemistry"
    },
    "ogx_mmlux_sv-college_biology": {
      "acc,none": 0.4375,
      "acc_stderr,none": 0.04148415739394154,
      "alias": "ogx_mmlux_sv-college_biology"
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "acc,none": 0.37358490566037733,
      "acc_stderr,none": 0.029773082713319878,
      "alias": "ogx_mmlux_sv-clinical_knowledge"
    },
    "ogx_mmlux_sv-business_ethics": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_sv-business_ethics"
    },
    "ogx_mmlux_sv-astronomy": {
      "acc,none": 0.40131578947368424,
      "acc_stderr,none": 0.039889037033362836,
      "alias": "ogx_mmlux_sv-astronomy"
    },
    "ogx_mmlux_sv-anatomy": {
      "acc,none": 0.42962962962962964,
      "acc_stderr,none": 0.04276349494376599,
      "alias": "ogx_mmlux_sv-anatomy"
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252606,
      "alias": "ogx_mmlux_sv-abstract_algebra"
    },
    "ogx_mmlux_sl-world_religions": {
      "acc,none": 0.5380116959064327,
      "acc_stderr,none": 0.03823727092882307,
      "alias": "ogx_mmlux_sl-world_religions"
    },
    "ogx_mmlux_sl-virology": {
      "acc,none": 0.3313253012048193,
      "acc_stderr,none": 0.03664314777288085,
      "alias": "ogx_mmlux_sl-virology"
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "acc,none": 0.53,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_sl-us_foreign_policy"
    },
    "ogx_mmlux_sl-sociology": {
      "acc,none": 0.4577114427860697,
      "acc_stderr,none": 0.035228658640995975,
      "alias": "ogx_mmlux_sl-sociology"
    },
    "ogx_mmlux_sl-security_studies": {
      "acc,none": 0.2693877551020408,
      "acc_stderr,none": 0.02840125202902294,
      "alias": "ogx_mmlux_sl-security_studies"
    },
    "ogx_mmlux_sl-public_relations": {
      "acc,none": 0.37272727272727274,
      "acc_stderr,none": 0.04631381319425464,
      "alias": "ogx_mmlux_sl-public_relations"
    },
    "ogx_mmlux_sl-professional_psychology": {
      "acc,none": 0.3284313725490196,
      "acc_stderr,none": 0.01899970738316267,
      "alias": "ogx_mmlux_sl-professional_psychology"
    },
    "ogx_mmlux_sl-professional_medicine": {
      "acc,none": 0.1948529411764706,
      "acc_stderr,none": 0.024060599423487417,
      "alias": "ogx_mmlux_sl-professional_medicine"
    },
    "ogx_mmlux_sl-professional_law": {
      "acc,none": 0.2940026075619296,
      "acc_stderr,none": 0.011636062953698609,
      "alias": "ogx_mmlux_sl-professional_law"
    },
    "ogx_mmlux_sl-professional_accounting": {
      "acc,none": 0.2553191489361702,
      "acc_stderr,none": 0.02601199293090202,
      "alias": "ogx_mmlux_sl-professional_accounting"
    },
    "ogx_mmlux_sl-prehistory": {
      "acc,none": 0.3765432098765432,
      "acc_stderr,none": 0.02695934451874779,
      "alias": "ogx_mmlux_sl-prehistory"
    },
    "ogx_mmlux_sl-philosophy": {
      "acc,none": 0.3054662379421222,
      "acc_stderr,none": 0.026160584450140478,
      "alias": "ogx_mmlux_sl-philosophy"
    },
    "ogx_mmlux_sl-nutrition": {
      "acc,none": 0.4019607843137255,
      "acc_stderr,none": 0.028074158947600666,
      "alias": "ogx_mmlux_sl-nutrition"
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "acc,none": 0.23798882681564246,
      "acc_stderr,none": 0.014242630070574885,
      "alias": "ogx_mmlux_sl-moral_scenarios"
    },
    "ogx_mmlux_sl-moral_disputes": {
      "acc,none": 0.40173410404624277,
      "acc_stderr,none": 0.026394104177643634,
      "alias": "ogx_mmlux_sl-moral_disputes"
    },
    "ogx_mmlux_sl-miscellaneous": {
      "acc,none": 0.44572158365261816,
      "acc_stderr,none": 0.0177742972824795,
      "alias": "ogx_mmlux_sl-miscellaneous"
    },
    "ogx_mmlux_sl-medical_genetics": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_sl-medical_genetics"
    },
    "ogx_mmlux_sl-marketing": {
      "acc,none": 0.5555555555555556,
      "acc_stderr,none": 0.03255326307272487,
      "alias": "ogx_mmlux_sl-marketing"
    },
    "ogx_mmlux_sl-management": {
      "acc,none": 0.2621359223300971,
      "acc_stderr,none": 0.04354631077260595,
      "alias": "ogx_mmlux_sl-management"
    },
    "ogx_mmlux_sl-machine_learning": {
      "acc,none": 0.3392857142857143,
      "acc_stderr,none": 0.04493949068613539,
      "alias": "ogx_mmlux_sl-machine_learning"
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "acc,none": 0.26380368098159507,
      "acc_stderr,none": 0.03462419931615624,
      "alias": "ogx_mmlux_sl-logical_fallacies"
    },
    "ogx_mmlux_sl-jurisprudence": {
      "acc,none": 0.37962962962962965,
      "acc_stderr,none": 0.04691521224077742,
      "alias": "ogx_mmlux_sl-jurisprudence"
    },
    "ogx_mmlux_sl-international_law": {
      "acc,none": 0.5702479338842975,
      "acc_stderr,none": 0.04519082021319773,
      "alias": "ogx_mmlux_sl-international_law"
    },
    "ogx_mmlux_sl-human_sexuality": {
      "acc,none": 0.45038167938931295,
      "acc_stderr,none": 0.04363643698524779,
      "alias": "ogx_mmlux_sl-human_sexuality"
    },
    "ogx_mmlux_sl-human_aging": {
      "acc,none": 0.43946188340807174,
      "acc_stderr,none": 0.03331092511038179,
      "alias": "ogx_mmlux_sl-human_aging"
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "acc,none": 0.4388185654008439,
      "acc_stderr,none": 0.032302649315470375,
      "alias": "ogx_mmlux_sl-high_school_world_history"
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "acc,none": 0.37745098039215685,
      "acc_stderr,none": 0.03402272044340703,
      "alias": "ogx_mmlux_sl-high_school_us_history"
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "acc,none": 0.16666666666666666,
      "acc_stderr,none": 0.02541642838876747,
      "alias": "ogx_mmlux_sl-high_school_statistics"
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "acc,none": 0.4018348623853211,
      "acc_stderr,none": 0.021020106172997006,
      "alias": "ogx_mmlux_sl-high_school_psychology"
    },
    "ogx_mmlux_sl-high_school_physics": {
      "acc,none": 0.24503311258278146,
      "acc_stderr,none": 0.035118075718047245,
      "alias": "ogx_mmlux_sl-high_school_physics"
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "acc,none": 0.28991596638655465,
      "acc_stderr,none": 0.029472485833136077,
      "alias": "ogx_mmlux_sl-high_school_microeconomics"
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "acc,none": 0.23333333333333334,
      "acc_stderr,none": 0.02578787422095931,
      "alias": "ogx_mmlux_sl-high_school_mathematics"
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "acc,none": 0.3128205128205128,
      "acc_stderr,none": 0.02350757902064536,
      "alias": "ogx_mmlux_sl-high_school_macroeconomics"
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "acc,none": 0.33678756476683935,
      "acc_stderr,none": 0.034107802518361825,
      "alias": "ogx_mmlux_sl-high_school_government_and_politics"
    },
    "ogx_mmlux_sl-high_school_geography": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.0347327959083696,
      "alias": "ogx_mmlux_sl-high_school_geography"
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "acc,none": 0.43636363636363634,
      "acc_stderr,none": 0.03872592983524754,
      "alias": "ogx_mmlux_sl-high_school_european_history"
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_sl-high_school_computer_science"
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "acc,none": 0.2561576354679803,
      "acc_stderr,none": 0.0307127300709826,
      "alias": "ogx_mmlux_sl-high_school_chemistry"
    },
    "ogx_mmlux_sl-high_school_biology": {
      "acc,none": 0.34838709677419355,
      "acc_stderr,none": 0.027104826328100944,
      "alias": "ogx_mmlux_sl-high_school_biology"
    },
    "ogx_mmlux_sl-global_facts": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_sl-global_facts"
    },
    "ogx_mmlux_sl-formal_logic": {
      "acc,none": 0.21428571428571427,
      "acc_stderr,none": 0.03670066451047182,
      "alias": "ogx_mmlux_sl-formal_logic"
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "acc,none": 0.24867724867724866,
      "acc_stderr,none": 0.022261817692400158,
      "alias": "ogx_mmlux_sl-elementary_mathematics"
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "acc,none": 0.3448275862068966,
      "acc_stderr,none": 0.03960933549451208,
      "alias": "ogx_mmlux_sl-electrical_engineering"
    },
    "ogx_mmlux_sl-econometrics": {
      "acc,none": 0.2543859649122807,
      "acc_stderr,none": 0.04096985139843671,
      "alias": "ogx_mmlux_sl-econometrics"
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "acc,none": 0.37872340425531914,
      "acc_stderr,none": 0.03170995606040655,
      "alias": "ogx_mmlux_sl-conceptual_physics"
    },
    "ogx_mmlux_sl-computer_security": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_sl-computer_security"
    },
    "ogx_mmlux_sl-college_physics": {
      "acc,none": 0.23529411764705882,
      "acc_stderr,none": 0.042207736591714534,
      "alias": "ogx_mmlux_sl-college_physics"
    },
    "ogx_mmlux_sl-college_medicine": {
      "acc,none": 0.28901734104046245,
      "acc_stderr,none": 0.03456425745087,
      "alias": "ogx_mmlux_sl-college_medicine"
    },
    "ogx_mmlux_sl-college_mathematics": {
      "acc,none": 0.21,
      "acc_stderr,none": 0.04093601807403326,
      "alias": "ogx_mmlux_sl-college_mathematics"
    },
    "ogx_mmlux_sl-college_computer_science": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_sl-college_computer_science"
    },
    "ogx_mmlux_sl-college_chemistry": {
      "acc,none": 0.23,
      "acc_stderr,none": 0.04229525846816506,
      "alias": "ogx_mmlux_sl-college_chemistry"
    },
    "ogx_mmlux_sl-college_biology": {
      "acc,none": 0.3402777777777778,
      "acc_stderr,none": 0.03962135573486219,
      "alias": "ogx_mmlux_sl-college_biology"
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "acc,none": 0.32452830188679244,
      "acc_stderr,none": 0.02881561571343211,
      "alias": "ogx_mmlux_sl-clinical_knowledge"
    },
    "ogx_mmlux_sl-business_ethics": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_sl-business_ethics"
    },
    "ogx_mmlux_sl-astronomy": {
      "acc,none": 0.32894736842105265,
      "acc_stderr,none": 0.03823428969926604,
      "alias": "ogx_mmlux_sl-astronomy"
    },
    "ogx_mmlux_sl-anatomy": {
      "acc,none": 0.35555555555555557,
      "acc_stderr,none": 0.04135176749720386,
      "alias": "ogx_mmlux_sl-anatomy"
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.046482319871173156,
      "alias": "ogx_mmlux_sl-abstract_algebra"
    },
    "ogx_mmlux_sk-world_religions": {
      "acc,none": 0.5964912280701754,
      "acc_stderr,none": 0.03762738699917057,
      "alias": "ogx_mmlux_sk-world_religions"
    },
    "ogx_mmlux_sk-virology": {
      "acc,none": 0.35542168674698793,
      "acc_stderr,none": 0.03726214354322415,
      "alias": "ogx_mmlux_sk-virology"
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "acc,none": 0.56,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_sk-us_foreign_policy"
    },
    "ogx_mmlux_sk-sociology": {
      "acc,none": 0.5323383084577115,
      "acc_stderr,none": 0.035281314729336065,
      "alias": "ogx_mmlux_sk-sociology"
    },
    "ogx_mmlux_sk-security_studies": {
      "acc,none": 0.3142857142857143,
      "acc_stderr,none": 0.029719329422417468,
      "alias": "ogx_mmlux_sk-security_studies"
    },
    "ogx_mmlux_sk-public_relations": {
      "acc,none": 0.39090909090909093,
      "acc_stderr,none": 0.04673752333670239,
      "alias": "ogx_mmlux_sk-public_relations"
    },
    "ogx_mmlux_sk-professional_psychology": {
      "acc,none": 0.40032679738562094,
      "acc_stderr,none": 0.019821843688271768,
      "alias": "ogx_mmlux_sk-professional_psychology"
    },
    "ogx_mmlux_sk-professional_medicine": {
      "acc,none": 0.24632352941176472,
      "acc_stderr,none": 0.02617343857052,
      "alias": "ogx_mmlux_sk-professional_medicine"
    },
    "ogx_mmlux_sk-professional_law": {
      "acc,none": 0.3155149934810952,
      "acc_stderr,none": 0.011869184843058643,
      "alias": "ogx_mmlux_sk-professional_law"
    },
    "ogx_mmlux_sk-professional_accounting": {
      "acc,none": 0.3049645390070922,
      "acc_stderr,none": 0.027464708442022152,
      "alias": "ogx_mmlux_sk-professional_accounting"
    },
    "ogx_mmlux_sk-prehistory": {
      "acc,none": 0.3950617283950617,
      "acc_stderr,none": 0.027201117666925657,
      "alias": "ogx_mmlux_sk-prehistory"
    },
    "ogx_mmlux_sk-philosophy": {
      "acc,none": 0.4212218649517685,
      "acc_stderr,none": 0.028043399858210624,
      "alias": "ogx_mmlux_sk-philosophy"
    },
    "ogx_mmlux_sk-nutrition": {
      "acc,none": 0.4542483660130719,
      "acc_stderr,none": 0.028509807802626567,
      "alias": "ogx_mmlux_sk-nutrition"
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "acc,none": 0.24134078212290502,
      "acc_stderr,none": 0.014310999547961452,
      "alias": "ogx_mmlux_sk-moral_scenarios"
    },
    "ogx_mmlux_sk-moral_disputes": {
      "acc,none": 0.41040462427745666,
      "acc_stderr,none": 0.026483392042098177,
      "alias": "ogx_mmlux_sk-moral_disputes"
    },
    "ogx_mmlux_sk-miscellaneous": {
      "acc,none": 0.4955300127713921,
      "acc_stderr,none": 0.017879248970584377,
      "alias": "ogx_mmlux_sk-miscellaneous"
    },
    "ogx_mmlux_sk-medical_genetics": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_sk-medical_genetics"
    },
    "ogx_mmlux_sk-marketing": {
      "acc,none": 0.5982905982905983,
      "acc_stderr,none": 0.03211693751051622,
      "alias": "ogx_mmlux_sk-marketing"
    },
    "ogx_mmlux_sk-management": {
      "acc,none": 0.2912621359223301,
      "acc_stderr,none": 0.04498676320572922,
      "alias": "ogx_mmlux_sk-management"
    },
    "ogx_mmlux_sk-machine_learning": {
      "acc,none": 0.35714285714285715,
      "acc_stderr,none": 0.04547960999764376,
      "alias": "ogx_mmlux_sk-machine_learning"
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "acc,none": 0.34355828220858897,
      "acc_stderr,none": 0.03731133519673891,
      "alias": "ogx_mmlux_sk-logical_fallacies"
    },
    "ogx_mmlux_sk-jurisprudence": {
      "acc,none": 0.4537037037037037,
      "acc_stderr,none": 0.04812917324536823,
      "alias": "ogx_mmlux_sk-jurisprudence"
    },
    "ogx_mmlux_sk-international_law": {
      "acc,none": 0.628099173553719,
      "acc_stderr,none": 0.04412015806624502,
      "alias": "ogx_mmlux_sk-international_law"
    },
    "ogx_mmlux_sk-human_sexuality": {
      "acc,none": 0.4580152671755725,
      "acc_stderr,none": 0.04369802690578757,
      "alias": "ogx_mmlux_sk-human_sexuality"
    },
    "ogx_mmlux_sk-human_aging": {
      "acc,none": 0.4618834080717489,
      "acc_stderr,none": 0.033460150119732274,
      "alias": "ogx_mmlux_sk-human_aging"
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "acc,none": 0.46835443037974683,
      "acc_stderr,none": 0.03248197400511075,
      "alias": "ogx_mmlux_sk-high_school_world_history"
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "acc,none": 0.44607843137254904,
      "acc_stderr,none": 0.03488845451304974,
      "alias": "ogx_mmlux_sk-high_school_us_history"
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "acc,none": 0.19444444444444445,
      "acc_stderr,none": 0.02699145450203672,
      "alias": "ogx_mmlux_sk-high_school_statistics"
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "acc,none": 0.44770642201834865,
      "acc_stderr,none": 0.02131975496242546,
      "alias": "ogx_mmlux_sk-high_school_psychology"
    },
    "ogx_mmlux_sk-high_school_physics": {
      "acc,none": 0.26490066225165565,
      "acc_stderr,none": 0.03603038545360383,
      "alias": "ogx_mmlux_sk-high_school_physics"
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "acc,none": 0.31932773109243695,
      "acc_stderr,none": 0.030283995525884396,
      "alias": "ogx_mmlux_sk-high_school_microeconomics"
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "acc,none": 0.2814814814814815,
      "acc_stderr,none": 0.02742001935094528,
      "alias": "ogx_mmlux_sk-high_school_mathematics"
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "acc,none": 0.32051282051282054,
      "acc_stderr,none": 0.023661296393964273,
      "alias": "ogx_mmlux_sk-high_school_macroeconomics"
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "acc,none": 0.39896373056994816,
      "acc_stderr,none": 0.03533999094065696,
      "alias": "ogx_mmlux_sk-high_school_government_and_politics"
    },
    "ogx_mmlux_sk-high_school_geography": {
      "acc,none": 0.41919191919191917,
      "acc_stderr,none": 0.035155207286704175,
      "alias": "ogx_mmlux_sk-high_school_geography"
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "acc,none": 0.49696969696969695,
      "acc_stderr,none": 0.03904272341431856,
      "alias": "ogx_mmlux_sk-high_school_european_history"
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.04975698519562428,
      "alias": "ogx_mmlux_sk-high_school_computer_science"
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "acc,none": 0.24630541871921183,
      "acc_stderr,none": 0.030315099285617732,
      "alias": "ogx_mmlux_sk-high_school_chemistry"
    },
    "ogx_mmlux_sk-high_school_biology": {
      "acc,none": 0.4161290322580645,
      "acc_stderr,none": 0.028040981380761533,
      "alias": "ogx_mmlux_sk-high_school_biology"
    },
    "ogx_mmlux_sk-global_facts": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.046882617226215034,
      "alias": "ogx_mmlux_sk-global_facts"
    },
    "ogx_mmlux_sk-formal_logic": {
      "acc,none": 0.30952380952380953,
      "acc_stderr,none": 0.04134913018303318,
      "alias": "ogx_mmlux_sk-formal_logic"
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "acc,none": 0.25132275132275134,
      "acc_stderr,none": 0.022340482339643895,
      "alias": "ogx_mmlux_sk-elementary_mathematics"
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "acc,none": 0.38620689655172413,
      "acc_stderr,none": 0.04057324734419036,
      "alias": "ogx_mmlux_sk-electrical_engineering"
    },
    "ogx_mmlux_sk-econometrics": {
      "acc,none": 0.2894736842105263,
      "acc_stderr,none": 0.04266339443159394,
      "alias": "ogx_mmlux_sk-econometrics"
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "acc,none": 0.35319148936170214,
      "acc_stderr,none": 0.03124532520276193,
      "alias": "ogx_mmlux_sk-conceptual_physics"
    },
    "ogx_mmlux_sk-computer_security": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_sk-computer_security"
    },
    "ogx_mmlux_sk-college_physics": {
      "acc,none": 0.22549019607843138,
      "acc_stderr,none": 0.041583075330832865,
      "alias": "ogx_mmlux_sk-college_physics"
    },
    "ogx_mmlux_sk-college_medicine": {
      "acc,none": 0.3179190751445087,
      "acc_stderr,none": 0.03550683989165582,
      "alias": "ogx_mmlux_sk-college_medicine"
    },
    "ogx_mmlux_sk-college_mathematics": {
      "acc,none": 0.24,
      "acc_stderr,none": 0.042923469599092816,
      "alias": "ogx_mmlux_sk-college_mathematics"
    },
    "ogx_mmlux_sk-college_computer_science": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.047258156262526045,
      "alias": "ogx_mmlux_sk-college_computer_science"
    },
    "ogx_mmlux_sk-college_chemistry": {
      "acc,none": 0.2,
      "acc_stderr,none": 0.040201512610368445,
      "alias": "ogx_mmlux_sk-college_chemistry"
    },
    "ogx_mmlux_sk-college_biology": {
      "acc,none": 0.3819444444444444,
      "acc_stderr,none": 0.040629907841466674,
      "alias": "ogx_mmlux_sk-college_biology"
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "acc,none": 0.36981132075471695,
      "acc_stderr,none": 0.029711421880107926,
      "alias": "ogx_mmlux_sk-clinical_knowledge"
    },
    "ogx_mmlux_sk-business_ethics": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_sk-business_ethics"
    },
    "ogx_mmlux_sk-astronomy": {
      "acc,none": 0.35526315789473684,
      "acc_stderr,none": 0.03894734487013317,
      "alias": "ogx_mmlux_sk-astronomy"
    },
    "ogx_mmlux_sk-anatomy": {
      "acc,none": 0.3925925925925926,
      "acc_stderr,none": 0.04218506215368879,
      "alias": "ogx_mmlux_sk-anatomy"
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_sk-abstract_algebra"
    },
    "ogx_mmlux_ro-world_religions": {
      "acc,none": 0.5847953216374269,
      "acc_stderr,none": 0.03779275945503201,
      "alias": "ogx_mmlux_ro-world_religions"
    },
    "ogx_mmlux_ro-virology": {
      "acc,none": 0.40963855421686746,
      "acc_stderr,none": 0.038284011150790234,
      "alias": "ogx_mmlux_ro-virology"
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "acc,none": 0.55,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_ro-us_foreign_policy"
    },
    "ogx_mmlux_ro-sociology": {
      "acc,none": 0.5174129353233831,
      "acc_stderr,none": 0.03533389234739245,
      "alias": "ogx_mmlux_ro-sociology"
    },
    "ogx_mmlux_ro-security_studies": {
      "acc,none": 0.27755102040816326,
      "acc_stderr,none": 0.02866685779027465,
      "alias": "ogx_mmlux_ro-security_studies"
    },
    "ogx_mmlux_ro-public_relations": {
      "acc,none": 0.4818181818181818,
      "acc_stderr,none": 0.04785964010794916,
      "alias": "ogx_mmlux_ro-public_relations"
    },
    "ogx_mmlux_ro-professional_psychology": {
      "acc,none": 0.36437908496732024,
      "acc_stderr,none": 0.019469518221573695,
      "alias": "ogx_mmlux_ro-professional_psychology"
    },
    "ogx_mmlux_ro-professional_medicine": {
      "acc,none": 0.24632352941176472,
      "acc_stderr,none": 0.02617343857052,
      "alias": "ogx_mmlux_ro-professional_medicine"
    },
    "ogx_mmlux_ro-professional_law": {
      "acc,none": 0.29986962190352023,
      "acc_stderr,none": 0.011702660860193994,
      "alias": "ogx_mmlux_ro-professional_law"
    },
    "ogx_mmlux_ro-professional_accounting": {
      "acc,none": 0.2765957446808511,
      "acc_stderr,none": 0.02668456434046101,
      "alias": "ogx_mmlux_ro-professional_accounting"
    },
    "ogx_mmlux_ro-prehistory": {
      "acc,none": 0.4104938271604938,
      "acc_stderr,none": 0.027371350925124764,
      "alias": "ogx_mmlux_ro-prehistory"
    },
    "ogx_mmlux_ro-philosophy": {
      "acc,none": 0.3440514469453376,
      "acc_stderr,none": 0.026981478043648043,
      "alias": "ogx_mmlux_ro-philosophy"
    },
    "ogx_mmlux_ro-nutrition": {
      "acc,none": 0.434640522875817,
      "acc_stderr,none": 0.028384256704883034,
      "alias": "ogx_mmlux_ro-nutrition"
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "acc,none": 0.23575418994413408,
      "acc_stderr,none": 0.014196375686290804,
      "alias": "ogx_mmlux_ro-moral_scenarios"
    },
    "ogx_mmlux_ro-moral_disputes": {
      "acc,none": 0.38439306358381503,
      "acc_stderr,none": 0.026189666966272035,
      "alias": "ogx_mmlux_ro-moral_disputes"
    },
    "ogx_mmlux_ro-miscellaneous": {
      "acc,none": 0.49936143039591313,
      "acc_stderr,none": 0.017879948914431686,
      "alias": "ogx_mmlux_ro-miscellaneous"
    },
    "ogx_mmlux_ro-medical_genetics": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_ro-medical_genetics"
    },
    "ogx_mmlux_ro-marketing": {
      "acc,none": 0.6111111111111112,
      "acc_stderr,none": 0.031937057262002924,
      "alias": "ogx_mmlux_ro-marketing"
    },
    "ogx_mmlux_ro-management": {
      "acc,none": 0.3300970873786408,
      "acc_stderr,none": 0.0465614711001235,
      "alias": "ogx_mmlux_ro-management"
    },
    "ogx_mmlux_ro-machine_learning": {
      "acc,none": 0.3482142857142857,
      "acc_stderr,none": 0.04521829902833586,
      "alias": "ogx_mmlux_ro-machine_learning"
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "acc,none": 0.26380368098159507,
      "acc_stderr,none": 0.03462419931615623,
      "alias": "ogx_mmlux_ro-logical_fallacies"
    },
    "ogx_mmlux_ro-jurisprudence": {
      "acc,none": 0.37037037037037035,
      "acc_stderr,none": 0.04668408033024931,
      "alias": "ogx_mmlux_ro-jurisprudence"
    },
    "ogx_mmlux_ro-international_law": {
      "acc,none": 0.6033057851239669,
      "acc_stderr,none": 0.04465869780531009,
      "alias": "ogx_mmlux_ro-international_law"
    },
    "ogx_mmlux_ro-human_sexuality": {
      "acc,none": 0.46564885496183206,
      "acc_stderr,none": 0.043749285605997376,
      "alias": "ogx_mmlux_ro-human_sexuality"
    },
    "ogx_mmlux_ro-human_aging": {
      "acc,none": 0.484304932735426,
      "acc_stderr,none": 0.0335412657542081,
      "alias": "ogx_mmlux_ro-human_aging"
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "acc,none": 0.45147679324894513,
      "acc_stderr,none": 0.032393600173974704,
      "alias": "ogx_mmlux_ro-high_school_world_history"
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "acc,none": 0.4215686274509804,
      "acc_stderr,none": 0.03465868196380758,
      "alias": "ogx_mmlux_ro-high_school_us_history"
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "acc,none": 0.18055555555555555,
      "acc_stderr,none": 0.02623287897149166,
      "alias": "ogx_mmlux_ro-high_school_statistics"
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "acc,none": 0.42385321100917434,
      "acc_stderr,none": 0.02118726320908752,
      "alias": "ogx_mmlux_ro-high_school_psychology"
    },
    "ogx_mmlux_ro-high_school_physics": {
      "acc,none": 0.2119205298013245,
      "acc_stderr,none": 0.03336767086567977,
      "alias": "ogx_mmlux_ro-high_school_physics"
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "acc,none": 0.29831932773109243,
      "acc_stderr,none": 0.02971914287634286,
      "alias": "ogx_mmlux_ro-high_school_microeconomics"
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "acc,none": 0.22962962962962963,
      "acc_stderr,none": 0.02564410863926763,
      "alias": "ogx_mmlux_ro-high_school_mathematics"
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "acc,none": 0.30256410256410254,
      "acc_stderr,none": 0.02329088805377272,
      "alias": "ogx_mmlux_ro-high_school_macroeconomics"
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "acc,none": 0.3471502590673575,
      "acc_stderr,none": 0.03435696168361355,
      "alias": "ogx_mmlux_ro-high_school_government_and_politics"
    },
    "ogx_mmlux_ro-high_school_geography": {
      "acc,none": 0.41919191919191917,
      "acc_stderr,none": 0.035155207286704175,
      "alias": "ogx_mmlux_ro-high_school_geography"
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "acc,none": 0.4303030303030303,
      "acc_stderr,none": 0.03866225962879077,
      "alias": "ogx_mmlux_ro-high_school_european_history"
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_ro-high_school_computer_science"
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "acc,none": 0.2660098522167488,
      "acc_stderr,none": 0.031089826002937523,
      "alias": "ogx_mmlux_ro-high_school_chemistry"
    },
    "ogx_mmlux_ro-high_school_biology": {
      "acc,none": 0.3870967741935484,
      "acc_stderr,none": 0.027709359675032484,
      "alias": "ogx_mmlux_ro-high_school_biology"
    },
    "ogx_mmlux_ro-global_facts": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_ro-global_facts"
    },
    "ogx_mmlux_ro-formal_logic": {
      "acc,none": 0.2619047619047619,
      "acc_stderr,none": 0.03932537680392872,
      "alias": "ogx_mmlux_ro-formal_logic"
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "acc,none": 0.2566137566137566,
      "acc_stderr,none": 0.022494510767503154,
      "alias": "ogx_mmlux_ro-elementary_mathematics"
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "acc,none": 0.3793103448275862,
      "acc_stderr,none": 0.04043461861916747,
      "alias": "ogx_mmlux_ro-electrical_engineering"
    },
    "ogx_mmlux_ro-econometrics": {
      "acc,none": 0.2719298245614035,
      "acc_stderr,none": 0.04185774424022056,
      "alias": "ogx_mmlux_ro-econometrics"
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "acc,none": 0.3829787234042553,
      "acc_stderr,none": 0.03177821250236922,
      "alias": "ogx_mmlux_ro-conceptual_physics"
    },
    "ogx_mmlux_ro-computer_security": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_ro-computer_security"
    },
    "ogx_mmlux_ro-college_physics": {
      "acc,none": 0.19607843137254902,
      "acc_stderr,none": 0.03950581861179963,
      "alias": "ogx_mmlux_ro-college_physics"
    },
    "ogx_mmlux_ro-college_medicine": {
      "acc,none": 0.3236994219653179,
      "acc_stderr,none": 0.035676037996391706,
      "alias": "ogx_mmlux_ro-college_medicine"
    },
    "ogx_mmlux_ro-college_mathematics": {
      "acc,none": 0.22,
      "acc_stderr,none": 0.041633319989322695,
      "alias": "ogx_mmlux_ro-college_mathematics"
    },
    "ogx_mmlux_ro-college_computer_science": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_ro-college_computer_science"
    },
    "ogx_mmlux_ro-college_chemistry": {
      "acc,none": 0.19,
      "acc_stderr,none": 0.03942772444036623,
      "alias": "ogx_mmlux_ro-college_chemistry"
    },
    "ogx_mmlux_ro-college_biology": {
      "acc,none": 0.3819444444444444,
      "acc_stderr,none": 0.040629907841466674,
      "alias": "ogx_mmlux_ro-college_biology"
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "acc,none": 0.32075471698113206,
      "acc_stderr,none": 0.02872750295788027,
      "alias": "ogx_mmlux_ro-clinical_knowledge"
    },
    "ogx_mmlux_ro-business_ethics": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_ro-business_ethics"
    },
    "ogx_mmlux_ro-astronomy": {
      "acc,none": 0.3092105263157895,
      "acc_stderr,none": 0.037610708698674805,
      "alias": "ogx_mmlux_ro-astronomy"
    },
    "ogx_mmlux_ro-anatomy": {
      "acc,none": 0.4148148148148148,
      "acc_stderr,none": 0.04256193767901407,
      "alias": "ogx_mmlux_ro-anatomy"
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695236,
      "alias": "ogx_mmlux_ro-abstract_algebra"
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "acc,none": 0.6491228070175439,
      "acc_stderr,none": 0.0366029883404916,
      "alias": "ogx_mmlux_pt-pt-world_religions"
    },
    "ogx_mmlux_pt-pt-virology": {
      "acc,none": 0.3795180722891566,
      "acc_stderr,none": 0.037777988227480165,
      "alias": "ogx_mmlux_pt-pt-virology"
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_pt-pt-us_foreign_policy"
    },
    "ogx_mmlux_pt-pt-sociology": {
      "acc,none": 0.5522388059701493,
      "acc_stderr,none": 0.03516184772952167,
      "alias": "ogx_mmlux_pt-pt-sociology"
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "acc,none": 0.43673469387755104,
      "acc_stderr,none": 0.03175195237583322,
      "alias": "ogx_mmlux_pt-pt-security_studies"
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "acc,none": 0.44545454545454544,
      "acc_stderr,none": 0.047605488214603246,
      "alias": "ogx_mmlux_pt-pt-public_relations"
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "acc,none": 0.43137254901960786,
      "acc_stderr,none": 0.020036393768352628,
      "alias": "ogx_mmlux_pt-pt-professional_psychology"
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "acc,none": 0.28308823529411764,
      "acc_stderr,none": 0.02736586113151381,
      "alias": "ogx_mmlux_pt-pt-professional_medicine"
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "acc,none": 0.30182529335071706,
      "acc_stderr,none": 0.011724350518105891,
      "alias": "ogx_mmlux_pt-pt-professional_law"
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "acc,none": 0.25886524822695034,
      "acc_stderr,none": 0.02612957252718085,
      "alias": "ogx_mmlux_pt-pt-professional_accounting"
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "acc,none": 0.4382716049382716,
      "acc_stderr,none": 0.027607914087400487,
      "alias": "ogx_mmlux_pt-pt-prehistory"
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "acc,none": 0.4340836012861736,
      "acc_stderr,none": 0.0281502322445356,
      "alias": "ogx_mmlux_pt-pt-philosophy"
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "acc,none": 0.4477124183006536,
      "acc_stderr,none": 0.02847293847803353,
      "alias": "ogx_mmlux_pt-pt-nutrition"
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "acc,none": 0.2782122905027933,
      "acc_stderr,none": 0.014987325439963547,
      "alias": "ogx_mmlux_pt-pt-moral_scenarios"
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "acc,none": 0.4421965317919075,
      "acc_stderr,none": 0.026738603643807396,
      "alias": "ogx_mmlux_pt-pt-moral_disputes"
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "acc,none": 0.5568326947637292,
      "acc_stderr,none": 0.0177640850353484,
      "alias": "ogx_mmlux_pt-pt-miscellaneous"
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.04923659639173309,
      "alias": "ogx_mmlux_pt-pt-medical_genetics"
    },
    "ogx_mmlux_pt-pt-marketing": {
      "acc,none": 0.6452991452991453,
      "acc_stderr,none": 0.03134250486245402,
      "alias": "ogx_mmlux_pt-pt-marketing"
    },
    "ogx_mmlux_pt-pt-management": {
      "acc,none": 0.34951456310679613,
      "acc_stderr,none": 0.04721188506097172,
      "alias": "ogx_mmlux_pt-pt-management"
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "acc,none": 0.33035714285714285,
      "acc_stderr,none": 0.04464285714285714,
      "alias": "ogx_mmlux_pt-pt-machine_learning"
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "acc,none": 0.3496932515337423,
      "acc_stderr,none": 0.03746668325470021,
      "alias": "ogx_mmlux_pt-pt-logical_fallacies"
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.04766075165356461,
      "alias": "ogx_mmlux_pt-pt-jurisprudence"
    },
    "ogx_mmlux_pt-pt-international_law": {
      "acc,none": 0.628099173553719,
      "acc_stderr,none": 0.04412015806624503,
      "alias": "ogx_mmlux_pt-pt-international_law"
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "acc,none": 0.5038167938931297,
      "acc_stderr,none": 0.043851623256015534,
      "alias": "ogx_mmlux_pt-pt-human_sexuality"
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "acc,none": 0.5022421524663677,
      "acc_stderr,none": 0.033557465352232634,
      "alias": "ogx_mmlux_pt-pt-human_aging"
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "acc,none": 0.4430379746835443,
      "acc_stderr,none": 0.03233532777533484,
      "alias": "ogx_mmlux_pt-pt-high_school_world_history"
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "acc,none": 0.4362745098039216,
      "acc_stderr,none": 0.03480693138457039,
      "alias": "ogx_mmlux_pt-pt-high_school_us_history"
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "acc,none": 0.20833333333333334,
      "acc_stderr,none": 0.027696910713093936,
      "alias": "ogx_mmlux_pt-pt-high_school_statistics"
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "acc,none": 0.4917431192660551,
      "acc_stderr,none": 0.021434399918214334,
      "alias": "ogx_mmlux_pt-pt-high_school_psychology"
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "acc,none": 0.23178807947019867,
      "acc_stderr,none": 0.034454062719870546,
      "alias": "ogx_mmlux_pt-pt-high_school_physics"
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "acc,none": 0.3235294117647059,
      "acc_stderr,none": 0.030388353551886845,
      "alias": "ogx_mmlux_pt-pt-high_school_microeconomics"
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "acc,none": 0.25925925925925924,
      "acc_stderr,none": 0.02671924078371217,
      "alias": "ogx_mmlux_pt-pt-high_school_mathematics"
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "acc,none": 0.3282051282051282,
      "acc_stderr,none": 0.023807633198657262,
      "alias": "ogx_mmlux_pt-pt-high_school_macroeconomics"
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "acc,none": 0.41450777202072536,
      "acc_stderr,none": 0.035553003195576714,
      "alias": "ogx_mmlux_pt-pt-high_school_government_and_politics"
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "acc,none": 0.46464646464646464,
      "acc_stderr,none": 0.03553436368828063,
      "alias": "ogx_mmlux_pt-pt-high_school_geography"
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "acc,none": 0.4484848484848485,
      "acc_stderr,none": 0.03883565977956929,
      "alias": "ogx_mmlux_pt-pt-high_school_european_history"
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_pt-pt-high_school_computer_science"
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "acc,none": 0.2660098522167488,
      "acc_stderr,none": 0.031089826002937523,
      "alias": "ogx_mmlux_pt-pt-high_school_chemistry"
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "acc,none": 0.38387096774193546,
      "acc_stderr,none": 0.027666182075539635,
      "alias": "ogx_mmlux_pt-pt-high_school_biology"
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_pt-pt-global_facts"
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "acc,none": 0.2222222222222222,
      "acc_stderr,none": 0.037184890068181146,
      "alias": "ogx_mmlux_pt-pt-formal_logic"
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "acc,none": 0.291005291005291,
      "acc_stderr,none": 0.023393826500484865,
      "alias": "ogx_mmlux_pt-pt-elementary_mathematics"
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "acc,none": 0.43448275862068964,
      "acc_stderr,none": 0.04130740879555498,
      "alias": "ogx_mmlux_pt-pt-electrical_engineering"
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "acc,none": 0.2719298245614035,
      "acc_stderr,none": 0.04185774424022057,
      "alias": "ogx_mmlux_pt-pt-econometrics"
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "acc,none": 0.3574468085106383,
      "acc_stderr,none": 0.03132941789476424,
      "alias": "ogx_mmlux_pt-pt-conceptual_physics"
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_pt-pt-computer_security"
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "acc,none": 0.18627450980392157,
      "acc_stderr,none": 0.038739587141493524,
      "alias": "ogx_mmlux_pt-pt-college_physics"
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "acc,none": 0.3063583815028902,
      "acc_stderr,none": 0.03514942551267439,
      "alias": "ogx_mmlux_pt-pt-college_medicine"
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "acc,none": 0.26,
      "acc_stderr,none": 0.04408440022768078,
      "alias": "ogx_mmlux_pt-pt-college_mathematics"
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_pt-pt-college_computer_science"
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "acc,none": 0.24,
      "acc_stderr,none": 0.04292346959909282,
      "alias": "ogx_mmlux_pt-pt-college_chemistry"
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.04076663253918567,
      "alias": "ogx_mmlux_pt-pt-college_biology"
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "acc,none": 0.3433962264150943,
      "acc_stderr,none": 0.02922452646912479,
      "alias": "ogx_mmlux_pt-pt-clinical_knowledge"
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_pt-pt-business_ethics"
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "acc,none": 0.39473684210526316,
      "acc_stderr,none": 0.039777499346220734,
      "alias": "ogx_mmlux_pt-pt-astronomy"
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "acc,none": 0.3925925925925926,
      "acc_stderr,none": 0.04218506215368879,
      "alias": "ogx_mmlux_pt-pt-anatomy"
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_pt-pt-abstract_algebra"
    },
    "ogx_mmlux_pl-world_religions": {
      "acc,none": 0.6374269005847953,
      "acc_stderr,none": 0.0368713061556206,
      "alias": "ogx_mmlux_pl-world_religions"
    },
    "ogx_mmlux_pl-virology": {
      "acc,none": 0.3674698795180723,
      "acc_stderr,none": 0.03753267402120575,
      "alias": "ogx_mmlux_pl-virology"
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_pl-us_foreign_policy"
    },
    "ogx_mmlux_pl-sociology": {
      "acc,none": 0.5323383084577115,
      "acc_stderr,none": 0.035281314729336065,
      "alias": "ogx_mmlux_pl-sociology"
    },
    "ogx_mmlux_pl-security_studies": {
      "acc,none": 0.3020408163265306,
      "acc_stderr,none": 0.029393609319879815,
      "alias": "ogx_mmlux_pl-security_studies"
    },
    "ogx_mmlux_pl-public_relations": {
      "acc,none": 0.44545454545454544,
      "acc_stderr,none": 0.047605488214603246,
      "alias": "ogx_mmlux_pl-public_relations"
    },
    "ogx_mmlux_pl-professional_psychology": {
      "acc,none": 0.3954248366013072,
      "acc_stderr,none": 0.01978046595477753,
      "alias": "ogx_mmlux_pl-professional_psychology"
    },
    "ogx_mmlux_pl-professional_medicine": {
      "acc,none": 0.23897058823529413,
      "acc_stderr,none": 0.025905280644893006,
      "alias": "ogx_mmlux_pl-professional_medicine"
    },
    "ogx_mmlux_pl-professional_law": {
      "acc,none": 0.3194263363754889,
      "acc_stderr,none": 0.011908357176756158,
      "alias": "ogx_mmlux_pl-professional_law"
    },
    "ogx_mmlux_pl-professional_accounting": {
      "acc,none": 0.2907801418439716,
      "acc_stderr,none": 0.027090664368353178,
      "alias": "ogx_mmlux_pl-professional_accounting"
    },
    "ogx_mmlux_pl-prehistory": {
      "acc,none": 0.3950617283950617,
      "acc_stderr,none": 0.027201117666925657,
      "alias": "ogx_mmlux_pl-prehistory"
    },
    "ogx_mmlux_pl-philosophy": {
      "acc,none": 0.3890675241157556,
      "acc_stderr,none": 0.027690337536485376,
      "alias": "ogx_mmlux_pl-philosophy"
    },
    "ogx_mmlux_pl-nutrition": {
      "acc,none": 0.46405228758169936,
      "acc_stderr,none": 0.028555827516528787,
      "alias": "ogx_mmlux_pl-nutrition"
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "acc,none": 0.2569832402234637,
      "acc_stderr,none": 0.014614465821966354,
      "alias": "ogx_mmlux_pl-moral_scenarios"
    },
    "ogx_mmlux_pl-moral_disputes": {
      "acc,none": 0.42485549132947975,
      "acc_stderr,none": 0.026613350840261736,
      "alias": "ogx_mmlux_pl-moral_disputes"
    },
    "ogx_mmlux_pl-miscellaneous": {
      "acc,none": 0.5159642401021711,
      "acc_stderr,none": 0.01787084750608173,
      "alias": "ogx_mmlux_pl-miscellaneous"
    },
    "ogx_mmlux_pl-medical_genetics": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_pl-medical_genetics"
    },
    "ogx_mmlux_pl-marketing": {
      "acc,none": 0.6282051282051282,
      "acc_stderr,none": 0.031660988918880785,
      "alias": "ogx_mmlux_pl-marketing"
    },
    "ogx_mmlux_pl-management": {
      "acc,none": 0.3786407766990291,
      "acc_stderr,none": 0.048026946982589726,
      "alias": "ogx_mmlux_pl-management"
    },
    "ogx_mmlux_pl-machine_learning": {
      "acc,none": 0.30357142857142855,
      "acc_stderr,none": 0.04364226155841044,
      "alias": "ogx_mmlux_pl-machine_learning"
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "acc,none": 0.294478527607362,
      "acc_stderr,none": 0.03581165790474082,
      "alias": "ogx_mmlux_pl-logical_fallacies"
    },
    "ogx_mmlux_pl-jurisprudence": {
      "acc,none": 0.4537037037037037,
      "acc_stderr,none": 0.04812917324536824,
      "alias": "ogx_mmlux_pl-jurisprudence"
    },
    "ogx_mmlux_pl-international_law": {
      "acc,none": 0.5619834710743802,
      "acc_stderr,none": 0.045291468044357915,
      "alias": "ogx_mmlux_pl-international_law"
    },
    "ogx_mmlux_pl-human_sexuality": {
      "acc,none": 0.4580152671755725,
      "acc_stderr,none": 0.04369802690578757,
      "alias": "ogx_mmlux_pl-human_sexuality"
    },
    "ogx_mmlux_pl-human_aging": {
      "acc,none": 0.515695067264574,
      "acc_stderr,none": 0.0335412657542081,
      "alias": "ogx_mmlux_pl-human_aging"
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "acc,none": 0.4345991561181435,
      "acc_stderr,none": 0.03226759995510145,
      "alias": "ogx_mmlux_pl-high_school_world_history"
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "acc,none": 0.46568627450980393,
      "acc_stderr,none": 0.03501038327635897,
      "alias": "ogx_mmlux_pl-high_school_us_history"
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "acc,none": 0.19444444444444445,
      "acc_stderr,none": 0.026991454502036716,
      "alias": "ogx_mmlux_pl-high_school_statistics"
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "acc,none": 0.42568807339449544,
      "acc_stderr,none": 0.021199235972470802,
      "alias": "ogx_mmlux_pl-high_school_psychology"
    },
    "ogx_mmlux_pl-high_school_physics": {
      "acc,none": 0.25165562913907286,
      "acc_stderr,none": 0.03543304234389985,
      "alias": "ogx_mmlux_pl-high_school_physics"
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "acc,none": 0.31932773109243695,
      "acc_stderr,none": 0.030283995525884396,
      "alias": "ogx_mmlux_pl-high_school_microeconomics"
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "acc,none": 0.23333333333333334,
      "acc_stderr,none": 0.02578787422095933,
      "alias": "ogx_mmlux_pl-high_school_mathematics"
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "acc,none": 0.3076923076923077,
      "acc_stderr,none": 0.0234009289183105,
      "alias": "ogx_mmlux_pl-high_school_macroeconomics"
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "acc,none": 0.37823834196891193,
      "acc_stderr,none": 0.0349980727619334,
      "alias": "ogx_mmlux_pl-high_school_government_and_politics"
    },
    "ogx_mmlux_pl-high_school_geography": {
      "acc,none": 0.3686868686868687,
      "acc_stderr,none": 0.03437305501980619,
      "alias": "ogx_mmlux_pl-high_school_geography"
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "acc,none": 0.5272727272727272,
      "acc_stderr,none": 0.03898531605579419,
      "alias": "ogx_mmlux_pl-high_school_european_history"
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001974,
      "alias": "ogx_mmlux_pl-high_school_computer_science"
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "acc,none": 0.2660098522167488,
      "acc_stderr,none": 0.031089826002937523,
      "alias": "ogx_mmlux_pl-high_school_chemistry"
    },
    "ogx_mmlux_pl-high_school_biology": {
      "acc,none": 0.3709677419354839,
      "acc_stderr,none": 0.027480541887953593,
      "alias": "ogx_mmlux_pl-high_school_biology"
    },
    "ogx_mmlux_pl-global_facts": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_pl-global_facts"
    },
    "ogx_mmlux_pl-formal_logic": {
      "acc,none": 0.2619047619047619,
      "acc_stderr,none": 0.03932537680392871,
      "alias": "ogx_mmlux_pl-formal_logic"
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "acc,none": 0.25396825396825395,
      "acc_stderr,none": 0.022418042891113932,
      "alias": "ogx_mmlux_pl-elementary_mathematics"
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "acc,none": 0.4068965517241379,
      "acc_stderr,none": 0.040937939812662374,
      "alias": "ogx_mmlux_pl-electrical_engineering"
    },
    "ogx_mmlux_pl-econometrics": {
      "acc,none": 0.2807017543859649,
      "acc_stderr,none": 0.04227054451232199,
      "alias": "ogx_mmlux_pl-econometrics"
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "acc,none": 0.41702127659574467,
      "acc_stderr,none": 0.03223276266711712,
      "alias": "ogx_mmlux_pl-conceptual_physics"
    },
    "ogx_mmlux_pl-computer_security": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_pl-computer_security"
    },
    "ogx_mmlux_pl-college_physics": {
      "acc,none": 0.20588235294117646,
      "acc_stderr,none": 0.04023382273617746,
      "alias": "ogx_mmlux_pl-college_physics"
    },
    "ogx_mmlux_pl-college_medicine": {
      "acc,none": 0.32947976878612717,
      "acc_stderr,none": 0.03583901754736411,
      "alias": "ogx_mmlux_pl-college_medicine"
    },
    "ogx_mmlux_pl-college_mathematics": {
      "acc,none": 0.22,
      "acc_stderr,none": 0.041633319989322695,
      "alias": "ogx_mmlux_pl-college_mathematics"
    },
    "ogx_mmlux_pl-college_computer_science": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.04688261722621505,
      "alias": "ogx_mmlux_pl-college_computer_science"
    },
    "ogx_mmlux_pl-college_chemistry": {
      "acc,none": 0.23,
      "acc_stderr,none": 0.04229525846816505,
      "alias": "ogx_mmlux_pl-college_chemistry"
    },
    "ogx_mmlux_pl-college_biology": {
      "acc,none": 0.375,
      "acc_stderr,none": 0.04048439222695598,
      "alias": "ogx_mmlux_pl-college_biology"
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "acc,none": 0.3622641509433962,
      "acc_stderr,none": 0.0295822451283843,
      "alias": "ogx_mmlux_pl-clinical_knowledge"
    },
    "ogx_mmlux_pl-business_ethics": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_pl-business_ethics"
    },
    "ogx_mmlux_pl-astronomy": {
      "acc,none": 0.34868421052631576,
      "acc_stderr,none": 0.0387813988879761,
      "alias": "ogx_mmlux_pl-astronomy"
    },
    "ogx_mmlux_pl-anatomy": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.04232073695151589,
      "alias": "ogx_mmlux_pl-anatomy"
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_pl-abstract_algebra"
    },
    "ogx_mmlux_nl-world_religions": {
      "acc,none": 0.6257309941520468,
      "acc_stderr,none": 0.037116011853894806,
      "alias": "ogx_mmlux_nl-world_religions"
    },
    "ogx_mmlux_nl-virology": {
      "acc,none": 0.4036144578313253,
      "acc_stderr,none": 0.03819486140758398,
      "alias": "ogx_mmlux_nl-virology"
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "acc,none": 0.64,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_nl-us_foreign_policy"
    },
    "ogx_mmlux_nl-sociology": {
      "acc,none": 0.5472636815920398,
      "acc_stderr,none": 0.035197027175769155,
      "alias": "ogx_mmlux_nl-sociology"
    },
    "ogx_mmlux_nl-security_studies": {
      "acc,none": 0.39591836734693875,
      "acc_stderr,none": 0.03130802899065686,
      "alias": "ogx_mmlux_nl-security_studies"
    },
    "ogx_mmlux_nl-public_relations": {
      "acc,none": 0.509090909090909,
      "acc_stderr,none": 0.04788339768702861,
      "alias": "ogx_mmlux_nl-public_relations"
    },
    "ogx_mmlux_nl-professional_psychology": {
      "acc,none": 0.42810457516339867,
      "acc_stderr,none": 0.02001762921421309,
      "alias": "ogx_mmlux_nl-professional_psychology"
    },
    "ogx_mmlux_nl-professional_medicine": {
      "acc,none": 0.31985294117647056,
      "acc_stderr,none": 0.028332959514031218,
      "alias": "ogx_mmlux_nl-professional_medicine"
    },
    "ogx_mmlux_nl-professional_law": {
      "acc,none": 0.32985658409387225,
      "acc_stderr,none": 0.012008129938540469,
      "alias": "ogx_mmlux_nl-professional_law"
    },
    "ogx_mmlux_nl-professional_accounting": {
      "acc,none": 0.2553191489361702,
      "acc_stderr,none": 0.026011992930902023,
      "alias": "ogx_mmlux_nl-professional_accounting"
    },
    "ogx_mmlux_nl-prehistory": {
      "acc,none": 0.4783950617283951,
      "acc_stderr,none": 0.027794760105008736,
      "alias": "ogx_mmlux_nl-prehistory"
    },
    "ogx_mmlux_nl-philosophy": {
      "acc,none": 0.43729903536977494,
      "acc_stderr,none": 0.028173917761762878,
      "alias": "ogx_mmlux_nl-philosophy"
    },
    "ogx_mmlux_nl-nutrition": {
      "acc,none": 0.4803921568627451,
      "acc_stderr,none": 0.028607893699576063,
      "alias": "ogx_mmlux_nl-nutrition"
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "acc,none": 0.2681564245810056,
      "acc_stderr,none": 0.014816119635317005,
      "alias": "ogx_mmlux_nl-moral_scenarios"
    },
    "ogx_mmlux_nl-moral_disputes": {
      "acc,none": 0.43352601156069365,
      "acc_stderr,none": 0.026680134761679217,
      "alias": "ogx_mmlux_nl-moral_disputes"
    },
    "ogx_mmlux_nl-miscellaneous": {
      "acc,none": 0.5823754789272031,
      "acc_stderr,none": 0.01763563732695153,
      "alias": "ogx_mmlux_nl-miscellaneous"
    },
    "ogx_mmlux_nl-medical_genetics": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_nl-medical_genetics"
    },
    "ogx_mmlux_nl-marketing": {
      "acc,none": 0.688034188034188,
      "acc_stderr,none": 0.030351527323344937,
      "alias": "ogx_mmlux_nl-marketing"
    },
    "ogx_mmlux_nl-management": {
      "acc,none": 0.39805825242718446,
      "acc_stderr,none": 0.04846748253977239,
      "alias": "ogx_mmlux_nl-management"
    },
    "ogx_mmlux_nl-machine_learning": {
      "acc,none": 0.30357142857142855,
      "acc_stderr,none": 0.04364226155841044,
      "alias": "ogx_mmlux_nl-machine_learning"
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "acc,none": 0.4539877300613497,
      "acc_stderr,none": 0.0391170190467718,
      "alias": "ogx_mmlux_nl-logical_fallacies"
    },
    "ogx_mmlux_nl-jurisprudence": {
      "acc,none": 0.49074074074074076,
      "acc_stderr,none": 0.04832853553437056,
      "alias": "ogx_mmlux_nl-jurisprudence"
    },
    "ogx_mmlux_nl-international_law": {
      "acc,none": 0.5950413223140496,
      "acc_stderr,none": 0.04481137755942469,
      "alias": "ogx_mmlux_nl-international_law"
    },
    "ogx_mmlux_nl-human_sexuality": {
      "acc,none": 0.5419847328244275,
      "acc_stderr,none": 0.04369802690578757,
      "alias": "ogx_mmlux_nl-human_sexuality"
    },
    "ogx_mmlux_nl-human_aging": {
      "acc,none": 0.5201793721973094,
      "acc_stderr,none": 0.033530461674123,
      "alias": "ogx_mmlux_nl-human_aging"
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "acc,none": 0.5443037974683544,
      "acc_stderr,none": 0.03241920684693334,
      "alias": "ogx_mmlux_nl-high_school_world_history"
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "acc,none": 0.47058823529411764,
      "acc_stderr,none": 0.03503235296367992,
      "alias": "ogx_mmlux_nl-high_school_us_history"
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "acc,none": 0.19907407407407407,
      "acc_stderr,none": 0.027232298462690242,
      "alias": "ogx_mmlux_nl-high_school_statistics"
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "acc,none": 0.5321100917431193,
      "acc_stderr,none": 0.021393071222680814,
      "alias": "ogx_mmlux_nl-high_school_psychology"
    },
    "ogx_mmlux_nl-high_school_physics": {
      "acc,none": 0.23841059602649006,
      "acc_stderr,none": 0.03479185572599661,
      "alias": "ogx_mmlux_nl-high_school_physics"
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "acc,none": 0.36554621848739494,
      "acc_stderr,none": 0.0312821770636846,
      "alias": "ogx_mmlux_nl-high_school_microeconomics"
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "acc,none": 0.27037037037037037,
      "acc_stderr,none": 0.02708037281514565,
      "alias": "ogx_mmlux_nl-high_school_mathematics"
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "acc,none": 0.36153846153846153,
      "acc_stderr,none": 0.02435958146539699,
      "alias": "ogx_mmlux_nl-high_school_macroeconomics"
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "acc,none": 0.47150259067357514,
      "acc_stderr,none": 0.036025735712884414,
      "alias": "ogx_mmlux_nl-high_school_government_and_politics"
    },
    "ogx_mmlux_nl-high_school_geography": {
      "acc,none": 0.4797979797979798,
      "acc_stderr,none": 0.035594435655639196,
      "alias": "ogx_mmlux_nl-high_school_geography"
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "acc,none": 0.5575757575757576,
      "acc_stderr,none": 0.038783721137112745,
      "alias": "ogx_mmlux_nl-high_school_european_history"
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "acc,none": 0.41,
      "acc_stderr,none": 0.049431107042371025,
      "alias": "ogx_mmlux_nl-high_school_computer_science"
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "acc,none": 0.2955665024630542,
      "acc_stderr,none": 0.032104944337514575,
      "alias": "ogx_mmlux_nl-high_school_chemistry"
    },
    "ogx_mmlux_nl-high_school_biology": {
      "acc,none": 0.4645161290322581,
      "acc_stderr,none": 0.028372287797962956,
      "alias": "ogx_mmlux_nl-high_school_biology"
    },
    "ogx_mmlux_nl-global_facts": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252606,
      "alias": "ogx_mmlux_nl-global_facts"
    },
    "ogx_mmlux_nl-formal_logic": {
      "acc,none": 0.25396825396825395,
      "acc_stderr,none": 0.038932596106046734,
      "alias": "ogx_mmlux_nl-formal_logic"
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "acc,none": 0.2566137566137566,
      "acc_stderr,none": 0.022494510767503154,
      "alias": "ogx_mmlux_nl-elementary_mathematics"
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "acc,none": 0.42758620689655175,
      "acc_stderr,none": 0.04122737111370333,
      "alias": "ogx_mmlux_nl-electrical_engineering"
    },
    "ogx_mmlux_nl-econometrics": {
      "acc,none": 0.22807017543859648,
      "acc_stderr,none": 0.03947152782669415,
      "alias": "ogx_mmlux_nl-econometrics"
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "acc,none": 0.37872340425531914,
      "acc_stderr,none": 0.03170995606040655,
      "alias": "ogx_mmlux_nl-conceptual_physics"
    },
    "ogx_mmlux_nl-computer_security": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_nl-computer_security"
    },
    "ogx_mmlux_nl-college_physics": {
      "acc,none": 0.23529411764705882,
      "acc_stderr,none": 0.04220773659171453,
      "alias": "ogx_mmlux_nl-college_physics"
    },
    "ogx_mmlux_nl-college_medicine": {
      "acc,none": 0.2947976878612717,
      "acc_stderr,none": 0.03476599607516479,
      "alias": "ogx_mmlux_nl-college_medicine"
    },
    "ogx_mmlux_nl-college_mathematics": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_nl-college_mathematics"
    },
    "ogx_mmlux_nl-college_computer_science": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.04878317312145632,
      "alias": "ogx_mmlux_nl-college_computer_science"
    },
    "ogx_mmlux_nl-college_chemistry": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_nl-college_chemistry"
    },
    "ogx_mmlux_nl-college_biology": {
      "acc,none": 0.4305555555555556,
      "acc_stderr,none": 0.04140685639111503,
      "alias": "ogx_mmlux_nl-college_biology"
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "acc,none": 0.4377358490566038,
      "acc_stderr,none": 0.030533338430467512,
      "alias": "ogx_mmlux_nl-clinical_knowledge"
    },
    "ogx_mmlux_nl-business_ethics": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_nl-business_ethics"
    },
    "ogx_mmlux_nl-astronomy": {
      "acc,none": 0.3815789473684211,
      "acc_stderr,none": 0.03953173377749193,
      "alias": "ogx_mmlux_nl-astronomy"
    },
    "ogx_mmlux_nl-anatomy": {
      "acc,none": 0.4666666666666667,
      "acc_stderr,none": 0.043097329010363554,
      "alias": "ogx_mmlux_nl-anatomy"
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252605,
      "alias": "ogx_mmlux_nl-abstract_algebra"
    },
    "ogx_mmlux_lv-world_religions": {
      "acc,none": 0.5672514619883041,
      "acc_stderr,none": 0.03799978644370606,
      "alias": "ogx_mmlux_lv-world_religions"
    },
    "ogx_mmlux_lv-virology": {
      "acc,none": 0.3614457831325301,
      "acc_stderr,none": 0.0374005938202932,
      "alias": "ogx_mmlux_lv-virology"
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "acc,none": 0.57,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_lv-us_foreign_policy"
    },
    "ogx_mmlux_lv-sociology": {
      "acc,none": 0.48258706467661694,
      "acc_stderr,none": 0.03533389234739245,
      "alias": "ogx_mmlux_lv-sociology"
    },
    "ogx_mmlux_lv-security_studies": {
      "acc,none": 0.2938775510204082,
      "acc_stderr,none": 0.02916273841024977,
      "alias": "ogx_mmlux_lv-security_studies"
    },
    "ogx_mmlux_lv-public_relations": {
      "acc,none": 0.4818181818181818,
      "acc_stderr,none": 0.04785964010794916,
      "alias": "ogx_mmlux_lv-public_relations"
    },
    "ogx_mmlux_lv-professional_psychology": {
      "acc,none": 0.33986928104575165,
      "acc_stderr,none": 0.01916241858862355,
      "alias": "ogx_mmlux_lv-professional_psychology"
    },
    "ogx_mmlux_lv-professional_medicine": {
      "acc,none": 0.2536764705882353,
      "acc_stderr,none": 0.026431329870789527,
      "alias": "ogx_mmlux_lv-professional_medicine"
    },
    "ogx_mmlux_lv-professional_law": {
      "acc,none": 0.3070404172099087,
      "acc_stderr,none": 0.011780959114513765,
      "alias": "ogx_mmlux_lv-professional_law"
    },
    "ogx_mmlux_lv-professional_accounting": {
      "acc,none": 0.2765957446808511,
      "acc_stderr,none": 0.026684564340461,
      "alias": "ogx_mmlux_lv-professional_accounting"
    },
    "ogx_mmlux_lv-prehistory": {
      "acc,none": 0.37037037037037035,
      "acc_stderr,none": 0.026869490744815247,
      "alias": "ogx_mmlux_lv-prehistory"
    },
    "ogx_mmlux_lv-philosophy": {
      "acc,none": 0.3408360128617363,
      "acc_stderr,none": 0.026920841260776165,
      "alias": "ogx_mmlux_lv-philosophy"
    },
    "ogx_mmlux_lv-nutrition": {
      "acc,none": 0.45098039215686275,
      "acc_stderr,none": 0.028491993586171573,
      "alias": "ogx_mmlux_lv-nutrition"
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "acc,none": 0.2670391061452514,
      "acc_stderr,none": 0.01479650262256256,
      "alias": "ogx_mmlux_lv-moral_scenarios"
    },
    "ogx_mmlux_lv-moral_disputes": {
      "acc,none": 0.3583815028901734,
      "acc_stderr,none": 0.025816756791584197,
      "alias": "ogx_mmlux_lv-moral_disputes"
    },
    "ogx_mmlux_lv-miscellaneous": {
      "acc,none": 0.46360153256704983,
      "acc_stderr,none": 0.01783252407959326,
      "alias": "ogx_mmlux_lv-miscellaneous"
    },
    "ogx_mmlux_lv-medical_genetics": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.04923659639173309,
      "alias": "ogx_mmlux_lv-medical_genetics"
    },
    "ogx_mmlux_lv-marketing": {
      "acc,none": 0.5769230769230769,
      "acc_stderr,none": 0.032366121762202014,
      "alias": "ogx_mmlux_lv-marketing"
    },
    "ogx_mmlux_lv-management": {
      "acc,none": 0.39805825242718446,
      "acc_stderr,none": 0.048467482539772386,
      "alias": "ogx_mmlux_lv-management"
    },
    "ogx_mmlux_lv-machine_learning": {
      "acc,none": 0.33035714285714285,
      "acc_stderr,none": 0.04464285714285714,
      "alias": "ogx_mmlux_lv-machine_learning"
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "acc,none": 0.3558282208588957,
      "acc_stderr,none": 0.03761521380046734,
      "alias": "ogx_mmlux_lv-logical_fallacies"
    },
    "ogx_mmlux_lv-jurisprudence": {
      "acc,none": 0.4074074074074074,
      "acc_stderr,none": 0.04750077341199984,
      "alias": "ogx_mmlux_lv-jurisprudence"
    },
    "ogx_mmlux_lv-international_law": {
      "acc,none": 0.5867768595041323,
      "acc_stderr,none": 0.04495087843548408,
      "alias": "ogx_mmlux_lv-international_law"
    },
    "ogx_mmlux_lv-human_sexuality": {
      "acc,none": 0.44274809160305345,
      "acc_stderr,none": 0.043564472026650695,
      "alias": "ogx_mmlux_lv-human_sexuality"
    },
    "ogx_mmlux_lv-human_aging": {
      "acc,none": 0.5022421524663677,
      "acc_stderr,none": 0.03355746535223263,
      "alias": "ogx_mmlux_lv-human_aging"
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "acc,none": 0.4430379746835443,
      "acc_stderr,none": 0.03233532777533484,
      "alias": "ogx_mmlux_lv-high_school_world_history"
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "acc,none": 0.4019607843137255,
      "acc_stderr,none": 0.034411900234824655,
      "alias": "ogx_mmlux_lv-high_school_us_history"
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "acc,none": 0.1712962962962963,
      "acc_stderr,none": 0.0256953416438247,
      "alias": "ogx_mmlux_lv-high_school_statistics"
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "acc,none": 0.41100917431192663,
      "acc_stderr,none": 0.021095050687277652,
      "alias": "ogx_mmlux_lv-high_school_psychology"
    },
    "ogx_mmlux_lv-high_school_physics": {
      "acc,none": 0.23178807947019867,
      "acc_stderr,none": 0.03445406271987054,
      "alias": "ogx_mmlux_lv-high_school_physics"
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "acc,none": 0.3403361344537815,
      "acc_stderr,none": 0.03077805742293167,
      "alias": "ogx_mmlux_lv-high_school_microeconomics"
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "acc,none": 0.26666666666666666,
      "acc_stderr,none": 0.02696242432507383,
      "alias": "ogx_mmlux_lv-high_school_mathematics"
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "acc,none": 0.30512820512820515,
      "acc_stderr,none": 0.023346335293325887,
      "alias": "ogx_mmlux_lv-high_school_macroeconomics"
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "acc,none": 0.3160621761658031,
      "acc_stderr,none": 0.033553973696861736,
      "alias": "ogx_mmlux_lv-high_school_government_and_politics"
    },
    "ogx_mmlux_lv-high_school_geography": {
      "acc,none": 0.3434343434343434,
      "acc_stderr,none": 0.03383201223244445,
      "alias": "ogx_mmlux_lv-high_school_geography"
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "acc,none": 0.46060606060606063,
      "acc_stderr,none": 0.03892207016552012,
      "alias": "ogx_mmlux_lv-high_school_european_history"
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_lv-high_school_computer_science"
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "acc,none": 0.28078817733990147,
      "acc_stderr,none": 0.0316185633535861,
      "alias": "ogx_mmlux_lv-high_school_chemistry"
    },
    "ogx_mmlux_lv-high_school_biology": {
      "acc,none": 0.3741935483870968,
      "acc_stderr,none": 0.027528904299845797,
      "alias": "ogx_mmlux_lv-high_school_biology"
    },
    "ogx_mmlux_lv-global_facts": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_lv-global_facts"
    },
    "ogx_mmlux_lv-formal_logic": {
      "acc,none": 0.21428571428571427,
      "acc_stderr,none": 0.03670066451047181,
      "alias": "ogx_mmlux_lv-formal_logic"
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "acc,none": 0.2619047619047619,
      "acc_stderr,none": 0.022644212615525208,
      "alias": "ogx_mmlux_lv-elementary_mathematics"
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "acc,none": 0.30344827586206896,
      "acc_stderr,none": 0.038312260488503336,
      "alias": "ogx_mmlux_lv-electrical_engineering"
    },
    "ogx_mmlux_lv-econometrics": {
      "acc,none": 0.24561403508771928,
      "acc_stderr,none": 0.0404933929774814,
      "alias": "ogx_mmlux_lv-econometrics"
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "acc,none": 0.3659574468085106,
      "acc_stderr,none": 0.0314895582974553,
      "alias": "ogx_mmlux_lv-conceptual_physics"
    },
    "ogx_mmlux_lv-computer_security": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_lv-computer_security"
    },
    "ogx_mmlux_lv-college_physics": {
      "acc,none": 0.24509803921568626,
      "acc_stderr,none": 0.04280105837364395,
      "alias": "ogx_mmlux_lv-college_physics"
    },
    "ogx_mmlux_lv-college_medicine": {
      "acc,none": 0.30057803468208094,
      "acc_stderr,none": 0.0349610148119118,
      "alias": "ogx_mmlux_lv-college_medicine"
    },
    "ogx_mmlux_lv-college_mathematics": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_lv-college_mathematics"
    },
    "ogx_mmlux_lv-college_computer_science": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_lv-college_computer_science"
    },
    "ogx_mmlux_lv-college_chemistry": {
      "acc,none": 0.24,
      "acc_stderr,none": 0.04292346959909283,
      "alias": "ogx_mmlux_lv-college_chemistry"
    },
    "ogx_mmlux_lv-college_biology": {
      "acc,none": 0.3611111111111111,
      "acc_stderr,none": 0.04016660030451232,
      "alias": "ogx_mmlux_lv-college_biology"
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "acc,none": 0.3433962264150943,
      "acc_stderr,none": 0.02922452646912479,
      "alias": "ogx_mmlux_lv-clinical_knowledge"
    },
    "ogx_mmlux_lv-business_ethics": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_lv-business_ethics"
    },
    "ogx_mmlux_lv-astronomy": {
      "acc,none": 0.3157894736842105,
      "acc_stderr,none": 0.037827289808654685,
      "alias": "ogx_mmlux_lv-astronomy"
    },
    "ogx_mmlux_lv-anatomy": {
      "acc,none": 0.35555555555555557,
      "acc_stderr,none": 0.04135176749720386,
      "alias": "ogx_mmlux_lv-anatomy"
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_lv-abstract_algebra"
    },
    "ogx_mmlux_lt-world_religions": {
      "acc,none": 0.5847953216374269,
      "acc_stderr,none": 0.03779275945503201,
      "alias": "ogx_mmlux_lt-world_religions"
    },
    "ogx_mmlux_lt-virology": {
      "acc,none": 0.3253012048192771,
      "acc_stderr,none": 0.03647168523683229,
      "alias": "ogx_mmlux_lt-virology"
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_lt-us_foreign_policy"
    },
    "ogx_mmlux_lt-sociology": {
      "acc,none": 0.47761194029850745,
      "acc_stderr,none": 0.03531987930208731,
      "alias": "ogx_mmlux_lt-sociology"
    },
    "ogx_mmlux_lt-security_studies": {
      "acc,none": 0.2816326530612245,
      "acc_stderr,none": 0.028795185574291282,
      "alias": "ogx_mmlux_lt-security_studies"
    },
    "ogx_mmlux_lt-public_relations": {
      "acc,none": 0.44545454545454544,
      "acc_stderr,none": 0.047605488214603246,
      "alias": "ogx_mmlux_lt-public_relations"
    },
    "ogx_mmlux_lt-professional_psychology": {
      "acc,none": 0.3545751633986928,
      "acc_stderr,none": 0.019353360547553704,
      "alias": "ogx_mmlux_lt-professional_psychology"
    },
    "ogx_mmlux_lt-professional_medicine": {
      "acc,none": 0.2647058823529412,
      "acc_stderr,none": 0.026799562024887674,
      "alias": "ogx_mmlux_lt-professional_medicine"
    },
    "ogx_mmlux_lt-professional_law": {
      "acc,none": 0.3057366362451108,
      "acc_stderr,none": 0.011766973847072915,
      "alias": "ogx_mmlux_lt-professional_law"
    },
    "ogx_mmlux_lt-professional_accounting": {
      "acc,none": 0.2978723404255319,
      "acc_stderr,none": 0.027281608344469414,
      "alias": "ogx_mmlux_lt-professional_accounting"
    },
    "ogx_mmlux_lt-prehistory": {
      "acc,none": 0.37962962962962965,
      "acc_stderr,none": 0.02700252103451647,
      "alias": "ogx_mmlux_lt-prehistory"
    },
    "ogx_mmlux_lt-philosophy": {
      "acc,none": 0.3504823151125402,
      "acc_stderr,none": 0.02709865262130175,
      "alias": "ogx_mmlux_lt-philosophy"
    },
    "ogx_mmlux_lt-nutrition": {
      "acc,none": 0.38235294117647056,
      "acc_stderr,none": 0.027826109307283693,
      "alias": "ogx_mmlux_lt-nutrition"
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "acc,none": 0.2569832402234637,
      "acc_stderr,none": 0.014614465821966339,
      "alias": "ogx_mmlux_lt-moral_scenarios"
    },
    "ogx_mmlux_lt-moral_disputes": {
      "acc,none": 0.4277456647398844,
      "acc_stderr,none": 0.026636539741116072,
      "alias": "ogx_mmlux_lt-moral_disputes"
    },
    "ogx_mmlux_lt-miscellaneous": {
      "acc,none": 0.4840357598978289,
      "acc_stderr,none": 0.01787084750608173,
      "alias": "ogx_mmlux_lt-miscellaneous"
    },
    "ogx_mmlux_lt-medical_genetics": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_lt-medical_genetics"
    },
    "ogx_mmlux_lt-marketing": {
      "acc,none": 0.5726495726495726,
      "acc_stderr,none": 0.032408473935163266,
      "alias": "ogx_mmlux_lt-marketing"
    },
    "ogx_mmlux_lt-management": {
      "acc,none": 0.3592233009708738,
      "acc_stderr,none": 0.047504583990416925,
      "alias": "ogx_mmlux_lt-management"
    },
    "ogx_mmlux_lt-machine_learning": {
      "acc,none": 0.33035714285714285,
      "acc_stderr,none": 0.04464285714285714,
      "alias": "ogx_mmlux_lt-machine_learning"
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "acc,none": 0.34355828220858897,
      "acc_stderr,none": 0.037311335196738925,
      "alias": "ogx_mmlux_lt-logical_fallacies"
    },
    "ogx_mmlux_lt-jurisprudence": {
      "acc,none": 0.4444444444444444,
      "acc_stderr,none": 0.04803752235190192,
      "alias": "ogx_mmlux_lt-jurisprudence"
    },
    "ogx_mmlux_lt-international_law": {
      "acc,none": 0.6115702479338843,
      "acc_stderr,none": 0.04449270350068383,
      "alias": "ogx_mmlux_lt-international_law"
    },
    "ogx_mmlux_lt-human_sexuality": {
      "acc,none": 0.4580152671755725,
      "acc_stderr,none": 0.04369802690578756,
      "alias": "ogx_mmlux_lt-human_sexuality"
    },
    "ogx_mmlux_lt-human_aging": {
      "acc,none": 0.484304932735426,
      "acc_stderr,none": 0.0335412657542081,
      "alias": "ogx_mmlux_lt-human_aging"
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "acc,none": 0.4641350210970464,
      "acc_stderr,none": 0.03246338898055659,
      "alias": "ogx_mmlux_lt-high_school_world_history"
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "acc,none": 0.43137254901960786,
      "acc_stderr,none": 0.03476099060501637,
      "alias": "ogx_mmlux_lt-high_school_us_history"
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "acc,none": 0.1574074074074074,
      "acc_stderr,none": 0.0248371735182424,
      "alias": "ogx_mmlux_lt-high_school_statistics"
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "acc,none": 0.42018348623853213,
      "acc_stderr,none": 0.021162420048273504,
      "alias": "ogx_mmlux_lt-high_school_psychology"
    },
    "ogx_mmlux_lt-high_school_physics": {
      "acc,none": 0.2582781456953642,
      "acc_stderr,none": 0.035737053147634576,
      "alias": "ogx_mmlux_lt-high_school_physics"
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "acc,none": 0.3067226890756303,
      "acc_stderr,none": 0.02995382389188704,
      "alias": "ogx_mmlux_lt-high_school_microeconomics"
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "acc,none": 0.2740740740740741,
      "acc_stderr,none": 0.027195934804085626,
      "alias": "ogx_mmlux_lt-high_school_mathematics"
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "acc,none": 0.31025641025641026,
      "acc_stderr,none": 0.023454674889404288,
      "alias": "ogx_mmlux_lt-high_school_macroeconomics"
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "acc,none": 0.3471502590673575,
      "acc_stderr,none": 0.03435696168361355,
      "alias": "ogx_mmlux_lt-high_school_government_and_politics"
    },
    "ogx_mmlux_lt-high_school_geography": {
      "acc,none": 0.398989898989899,
      "acc_stderr,none": 0.0348890161685273,
      "alias": "ogx_mmlux_lt-high_school_geography"
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "acc,none": 0.44242424242424244,
      "acc_stderr,none": 0.03878372113711274,
      "alias": "ogx_mmlux_lt-high_school_european_history"
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.04793724854411019,
      "alias": "ogx_mmlux_lt-high_school_computer_science"
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "acc,none": 0.28078817733990147,
      "acc_stderr,none": 0.03161856335358611,
      "alias": "ogx_mmlux_lt-high_school_chemistry"
    },
    "ogx_mmlux_lt-high_school_biology": {
      "acc,none": 0.38064516129032255,
      "acc_stderr,none": 0.02762171783290703,
      "alias": "ogx_mmlux_lt-high_school_biology"
    },
    "ogx_mmlux_lt-global_facts": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252604,
      "alias": "ogx_mmlux_lt-global_facts"
    },
    "ogx_mmlux_lt-formal_logic": {
      "acc,none": 0.24603174603174602,
      "acc_stderr,none": 0.038522733649243156,
      "alias": "ogx_mmlux_lt-formal_logic"
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "acc,none": 0.2830687830687831,
      "acc_stderr,none": 0.023201392938194974,
      "alias": "ogx_mmlux_lt-elementary_mathematics"
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "acc,none": 0.3448275862068966,
      "acc_stderr,none": 0.03960933549451207,
      "alias": "ogx_mmlux_lt-electrical_engineering"
    },
    "ogx_mmlux_lt-econometrics": {
      "acc,none": 0.24561403508771928,
      "acc_stderr,none": 0.040493392977481404,
      "alias": "ogx_mmlux_lt-econometrics"
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "acc,none": 0.37446808510638296,
      "acc_stderr,none": 0.03163910665367291,
      "alias": "ogx_mmlux_lt-conceptual_physics"
    },
    "ogx_mmlux_lt-computer_security": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_lt-computer_security"
    },
    "ogx_mmlux_lt-college_physics": {
      "acc,none": 0.21568627450980393,
      "acc_stderr,none": 0.04092563958237655,
      "alias": "ogx_mmlux_lt-college_physics"
    },
    "ogx_mmlux_lt-college_medicine": {
      "acc,none": 0.31213872832369943,
      "acc_stderr,none": 0.03533133389323657,
      "alias": "ogx_mmlux_lt-college_medicine"
    },
    "ogx_mmlux_lt-college_mathematics": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.04461960433384741,
      "alias": "ogx_mmlux_lt-college_mathematics"
    },
    "ogx_mmlux_lt-college_computer_science": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_lt-college_computer_science"
    },
    "ogx_mmlux_lt-college_chemistry": {
      "acc,none": 0.18,
      "acc_stderr,none": 0.03861229196653697,
      "alias": "ogx_mmlux_lt-college_chemistry"
    },
    "ogx_mmlux_lt-college_biology": {
      "acc,none": 0.3472222222222222,
      "acc_stderr,none": 0.039812405437178615,
      "alias": "ogx_mmlux_lt-college_biology"
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "acc,none": 0.3283018867924528,
      "acc_stderr,none": 0.028901593612411784,
      "alias": "ogx_mmlux_lt-clinical_knowledge"
    },
    "ogx_mmlux_lt-business_ethics": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_lt-business_ethics"
    },
    "ogx_mmlux_lt-astronomy": {
      "acc,none": 0.35526315789473684,
      "acc_stderr,none": 0.03894734487013316,
      "alias": "ogx_mmlux_lt-astronomy"
    },
    "ogx_mmlux_lt-anatomy": {
      "acc,none": 0.35555555555555557,
      "acc_stderr,none": 0.04135176749720386,
      "alias": "ogx_mmlux_lt-anatomy"
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_lt-abstract_algebra"
    },
    "ogx_mmlux_it-world_religions": {
      "acc,none": 0.5906432748538012,
      "acc_stderr,none": 0.037712831076265434,
      "alias": "ogx_mmlux_it-world_religions"
    },
    "ogx_mmlux_it-virology": {
      "acc,none": 0.3433734939759036,
      "acc_stderr,none": 0.03696584317010601,
      "alias": "ogx_mmlux_it-virology"
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "acc,none": 0.55,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_it-us_foreign_policy"
    },
    "ogx_mmlux_it-sociology": {
      "acc,none": 0.5074626865671642,
      "acc_stderr,none": 0.03535140084276719,
      "alias": "ogx_mmlux_it-sociology"
    },
    "ogx_mmlux_it-security_studies": {
      "acc,none": 0.2938775510204082,
      "acc_stderr,none": 0.029162738410249772,
      "alias": "ogx_mmlux_it-security_studies"
    },
    "ogx_mmlux_it-public_relations": {
      "acc,none": 0.4909090909090909,
      "acc_stderr,none": 0.0478833976870286,
      "alias": "ogx_mmlux_it-public_relations"
    },
    "ogx_mmlux_it-professional_psychology": {
      "acc,none": 0.3709150326797386,
      "acc_stderr,none": 0.019542101564854118,
      "alias": "ogx_mmlux_it-professional_psychology"
    },
    "ogx_mmlux_it-professional_medicine": {
      "acc,none": 0.27205882352941174,
      "acc_stderr,none": 0.02703304115168146,
      "alias": "ogx_mmlux_it-professional_medicine"
    },
    "ogx_mmlux_it-professional_law": {
      "acc,none": 0.31421121251629724,
      "acc_stderr,none": 0.011855911587048224,
      "alias": "ogx_mmlux_it-professional_law"
    },
    "ogx_mmlux_it-professional_accounting": {
      "acc,none": 0.2695035460992908,
      "acc_stderr,none": 0.026469036818590613,
      "alias": "ogx_mmlux_it-professional_accounting"
    },
    "ogx_mmlux_it-prehistory": {
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.027431623722415005,
      "alias": "ogx_mmlux_it-prehistory"
    },
    "ogx_mmlux_it-philosophy": {
      "acc,none": 0.3987138263665595,
      "acc_stderr,none": 0.0278093225857745,
      "alias": "ogx_mmlux_it-philosophy"
    },
    "ogx_mmlux_it-nutrition": {
      "acc,none": 0.4084967320261438,
      "acc_stderr,none": 0.028146405993096358,
      "alias": "ogx_mmlux_it-nutrition"
    },
    "ogx_mmlux_it-moral_scenarios": {
      "acc,none": 0.2435754189944134,
      "acc_stderr,none": 0.014355911964767865,
      "alias": "ogx_mmlux_it-moral_scenarios"
    },
    "ogx_mmlux_it-moral_disputes": {
      "acc,none": 0.36416184971098264,
      "acc_stderr,none": 0.025906632631016117,
      "alias": "ogx_mmlux_it-moral_disputes"
    },
    "ogx_mmlux_it-miscellaneous": {
      "acc,none": 0.5172413793103449,
      "acc_stderr,none": 0.017869330154003705,
      "alias": "ogx_mmlux_it-miscellaneous"
    },
    "ogx_mmlux_it-medical_genetics": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.05021167315686779,
      "alias": "ogx_mmlux_it-medical_genetics"
    },
    "ogx_mmlux_it-marketing": {
      "acc,none": 0.6410256410256411,
      "acc_stderr,none": 0.03142616993791924,
      "alias": "ogx_mmlux_it-marketing"
    },
    "ogx_mmlux_it-management": {
      "acc,none": 0.34951456310679613,
      "acc_stderr,none": 0.047211885060971716,
      "alias": "ogx_mmlux_it-management"
    },
    "ogx_mmlux_it-machine_learning": {
      "acc,none": 0.3392857142857143,
      "acc_stderr,none": 0.04493949068613539,
      "alias": "ogx_mmlux_it-machine_learning"
    },
    "ogx_mmlux_it-logical_fallacies": {
      "acc,none": 0.34355828220858897,
      "acc_stderr,none": 0.03731133519673893,
      "alias": "ogx_mmlux_it-logical_fallacies"
    },
    "ogx_mmlux_it-jurisprudence": {
      "acc,none": 0.42592592592592593,
      "acc_stderr,none": 0.0478034362693679,
      "alias": "ogx_mmlux_it-jurisprudence"
    },
    "ogx_mmlux_it-international_law": {
      "acc,none": 0.5950413223140496,
      "acc_stderr,none": 0.044811377559424694,
      "alias": "ogx_mmlux_it-international_law"
    },
    "ogx_mmlux_it-human_sexuality": {
      "acc,none": 0.48854961832061067,
      "acc_stderr,none": 0.043841400240780176,
      "alias": "ogx_mmlux_it-human_sexuality"
    },
    "ogx_mmlux_it-human_aging": {
      "acc,none": 0.4977578475336323,
      "acc_stderr,none": 0.033557465352232634,
      "alias": "ogx_mmlux_it-human_aging"
    },
    "ogx_mmlux_it-high_school_world_history": {
      "acc,none": 0.4472573839662447,
      "acc_stderr,none": 0.03236564251614192,
      "alias": "ogx_mmlux_it-high_school_world_history"
    },
    "ogx_mmlux_it-high_school_us_history": {
      "acc,none": 0.39705882352941174,
      "acc_stderr,none": 0.03434131164719129,
      "alias": "ogx_mmlux_it-high_school_us_history"
    },
    "ogx_mmlux_it-high_school_statistics": {
      "acc,none": 0.19907407407407407,
      "acc_stderr,none": 0.027232298462690232,
      "alias": "ogx_mmlux_it-high_school_statistics"
    },
    "ogx_mmlux_it-high_school_psychology": {
      "acc,none": 0.43302752293577984,
      "acc_stderr,none": 0.021244146569074345,
      "alias": "ogx_mmlux_it-high_school_psychology"
    },
    "ogx_mmlux_it-high_school_physics": {
      "acc,none": 0.23841059602649006,
      "acc_stderr,none": 0.0347918557259966,
      "alias": "ogx_mmlux_it-high_school_physics"
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "acc,none": 0.2857142857142857,
      "acc_stderr,none": 0.029344572500634346,
      "alias": "ogx_mmlux_it-high_school_microeconomics"
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "acc,none": 0.2,
      "acc_stderr,none": 0.02438843043398766,
      "alias": "ogx_mmlux_it-high_school_mathematics"
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.023901157979402534,
      "alias": "ogx_mmlux_it-high_school_macroeconomics"
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "acc,none": 0.40932642487046633,
      "acc_stderr,none": 0.03548608168860806,
      "alias": "ogx_mmlux_it-high_school_government_and_politics"
    },
    "ogx_mmlux_it-high_school_geography": {
      "acc,none": 0.41919191919191917,
      "acc_stderr,none": 0.035155207286704175,
      "alias": "ogx_mmlux_it-high_school_geography"
    },
    "ogx_mmlux_it-high_school_european_history": {
      "acc,none": 0.49696969696969695,
      "acc_stderr,none": 0.03904272341431856,
      "alias": "ogx_mmlux_it-high_school_european_history"
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_it-high_school_computer_science"
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "acc,none": 0.2315270935960591,
      "acc_stderr,none": 0.029678333141444455,
      "alias": "ogx_mmlux_it-high_school_chemistry"
    },
    "ogx_mmlux_it-high_school_biology": {
      "acc,none": 0.3870967741935484,
      "acc_stderr,none": 0.027709359675032488,
      "alias": "ogx_mmlux_it-high_school_biology"
    },
    "ogx_mmlux_it-global_facts": {
      "acc,none": 0.26,
      "acc_stderr,none": 0.04408440022768078,
      "alias": "ogx_mmlux_it-global_facts"
    },
    "ogx_mmlux_it-formal_logic": {
      "acc,none": 0.2619047619047619,
      "acc_stderr,none": 0.03932537680392871,
      "alias": "ogx_mmlux_it-formal_logic"
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "acc,none": 0.25132275132275134,
      "acc_stderr,none": 0.022340482339643895,
      "alias": "ogx_mmlux_it-elementary_mathematics"
    },
    "ogx_mmlux_it-electrical_engineering": {
      "acc,none": 0.3931034482758621,
      "acc_stderr,none": 0.040703290137070705,
      "alias": "ogx_mmlux_it-electrical_engineering"
    },
    "ogx_mmlux_it-econometrics": {
      "acc,none": 0.2631578947368421,
      "acc_stderr,none": 0.04142439719489358,
      "alias": "ogx_mmlux_it-econometrics"
    },
    "ogx_mmlux_it-conceptual_physics": {
      "acc,none": 0.34893617021276596,
      "acc_stderr,none": 0.03115852213135778,
      "alias": "ogx_mmlux_it-conceptual_physics"
    },
    "ogx_mmlux_it-computer_security": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_it-computer_security"
    },
    "ogx_mmlux_it-college_physics": {
      "acc,none": 0.19607843137254902,
      "acc_stderr,none": 0.03950581861179964,
      "alias": "ogx_mmlux_it-college_physics"
    },
    "ogx_mmlux_it-college_medicine": {
      "acc,none": 0.34104046242774566,
      "acc_stderr,none": 0.03614665424180826,
      "alias": "ogx_mmlux_it-college_medicine"
    },
    "ogx_mmlux_it-college_mathematics": {
      "acc,none": 0.22,
      "acc_stderr,none": 0.04163331998932269,
      "alias": "ogx_mmlux_it-college_mathematics"
    },
    "ogx_mmlux_it-college_computer_science": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_it-college_computer_science"
    },
    "ogx_mmlux_it-college_chemistry": {
      "acc,none": 0.22,
      "acc_stderr,none": 0.0416333199893227,
      "alias": "ogx_mmlux_it-college_chemistry"
    },
    "ogx_mmlux_it-college_biology": {
      "acc,none": 0.3541666666666667,
      "acc_stderr,none": 0.039994111357535424,
      "alias": "ogx_mmlux_it-college_biology"
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "acc,none": 0.3622641509433962,
      "acc_stderr,none": 0.0295822451283843,
      "alias": "ogx_mmlux_it-clinical_knowledge"
    },
    "ogx_mmlux_it-business_ethics": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_it-business_ethics"
    },
    "ogx_mmlux_it-astronomy": {
      "acc,none": 0.3223684210526316,
      "acc_stderr,none": 0.03803510248351585,
      "alias": "ogx_mmlux_it-astronomy"
    },
    "ogx_mmlux_it-anatomy": {
      "acc,none": 0.4222222222222222,
      "acc_stderr,none": 0.04266763404099582,
      "alias": "ogx_mmlux_it-anatomy"
    },
    "ogx_mmlux_it-abstract_algebra": {
      "acc,none": 0.22,
      "acc_stderr,none": 0.041633319989322695,
      "alias": "ogx_mmlux_it-abstract_algebra"
    },
    "ogx_mmlux_hu-world_religions": {
      "acc,none": 0.5555555555555556,
      "acc_stderr,none": 0.0381107966983353,
      "alias": "ogx_mmlux_hu-world_religions"
    },
    "ogx_mmlux_hu-virology": {
      "acc,none": 0.3373493975903614,
      "acc_stderr,none": 0.03680783690727581,
      "alias": "ogx_mmlux_hu-virology"
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_hu-us_foreign_policy"
    },
    "ogx_mmlux_hu-sociology": {
      "acc,none": 0.4626865671641791,
      "acc_stderr,none": 0.03525675167467974,
      "alias": "ogx_mmlux_hu-sociology"
    },
    "ogx_mmlux_hu-security_studies": {
      "acc,none": 0.23265306122448978,
      "acc_stderr,none": 0.02704925791589618,
      "alias": "ogx_mmlux_hu-security_studies"
    },
    "ogx_mmlux_hu-public_relations": {
      "acc,none": 0.32727272727272727,
      "acc_stderr,none": 0.04494290866252089,
      "alias": "ogx_mmlux_hu-public_relations"
    },
    "ogx_mmlux_hu-professional_psychology": {
      "acc,none": 0.31209150326797386,
      "acc_stderr,none": 0.01874501120127766,
      "alias": "ogx_mmlux_hu-professional_psychology"
    },
    "ogx_mmlux_hu-professional_medicine": {
      "acc,none": 0.20588235294117646,
      "acc_stderr,none": 0.024562204314142314,
      "alias": "ogx_mmlux_hu-professional_medicine"
    },
    "ogx_mmlux_hu-professional_law": {
      "acc,none": 0.25097783572359844,
      "acc_stderr,none": 0.011073730299187233,
      "alias": "ogx_mmlux_hu-professional_law"
    },
    "ogx_mmlux_hu-professional_accounting": {
      "acc,none": 0.24822695035460993,
      "acc_stderr,none": 0.02577001564429039,
      "alias": "ogx_mmlux_hu-professional_accounting"
    },
    "ogx_mmlux_hu-prehistory": {
      "acc,none": 0.32407407407407407,
      "acc_stderr,none": 0.02604176620271716,
      "alias": "ogx_mmlux_hu-prehistory"
    },
    "ogx_mmlux_hu-philosophy": {
      "acc,none": 0.26688102893890675,
      "acc_stderr,none": 0.025122637608816646,
      "alias": "ogx_mmlux_hu-philosophy"
    },
    "ogx_mmlux_hu-nutrition": {
      "acc,none": 0.3235294117647059,
      "acc_stderr,none": 0.026787453111906535,
      "alias": "ogx_mmlux_hu-nutrition"
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "acc,none": 0.23798882681564246,
      "acc_stderr,none": 0.014242630070574885,
      "alias": "ogx_mmlux_hu-moral_scenarios"
    },
    "ogx_mmlux_hu-moral_disputes": {
      "acc,none": 0.2745664739884393,
      "acc_stderr,none": 0.02402774515526501,
      "alias": "ogx_mmlux_hu-moral_disputes"
    },
    "ogx_mmlux_hu-miscellaneous": {
      "acc,none": 0.41762452107279696,
      "acc_stderr,none": 0.017635637326951514,
      "alias": "ogx_mmlux_hu-miscellaneous"
    },
    "ogx_mmlux_hu-medical_genetics": {
      "acc,none": 0.41,
      "acc_stderr,none": 0.049431107042371025,
      "alias": "ogx_mmlux_hu-medical_genetics"
    },
    "ogx_mmlux_hu-marketing": {
      "acc,none": 0.45726495726495725,
      "acc_stderr,none": 0.03263622596380688,
      "alias": "ogx_mmlux_hu-marketing"
    },
    "ogx_mmlux_hu-management": {
      "acc,none": 0.21359223300970873,
      "acc_stderr,none": 0.04058042015646035,
      "alias": "ogx_mmlux_hu-management"
    },
    "ogx_mmlux_hu-machine_learning": {
      "acc,none": 0.30357142857142855,
      "acc_stderr,none": 0.04364226155841044,
      "alias": "ogx_mmlux_hu-machine_learning"
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "acc,none": 0.2331288343558282,
      "acc_stderr,none": 0.033220157957767414,
      "alias": "ogx_mmlux_hu-logical_fallacies"
    },
    "ogx_mmlux_hu-jurisprudence": {
      "acc,none": 0.3055555555555556,
      "acc_stderr,none": 0.04453197507374983,
      "alias": "ogx_mmlux_hu-jurisprudence"
    },
    "ogx_mmlux_hu-international_law": {
      "acc,none": 0.3884297520661157,
      "acc_stderr,none": 0.04449270350068382,
      "alias": "ogx_mmlux_hu-international_law"
    },
    "ogx_mmlux_hu-human_sexuality": {
      "acc,none": 0.33587786259541985,
      "acc_stderr,none": 0.04142313771996664,
      "alias": "ogx_mmlux_hu-human_sexuality"
    },
    "ogx_mmlux_hu-human_aging": {
      "acc,none": 0.39461883408071746,
      "acc_stderr,none": 0.03280400504755291,
      "alias": "ogx_mmlux_hu-human_aging"
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "acc,none": 0.33755274261603374,
      "acc_stderr,none": 0.030781549102026216,
      "alias": "ogx_mmlux_hu-high_school_world_history"
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "acc,none": 0.3431372549019608,
      "acc_stderr,none": 0.033321399446680854,
      "alias": "ogx_mmlux_hu-high_school_us_history"
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "acc,none": 0.1527777777777778,
      "acc_stderr,none": 0.024536326026134217,
      "alias": "ogx_mmlux_hu-high_school_statistics"
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "acc,none": 0.3431192660550459,
      "acc_stderr,none": 0.02035477773608604,
      "alias": "ogx_mmlux_hu-high_school_psychology"
    },
    "ogx_mmlux_hu-high_school_physics": {
      "acc,none": 0.2052980132450331,
      "acc_stderr,none": 0.03297986648473834,
      "alias": "ogx_mmlux_hu-high_school_physics"
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "acc,none": 0.25210084033613445,
      "acc_stderr,none": 0.02820554503327773,
      "alias": "ogx_mmlux_hu-high_school_microeconomics"
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "acc,none": 0.2111111111111111,
      "acc_stderr,none": 0.024882116857655092,
      "alias": "ogx_mmlux_hu-high_school_mathematics"
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "acc,none": 0.2564102564102564,
      "acc_stderr,none": 0.022139081103971538,
      "alias": "ogx_mmlux_hu-high_school_macroeconomics"
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "acc,none": 0.27461139896373055,
      "acc_stderr,none": 0.032210245080411544,
      "alias": "ogx_mmlux_hu-high_school_government_and_politics"
    },
    "ogx_mmlux_hu-high_school_geography": {
      "acc,none": 0.29797979797979796,
      "acc_stderr,none": 0.03258630383836556,
      "alias": "ogx_mmlux_hu-high_school_geography"
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "acc,none": 0.36363636363636365,
      "acc_stderr,none": 0.037563357751878974,
      "alias": "ogx_mmlux_hu-high_school_european_history"
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_hu-high_school_computer_science"
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "acc,none": 0.2019704433497537,
      "acc_stderr,none": 0.02824735012218026,
      "alias": "ogx_mmlux_hu-high_school_chemistry"
    },
    "ogx_mmlux_hu-high_school_biology": {
      "acc,none": 0.25806451612903225,
      "acc_stderr,none": 0.02489246917246284,
      "alias": "ogx_mmlux_hu-high_school_biology"
    },
    "ogx_mmlux_hu-global_facts": {
      "acc,none": 0.18,
      "acc_stderr,none": 0.03861229196653694,
      "alias": "ogx_mmlux_hu-global_facts"
    },
    "ogx_mmlux_hu-formal_logic": {
      "acc,none": 0.2698412698412698,
      "acc_stderr,none": 0.03970158273235172,
      "alias": "ogx_mmlux_hu-formal_logic"
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "acc,none": 0.21164021164021163,
      "acc_stderr,none": 0.02103733150526289,
      "alias": "ogx_mmlux_hu-elementary_mathematics"
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "acc,none": 0.30344827586206896,
      "acc_stderr,none": 0.038312260488503336,
      "alias": "ogx_mmlux_hu-electrical_engineering"
    },
    "ogx_mmlux_hu-econometrics": {
      "acc,none": 0.23684210526315788,
      "acc_stderr,none": 0.039994238792813344,
      "alias": "ogx_mmlux_hu-econometrics"
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "acc,none": 0.2978723404255319,
      "acc_stderr,none": 0.029896145682095462,
      "alias": "ogx_mmlux_hu-conceptual_physics"
    },
    "ogx_mmlux_hu-computer_security": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_hu-computer_security"
    },
    "ogx_mmlux_hu-college_physics": {
      "acc,none": 0.21568627450980393,
      "acc_stderr,none": 0.04092563958237654,
      "alias": "ogx_mmlux_hu-college_physics"
    },
    "ogx_mmlux_hu-college_medicine": {
      "acc,none": 0.23121387283236994,
      "acc_stderr,none": 0.0321473730202947,
      "alias": "ogx_mmlux_hu-college_medicine"
    },
    "ogx_mmlux_hu-college_mathematics": {
      "acc,none": 0.21,
      "acc_stderr,none": 0.040936018074033256,
      "alias": "ogx_mmlux_hu-college_mathematics"
    },
    "ogx_mmlux_hu-college_computer_science": {
      "acc,none": 0.26,
      "acc_stderr,none": 0.0440844002276808,
      "alias": "ogx_mmlux_hu-college_computer_science"
    },
    "ogx_mmlux_hu-college_chemistry": {
      "acc,none": 0.23,
      "acc_stderr,none": 0.042295258468165065,
      "alias": "ogx_mmlux_hu-college_chemistry"
    },
    "ogx_mmlux_hu-college_biology": {
      "acc,none": 0.2986111111111111,
      "acc_stderr,none": 0.03827052357950756,
      "alias": "ogx_mmlux_hu-college_biology"
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "acc,none": 0.2339622641509434,
      "acc_stderr,none": 0.02605529690115292,
      "alias": "ogx_mmlux_hu-clinical_knowledge"
    },
    "ogx_mmlux_hu-business_ethics": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_hu-business_ethics"
    },
    "ogx_mmlux_hu-astronomy": {
      "acc,none": 0.21710526315789475,
      "acc_stderr,none": 0.03355045304882923,
      "alias": "ogx_mmlux_hu-astronomy"
    },
    "ogx_mmlux_hu-anatomy": {
      "acc,none": 0.2814814814814815,
      "acc_stderr,none": 0.03885004245800254,
      "alias": "ogx_mmlux_hu-anatomy"
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "acc,none": 0.23,
      "acc_stderr,none": 0.04229525846816506,
      "alias": "ogx_mmlux_hu-abstract_algebra"
    },
    "ogx_mmlux_fr-world_religions": {
      "acc,none": 0.6608187134502924,
      "acc_stderr,none": 0.03631053496488905,
      "alias": "ogx_mmlux_fr-world_religions"
    },
    "ogx_mmlux_fr-virology": {
      "acc,none": 0.41566265060240964,
      "acc_stderr,none": 0.038367221765980515,
      "alias": "ogx_mmlux_fr-virology"
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "acc,none": 0.65,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_fr-us_foreign_policy"
    },
    "ogx_mmlux_fr-sociology": {
      "acc,none": 0.582089552238806,
      "acc_stderr,none": 0.034875586404620636,
      "alias": "ogx_mmlux_fr-sociology"
    },
    "ogx_mmlux_fr-security_studies": {
      "acc,none": 0.3673469387755102,
      "acc_stderr,none": 0.030862144921087555,
      "alias": "ogx_mmlux_fr-security_studies"
    },
    "ogx_mmlux_fr-public_relations": {
      "acc,none": 0.5181818181818182,
      "acc_stderr,none": 0.04785964010794916,
      "alias": "ogx_mmlux_fr-public_relations"
    },
    "ogx_mmlux_fr-professional_psychology": {
      "acc,none": 0.4150326797385621,
      "acc_stderr,none": 0.01993362777685742,
      "alias": "ogx_mmlux_fr-professional_psychology"
    },
    "ogx_mmlux_fr-professional_medicine": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.026303648393696036,
      "alias": "ogx_mmlux_fr-professional_medicine"
    },
    "ogx_mmlux_fr-professional_law": {
      "acc,none": 0.32529335071707954,
      "acc_stderr,none": 0.011965311536571531,
      "alias": "ogx_mmlux_fr-professional_law"
    },
    "ogx_mmlux_fr-professional_accounting": {
      "acc,none": 0.32269503546099293,
      "acc_stderr,none": 0.02788913930053481,
      "alias": "ogx_mmlux_fr-professional_accounting"
    },
    "ogx_mmlux_fr-prehistory": {
      "acc,none": 0.4660493827160494,
      "acc_stderr,none": 0.027756535257347666,
      "alias": "ogx_mmlux_fr-prehistory"
    },
    "ogx_mmlux_fr-philosophy": {
      "acc,none": 0.4630225080385852,
      "acc_stderr,none": 0.028320325830105908,
      "alias": "ogx_mmlux_fr-philosophy"
    },
    "ogx_mmlux_fr-nutrition": {
      "acc,none": 0.4477124183006536,
      "acc_stderr,none": 0.02847293847803353,
      "alias": "ogx_mmlux_fr-nutrition"
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "acc,none": 0.2659217877094972,
      "acc_stderr,none": 0.014776765066438888,
      "alias": "ogx_mmlux_fr-moral_scenarios"
    },
    "ogx_mmlux_fr-moral_disputes": {
      "acc,none": 0.45375722543352603,
      "acc_stderr,none": 0.02680372058320619,
      "alias": "ogx_mmlux_fr-moral_disputes"
    },
    "ogx_mmlux_fr-miscellaneous": {
      "acc,none": 0.578544061302682,
      "acc_stderr,none": 0.017657976412654854,
      "alias": "ogx_mmlux_fr-miscellaneous"
    },
    "ogx_mmlux_fr-medical_genetics": {
      "acc,none": 0.53,
      "acc_stderr,none": 0.050161355804659205,
      "alias": "ogx_mmlux_fr-medical_genetics"
    },
    "ogx_mmlux_fr-marketing": {
      "acc,none": 0.6153846153846154,
      "acc_stderr,none": 0.03187195347942466,
      "alias": "ogx_mmlux_fr-marketing"
    },
    "ogx_mmlux_fr-management": {
      "acc,none": 0.3592233009708738,
      "acc_stderr,none": 0.04750458399041692,
      "alias": "ogx_mmlux_fr-management"
    },
    "ogx_mmlux_fr-machine_learning": {
      "acc,none": 0.375,
      "acc_stderr,none": 0.04595091388086298,
      "alias": "ogx_mmlux_fr-machine_learning"
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "acc,none": 0.4171779141104294,
      "acc_stderr,none": 0.038741028598180814,
      "alias": "ogx_mmlux_fr-logical_fallacies"
    },
    "ogx_mmlux_fr-jurisprudence": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.04833682445228318,
      "alias": "ogx_mmlux_fr-jurisprudence"
    },
    "ogx_mmlux_fr-international_law": {
      "acc,none": 0.6198347107438017,
      "acc_stderr,none": 0.04431324501968431,
      "alias": "ogx_mmlux_fr-international_law"
    },
    "ogx_mmlux_fr-human_sexuality": {
      "acc,none": 0.5038167938931297,
      "acc_stderr,none": 0.043851623256015534,
      "alias": "ogx_mmlux_fr-human_sexuality"
    },
    "ogx_mmlux_fr-human_aging": {
      "acc,none": 0.5022421524663677,
      "acc_stderr,none": 0.033557465352232634,
      "alias": "ogx_mmlux_fr-human_aging"
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "acc,none": 0.5443037974683544,
      "acc_stderr,none": 0.03241920684693335,
      "alias": "ogx_mmlux_fr-high_school_world_history"
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "acc,none": 0.46078431372549017,
      "acc_stderr,none": 0.03498501649369527,
      "alias": "ogx_mmlux_fr-high_school_us_history"
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.029531221160930918,
      "alias": "ogx_mmlux_fr-high_school_statistics"
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "acc,none": 0.4935779816513762,
      "acc_stderr,none": 0.021435554820013077,
      "alias": "ogx_mmlux_fr-high_school_psychology"
    },
    "ogx_mmlux_fr-high_school_physics": {
      "acc,none": 0.26490066225165565,
      "acc_stderr,none": 0.03603038545360385,
      "alias": "ogx_mmlux_fr-high_school_physics"
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "acc,none": 0.36134453781512604,
      "acc_stderr,none": 0.031204691225150006,
      "alias": "ogx_mmlux_fr-high_school_microeconomics"
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "acc,none": 0.2814814814814815,
      "acc_stderr,none": 0.027420019350945284,
      "alias": "ogx_mmlux_fr-high_school_mathematics"
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "acc,none": 0.35128205128205126,
      "acc_stderr,none": 0.024203665177902796,
      "alias": "ogx_mmlux_fr-high_school_macroeconomics"
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "acc,none": 0.49222797927461137,
      "acc_stderr,none": 0.03608003225569654,
      "alias": "ogx_mmlux_fr-high_school_government_and_politics"
    },
    "ogx_mmlux_fr-high_school_geography": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.035623524993954825,
      "alias": "ogx_mmlux_fr-high_school_geography"
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "acc,none": 0.4727272727272727,
      "acc_stderr,none": 0.0389853160557942,
      "alias": "ogx_mmlux_fr-high_school_european_history"
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_fr-high_school_computer_science"
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "acc,none": 0.3448275862068966,
      "acc_stderr,none": 0.033442837442804574,
      "alias": "ogx_mmlux_fr-high_school_chemistry"
    },
    "ogx_mmlux_fr-high_school_biology": {
      "acc,none": 0.4258064516129032,
      "acc_stderr,none": 0.028129112709165908,
      "alias": "ogx_mmlux_fr-high_school_biology"
    },
    "ogx_mmlux_fr-global_facts": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_fr-global_facts"
    },
    "ogx_mmlux_fr-formal_logic": {
      "acc,none": 0.2222222222222222,
      "acc_stderr,none": 0.037184890068181146,
      "alias": "ogx_mmlux_fr-formal_logic"
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "acc,none": 0.2751322751322751,
      "acc_stderr,none": 0.023000086859068652,
      "alias": "ogx_mmlux_fr-elementary_mathematics"
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "acc,none": 0.4413793103448276,
      "acc_stderr,none": 0.04137931034482757,
      "alias": "ogx_mmlux_fr-electrical_engineering"
    },
    "ogx_mmlux_fr-econometrics": {
      "acc,none": 0.24561403508771928,
      "acc_stderr,none": 0.0404933929774814,
      "alias": "ogx_mmlux_fr-econometrics"
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "acc,none": 0.3702127659574468,
      "acc_stderr,none": 0.03156564682236785,
      "alias": "ogx_mmlux_fr-conceptual_physics"
    },
    "ogx_mmlux_fr-computer_security": {
      "acc,none": 0.53,
      "acc_stderr,none": 0.050161355804659205,
      "alias": "ogx_mmlux_fr-computer_security"
    },
    "ogx_mmlux_fr-college_physics": {
      "acc,none": 0.18627450980392157,
      "acc_stderr,none": 0.038739587141493524,
      "alias": "ogx_mmlux_fr-college_physics"
    },
    "ogx_mmlux_fr-college_medicine": {
      "acc,none": 0.36416184971098264,
      "acc_stderr,none": 0.036690724774169084,
      "alias": "ogx_mmlux_fr-college_medicine"
    },
    "ogx_mmlux_fr-college_mathematics": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.0446196043338474,
      "alias": "ogx_mmlux_fr-college_mathematics"
    },
    "ogx_mmlux_fr-college_computer_science": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_fr-college_computer_science"
    },
    "ogx_mmlux_fr-college_chemistry": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542127,
      "alias": "ogx_mmlux_fr-college_chemistry"
    },
    "ogx_mmlux_fr-college_biology": {
      "acc,none": 0.4583333333333333,
      "acc_stderr,none": 0.04166666666666666,
      "alias": "ogx_mmlux_fr-college_biology"
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "acc,none": 0.4188679245283019,
      "acc_stderr,none": 0.030365050829115208,
      "alias": "ogx_mmlux_fr-clinical_knowledge"
    },
    "ogx_mmlux_fr-business_ethics": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_fr-business_ethics"
    },
    "ogx_mmlux_fr-astronomy": {
      "acc,none": 0.40131578947368424,
      "acc_stderr,none": 0.039889037033362836,
      "alias": "ogx_mmlux_fr-astronomy"
    },
    "ogx_mmlux_fr-anatomy": {
      "acc,none": 0.4148148148148148,
      "acc_stderr,none": 0.042561937679014075,
      "alias": "ogx_mmlux_fr-anatomy"
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542128,
      "alias": "ogx_mmlux_fr-abstract_algebra"
    },
    "ogx_mmlux_fi-world_religions": {
      "acc,none": 0.6198830409356725,
      "acc_stderr,none": 0.037229657413855394,
      "alias": "ogx_mmlux_fi-world_religions"
    },
    "ogx_mmlux_fi-virology": {
      "acc,none": 0.37349397590361444,
      "acc_stderr,none": 0.037658451171688624,
      "alias": "ogx_mmlux_fi-virology"
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_fi-us_foreign_policy"
    },
    "ogx_mmlux_fi-sociology": {
      "acc,none": 0.5522388059701493,
      "acc_stderr,none": 0.03516184772952167,
      "alias": "ogx_mmlux_fi-sociology"
    },
    "ogx_mmlux_fi-security_studies": {
      "acc,none": 0.4122448979591837,
      "acc_stderr,none": 0.03151236044674281,
      "alias": "ogx_mmlux_fi-security_studies"
    },
    "ogx_mmlux_fi-public_relations": {
      "acc,none": 0.44545454545454544,
      "acc_stderr,none": 0.047605488214603246,
      "alias": "ogx_mmlux_fi-public_relations"
    },
    "ogx_mmlux_fi-professional_psychology": {
      "acc,none": 0.37745098039215685,
      "acc_stderr,none": 0.019610851474880276,
      "alias": "ogx_mmlux_fi-professional_psychology"
    },
    "ogx_mmlux_fi-professional_medicine": {
      "acc,none": 0.27941176470588236,
      "acc_stderr,none": 0.027257202606114944,
      "alias": "ogx_mmlux_fi-professional_medicine"
    },
    "ogx_mmlux_fi-professional_law": {
      "acc,none": 0.31290743155149936,
      "acc_stderr,none": 0.011842529823062995,
      "alias": "ogx_mmlux_fi-professional_law"
    },
    "ogx_mmlux_fi-professional_accounting": {
      "acc,none": 0.2872340425531915,
      "acc_stderr,none": 0.026992199173064356,
      "alias": "ogx_mmlux_fi-professional_accounting"
    },
    "ogx_mmlux_fi-prehistory": {
      "acc,none": 0.4351851851851852,
      "acc_stderr,none": 0.027586006221607708,
      "alias": "ogx_mmlux_fi-prehistory"
    },
    "ogx_mmlux_fi-philosophy": {
      "acc,none": 0.43729903536977494,
      "acc_stderr,none": 0.02817391776176288,
      "alias": "ogx_mmlux_fi-philosophy"
    },
    "ogx_mmlux_fi-nutrition": {
      "acc,none": 0.4411764705882353,
      "acc_stderr,none": 0.028431095444176647,
      "alias": "ogx_mmlux_fi-nutrition"
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "acc,none": 0.25027932960893856,
      "acc_stderr,none": 0.014487500852850414,
      "alias": "ogx_mmlux_fi-moral_scenarios"
    },
    "ogx_mmlux_fi-moral_disputes": {
      "acc,none": 0.4479768786127168,
      "acc_stderr,none": 0.02677299065336182,
      "alias": "ogx_mmlux_fi-moral_disputes"
    },
    "ogx_mmlux_fi-miscellaneous": {
      "acc,none": 0.5159642401021711,
      "acc_stderr,none": 0.017870847506081734,
      "alias": "ogx_mmlux_fi-miscellaneous"
    },
    "ogx_mmlux_fi-medical_genetics": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_fi-medical_genetics"
    },
    "ogx_mmlux_fi-marketing": {
      "acc,none": 0.6196581196581197,
      "acc_stderr,none": 0.03180425204384099,
      "alias": "ogx_mmlux_fi-marketing"
    },
    "ogx_mmlux_fi-management": {
      "acc,none": 0.4174757281553398,
      "acc_stderr,none": 0.048828405482122375,
      "alias": "ogx_mmlux_fi-management"
    },
    "ogx_mmlux_fi-machine_learning": {
      "acc,none": 0.29464285714285715,
      "acc_stderr,none": 0.043270409325787296,
      "alias": "ogx_mmlux_fi-machine_learning"
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "acc,none": 0.37423312883435583,
      "acc_stderr,none": 0.038020681028996146,
      "alias": "ogx_mmlux_fi-logical_fallacies"
    },
    "ogx_mmlux_fi-jurisprudence": {
      "acc,none": 0.39814814814814814,
      "acc_stderr,none": 0.04732332615978814,
      "alias": "ogx_mmlux_fi-jurisprudence"
    },
    "ogx_mmlux_fi-international_law": {
      "acc,none": 0.5867768595041323,
      "acc_stderr,none": 0.04495087843548408,
      "alias": "ogx_mmlux_fi-international_law"
    },
    "ogx_mmlux_fi-human_sexuality": {
      "acc,none": 0.48091603053435117,
      "acc_stderr,none": 0.04382094705550988,
      "alias": "ogx_mmlux_fi-human_sexuality"
    },
    "ogx_mmlux_fi-human_aging": {
      "acc,none": 0.5112107623318386,
      "acc_stderr,none": 0.033549366530984746,
      "alias": "ogx_mmlux_fi-human_aging"
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "acc,none": 0.4936708860759494,
      "acc_stderr,none": 0.03254462010767859,
      "alias": "ogx_mmlux_fi-high_school_world_history"
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "acc,none": 0.4803921568627451,
      "acc_stderr,none": 0.03506612560524866,
      "alias": "ogx_mmlux_fi-high_school_us_history"
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "acc,none": 0.18055555555555555,
      "acc_stderr,none": 0.02623287897149166,
      "alias": "ogx_mmlux_fi-high_school_statistics"
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "acc,none": 0.44403669724770645,
      "acc_stderr,none": 0.021302621211654525,
      "alias": "ogx_mmlux_fi-high_school_psychology"
    },
    "ogx_mmlux_fi-high_school_physics": {
      "acc,none": 0.2582781456953642,
      "acc_stderr,none": 0.035737053147634576,
      "alias": "ogx_mmlux_fi-high_school_physics"
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "acc,none": 0.31512605042016806,
      "acc_stderr,none": 0.030176808288974337,
      "alias": "ogx_mmlux_fi-high_school_microeconomics"
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "acc,none": 0.2740740740740741,
      "acc_stderr,none": 0.027195934804085626,
      "alias": "ogx_mmlux_fi-high_school_mathematics"
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "acc,none": 0.3230769230769231,
      "acc_stderr,none": 0.02371088850197057,
      "alias": "ogx_mmlux_fi-high_school_macroeconomics"
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "acc,none": 0.40414507772020725,
      "acc_stderr,none": 0.0354150857888402,
      "alias": "ogx_mmlux_fi-high_school_government_and_politics"
    },
    "ogx_mmlux_fi-high_school_geography": {
      "acc,none": 0.42424242424242425,
      "acc_stderr,none": 0.03521224908841583,
      "alias": "ogx_mmlux_fi-high_school_geography"
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "acc,none": 0.47878787878787876,
      "acc_stderr,none": 0.03900828913737302,
      "alias": "ogx_mmlux_fi-high_school_european_history"
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_fi-high_school_computer_science"
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "acc,none": 0.27586206896551724,
      "acc_stderr,none": 0.0314471258167824,
      "alias": "ogx_mmlux_fi-high_school_chemistry"
    },
    "ogx_mmlux_fi-high_school_biology": {
      "acc,none": 0.38387096774193546,
      "acc_stderr,none": 0.02766618207553965,
      "alias": "ogx_mmlux_fi-high_school_biology"
    },
    "ogx_mmlux_fi-global_facts": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_fi-global_facts"
    },
    "ogx_mmlux_fi-formal_logic": {
      "acc,none": 0.2222222222222222,
      "acc_stderr,none": 0.03718489006818115,
      "alias": "ogx_mmlux_fi-formal_logic"
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "acc,none": 0.25925925925925924,
      "acc_stderr,none": 0.022569897074918424,
      "alias": "ogx_mmlux_fi-elementary_mathematics"
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "acc,none": 0.4068965517241379,
      "acc_stderr,none": 0.04093793981266237,
      "alias": "ogx_mmlux_fi-electrical_engineering"
    },
    "ogx_mmlux_fi-econometrics": {
      "acc,none": 0.2719298245614035,
      "acc_stderr,none": 0.04185774424022056,
      "alias": "ogx_mmlux_fi-econometrics"
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "acc,none": 0.34893617021276596,
      "acc_stderr,none": 0.031158522131357776,
      "alias": "ogx_mmlux_fi-conceptual_physics"
    },
    "ogx_mmlux_fi-computer_security": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_fi-computer_security"
    },
    "ogx_mmlux_fi-college_physics": {
      "acc,none": 0.2549019607843137,
      "acc_stderr,none": 0.04336432707993176,
      "alias": "ogx_mmlux_fi-college_physics"
    },
    "ogx_mmlux_fi-college_medicine": {
      "acc,none": 0.3583815028901734,
      "acc_stderr,none": 0.036563436533531585,
      "alias": "ogx_mmlux_fi-college_medicine"
    },
    "ogx_mmlux_fi-college_mathematics": {
      "acc,none": 0.22,
      "acc_stderr,none": 0.041633319989322695,
      "alias": "ogx_mmlux_fi-college_mathematics"
    },
    "ogx_mmlux_fi-college_computer_science": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.04793724854411018,
      "alias": "ogx_mmlux_fi-college_computer_science"
    },
    "ogx_mmlux_fi-college_chemistry": {
      "acc,none": 0.16,
      "acc_stderr,none": 0.03684529491774711,
      "alias": "ogx_mmlux_fi-college_chemistry"
    },
    "ogx_mmlux_fi-college_biology": {
      "acc,none": 0.3125,
      "acc_stderr,none": 0.038760854559127644,
      "alias": "ogx_mmlux_fi-college_biology"
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "acc,none": 0.3849056603773585,
      "acc_stderr,none": 0.02994649856769995,
      "alias": "ogx_mmlux_fi-clinical_knowledge"
    },
    "ogx_mmlux_fi-business_ethics": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_fi-business_ethics"
    },
    "ogx_mmlux_fi-astronomy": {
      "acc,none": 0.39473684210526316,
      "acc_stderr,none": 0.039777499346220734,
      "alias": "ogx_mmlux_fi-astronomy"
    },
    "ogx_mmlux_fi-anatomy": {
      "acc,none": 0.35555555555555557,
      "acc_stderr,none": 0.04135176749720386,
      "alias": "ogx_mmlux_fi-anatomy"
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252606,
      "alias": "ogx_mmlux_fi-abstract_algebra"
    },
    "ogx_mmlux_et-world_religions": {
      "acc,none": 0.5847953216374269,
      "acc_stderr,none": 0.037792759455032,
      "alias": "ogx_mmlux_et-world_religions"
    },
    "ogx_mmlux_et-virology": {
      "acc,none": 0.3795180722891566,
      "acc_stderr,none": 0.03777798822748018,
      "alias": "ogx_mmlux_et-virology"
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "acc,none": 0.68,
      "acc_stderr,none": 0.046882617226215034,
      "alias": "ogx_mmlux_et-us_foreign_policy"
    },
    "ogx_mmlux_et-sociology": {
      "acc,none": 0.5223880597014925,
      "acc_stderr,none": 0.03531987930208731,
      "alias": "ogx_mmlux_et-sociology"
    },
    "ogx_mmlux_et-security_studies": {
      "acc,none": 0.31020408163265306,
      "acc_stderr,none": 0.02961345987248438,
      "alias": "ogx_mmlux_et-security_studies"
    },
    "ogx_mmlux_et-public_relations": {
      "acc,none": 0.5363636363636364,
      "acc_stderr,none": 0.047764491623961985,
      "alias": "ogx_mmlux_et-public_relations"
    },
    "ogx_mmlux_et-professional_psychology": {
      "acc,none": 0.3937908496732026,
      "acc_stderr,none": 0.019766211991073063,
      "alias": "ogx_mmlux_et-professional_psychology"
    },
    "ogx_mmlux_et-professional_medicine": {
      "acc,none": 0.24632352941176472,
      "acc_stderr,none": 0.02617343857052,
      "alias": "ogx_mmlux_et-professional_medicine"
    },
    "ogx_mmlux_et-professional_law": {
      "acc,none": 0.3057366362451108,
      "acc_stderr,none": 0.011766973847072915,
      "alias": "ogx_mmlux_et-professional_law"
    },
    "ogx_mmlux_et-professional_accounting": {
      "acc,none": 0.2872340425531915,
      "acc_stderr,none": 0.026992199173064356,
      "alias": "ogx_mmlux_et-professional_accounting"
    },
    "ogx_mmlux_et-prehistory": {
      "acc,none": 0.4567901234567901,
      "acc_stderr,none": 0.02771666165019404,
      "alias": "ogx_mmlux_et-prehistory"
    },
    "ogx_mmlux_et-philosophy": {
      "acc,none": 0.3987138263665595,
      "acc_stderr,none": 0.0278093225857745,
      "alias": "ogx_mmlux_et-philosophy"
    },
    "ogx_mmlux_et-nutrition": {
      "acc,none": 0.4738562091503268,
      "acc_stderr,none": 0.028590752958852394,
      "alias": "ogx_mmlux_et-nutrition"
    },
    "ogx_mmlux_et-moral_scenarios": {
      "acc,none": 0.28156424581005585,
      "acc_stderr,none": 0.015042290171866127,
      "alias": "ogx_mmlux_et-moral_scenarios"
    },
    "ogx_mmlux_et-moral_disputes": {
      "acc,none": 0.3959537572254335,
      "acc_stderr,none": 0.02632981334194625,
      "alias": "ogx_mmlux_et-moral_disputes"
    },
    "ogx_mmlux_et-miscellaneous": {
      "acc,none": 0.5197956577266922,
      "acc_stderr,none": 0.017865944827291622,
      "alias": "ogx_mmlux_et-miscellaneous"
    },
    "ogx_mmlux_et-medical_genetics": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_et-medical_genetics"
    },
    "ogx_mmlux_et-marketing": {
      "acc,none": 0.5811965811965812,
      "acc_stderr,none": 0.03232128912157792,
      "alias": "ogx_mmlux_et-marketing"
    },
    "ogx_mmlux_et-management": {
      "acc,none": 0.4077669902912621,
      "acc_stderr,none": 0.048657775704107696,
      "alias": "ogx_mmlux_et-management"
    },
    "ogx_mmlux_et-machine_learning": {
      "acc,none": 0.33035714285714285,
      "acc_stderr,none": 0.04464285714285713,
      "alias": "ogx_mmlux_et-machine_learning"
    },
    "ogx_mmlux_et-logical_fallacies": {
      "acc,none": 0.3558282208588957,
      "acc_stderr,none": 0.03761521380046734,
      "alias": "ogx_mmlux_et-logical_fallacies"
    },
    "ogx_mmlux_et-jurisprudence": {
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.04766075165356462,
      "alias": "ogx_mmlux_et-jurisprudence"
    },
    "ogx_mmlux_et-international_law": {
      "acc,none": 0.6446280991735537,
      "acc_stderr,none": 0.04369236326573981,
      "alias": "ogx_mmlux_et-international_law"
    },
    "ogx_mmlux_et-human_sexuality": {
      "acc,none": 0.48091603053435117,
      "acc_stderr,none": 0.04382094705550988,
      "alias": "ogx_mmlux_et-human_sexuality"
    },
    "ogx_mmlux_et-human_aging": {
      "acc,none": 0.47085201793721976,
      "acc_stderr,none": 0.03350073248773403,
      "alias": "ogx_mmlux_et-human_aging"
    },
    "ogx_mmlux_et-high_school_world_history": {
      "acc,none": 0.4936708860759494,
      "acc_stderr,none": 0.03254462010767859,
      "alias": "ogx_mmlux_et-high_school_world_history"
    },
    "ogx_mmlux_et-high_school_us_history": {
      "acc,none": 0.44607843137254904,
      "acc_stderr,none": 0.03488845451304974,
      "alias": "ogx_mmlux_et-high_school_us_history"
    },
    "ogx_mmlux_et-high_school_statistics": {
      "acc,none": 0.17592592592592593,
      "acc_stderr,none": 0.025967420958258526,
      "alias": "ogx_mmlux_et-high_school_statistics"
    },
    "ogx_mmlux_et-high_school_psychology": {
      "acc,none": 0.45688073394495415,
      "acc_stderr,none": 0.021357458785226203,
      "alias": "ogx_mmlux_et-high_school_psychology"
    },
    "ogx_mmlux_et-high_school_physics": {
      "acc,none": 0.2781456953642384,
      "acc_stderr,none": 0.036586032627637426,
      "alias": "ogx_mmlux_et-high_school_physics"
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "acc,none": 0.3403361344537815,
      "acc_stderr,none": 0.030778057422931673,
      "alias": "ogx_mmlux_et-high_school_microeconomics"
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "acc,none": 0.25925925925925924,
      "acc_stderr,none": 0.026719240783712163,
      "alias": "ogx_mmlux_et-high_school_mathematics"
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "acc,none": 0.32051282051282054,
      "acc_stderr,none": 0.023661296393964273,
      "alias": "ogx_mmlux_et-high_school_macroeconomics"
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "acc,none": 0.41450777202072536,
      "acc_stderr,none": 0.03555300319557672,
      "alias": "ogx_mmlux_et-high_school_government_and_politics"
    },
    "ogx_mmlux_et-high_school_geography": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.0347327959083696,
      "alias": "ogx_mmlux_et-high_school_geography"
    },
    "ogx_mmlux_et-high_school_european_history": {
      "acc,none": 0.4666666666666667,
      "acc_stderr,none": 0.03895658065271846,
      "alias": "ogx_mmlux_et-high_school_european_history"
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_et-high_school_computer_science"
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "acc,none": 0.23645320197044334,
      "acc_stderr,none": 0.029896114291733552,
      "alias": "ogx_mmlux_et-high_school_chemistry"
    },
    "ogx_mmlux_et-high_school_biology": {
      "acc,none": 0.3709677419354839,
      "acc_stderr,none": 0.027480541887953593,
      "alias": "ogx_mmlux_et-high_school_biology"
    },
    "ogx_mmlux_et-global_facts": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_et-global_facts"
    },
    "ogx_mmlux_et-formal_logic": {
      "acc,none": 0.18253968253968253,
      "acc_stderr,none": 0.03455071019102149,
      "alias": "ogx_mmlux_et-formal_logic"
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "acc,none": 0.28835978835978837,
      "acc_stderr,none": 0.023330654054535868,
      "alias": "ogx_mmlux_et-elementary_mathematics"
    },
    "ogx_mmlux_et-electrical_engineering": {
      "acc,none": 0.35172413793103446,
      "acc_stderr,none": 0.0397923663749741,
      "alias": "ogx_mmlux_et-electrical_engineering"
    },
    "ogx_mmlux_et-econometrics": {
      "acc,none": 0.2631578947368421,
      "acc_stderr,none": 0.041424397194893596,
      "alias": "ogx_mmlux_et-econometrics"
    },
    "ogx_mmlux_et-conceptual_physics": {
      "acc,none": 0.3148936170212766,
      "acc_stderr,none": 0.03036358219723816,
      "alias": "ogx_mmlux_et-conceptual_physics"
    },
    "ogx_mmlux_et-computer_security": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_et-computer_security"
    },
    "ogx_mmlux_et-college_physics": {
      "acc,none": 0.22549019607843138,
      "acc_stderr,none": 0.041583075330832865,
      "alias": "ogx_mmlux_et-college_physics"
    },
    "ogx_mmlux_et-college_medicine": {
      "acc,none": 0.3063583815028902,
      "acc_stderr,none": 0.03514942551267438,
      "alias": "ogx_mmlux_et-college_medicine"
    },
    "ogx_mmlux_et-college_mathematics": {
      "acc,none": 0.23,
      "acc_stderr,none": 0.04229525846816506,
      "alias": "ogx_mmlux_et-college_mathematics"
    },
    "ogx_mmlux_et-college_computer_science": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_et-college_computer_science"
    },
    "ogx_mmlux_et-college_chemistry": {
      "acc,none": 0.2,
      "acc_stderr,none": 0.040201512610368445,
      "alias": "ogx_mmlux_et-college_chemistry"
    },
    "ogx_mmlux_et-college_biology": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.04076663253918567,
      "alias": "ogx_mmlux_et-college_biology"
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "acc,none": 0.37735849056603776,
      "acc_stderr,none": 0.029832808114796005,
      "alias": "ogx_mmlux_et-clinical_knowledge"
    },
    "ogx_mmlux_et-business_ethics": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_et-business_ethics"
    },
    "ogx_mmlux_et-astronomy": {
      "acc,none": 0.3618421052631579,
      "acc_stderr,none": 0.03910525752849724,
      "alias": "ogx_mmlux_et-astronomy"
    },
    "ogx_mmlux_et-anatomy": {
      "acc,none": 0.32592592592592595,
      "acc_stderr,none": 0.040491220417025055,
      "alias": "ogx_mmlux_et-anatomy"
    },
    "ogx_mmlux_et-abstract_algebra": {
      "acc,none": 0.24,
      "acc_stderr,none": 0.04292346959909281,
      "alias": "ogx_mmlux_et-abstract_algebra"
    },
    "ogx_mmlux_es-world_religions": {
      "acc,none": 0.6549707602339181,
      "acc_stderr,none": 0.03645981377388807,
      "alias": "ogx_mmlux_es-world_religions"
    },
    "ogx_mmlux_es-virology": {
      "acc,none": 0.41566265060240964,
      "acc_stderr,none": 0.038367221765980515,
      "alias": "ogx_mmlux_es-virology"
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.04878317312145632,
      "alias": "ogx_mmlux_es-us_foreign_policy"
    },
    "ogx_mmlux_es-sociology": {
      "acc,none": 0.5671641791044776,
      "acc_stderr,none": 0.03503490923673282,
      "alias": "ogx_mmlux_es-sociology"
    },
    "ogx_mmlux_es-security_studies": {
      "acc,none": 0.46530612244897956,
      "acc_stderr,none": 0.03193207024425314,
      "alias": "ogx_mmlux_es-security_studies"
    },
    "ogx_mmlux_es-public_relations": {
      "acc,none": 0.4909090909090909,
      "acc_stderr,none": 0.0478833976870286,
      "alias": "ogx_mmlux_es-public_relations"
    },
    "ogx_mmlux_es-professional_psychology": {
      "acc,none": 0.41830065359477125,
      "acc_stderr,none": 0.019955975145835542,
      "alias": "ogx_mmlux_es-professional_psychology"
    },
    "ogx_mmlux_es-professional_medicine": {
      "acc,none": 0.2757352941176471,
      "acc_stderr,none": 0.02714627193662517,
      "alias": "ogx_mmlux_es-professional_medicine"
    },
    "ogx_mmlux_es-professional_law": {
      "acc,none": 0.30638852672750977,
      "acc_stderr,none": 0.011773980329380741,
      "alias": "ogx_mmlux_es-professional_law"
    },
    "ogx_mmlux_es-professional_accounting": {
      "acc,none": 0.2978723404255319,
      "acc_stderr,none": 0.02728160834446941,
      "alias": "ogx_mmlux_es-professional_accounting"
    },
    "ogx_mmlux_es-prehistory": {
      "acc,none": 0.43209876543209874,
      "acc_stderr,none": 0.02756301097160668,
      "alias": "ogx_mmlux_es-prehistory"
    },
    "ogx_mmlux_es-philosophy": {
      "acc,none": 0.4212218649517685,
      "acc_stderr,none": 0.028043399858210628,
      "alias": "ogx_mmlux_es-philosophy"
    },
    "ogx_mmlux_es-nutrition": {
      "acc,none": 0.477124183006536,
      "acc_stderr,none": 0.028599936776089782,
      "alias": "ogx_mmlux_es-nutrition"
    },
    "ogx_mmlux_es-moral_scenarios": {
      "acc,none": 0.2748603351955307,
      "acc_stderr,none": 0.014931316703220506,
      "alias": "ogx_mmlux_es-moral_scenarios"
    },
    "ogx_mmlux_es-moral_disputes": {
      "acc,none": 0.3959537572254335,
      "acc_stderr,none": 0.026329813341946243,
      "alias": "ogx_mmlux_es-moral_disputes"
    },
    "ogx_mmlux_es-miscellaneous": {
      "acc,none": 0.545338441890166,
      "acc_stderr,none": 0.017806304585052602,
      "alias": "ogx_mmlux_es-miscellaneous"
    },
    "ogx_mmlux_es-medical_genetics": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_es-medical_genetics"
    },
    "ogx_mmlux_es-marketing": {
      "acc,none": 0.6581196581196581,
      "acc_stderr,none": 0.031075028526507748,
      "alias": "ogx_mmlux_es-marketing"
    },
    "ogx_mmlux_es-management": {
      "acc,none": 0.3106796116504854,
      "acc_stderr,none": 0.04582124160161549,
      "alias": "ogx_mmlux_es-management"
    },
    "ogx_mmlux_es-machine_learning": {
      "acc,none": 0.35714285714285715,
      "acc_stderr,none": 0.04547960999764376,
      "alias": "ogx_mmlux_es-machine_learning"
    },
    "ogx_mmlux_es-logical_fallacies": {
      "acc,none": 0.3803680981595092,
      "acc_stderr,none": 0.03814269893261836,
      "alias": "ogx_mmlux_es-logical_fallacies"
    },
    "ogx_mmlux_es-jurisprudence": {
      "acc,none": 0.42592592592592593,
      "acc_stderr,none": 0.0478034362693679,
      "alias": "ogx_mmlux_es-jurisprudence"
    },
    "ogx_mmlux_es-international_law": {
      "acc,none": 0.6115702479338843,
      "acc_stderr,none": 0.04449270350068382,
      "alias": "ogx_mmlux_es-international_law"
    },
    "ogx_mmlux_es-human_sexuality": {
      "acc,none": 0.5267175572519084,
      "acc_stderr,none": 0.04379024936553894,
      "alias": "ogx_mmlux_es-human_sexuality"
    },
    "ogx_mmlux_es-human_aging": {
      "acc,none": 0.5112107623318386,
      "acc_stderr,none": 0.033549366530984746,
      "alias": "ogx_mmlux_es-human_aging"
    },
    "ogx_mmlux_es-high_school_world_history": {
      "acc,none": 0.5358649789029536,
      "acc_stderr,none": 0.03246338898055659,
      "alias": "ogx_mmlux_es-high_school_world_history"
    },
    "ogx_mmlux_es-high_school_us_history": {
      "acc,none": 0.4215686274509804,
      "acc_stderr,none": 0.03465868196380758,
      "alias": "ogx_mmlux_es-high_school_us_history"
    },
    "ogx_mmlux_es-high_school_statistics": {
      "acc,none": 0.21296296296296297,
      "acc_stderr,none": 0.027920963147993666,
      "alias": "ogx_mmlux_es-high_school_statistics"
    },
    "ogx_mmlux_es-high_school_psychology": {
      "acc,none": 0.5302752293577981,
      "acc_stderr,none": 0.021397988604936965,
      "alias": "ogx_mmlux_es-high_school_psychology"
    },
    "ogx_mmlux_es-high_school_physics": {
      "acc,none": 0.2582781456953642,
      "acc_stderr,none": 0.035737053147634576,
      "alias": "ogx_mmlux_es-high_school_physics"
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "acc,none": 0.3319327731092437,
      "acc_stderr,none": 0.030588697013783663,
      "alias": "ogx_mmlux_es-high_school_microeconomics"
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "acc,none": 0.26296296296296295,
      "acc_stderr,none": 0.02684205787383371,
      "alias": "ogx_mmlux_es-high_school_mathematics"
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "acc,none": 0.3487179487179487,
      "acc_stderr,none": 0.02416278028401772,
      "alias": "ogx_mmlux_es-high_school_macroeconomics"
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "acc,none": 0.44041450777202074,
      "acc_stderr,none": 0.03582724530036094,
      "alias": "ogx_mmlux_es-high_school_government_and_politics"
    },
    "ogx_mmlux_es-high_school_geography": {
      "acc,none": 0.4696969696969697,
      "acc_stderr,none": 0.03555804051763929,
      "alias": "ogx_mmlux_es-high_school_geography"
    },
    "ogx_mmlux_es-high_school_european_history": {
      "acc,none": 0.509090909090909,
      "acc_stderr,none": 0.03903698647748441,
      "alias": "ogx_mmlux_es-high_school_european_history"
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_es-high_school_computer_science"
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "acc,none": 0.2413793103448276,
      "acc_stderr,none": 0.030108330718011625,
      "alias": "ogx_mmlux_es-high_school_chemistry"
    },
    "ogx_mmlux_es-high_school_biology": {
      "acc,none": 0.36774193548387096,
      "acc_stderr,none": 0.027430866579973463,
      "alias": "ogx_mmlux_es-high_school_biology"
    },
    "ogx_mmlux_es-global_facts": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_es-global_facts"
    },
    "ogx_mmlux_es-formal_logic": {
      "acc,none": 0.2619047619047619,
      "acc_stderr,none": 0.03932537680392871,
      "alias": "ogx_mmlux_es-formal_logic"
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "acc,none": 0.26455026455026454,
      "acc_stderr,none": 0.022717467897708624,
      "alias": "ogx_mmlux_es-elementary_mathematics"
    },
    "ogx_mmlux_es-electrical_engineering": {
      "acc,none": 0.4413793103448276,
      "acc_stderr,none": 0.04137931034482757,
      "alias": "ogx_mmlux_es-electrical_engineering"
    },
    "ogx_mmlux_es-econometrics": {
      "acc,none": 0.2543859649122807,
      "acc_stderr,none": 0.040969851398436695,
      "alias": "ogx_mmlux_es-econometrics"
    },
    "ogx_mmlux_es-conceptual_physics": {
      "acc,none": 0.39574468085106385,
      "acc_stderr,none": 0.031967586978353627,
      "alias": "ogx_mmlux_es-conceptual_physics"
    },
    "ogx_mmlux_es-computer_security": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_es-computer_security"
    },
    "ogx_mmlux_es-college_physics": {
      "acc,none": 0.18627450980392157,
      "acc_stderr,none": 0.038739587141493524,
      "alias": "ogx_mmlux_es-college_physics"
    },
    "ogx_mmlux_es-college_medicine": {
      "acc,none": 0.36416184971098264,
      "acc_stderr,none": 0.03669072477416907,
      "alias": "ogx_mmlux_es-college_medicine"
    },
    "ogx_mmlux_es-college_mathematics": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_es-college_mathematics"
    },
    "ogx_mmlux_es-college_computer_science": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_es-college_computer_science"
    },
    "ogx_mmlux_es-college_chemistry": {
      "acc,none": 0.24,
      "acc_stderr,none": 0.04292346959909282,
      "alias": "ogx_mmlux_es-college_chemistry"
    },
    "ogx_mmlux_es-college_biology": {
      "acc,none": 0.3472222222222222,
      "acc_stderr,none": 0.039812405437178615,
      "alias": "ogx_mmlux_es-college_biology"
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "acc,none": 0.37358490566037733,
      "acc_stderr,none": 0.029773082713319878,
      "alias": "ogx_mmlux_es-clinical_knowledge"
    },
    "ogx_mmlux_es-business_ethics": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_es-business_ethics"
    },
    "ogx_mmlux_es-astronomy": {
      "acc,none": 0.4342105263157895,
      "acc_stderr,none": 0.040335656678483205,
      "alias": "ogx_mmlux_es-astronomy"
    },
    "ogx_mmlux_es-anatomy": {
      "acc,none": 0.3851851851851852,
      "acc_stderr,none": 0.042039210401562783,
      "alias": "ogx_mmlux_es-anatomy"
    },
    "ogx_mmlux_es-abstract_algebra": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_es-abstract_algebra"
    },
    "ogx_mmlux_el-world_religions": {
      "acc,none": 0.39766081871345027,
      "acc_stderr,none": 0.0375363895576169,
      "alias": "ogx_mmlux_el-world_religions"
    },
    "ogx_mmlux_el-virology": {
      "acc,none": 0.2710843373493976,
      "acc_stderr,none": 0.03460579907553026,
      "alias": "ogx_mmlux_el-virology"
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_el-us_foreign_policy"
    },
    "ogx_mmlux_el-sociology": {
      "acc,none": 0.46766169154228854,
      "acc_stderr,none": 0.035281314729336065,
      "alias": "ogx_mmlux_el-sociology"
    },
    "ogx_mmlux_el-security_studies": {
      "acc,none": 0.4204081632653061,
      "acc_stderr,none": 0.03160106993449603,
      "alias": "ogx_mmlux_el-security_studies"
    },
    "ogx_mmlux_el-public_relations": {
      "acc,none": 0.36363636363636365,
      "acc_stderr,none": 0.04607582090719976,
      "alias": "ogx_mmlux_el-public_relations"
    },
    "ogx_mmlux_el-professional_psychology": {
      "acc,none": 0.27124183006535946,
      "acc_stderr,none": 0.01798661530403031,
      "alias": "ogx_mmlux_el-professional_psychology"
    },
    "ogx_mmlux_el-professional_medicine": {
      "acc,none": 0.4522058823529412,
      "acc_stderr,none": 0.03023375855159645,
      "alias": "ogx_mmlux_el-professional_medicine"
    },
    "ogx_mmlux_el-professional_law": {
      "acc,none": 0.25097783572359844,
      "acc_stderr,none": 0.011073730299187214,
      "alias": "ogx_mmlux_el-professional_law"
    },
    "ogx_mmlux_el-professional_accounting": {
      "acc,none": 0.24468085106382978,
      "acc_stderr,none": 0.025645553622266733,
      "alias": "ogx_mmlux_el-professional_accounting"
    },
    "ogx_mmlux_el-prehistory": {
      "acc,none": 0.30246913580246915,
      "acc_stderr,none": 0.025557653981868045,
      "alias": "ogx_mmlux_el-prehistory"
    },
    "ogx_mmlux_el-philosophy": {
      "acc,none": 0.41479099678456594,
      "acc_stderr,none": 0.027982680459759567,
      "alias": "ogx_mmlux_el-philosophy"
    },
    "ogx_mmlux_el-nutrition": {
      "acc,none": 0.40522875816993464,
      "acc_stderr,none": 0.028110928492809075,
      "alias": "ogx_mmlux_el-nutrition"
    },
    "ogx_mmlux_el-moral_scenarios": {
      "acc,none": 0.2770949720670391,
      "acc_stderr,none": 0.014968772435812145,
      "alias": "ogx_mmlux_el-moral_scenarios"
    },
    "ogx_mmlux_el-moral_disputes": {
      "acc,none": 0.29190751445086704,
      "acc_stderr,none": 0.024476994076247326,
      "alias": "ogx_mmlux_el-moral_disputes"
    },
    "ogx_mmlux_el-miscellaneous": {
      "acc,none": 0.3716475095785441,
      "acc_stderr,none": 0.017280802522133182,
      "alias": "ogx_mmlux_el-miscellaneous"
    },
    "ogx_mmlux_el-medical_genetics": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.04688261722621505,
      "alias": "ogx_mmlux_el-medical_genetics"
    },
    "ogx_mmlux_el-marketing": {
      "acc,none": 0.3803418803418803,
      "acc_stderr,none": 0.03180425204384099,
      "alias": "ogx_mmlux_el-marketing"
    },
    "ogx_mmlux_el-management": {
      "acc,none": 0.46601941747572817,
      "acc_stderr,none": 0.04939291447273481,
      "alias": "ogx_mmlux_el-management"
    },
    "ogx_mmlux_el-machine_learning": {
      "acc,none": 0.17857142857142858,
      "acc_stderr,none": 0.03635209121577806,
      "alias": "ogx_mmlux_el-machine_learning"
    },
    "ogx_mmlux_el-logical_fallacies": {
      "acc,none": 0.36809815950920244,
      "acc_stderr,none": 0.03789213935838396,
      "alias": "ogx_mmlux_el-logical_fallacies"
    },
    "ogx_mmlux_el-jurisprudence": {
      "acc,none": 0.2962962962962963,
      "acc_stderr,none": 0.04414343666854933,
      "alias": "ogx_mmlux_el-jurisprudence"
    },
    "ogx_mmlux_el-international_law": {
      "acc,none": 0.4214876033057851,
      "acc_stderr,none": 0.04507732278775094,
      "alias": "ogx_mmlux_el-international_law"
    },
    "ogx_mmlux_el-human_sexuality": {
      "acc,none": 0.3816793893129771,
      "acc_stderr,none": 0.0426073515764456,
      "alias": "ogx_mmlux_el-human_sexuality"
    },
    "ogx_mmlux_el-human_aging": {
      "acc,none": 0.23318385650224216,
      "acc_stderr,none": 0.028380391147094723,
      "alias": "ogx_mmlux_el-human_aging"
    },
    "ogx_mmlux_el-high_school_world_history": {
      "acc,none": 0.270042194092827,
      "acc_stderr,none": 0.028900721906293433,
      "alias": "ogx_mmlux_el-high_school_world_history"
    },
    "ogx_mmlux_el-high_school_us_history": {
      "acc,none": 0.31862745098039214,
      "acc_stderr,none": 0.03270287181482081,
      "alias": "ogx_mmlux_el-high_school_us_history"
    },
    "ogx_mmlux_el-high_school_statistics": {
      "acc,none": 0.4351851851851852,
      "acc_stderr,none": 0.03381200005643525,
      "alias": "ogx_mmlux_el-high_school_statistics"
    },
    "ogx_mmlux_el-high_school_psychology": {
      "acc,none": 0.45321100917431195,
      "acc_stderr,none": 0.021343255165546034,
      "alias": "ogx_mmlux_el-high_school_psychology"
    },
    "ogx_mmlux_el-high_school_physics": {
      "acc,none": 0.33774834437086093,
      "acc_stderr,none": 0.0386155754625517,
      "alias": "ogx_mmlux_el-high_school_physics"
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "acc,none": 0.42857142857142855,
      "acc_stderr,none": 0.03214536859788639,
      "alias": "ogx_mmlux_el-high_school_microeconomics"
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "acc,none": 0.26666666666666666,
      "acc_stderr,none": 0.02696242432507382,
      "alias": "ogx_mmlux_el-high_school_mathematics"
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "acc,none": 0.4025641025641026,
      "acc_stderr,none": 0.024864995159767755,
      "alias": "ogx_mmlux_el-high_school_macroeconomics"
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "acc,none": 0.44559585492227977,
      "acc_stderr,none": 0.03587014986075659,
      "alias": "ogx_mmlux_el-high_school_government_and_politics"
    },
    "ogx_mmlux_el-high_school_geography": {
      "acc,none": 0.4494949494949495,
      "acc_stderr,none": 0.0354413249194797,
      "alias": "ogx_mmlux_el-high_school_geography"
    },
    "ogx_mmlux_el-high_school_european_history": {
      "acc,none": 0.3515151515151515,
      "acc_stderr,none": 0.037282069986826503,
      "alias": "ogx_mmlux_el-high_school_european_history"
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "acc,none": 0.21,
      "acc_stderr,none": 0.040936018074033256,
      "alias": "ogx_mmlux_el-high_school_computer_science"
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "acc,none": 0.3103448275862069,
      "acc_stderr,none": 0.03255086769970103,
      "alias": "ogx_mmlux_el-high_school_chemistry"
    },
    "ogx_mmlux_el-high_school_biology": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.027869320571664632,
      "alias": "ogx_mmlux_el-high_school_biology"
    },
    "ogx_mmlux_el-global_facts": {
      "acc,none": 0.18,
      "acc_stderr,none": 0.038612291966536955,
      "alias": "ogx_mmlux_el-global_facts"
    },
    "ogx_mmlux_el-formal_logic": {
      "acc,none": 0.30952380952380953,
      "acc_stderr,none": 0.04134913018303316,
      "alias": "ogx_mmlux_el-formal_logic"
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "acc,none": 0.2698412698412698,
      "acc_stderr,none": 0.022860838309232072,
      "alias": "ogx_mmlux_el-elementary_mathematics"
    },
    "ogx_mmlux_el-electrical_engineering": {
      "acc,none": 0.30344827586206896,
      "acc_stderr,none": 0.038312260488503336,
      "alias": "ogx_mmlux_el-electrical_engineering"
    },
    "ogx_mmlux_el-econometrics": {
      "acc,none": 0.2807017543859649,
      "acc_stderr,none": 0.04227054451232199,
      "alias": "ogx_mmlux_el-econometrics"
    },
    "ogx_mmlux_el-conceptual_physics": {
      "acc,none": 0.28085106382978725,
      "acc_stderr,none": 0.02937917046412482,
      "alias": "ogx_mmlux_el-conceptual_physics"
    },
    "ogx_mmlux_el-computer_security": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_el-computer_security"
    },
    "ogx_mmlux_el-college_physics": {
      "acc,none": 0.3627450980392157,
      "acc_stderr,none": 0.04784060704105654,
      "alias": "ogx_mmlux_el-college_physics"
    },
    "ogx_mmlux_el-college_medicine": {
      "acc,none": 0.3872832369942196,
      "acc_stderr,none": 0.03714325906302065,
      "alias": "ogx_mmlux_el-college_medicine"
    },
    "ogx_mmlux_el-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_el-college_mathematics"
    },
    "ogx_mmlux_el-college_computer_science": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.047937248544110196,
      "alias": "ogx_mmlux_el-college_computer_science"
    },
    "ogx_mmlux_el-college_chemistry": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_el-college_chemistry"
    },
    "ogx_mmlux_el-college_biology": {
      "acc,none": 0.3402777777777778,
      "acc_stderr,none": 0.03962135573486219,
      "alias": "ogx_mmlux_el-college_biology"
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "acc,none": 0.3886792452830189,
      "acc_stderr,none": 0.030000485448675986,
      "alias": "ogx_mmlux_el-clinical_knowledge"
    },
    "ogx_mmlux_el-business_ethics": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.04560480215720684,
      "alias": "ogx_mmlux_el-business_ethics"
    },
    "ogx_mmlux_el-astronomy": {
      "acc,none": 0.4276315789473684,
      "acc_stderr,none": 0.04026097083296559,
      "alias": "ogx_mmlux_el-astronomy"
    },
    "ogx_mmlux_el-anatomy": {
      "acc,none": 0.31851851851851853,
      "acc_stderr,none": 0.040247784019771096,
      "alias": "ogx_mmlux_el-anatomy"
    },
    "ogx_mmlux_el-abstract_algebra": {
      "acc,none": 0.24,
      "acc_stderr,none": 0.042923469599092816,
      "alias": "ogx_mmlux_el-abstract_algebra"
    },
    "ogx_mmlux_de-world_religions": {
      "acc,none": 0.6666666666666666,
      "acc_stderr,none": 0.036155076303109344,
      "alias": "ogx_mmlux_de-world_religions"
    },
    "ogx_mmlux_de-virology": {
      "acc,none": 0.39759036144578314,
      "acc_stderr,none": 0.03809973084540219,
      "alias": "ogx_mmlux_de-virology"
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "acc,none": 0.66,
      "acc_stderr,none": 0.04760952285695237,
      "alias": "ogx_mmlux_de-us_foreign_policy"
    },
    "ogx_mmlux_de-sociology": {
      "acc,none": 0.6368159203980099,
      "acc_stderr,none": 0.03400598505599014,
      "alias": "ogx_mmlux_de-sociology"
    },
    "ogx_mmlux_de-security_studies": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.03136250240935893,
      "alias": "ogx_mmlux_de-security_studies"
    },
    "ogx_mmlux_de-public_relations": {
      "acc,none": 0.4818181818181818,
      "acc_stderr,none": 0.04785964010794916,
      "alias": "ogx_mmlux_de-public_relations"
    },
    "ogx_mmlux_de-professional_psychology": {
      "acc,none": 0.43790849673202614,
      "acc_stderr,none": 0.020071257886886525,
      "alias": "ogx_mmlux_de-professional_psychology"
    },
    "ogx_mmlux_de-professional_medicine": {
      "acc,none": 0.29044117647058826,
      "acc_stderr,none": 0.027576468622740515,
      "alias": "ogx_mmlux_de-professional_medicine"
    },
    "ogx_mmlux_de-professional_law": {
      "acc,none": 0.3220338983050847,
      "acc_stderr,none": 0.01193393607189109,
      "alias": "ogx_mmlux_de-professional_law"
    },
    "ogx_mmlux_de-professional_accounting": {
      "acc,none": 0.2765957446808511,
      "acc_stderr,none": 0.026684564340461008,
      "alias": "ogx_mmlux_de-professional_accounting"
    },
    "ogx_mmlux_de-prehistory": {
      "acc,none": 0.4382716049382716,
      "acc_stderr,none": 0.027607914087400477,
      "alias": "ogx_mmlux_de-prehistory"
    },
    "ogx_mmlux_de-philosophy": {
      "acc,none": 0.43729903536977494,
      "acc_stderr,none": 0.02817391776176287,
      "alias": "ogx_mmlux_de-philosophy"
    },
    "ogx_mmlux_de-nutrition": {
      "acc,none": 0.45098039215686275,
      "acc_stderr,none": 0.028491993586171573,
      "alias": "ogx_mmlux_de-nutrition"
    },
    "ogx_mmlux_de-moral_scenarios": {
      "acc,none": 0.24804469273743016,
      "acc_stderr,none": 0.014444157808261452,
      "alias": "ogx_mmlux_de-moral_scenarios"
    },
    "ogx_mmlux_de-moral_disputes": {
      "acc,none": 0.4508670520231214,
      "acc_stderr,none": 0.026788811931562757,
      "alias": "ogx_mmlux_de-moral_disputes"
    },
    "ogx_mmlux_de-miscellaneous": {
      "acc,none": 0.5925925925925926,
      "acc_stderr,none": 0.017570705239256534,
      "alias": "ogx_mmlux_de-miscellaneous"
    },
    "ogx_mmlux_de-medical_genetics": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_de-medical_genetics"
    },
    "ogx_mmlux_de-marketing": {
      "acc,none": 0.688034188034188,
      "acc_stderr,none": 0.030351527323344944,
      "alias": "ogx_mmlux_de-marketing"
    },
    "ogx_mmlux_de-management": {
      "acc,none": 0.36893203883495146,
      "acc_stderr,none": 0.047776151811567386,
      "alias": "ogx_mmlux_de-management"
    },
    "ogx_mmlux_de-machine_learning": {
      "acc,none": 0.38392857142857145,
      "acc_stderr,none": 0.04616143075028547,
      "alias": "ogx_mmlux_de-machine_learning"
    },
    "ogx_mmlux_de-logical_fallacies": {
      "acc,none": 0.38650306748466257,
      "acc_stderr,none": 0.038258255488486076,
      "alias": "ogx_mmlux_de-logical_fallacies"
    },
    "ogx_mmlux_de-jurisprudence": {
      "acc,none": 0.4537037037037037,
      "acc_stderr,none": 0.04812917324536823,
      "alias": "ogx_mmlux_de-jurisprudence"
    },
    "ogx_mmlux_de-international_law": {
      "acc,none": 0.6033057851239669,
      "acc_stderr,none": 0.04465869780531009,
      "alias": "ogx_mmlux_de-international_law"
    },
    "ogx_mmlux_de-human_sexuality": {
      "acc,none": 0.4961832061068702,
      "acc_stderr,none": 0.043851623256015534,
      "alias": "ogx_mmlux_de-human_sexuality"
    },
    "ogx_mmlux_de-human_aging": {
      "acc,none": 0.5201793721973094,
      "acc_stderr,none": 0.033530461674123,
      "alias": "ogx_mmlux_de-human_aging"
    },
    "ogx_mmlux_de-high_school_world_history": {
      "acc,none": 0.5316455696202531,
      "acc_stderr,none": 0.03248197400511075,
      "alias": "ogx_mmlux_de-high_school_world_history"
    },
    "ogx_mmlux_de-high_school_us_history": {
      "acc,none": 0.5098039215686274,
      "acc_stderr,none": 0.03508637358630572,
      "alias": "ogx_mmlux_de-high_school_us_history"
    },
    "ogx_mmlux_de-high_school_statistics": {
      "acc,none": 0.19907407407407407,
      "acc_stderr,none": 0.02723229846269024,
      "alias": "ogx_mmlux_de-high_school_statistics"
    },
    "ogx_mmlux_de-high_school_psychology": {
      "acc,none": 0.5027522935779817,
      "acc_stderr,none": 0.02143699835976532,
      "alias": "ogx_mmlux_de-high_school_psychology"
    },
    "ogx_mmlux_de-high_school_physics": {
      "acc,none": 0.2251655629139073,
      "acc_stderr,none": 0.03410435282008936,
      "alias": "ogx_mmlux_de-high_school_physics"
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "acc,none": 0.31932773109243695,
      "acc_stderr,none": 0.030283995525884396,
      "alias": "ogx_mmlux_de-high_school_microeconomics"
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "acc,none": 0.24814814814814815,
      "acc_stderr,none": 0.026335739404055803,
      "alias": "ogx_mmlux_de-high_school_mathematics"
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "acc,none": 0.3641025641025641,
      "acc_stderr,none": 0.024396672985094757,
      "alias": "ogx_mmlux_de-high_school_macroeconomics"
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "acc,none": 0.45595854922279794,
      "acc_stderr,none": 0.03594413711272437,
      "alias": "ogx_mmlux_de-high_school_government_and_politics"
    },
    "ogx_mmlux_de-high_school_geography": {
      "acc,none": 0.47474747474747475,
      "acc_stderr,none": 0.03557806245087314,
      "alias": "ogx_mmlux_de-high_school_geography"
    },
    "ogx_mmlux_de-high_school_european_history": {
      "acc,none": 0.5212121212121212,
      "acc_stderr,none": 0.03900828913737302,
      "alias": "ogx_mmlux_de-high_school_european_history"
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.04960449637488585,
      "alias": "ogx_mmlux_de-high_school_computer_science"
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "acc,none": 0.2857142857142857,
      "acc_stderr,none": 0.03178529710642748,
      "alias": "ogx_mmlux_de-high_school_chemistry"
    },
    "ogx_mmlux_de-high_school_biology": {
      "acc,none": 0.42258064516129035,
      "acc_stderr,none": 0.02810096472427264,
      "alias": "ogx_mmlux_de-high_school_biology"
    },
    "ogx_mmlux_de-global_facts": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_de-global_facts"
    },
    "ogx_mmlux_de-formal_logic": {
      "acc,none": 0.23015873015873015,
      "acc_stderr,none": 0.03764950879790606,
      "alias": "ogx_mmlux_de-formal_logic"
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "acc,none": 0.24603174603174602,
      "acc_stderr,none": 0.022182037202948368,
      "alias": "ogx_mmlux_de-elementary_mathematics"
    },
    "ogx_mmlux_de-electrical_engineering": {
      "acc,none": 0.3793103448275862,
      "acc_stderr,none": 0.04043461861916746,
      "alias": "ogx_mmlux_de-electrical_engineering"
    },
    "ogx_mmlux_de-econometrics": {
      "acc,none": 0.2543859649122807,
      "acc_stderr,none": 0.04096985139843669,
      "alias": "ogx_mmlux_de-econometrics"
    },
    "ogx_mmlux_de-conceptual_physics": {
      "acc,none": 0.37872340425531914,
      "acc_stderr,none": 0.03170995606040655,
      "alias": "ogx_mmlux_de-conceptual_physics"
    },
    "ogx_mmlux_de-computer_security": {
      "acc,none": 0.53,
      "acc_stderr,none": 0.050161355804659205,
      "alias": "ogx_mmlux_de-computer_security"
    },
    "ogx_mmlux_de-college_physics": {
      "acc,none": 0.17647058823529413,
      "acc_stderr,none": 0.03793281185307809,
      "alias": "ogx_mmlux_de-college_physics"
    },
    "ogx_mmlux_de-college_medicine": {
      "acc,none": 0.3236994219653179,
      "acc_stderr,none": 0.0356760379963917,
      "alias": "ogx_mmlux_de-college_medicine"
    },
    "ogx_mmlux_de-college_mathematics": {
      "acc,none": 0.24,
      "acc_stderr,none": 0.04292346959909282,
      "alias": "ogx_mmlux_de-college_mathematics"
    },
    "ogx_mmlux_de-college_computer_science": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.04878317312145632,
      "alias": "ogx_mmlux_de-college_computer_science"
    },
    "ogx_mmlux_de-college_chemistry": {
      "acc,none": 0.2,
      "acc_stderr,none": 0.04020151261036843,
      "alias": "ogx_mmlux_de-college_chemistry"
    },
    "ogx_mmlux_de-college_biology": {
      "acc,none": 0.4513888888888889,
      "acc_stderr,none": 0.04161402398403279,
      "alias": "ogx_mmlux_de-college_biology"
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "acc,none": 0.41132075471698115,
      "acc_stderr,none": 0.0302850092590098,
      "alias": "ogx_mmlux_de-clinical_knowledge"
    },
    "ogx_mmlux_de-business_ethics": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_de-business_ethics"
    },
    "ogx_mmlux_de-astronomy": {
      "acc,none": 0.4144736842105263,
      "acc_stderr,none": 0.04008973785779207,
      "alias": "ogx_mmlux_de-astronomy"
    },
    "ogx_mmlux_de-anatomy": {
      "acc,none": 0.4666666666666667,
      "acc_stderr,none": 0.043097329010363554,
      "alias": "ogx_mmlux_de-anatomy"
    },
    "ogx_mmlux_de-abstract_algebra": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_de-abstract_algebra"
    },
    "ogx_mmlux_da-world_religions": {
      "acc,none": 0.6432748538011696,
      "acc_stderr,none": 0.03674013002860954,
      "alias": "ogx_mmlux_da-world_religions"
    },
    "ogx_mmlux_da-virology": {
      "acc,none": 0.39156626506024095,
      "acc_stderr,none": 0.037998574544796354,
      "alias": "ogx_mmlux_da-virology"
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "acc,none": 0.65,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_da-us_foreign_policy"
    },
    "ogx_mmlux_da-sociology": {
      "acc,none": 0.5870646766169154,
      "acc_stderr,none": 0.03481520803367348,
      "alias": "ogx_mmlux_da-sociology"
    },
    "ogx_mmlux_da-security_studies": {
      "acc,none": 0.35918367346938773,
      "acc_stderr,none": 0.03071356045510849,
      "alias": "ogx_mmlux_da-security_studies"
    },
    "ogx_mmlux_da-public_relations": {
      "acc,none": 0.5363636363636364,
      "acc_stderr,none": 0.047764491623961985,
      "alias": "ogx_mmlux_da-public_relations"
    },
    "ogx_mmlux_da-professional_psychology": {
      "acc,none": 0.4019607843137255,
      "acc_stderr,none": 0.019835176484375387,
      "alias": "ogx_mmlux_da-professional_psychology"
    },
    "ogx_mmlux_da-professional_medicine": {
      "acc,none": 0.2867647058823529,
      "acc_stderr,none": 0.027472274473233818,
      "alias": "ogx_mmlux_da-professional_medicine"
    },
    "ogx_mmlux_da-professional_law": {
      "acc,none": 0.32659713168187743,
      "acc_stderr,none": 0.011977676704715993,
      "alias": "ogx_mmlux_da-professional_law"
    },
    "ogx_mmlux_da-professional_accounting": {
      "acc,none": 0.3049645390070922,
      "acc_stderr,none": 0.02746470844202216,
      "alias": "ogx_mmlux_da-professional_accounting"
    },
    "ogx_mmlux_da-prehistory": {
      "acc,none": 0.4506172839506173,
      "acc_stderr,none": 0.027684721415656196,
      "alias": "ogx_mmlux_da-prehistory"
    },
    "ogx_mmlux_da-philosophy": {
      "acc,none": 0.4212218649517685,
      "acc_stderr,none": 0.028043399858210628,
      "alias": "ogx_mmlux_da-philosophy"
    },
    "ogx_mmlux_da-nutrition": {
      "acc,none": 0.4477124183006536,
      "acc_stderr,none": 0.02847293847803353,
      "alias": "ogx_mmlux_da-nutrition"
    },
    "ogx_mmlux_da-moral_scenarios": {
      "acc,none": 0.23798882681564246,
      "acc_stderr,none": 0.014242630070574885,
      "alias": "ogx_mmlux_da-moral_scenarios"
    },
    "ogx_mmlux_da-moral_disputes": {
      "acc,none": 0.4479768786127168,
      "acc_stderr,none": 0.026772990653361816,
      "alias": "ogx_mmlux_da-moral_disputes"
    },
    "ogx_mmlux_da-miscellaneous": {
      "acc,none": 0.5478927203065134,
      "acc_stderr,none": 0.017797751493865626,
      "alias": "ogx_mmlux_da-miscellaneous"
    },
    "ogx_mmlux_da-medical_genetics": {
      "acc,none": 0.57,
      "acc_stderr,none": 0.04975698519562427,
      "alias": "ogx_mmlux_da-medical_genetics"
    },
    "ogx_mmlux_da-marketing": {
      "acc,none": 0.6709401709401709,
      "acc_stderr,none": 0.03078232157768817,
      "alias": "ogx_mmlux_da-marketing"
    },
    "ogx_mmlux_da-management": {
      "acc,none": 0.3786407766990291,
      "acc_stderr,none": 0.048026946982589726,
      "alias": "ogx_mmlux_da-management"
    },
    "ogx_mmlux_da-machine_learning": {
      "acc,none": 0.4017857142857143,
      "acc_stderr,none": 0.04653333146973646,
      "alias": "ogx_mmlux_da-machine_learning"
    },
    "ogx_mmlux_da-logical_fallacies": {
      "acc,none": 0.34355828220858897,
      "acc_stderr,none": 0.037311335196738925,
      "alias": "ogx_mmlux_da-logical_fallacies"
    },
    "ogx_mmlux_da-jurisprudence": {
      "acc,none": 0.4722222222222222,
      "acc_stderr,none": 0.048262172941398944,
      "alias": "ogx_mmlux_da-jurisprudence"
    },
    "ogx_mmlux_da-international_law": {
      "acc,none": 0.5454545454545454,
      "acc_stderr,none": 0.04545454545454548,
      "alias": "ogx_mmlux_da-international_law"
    },
    "ogx_mmlux_da-human_sexuality": {
      "acc,none": 0.4732824427480916,
      "acc_stderr,none": 0.04379024936553894,
      "alias": "ogx_mmlux_da-human_sexuality"
    },
    "ogx_mmlux_da-human_aging": {
      "acc,none": 0.5515695067264574,
      "acc_stderr,none": 0.033378837362550984,
      "alias": "ogx_mmlux_da-human_aging"
    },
    "ogx_mmlux_da-high_school_world_history": {
      "acc,none": 0.5021097046413502,
      "acc_stderr,none": 0.03254693801802007,
      "alias": "ogx_mmlux_da-high_school_world_history"
    },
    "ogx_mmlux_da-high_school_us_history": {
      "acc,none": 0.4803921568627451,
      "acc_stderr,none": 0.03506612560524866,
      "alias": "ogx_mmlux_da-high_school_us_history"
    },
    "ogx_mmlux_da-high_school_statistics": {
      "acc,none": 0.20833333333333334,
      "acc_stderr,none": 0.027696910713093933,
      "alias": "ogx_mmlux_da-high_school_statistics"
    },
    "ogx_mmlux_da-high_school_psychology": {
      "acc,none": 0.4935779816513762,
      "acc_stderr,none": 0.021435554820013077,
      "alias": "ogx_mmlux_da-high_school_psychology"
    },
    "ogx_mmlux_da-high_school_physics": {
      "acc,none": 0.24503311258278146,
      "acc_stderr,none": 0.03511807571804724,
      "alias": "ogx_mmlux_da-high_school_physics"
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "acc,none": 0.33613445378151263,
      "acc_stderr,none": 0.030684737115135363,
      "alias": "ogx_mmlux_da-high_school_microeconomics"
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "acc,none": 0.2740740740740741,
      "acc_stderr,none": 0.027195934804085626,
      "alias": "ogx_mmlux_da-high_school_mathematics"
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "acc,none": 0.3153846153846154,
      "acc_stderr,none": 0.02355964698318995,
      "alias": "ogx_mmlux_da-high_school_macroeconomics"
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "acc,none": 0.39378238341968913,
      "acc_stderr,none": 0.035260770955482364,
      "alias": "ogx_mmlux_da-high_school_government_and_politics"
    },
    "ogx_mmlux_da-high_school_geography": {
      "acc,none": 0.45454545454545453,
      "acc_stderr,none": 0.03547601494006938,
      "alias": "ogx_mmlux_da-high_school_geography"
    },
    "ogx_mmlux_da-high_school_european_history": {
      "acc,none": 0.5393939393939394,
      "acc_stderr,none": 0.03892207016552012,
      "alias": "ogx_mmlux_da-high_school_european_history"
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.04975698519562428,
      "alias": "ogx_mmlux_da-high_school_computer_science"
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "acc,none": 0.30049261083743845,
      "acc_stderr,none": 0.03225799476233486,
      "alias": "ogx_mmlux_da-high_school_chemistry"
    },
    "ogx_mmlux_da-high_school_biology": {
      "acc,none": 0.41935483870967744,
      "acc_stderr,none": 0.02807158890109185,
      "alias": "ogx_mmlux_da-high_school_biology"
    },
    "ogx_mmlux_da-global_facts": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_da-global_facts"
    },
    "ogx_mmlux_da-formal_logic": {
      "acc,none": 0.24603174603174602,
      "acc_stderr,none": 0.03852273364924316,
      "alias": "ogx_mmlux_da-formal_logic"
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "acc,none": 0.291005291005291,
      "acc_stderr,none": 0.023393826500484854,
      "alias": "ogx_mmlux_da-elementary_mathematics"
    },
    "ogx_mmlux_da-electrical_engineering": {
      "acc,none": 0.3793103448275862,
      "acc_stderr,none": 0.040434618619167466,
      "alias": "ogx_mmlux_da-electrical_engineering"
    },
    "ogx_mmlux_da-econometrics": {
      "acc,none": 0.2807017543859649,
      "acc_stderr,none": 0.042270544512322,
      "alias": "ogx_mmlux_da-econometrics"
    },
    "ogx_mmlux_da-conceptual_physics": {
      "acc,none": 0.33617021276595743,
      "acc_stderr,none": 0.030881618520676942,
      "alias": "ogx_mmlux_da-conceptual_physics"
    },
    "ogx_mmlux_da-computer_security": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_da-computer_security"
    },
    "ogx_mmlux_da-college_physics": {
      "acc,none": 0.21568627450980393,
      "acc_stderr,none": 0.04092563958237655,
      "alias": "ogx_mmlux_da-college_physics"
    },
    "ogx_mmlux_da-college_medicine": {
      "acc,none": 0.3699421965317919,
      "acc_stderr,none": 0.03681229633394319,
      "alias": "ogx_mmlux_da-college_medicine"
    },
    "ogx_mmlux_da-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_da-college_mathematics"
    },
    "ogx_mmlux_da-college_computer_science": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.047937248544110196,
      "alias": "ogx_mmlux_da-college_computer_science"
    },
    "ogx_mmlux_da-college_chemistry": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_da-college_chemistry"
    },
    "ogx_mmlux_da-college_biology": {
      "acc,none": 0.4236111111111111,
      "acc_stderr,none": 0.04132125019723369,
      "alias": "ogx_mmlux_da-college_biology"
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "acc,none": 0.4075471698113208,
      "acc_stderr,none": 0.030242233800854498,
      "alias": "ogx_mmlux_da-clinical_knowledge"
    },
    "ogx_mmlux_da-business_ethics": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620333,
      "alias": "ogx_mmlux_da-business_ethics"
    },
    "ogx_mmlux_da-astronomy": {
      "acc,none": 0.40789473684210525,
      "acc_stderr,none": 0.039993097127774706,
      "alias": "ogx_mmlux_da-astronomy"
    },
    "ogx_mmlux_da-anatomy": {
      "acc,none": 0.3925925925925926,
      "acc_stderr,none": 0.04218506215368879,
      "alias": "ogx_mmlux_da-anatomy"
    },
    "ogx_mmlux_da-abstract_algebra": {
      "acc,none": 0.24,
      "acc_stderr,none": 0.042923469599092816,
      "alias": "ogx_mmlux_da-abstract_algebra"
    },
    "ogx_mmlux_cs-world_religions": {
      "acc,none": 0.6257309941520468,
      "acc_stderr,none": 0.037116011853894806,
      "alias": "ogx_mmlux_cs-world_religions"
    },
    "ogx_mmlux_cs-virology": {
      "acc,none": 0.3433734939759036,
      "acc_stderr,none": 0.03696584317010601,
      "alias": "ogx_mmlux_cs-virology"
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "acc,none": 0.53,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_cs-us_foreign_policy"
    },
    "ogx_mmlux_cs-sociology": {
      "acc,none": 0.5373134328358209,
      "acc_stderr,none": 0.03525675167467974,
      "alias": "ogx_mmlux_cs-sociology"
    },
    "ogx_mmlux_cs-security_studies": {
      "acc,none": 0.3183673469387755,
      "acc_stderr,none": 0.029822533793982066,
      "alias": "ogx_mmlux_cs-security_studies"
    },
    "ogx_mmlux_cs-public_relations": {
      "acc,none": 0.38181818181818183,
      "acc_stderr,none": 0.046534298079135075,
      "alias": "ogx_mmlux_cs-public_relations"
    },
    "ogx_mmlux_cs-professional_psychology": {
      "acc,none": 0.3758169934640523,
      "acc_stderr,none": 0.019594021136577443,
      "alias": "ogx_mmlux_cs-professional_psychology"
    },
    "ogx_mmlux_cs-professional_medicine": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.026303648393696036,
      "alias": "ogx_mmlux_cs-professional_medicine"
    },
    "ogx_mmlux_cs-professional_law": {
      "acc,none": 0.31029986962190353,
      "acc_stderr,none": 0.011815439293469836,
      "alias": "ogx_mmlux_cs-professional_law"
    },
    "ogx_mmlux_cs-professional_accounting": {
      "acc,none": 0.2695035460992908,
      "acc_stderr,none": 0.026469036818590613,
      "alias": "ogx_mmlux_cs-professional_accounting"
    },
    "ogx_mmlux_cs-prehistory": {
      "acc,none": 0.36728395061728397,
      "acc_stderr,none": 0.026822801759507894,
      "alias": "ogx_mmlux_cs-prehistory"
    },
    "ogx_mmlux_cs-philosophy": {
      "acc,none": 0.3408360128617363,
      "acc_stderr,none": 0.02692084126077616,
      "alias": "ogx_mmlux_cs-philosophy"
    },
    "ogx_mmlux_cs-nutrition": {
      "acc,none": 0.4150326797385621,
      "acc_stderr,none": 0.028213504177824106,
      "alias": "ogx_mmlux_cs-nutrition"
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "acc,none": 0.23798882681564246,
      "acc_stderr,none": 0.014242630070574885,
      "alias": "ogx_mmlux_cs-moral_scenarios"
    },
    "ogx_mmlux_cs-moral_disputes": {
      "acc,none": 0.45375722543352603,
      "acc_stderr,none": 0.026803720583206188,
      "alias": "ogx_mmlux_cs-moral_disputes"
    },
    "ogx_mmlux_cs-miscellaneous": {
      "acc,none": 0.51213282247765,
      "acc_stderr,none": 0.01787469866749134,
      "alias": "ogx_mmlux_cs-miscellaneous"
    },
    "ogx_mmlux_cs-medical_genetics": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_cs-medical_genetics"
    },
    "ogx_mmlux_cs-marketing": {
      "acc,none": 0.6068376068376068,
      "acc_stderr,none": 0.03199957924651047,
      "alias": "ogx_mmlux_cs-marketing"
    },
    "ogx_mmlux_cs-management": {
      "acc,none": 0.2912621359223301,
      "acc_stderr,none": 0.044986763205729224,
      "alias": "ogx_mmlux_cs-management"
    },
    "ogx_mmlux_cs-machine_learning": {
      "acc,none": 0.35714285714285715,
      "acc_stderr,none": 0.04547960999764376,
      "alias": "ogx_mmlux_cs-machine_learning"
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "acc,none": 0.38650306748466257,
      "acc_stderr,none": 0.038258255488486076,
      "alias": "ogx_mmlux_cs-logical_fallacies"
    },
    "ogx_mmlux_cs-jurisprudence": {
      "acc,none": 0.39814814814814814,
      "acc_stderr,none": 0.047323326159788126,
      "alias": "ogx_mmlux_cs-jurisprudence"
    },
    "ogx_mmlux_cs-international_law": {
      "acc,none": 0.5950413223140496,
      "acc_stderr,none": 0.044811377559424694,
      "alias": "ogx_mmlux_cs-international_law"
    },
    "ogx_mmlux_cs-human_sexuality": {
      "acc,none": 0.46564885496183206,
      "acc_stderr,none": 0.04374928560599738,
      "alias": "ogx_mmlux_cs-human_sexuality"
    },
    "ogx_mmlux_cs-human_aging": {
      "acc,none": 0.4439461883408072,
      "acc_stderr,none": 0.03334625674242728,
      "alias": "ogx_mmlux_cs-human_aging"
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "acc,none": 0.47257383966244726,
      "acc_stderr,none": 0.03249822718301303,
      "alias": "ogx_mmlux_cs-high_school_world_history"
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "acc,none": 0.45098039215686275,
      "acc_stderr,none": 0.03492406104163613,
      "alias": "ogx_mmlux_cs-high_school_us_history"
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "acc,none": 0.18518518518518517,
      "acc_stderr,none": 0.026491914727355168,
      "alias": "ogx_mmlux_cs-high_school_statistics"
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "acc,none": 0.41284403669724773,
      "acc_stderr,none": 0.02110912813341392,
      "alias": "ogx_mmlux_cs-high_school_psychology"
    },
    "ogx_mmlux_cs-high_school_physics": {
      "acc,none": 0.25165562913907286,
      "acc_stderr,none": 0.035433042343899844,
      "alias": "ogx_mmlux_cs-high_school_physics"
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "acc,none": 0.3067226890756303,
      "acc_stderr,none": 0.02995382389188705,
      "alias": "ogx_mmlux_cs-high_school_microeconomics"
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "acc,none": 0.26296296296296295,
      "acc_stderr,none": 0.02684205787383371,
      "alias": "ogx_mmlux_cs-high_school_mathematics"
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "acc,none": 0.3076923076923077,
      "acc_stderr,none": 0.02340092891831049,
      "alias": "ogx_mmlux_cs-high_school_macroeconomics"
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "acc,none": 0.35233160621761656,
      "acc_stderr,none": 0.03447478286414359,
      "alias": "ogx_mmlux_cs-high_school_government_and_politics"
    },
    "ogx_mmlux_cs-high_school_geography": {
      "acc,none": 0.4090909090909091,
      "acc_stderr,none": 0.03502975799413007,
      "alias": "ogx_mmlux_cs-high_school_geography"
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "acc,none": 0.4666666666666667,
      "acc_stderr,none": 0.03895658065271846,
      "alias": "ogx_mmlux_cs-high_school_european_history"
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.04960449637488584,
      "alias": "ogx_mmlux_cs-high_school_computer_science"
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "acc,none": 0.2561576354679803,
      "acc_stderr,none": 0.030712730070982592,
      "alias": "ogx_mmlux_cs-high_school_chemistry"
    },
    "ogx_mmlux_cs-high_school_biology": {
      "acc,none": 0.36451612903225805,
      "acc_stderr,none": 0.02737987122994324,
      "alias": "ogx_mmlux_cs-high_school_biology"
    },
    "ogx_mmlux_cs-global_facts": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_cs-global_facts"
    },
    "ogx_mmlux_cs-formal_logic": {
      "acc,none": 0.25396825396825395,
      "acc_stderr,none": 0.03893259610604672,
      "alias": "ogx_mmlux_cs-formal_logic"
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "acc,none": 0.291005291005291,
      "acc_stderr,none": 0.023393826500484865,
      "alias": "ogx_mmlux_cs-elementary_mathematics"
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "acc,none": 0.4068965517241379,
      "acc_stderr,none": 0.04093793981266237,
      "alias": "ogx_mmlux_cs-electrical_engineering"
    },
    "ogx_mmlux_cs-econometrics": {
      "acc,none": 0.2719298245614035,
      "acc_stderr,none": 0.04185774424022057,
      "alias": "ogx_mmlux_cs-econometrics"
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "acc,none": 0.33191489361702126,
      "acc_stderr,none": 0.030783736757745647,
      "alias": "ogx_mmlux_cs-conceptual_physics"
    },
    "ogx_mmlux_cs-computer_security": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_cs-computer_security"
    },
    "ogx_mmlux_cs-college_physics": {
      "acc,none": 0.18627450980392157,
      "acc_stderr,none": 0.038739587141493524,
      "alias": "ogx_mmlux_cs-college_physics"
    },
    "ogx_mmlux_cs-college_medicine": {
      "acc,none": 0.3179190751445087,
      "acc_stderr,none": 0.03550683989165582,
      "alias": "ogx_mmlux_cs-college_medicine"
    },
    "ogx_mmlux_cs-college_mathematics": {
      "acc,none": 0.23,
      "acc_stderr,none": 0.04229525846816506,
      "alias": "ogx_mmlux_cs-college_mathematics"
    },
    "ogx_mmlux_cs-college_computer_science": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_cs-college_computer_science"
    },
    "ogx_mmlux_cs-college_chemistry": {
      "acc,none": 0.2,
      "acc_stderr,none": 0.040201512610368445,
      "alias": "ogx_mmlux_cs-college_chemistry"
    },
    "ogx_mmlux_cs-college_biology": {
      "acc,none": 0.3958333333333333,
      "acc_stderr,none": 0.04089465449325582,
      "alias": "ogx_mmlux_cs-college_biology"
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "acc,none": 0.35471698113207545,
      "acc_stderr,none": 0.029445175328199596,
      "alias": "ogx_mmlux_cs-clinical_knowledge"
    },
    "ogx_mmlux_cs-business_ethics": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_cs-business_ethics"
    },
    "ogx_mmlux_cs-astronomy": {
      "acc,none": 0.3092105263157895,
      "acc_stderr,none": 0.03761070869867479,
      "alias": "ogx_mmlux_cs-astronomy"
    },
    "ogx_mmlux_cs-anatomy": {
      "acc,none": 0.3851851851851852,
      "acc_stderr,none": 0.042039210401562783,
      "alias": "ogx_mmlux_cs-anatomy"
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_cs-abstract_algebra"
    },
    "ogx_mmlux_bg-world_religions": {
      "acc,none": 0.38011695906432746,
      "acc_stderr,none": 0.037229657413855394,
      "alias": "ogx_mmlux_bg-world_religions"
    },
    "ogx_mmlux_bg-virology": {
      "acc,none": 0.2289156626506024,
      "acc_stderr,none": 0.03270745277352477,
      "alias": "ogx_mmlux_bg-virology"
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252604,
      "alias": "ogx_mmlux_bg-us_foreign_policy"
    },
    "ogx_mmlux_bg-sociology": {
      "acc,none": 0.31343283582089554,
      "acc_stderr,none": 0.03280188205348642,
      "alias": "ogx_mmlux_bg-sociology"
    },
    "ogx_mmlux_bg-security_studies": {
      "acc,none": 0.2612244897959184,
      "acc_stderr,none": 0.028123429335142783,
      "alias": "ogx_mmlux_bg-security_studies"
    },
    "ogx_mmlux_bg-public_relations": {
      "acc,none": 0.2636363636363636,
      "acc_stderr,none": 0.04220224692971987,
      "alias": "ogx_mmlux_bg-public_relations"
    },
    "ogx_mmlux_bg-professional_psychology": {
      "acc,none": 0.315359477124183,
      "acc_stderr,none": 0.018798086284886887,
      "alias": "ogx_mmlux_bg-professional_psychology"
    },
    "ogx_mmlux_bg-professional_medicine": {
      "acc,none": 0.18382352941176472,
      "acc_stderr,none": 0.023529242185193106,
      "alias": "ogx_mmlux_bg-professional_medicine"
    },
    "ogx_mmlux_bg-professional_law": {
      "acc,none": 0.27640156453715775,
      "acc_stderr,none": 0.011422153194553579,
      "alias": "ogx_mmlux_bg-professional_law"
    },
    "ogx_mmlux_bg-professional_accounting": {
      "acc,none": 0.29432624113475175,
      "acc_stderr,none": 0.027187127011503796,
      "alias": "ogx_mmlux_bg-professional_accounting"
    },
    "ogx_mmlux_bg-prehistory": {
      "acc,none": 0.38271604938271603,
      "acc_stderr,none": 0.027044538138402605,
      "alias": "ogx_mmlux_bg-prehistory"
    },
    "ogx_mmlux_bg-philosophy": {
      "acc,none": 0.31511254019292606,
      "acc_stderr,none": 0.026385273703464492,
      "alias": "ogx_mmlux_bg-philosophy"
    },
    "ogx_mmlux_bg-nutrition": {
      "acc,none": 0.33986928104575165,
      "acc_stderr,none": 0.027121956071388852,
      "alias": "ogx_mmlux_bg-nutrition"
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "acc,none": 0.24692737430167597,
      "acc_stderr,none": 0.01442229220480886,
      "alias": "ogx_mmlux_bg-moral_scenarios"
    },
    "ogx_mmlux_bg-moral_disputes": {
      "acc,none": 0.3468208092485549,
      "acc_stderr,none": 0.025624723994030457,
      "alias": "ogx_mmlux_bg-moral_disputes"
    },
    "ogx_mmlux_bg-miscellaneous": {
      "acc,none": 0.35887611749680715,
      "acc_stderr,none": 0.017152991797501342,
      "alias": "ogx_mmlux_bg-miscellaneous"
    },
    "ogx_mmlux_bg-medical_genetics": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_bg-medical_genetics"
    },
    "ogx_mmlux_bg-marketing": {
      "acc,none": 0.47435897435897434,
      "acc_stderr,none": 0.03271298896811159,
      "alias": "ogx_mmlux_bg-marketing"
    },
    "ogx_mmlux_bg-management": {
      "acc,none": 0.20388349514563106,
      "acc_stderr,none": 0.03989139859531769,
      "alias": "ogx_mmlux_bg-management"
    },
    "ogx_mmlux_bg-machine_learning": {
      "acc,none": 0.29464285714285715,
      "acc_stderr,none": 0.043270409325787296,
      "alias": "ogx_mmlux_bg-machine_learning"
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "acc,none": 0.3374233128834356,
      "acc_stderr,none": 0.03714908409935575,
      "alias": "ogx_mmlux_bg-logical_fallacies"
    },
    "ogx_mmlux_bg-jurisprudence": {
      "acc,none": 0.35185185185185186,
      "acc_stderr,none": 0.04616631111801713,
      "alias": "ogx_mmlux_bg-jurisprudence"
    },
    "ogx_mmlux_bg-international_law": {
      "acc,none": 0.5371900826446281,
      "acc_stderr,none": 0.04551711196104218,
      "alias": "ogx_mmlux_bg-international_law"
    },
    "ogx_mmlux_bg-human_sexuality": {
      "acc,none": 0.31297709923664124,
      "acc_stderr,none": 0.04066962905677697,
      "alias": "ogx_mmlux_bg-human_sexuality"
    },
    "ogx_mmlux_bg-human_aging": {
      "acc,none": 0.3273542600896861,
      "acc_stderr,none": 0.031493846709941306,
      "alias": "ogx_mmlux_bg-human_aging"
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.030685820596610795,
      "alias": "ogx_mmlux_bg-high_school_world_history"
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "acc,none": 0.2647058823529412,
      "acc_stderr,none": 0.03096451792692339,
      "alias": "ogx_mmlux_bg-high_school_us_history"
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "acc,none": 0.22685185185185186,
      "acc_stderr,none": 0.028561650102422245,
      "alias": "ogx_mmlux_bg-high_school_statistics"
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "acc,none": 0.3376146788990826,
      "acc_stderr,none": 0.02027526598663891,
      "alias": "ogx_mmlux_bg-high_school_psychology"
    },
    "ogx_mmlux_bg-high_school_physics": {
      "acc,none": 0.271523178807947,
      "acc_stderr,none": 0.03631329803969654,
      "alias": "ogx_mmlux_bg-high_school_physics"
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "acc,none": 0.25630252100840334,
      "acc_stderr,none": 0.02835962087053395,
      "alias": "ogx_mmlux_bg-high_school_microeconomics"
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "acc,none": 0.26666666666666666,
      "acc_stderr,none": 0.026962424325073828,
      "alias": "ogx_mmlux_bg-high_school_mathematics"
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "acc,none": 0.28205128205128205,
      "acc_stderr,none": 0.022815813098896597,
      "alias": "ogx_mmlux_bg-high_school_macroeconomics"
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "acc,none": 0.29015544041450775,
      "acc_stderr,none": 0.03275264467791515,
      "alias": "ogx_mmlux_bg-high_school_government_and_politics"
    },
    "ogx_mmlux_bg-high_school_geography": {
      "acc,none": 0.37373737373737376,
      "acc_stderr,none": 0.034468977386593325,
      "alias": "ogx_mmlux_bg-high_school_geography"
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "acc,none": 0.3151515151515151,
      "acc_stderr,none": 0.0362773057502241,
      "alias": "ogx_mmlux_bg-high_school_european_history"
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252605,
      "alias": "ogx_mmlux_bg-high_school_computer_science"
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "acc,none": 0.3103448275862069,
      "acc_stderr,none": 0.032550867699701024,
      "alias": "ogx_mmlux_bg-high_school_chemistry"
    },
    "ogx_mmlux_bg-high_school_biology": {
      "acc,none": 0.35161290322580646,
      "acc_stderr,none": 0.027162537826948458,
      "alias": "ogx_mmlux_bg-high_school_biology"
    },
    "ogx_mmlux_bg-global_facts": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695236,
      "alias": "ogx_mmlux_bg-global_facts"
    },
    "ogx_mmlux_bg-formal_logic": {
      "acc,none": 0.15873015873015872,
      "acc_stderr,none": 0.03268454013011744,
      "alias": "ogx_mmlux_bg-formal_logic"
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "acc,none": 0.2804232804232804,
      "acc_stderr,none": 0.02313528797432562,
      "alias": "ogx_mmlux_bg-elementary_mathematics"
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "acc,none": 0.3103448275862069,
      "acc_stderr,none": 0.03855289616378948,
      "alias": "ogx_mmlux_bg-electrical_engineering"
    },
    "ogx_mmlux_bg-econometrics": {
      "acc,none": 0.24561403508771928,
      "acc_stderr,none": 0.040493392977481404,
      "alias": "ogx_mmlux_bg-econometrics"
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "acc,none": 0.2297872340425532,
      "acc_stderr,none": 0.027501752944412428,
      "alias": "ogx_mmlux_bg-conceptual_physics"
    },
    "ogx_mmlux_bg-computer_security": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_bg-computer_security"
    },
    "ogx_mmlux_bg-college_physics": {
      "acc,none": 0.22549019607843138,
      "acc_stderr,none": 0.041583075330832865,
      "alias": "ogx_mmlux_bg-college_physics"
    },
    "ogx_mmlux_bg-college_medicine": {
      "acc,none": 0.3179190751445087,
      "acc_stderr,none": 0.03550683989165582,
      "alias": "ogx_mmlux_bg-college_medicine"
    },
    "ogx_mmlux_bg-college_mathematics": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_bg-college_mathematics"
    },
    "ogx_mmlux_bg-college_computer_science": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.047258156262526045,
      "alias": "ogx_mmlux_bg-college_computer_science"
    },
    "ogx_mmlux_bg-college_chemistry": {
      "acc,none": 0.18,
      "acc_stderr,none": 0.03861229196653695,
      "alias": "ogx_mmlux_bg-college_chemistry"
    },
    "ogx_mmlux_bg-college_biology": {
      "acc,none": 0.2777777777777778,
      "acc_stderr,none": 0.03745554791462457,
      "alias": "ogx_mmlux_bg-college_biology"
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "acc,none": 0.2792452830188679,
      "acc_stderr,none": 0.027611163402399715,
      "alias": "ogx_mmlux_bg-clinical_knowledge"
    },
    "ogx_mmlux_bg-business_ethics": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_bg-business_ethics"
    },
    "ogx_mmlux_bg-astronomy": {
      "acc,none": 0.3815789473684211,
      "acc_stderr,none": 0.03953173377749194,
      "alias": "ogx_mmlux_bg-astronomy"
    },
    "ogx_mmlux_bg-anatomy": {
      "acc,none": 0.4074074074074074,
      "acc_stderr,none": 0.04244633238353227,
      "alias": "ogx_mmlux_bg-anatomy"
    },
    "ogx_mmlux_bg-abstract_algebra": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.047258156262526045,
      "alias": "ogx_mmlux_bg-abstract_algebra"
    }
  },
  "group_subtasks": {
    "ogx_mmlux_bg-abstract_algebra": [],
    "ogx_mmlux_bg-anatomy": [],
    "ogx_mmlux_bg-astronomy": [],
    "ogx_mmlux_bg-business_ethics": [],
    "ogx_mmlux_bg-clinical_knowledge": [],
    "ogx_mmlux_bg-college_biology": [],
    "ogx_mmlux_bg-college_chemistry": [],
    "ogx_mmlux_bg-college_computer_science": [],
    "ogx_mmlux_bg-college_mathematics": [],
    "ogx_mmlux_bg-college_medicine": [],
    "ogx_mmlux_bg-college_physics": [],
    "ogx_mmlux_bg-computer_security": [],
    "ogx_mmlux_bg-conceptual_physics": [],
    "ogx_mmlux_bg-econometrics": [],
    "ogx_mmlux_bg-electrical_engineering": [],
    "ogx_mmlux_bg-elementary_mathematics": [],
    "ogx_mmlux_bg-formal_logic": [],
    "ogx_mmlux_bg-global_facts": [],
    "ogx_mmlux_bg-high_school_biology": [],
    "ogx_mmlux_bg-high_school_chemistry": [],
    "ogx_mmlux_bg-high_school_computer_science": [],
    "ogx_mmlux_bg-high_school_european_history": [],
    "ogx_mmlux_bg-high_school_geography": [],
    "ogx_mmlux_bg-high_school_government_and_politics": [],
    "ogx_mmlux_bg-high_school_macroeconomics": [],
    "ogx_mmlux_bg-high_school_mathematics": [],
    "ogx_mmlux_bg-high_school_microeconomics": [],
    "ogx_mmlux_bg-high_school_physics": [],
    "ogx_mmlux_bg-high_school_psychology": [],
    "ogx_mmlux_bg-high_school_statistics": [],
    "ogx_mmlux_bg-high_school_us_history": [],
    "ogx_mmlux_bg-high_school_world_history": [],
    "ogx_mmlux_bg-human_aging": [],
    "ogx_mmlux_bg-human_sexuality": [],
    "ogx_mmlux_bg-international_law": [],
    "ogx_mmlux_bg-jurisprudence": [],
    "ogx_mmlux_bg-logical_fallacies": [],
    "ogx_mmlux_bg-machine_learning": [],
    "ogx_mmlux_bg-management": [],
    "ogx_mmlux_bg-marketing": [],
    "ogx_mmlux_bg-medical_genetics": [],
    "ogx_mmlux_bg-miscellaneous": [],
    "ogx_mmlux_bg-moral_disputes": [],
    "ogx_mmlux_bg-moral_scenarios": [],
    "ogx_mmlux_bg-nutrition": [],
    "ogx_mmlux_bg-philosophy": [],
    "ogx_mmlux_bg-prehistory": [],
    "ogx_mmlux_bg-professional_accounting": [],
    "ogx_mmlux_bg-professional_law": [],
    "ogx_mmlux_bg-professional_medicine": [],
    "ogx_mmlux_bg-professional_psychology": [],
    "ogx_mmlux_bg-public_relations": [],
    "ogx_mmlux_bg-security_studies": [],
    "ogx_mmlux_bg-sociology": [],
    "ogx_mmlux_bg-us_foreign_policy": [],
    "ogx_mmlux_bg-virology": [],
    "ogx_mmlux_bg-world_religions": [],
    "ogx_mmlux_cs-abstract_algebra": [],
    "ogx_mmlux_cs-anatomy": [],
    "ogx_mmlux_cs-astronomy": [],
    "ogx_mmlux_cs-business_ethics": [],
    "ogx_mmlux_cs-clinical_knowledge": [],
    "ogx_mmlux_cs-college_biology": [],
    "ogx_mmlux_cs-college_chemistry": [],
    "ogx_mmlux_cs-college_computer_science": [],
    "ogx_mmlux_cs-college_mathematics": [],
    "ogx_mmlux_cs-college_medicine": [],
    "ogx_mmlux_cs-college_physics": [],
    "ogx_mmlux_cs-computer_security": [],
    "ogx_mmlux_cs-conceptual_physics": [],
    "ogx_mmlux_cs-econometrics": [],
    "ogx_mmlux_cs-electrical_engineering": [],
    "ogx_mmlux_cs-elementary_mathematics": [],
    "ogx_mmlux_cs-formal_logic": [],
    "ogx_mmlux_cs-global_facts": [],
    "ogx_mmlux_cs-high_school_biology": [],
    "ogx_mmlux_cs-high_school_chemistry": [],
    "ogx_mmlux_cs-high_school_computer_science": [],
    "ogx_mmlux_cs-high_school_european_history": [],
    "ogx_mmlux_cs-high_school_geography": [],
    "ogx_mmlux_cs-high_school_government_and_politics": [],
    "ogx_mmlux_cs-high_school_macroeconomics": [],
    "ogx_mmlux_cs-high_school_mathematics": [],
    "ogx_mmlux_cs-high_school_microeconomics": [],
    "ogx_mmlux_cs-high_school_physics": [],
    "ogx_mmlux_cs-high_school_psychology": [],
    "ogx_mmlux_cs-high_school_statistics": [],
    "ogx_mmlux_cs-high_school_us_history": [],
    "ogx_mmlux_cs-high_school_world_history": [],
    "ogx_mmlux_cs-human_aging": [],
    "ogx_mmlux_cs-human_sexuality": [],
    "ogx_mmlux_cs-international_law": [],
    "ogx_mmlux_cs-jurisprudence": [],
    "ogx_mmlux_cs-logical_fallacies": [],
    "ogx_mmlux_cs-machine_learning": [],
    "ogx_mmlux_cs-management": [],
    "ogx_mmlux_cs-marketing": [],
    "ogx_mmlux_cs-medical_genetics": [],
    "ogx_mmlux_cs-miscellaneous": [],
    "ogx_mmlux_cs-moral_disputes": [],
    "ogx_mmlux_cs-moral_scenarios": [],
    "ogx_mmlux_cs-nutrition": [],
    "ogx_mmlux_cs-philosophy": [],
    "ogx_mmlux_cs-prehistory": [],
    "ogx_mmlux_cs-professional_accounting": [],
    "ogx_mmlux_cs-professional_law": [],
    "ogx_mmlux_cs-professional_medicine": [],
    "ogx_mmlux_cs-professional_psychology": [],
    "ogx_mmlux_cs-public_relations": [],
    "ogx_mmlux_cs-security_studies": [],
    "ogx_mmlux_cs-sociology": [],
    "ogx_mmlux_cs-us_foreign_policy": [],
    "ogx_mmlux_cs-virology": [],
    "ogx_mmlux_cs-world_religions": [],
    "ogx_mmlux_da-abstract_algebra": [],
    "ogx_mmlux_da-anatomy": [],
    "ogx_mmlux_da-astronomy": [],
    "ogx_mmlux_da-business_ethics": [],
    "ogx_mmlux_da-clinical_knowledge": [],
    "ogx_mmlux_da-college_biology": [],
    "ogx_mmlux_da-college_chemistry": [],
    "ogx_mmlux_da-college_computer_science": [],
    "ogx_mmlux_da-college_mathematics": [],
    "ogx_mmlux_da-college_medicine": [],
    "ogx_mmlux_da-college_physics": [],
    "ogx_mmlux_da-computer_security": [],
    "ogx_mmlux_da-conceptual_physics": [],
    "ogx_mmlux_da-econometrics": [],
    "ogx_mmlux_da-electrical_engineering": [],
    "ogx_mmlux_da-elementary_mathematics": [],
    "ogx_mmlux_da-formal_logic": [],
    "ogx_mmlux_da-global_facts": [],
    "ogx_mmlux_da-high_school_biology": [],
    "ogx_mmlux_da-high_school_chemistry": [],
    "ogx_mmlux_da-high_school_computer_science": [],
    "ogx_mmlux_da-high_school_european_history": [],
    "ogx_mmlux_da-high_school_geography": [],
    "ogx_mmlux_da-high_school_government_and_politics": [],
    "ogx_mmlux_da-high_school_macroeconomics": [],
    "ogx_mmlux_da-high_school_mathematics": [],
    "ogx_mmlux_da-high_school_microeconomics": [],
    "ogx_mmlux_da-high_school_physics": [],
    "ogx_mmlux_da-high_school_psychology": [],
    "ogx_mmlux_da-high_school_statistics": [],
    "ogx_mmlux_da-high_school_us_history": [],
    "ogx_mmlux_da-high_school_world_history": [],
    "ogx_mmlux_da-human_aging": [],
    "ogx_mmlux_da-human_sexuality": [],
    "ogx_mmlux_da-international_law": [],
    "ogx_mmlux_da-jurisprudence": [],
    "ogx_mmlux_da-logical_fallacies": [],
    "ogx_mmlux_da-machine_learning": [],
    "ogx_mmlux_da-management": [],
    "ogx_mmlux_da-marketing": [],
    "ogx_mmlux_da-medical_genetics": [],
    "ogx_mmlux_da-miscellaneous": [],
    "ogx_mmlux_da-moral_disputes": [],
    "ogx_mmlux_da-moral_scenarios": [],
    "ogx_mmlux_da-nutrition": [],
    "ogx_mmlux_da-philosophy": [],
    "ogx_mmlux_da-prehistory": [],
    "ogx_mmlux_da-professional_accounting": [],
    "ogx_mmlux_da-professional_law": [],
    "ogx_mmlux_da-professional_medicine": [],
    "ogx_mmlux_da-professional_psychology": [],
    "ogx_mmlux_da-public_relations": [],
    "ogx_mmlux_da-security_studies": [],
    "ogx_mmlux_da-sociology": [],
    "ogx_mmlux_da-us_foreign_policy": [],
    "ogx_mmlux_da-virology": [],
    "ogx_mmlux_da-world_religions": [],
    "ogx_mmlux_de-abstract_algebra": [],
    "ogx_mmlux_de-anatomy": [],
    "ogx_mmlux_de-astronomy": [],
    "ogx_mmlux_de-business_ethics": [],
    "ogx_mmlux_de-clinical_knowledge": [],
    "ogx_mmlux_de-college_biology": [],
    "ogx_mmlux_de-college_chemistry": [],
    "ogx_mmlux_de-college_computer_science": [],
    "ogx_mmlux_de-college_mathematics": [],
    "ogx_mmlux_de-college_medicine": [],
    "ogx_mmlux_de-college_physics": [],
    "ogx_mmlux_de-computer_security": [],
    "ogx_mmlux_de-conceptual_physics": [],
    "ogx_mmlux_de-econometrics": [],
    "ogx_mmlux_de-electrical_engineering": [],
    "ogx_mmlux_de-elementary_mathematics": [],
    "ogx_mmlux_de-formal_logic": [],
    "ogx_mmlux_de-global_facts": [],
    "ogx_mmlux_de-high_school_biology": [],
    "ogx_mmlux_de-high_school_chemistry": [],
    "ogx_mmlux_de-high_school_computer_science": [],
    "ogx_mmlux_de-high_school_european_history": [],
    "ogx_mmlux_de-high_school_geography": [],
    "ogx_mmlux_de-high_school_government_and_politics": [],
    "ogx_mmlux_de-high_school_macroeconomics": [],
    "ogx_mmlux_de-high_school_mathematics": [],
    "ogx_mmlux_de-high_school_microeconomics": [],
    "ogx_mmlux_de-high_school_physics": [],
    "ogx_mmlux_de-high_school_psychology": [],
    "ogx_mmlux_de-high_school_statistics": [],
    "ogx_mmlux_de-high_school_us_history": [],
    "ogx_mmlux_de-high_school_world_history": [],
    "ogx_mmlux_de-human_aging": [],
    "ogx_mmlux_de-human_sexuality": [],
    "ogx_mmlux_de-international_law": [],
    "ogx_mmlux_de-jurisprudence": [],
    "ogx_mmlux_de-logical_fallacies": [],
    "ogx_mmlux_de-machine_learning": [],
    "ogx_mmlux_de-management": [],
    "ogx_mmlux_de-marketing": [],
    "ogx_mmlux_de-medical_genetics": [],
    "ogx_mmlux_de-miscellaneous": [],
    "ogx_mmlux_de-moral_disputes": [],
    "ogx_mmlux_de-moral_scenarios": [],
    "ogx_mmlux_de-nutrition": [],
    "ogx_mmlux_de-philosophy": [],
    "ogx_mmlux_de-prehistory": [],
    "ogx_mmlux_de-professional_accounting": [],
    "ogx_mmlux_de-professional_law": [],
    "ogx_mmlux_de-professional_medicine": [],
    "ogx_mmlux_de-professional_psychology": [],
    "ogx_mmlux_de-public_relations": [],
    "ogx_mmlux_de-security_studies": [],
    "ogx_mmlux_de-sociology": [],
    "ogx_mmlux_de-us_foreign_policy": [],
    "ogx_mmlux_de-virology": [],
    "ogx_mmlux_de-world_religions": [],
    "ogx_mmlux_el-abstract_algebra": [],
    "ogx_mmlux_el-anatomy": [],
    "ogx_mmlux_el-astronomy": [],
    "ogx_mmlux_el-business_ethics": [],
    "ogx_mmlux_el-clinical_knowledge": [],
    "ogx_mmlux_el-college_biology": [],
    "ogx_mmlux_el-college_chemistry": [],
    "ogx_mmlux_el-college_computer_science": [],
    "ogx_mmlux_el-college_mathematics": [],
    "ogx_mmlux_el-college_medicine": [],
    "ogx_mmlux_el-college_physics": [],
    "ogx_mmlux_el-computer_security": [],
    "ogx_mmlux_el-conceptual_physics": [],
    "ogx_mmlux_el-econometrics": [],
    "ogx_mmlux_el-electrical_engineering": [],
    "ogx_mmlux_el-elementary_mathematics": [],
    "ogx_mmlux_el-formal_logic": [],
    "ogx_mmlux_el-global_facts": [],
    "ogx_mmlux_el-high_school_biology": [],
    "ogx_mmlux_el-high_school_chemistry": [],
    "ogx_mmlux_el-high_school_computer_science": [],
    "ogx_mmlux_el-high_school_european_history": [],
    "ogx_mmlux_el-high_school_geography": [],
    "ogx_mmlux_el-high_school_government_and_politics": [],
    "ogx_mmlux_el-high_school_macroeconomics": [],
    "ogx_mmlux_el-high_school_mathematics": [],
    "ogx_mmlux_el-high_school_microeconomics": [],
    "ogx_mmlux_el-high_school_physics": [],
    "ogx_mmlux_el-high_school_psychology": [],
    "ogx_mmlux_el-high_school_statistics": [],
    "ogx_mmlux_el-high_school_us_history": [],
    "ogx_mmlux_el-high_school_world_history": [],
    "ogx_mmlux_el-human_aging": [],
    "ogx_mmlux_el-human_sexuality": [],
    "ogx_mmlux_el-international_law": [],
    "ogx_mmlux_el-jurisprudence": [],
    "ogx_mmlux_el-logical_fallacies": [],
    "ogx_mmlux_el-machine_learning": [],
    "ogx_mmlux_el-management": [],
    "ogx_mmlux_el-marketing": [],
    "ogx_mmlux_el-medical_genetics": [],
    "ogx_mmlux_el-miscellaneous": [],
    "ogx_mmlux_el-moral_disputes": [],
    "ogx_mmlux_el-moral_scenarios": [],
    "ogx_mmlux_el-nutrition": [],
    "ogx_mmlux_el-philosophy": [],
    "ogx_mmlux_el-prehistory": [],
    "ogx_mmlux_el-professional_accounting": [],
    "ogx_mmlux_el-professional_law": [],
    "ogx_mmlux_el-professional_medicine": [],
    "ogx_mmlux_el-professional_psychology": [],
    "ogx_mmlux_el-public_relations": [],
    "ogx_mmlux_el-security_studies": [],
    "ogx_mmlux_el-sociology": [],
    "ogx_mmlux_el-us_foreign_policy": [],
    "ogx_mmlux_el-virology": [],
    "ogx_mmlux_el-world_religions": [],
    "ogx_mmlux_es-abstract_algebra": [],
    "ogx_mmlux_es-anatomy": [],
    "ogx_mmlux_es-astronomy": [],
    "ogx_mmlux_es-business_ethics": [],
    "ogx_mmlux_es-clinical_knowledge": [],
    "ogx_mmlux_es-college_biology": [],
    "ogx_mmlux_es-college_chemistry": [],
    "ogx_mmlux_es-college_computer_science": [],
    "ogx_mmlux_es-college_mathematics": [],
    "ogx_mmlux_es-college_medicine": [],
    "ogx_mmlux_es-college_physics": [],
    "ogx_mmlux_es-computer_security": [],
    "ogx_mmlux_es-conceptual_physics": [],
    "ogx_mmlux_es-econometrics": [],
    "ogx_mmlux_es-electrical_engineering": [],
    "ogx_mmlux_es-elementary_mathematics": [],
    "ogx_mmlux_es-formal_logic": [],
    "ogx_mmlux_es-global_facts": [],
    "ogx_mmlux_es-high_school_biology": [],
    "ogx_mmlux_es-high_school_chemistry": [],
    "ogx_mmlux_es-high_school_computer_science": [],
    "ogx_mmlux_es-high_school_european_history": [],
    "ogx_mmlux_es-high_school_geography": [],
    "ogx_mmlux_es-high_school_government_and_politics": [],
    "ogx_mmlux_es-high_school_macroeconomics": [],
    "ogx_mmlux_es-high_school_mathematics": [],
    "ogx_mmlux_es-high_school_microeconomics": [],
    "ogx_mmlux_es-high_school_physics": [],
    "ogx_mmlux_es-high_school_psychology": [],
    "ogx_mmlux_es-high_school_statistics": [],
    "ogx_mmlux_es-high_school_us_history": [],
    "ogx_mmlux_es-high_school_world_history": [],
    "ogx_mmlux_es-human_aging": [],
    "ogx_mmlux_es-human_sexuality": [],
    "ogx_mmlux_es-international_law": [],
    "ogx_mmlux_es-jurisprudence": [],
    "ogx_mmlux_es-logical_fallacies": [],
    "ogx_mmlux_es-machine_learning": [],
    "ogx_mmlux_es-management": [],
    "ogx_mmlux_es-marketing": [],
    "ogx_mmlux_es-medical_genetics": [],
    "ogx_mmlux_es-miscellaneous": [],
    "ogx_mmlux_es-moral_disputes": [],
    "ogx_mmlux_es-moral_scenarios": [],
    "ogx_mmlux_es-nutrition": [],
    "ogx_mmlux_es-philosophy": [],
    "ogx_mmlux_es-prehistory": [],
    "ogx_mmlux_es-professional_accounting": [],
    "ogx_mmlux_es-professional_law": [],
    "ogx_mmlux_es-professional_medicine": [],
    "ogx_mmlux_es-professional_psychology": [],
    "ogx_mmlux_es-public_relations": [],
    "ogx_mmlux_es-security_studies": [],
    "ogx_mmlux_es-sociology": [],
    "ogx_mmlux_es-us_foreign_policy": [],
    "ogx_mmlux_es-virology": [],
    "ogx_mmlux_es-world_religions": [],
    "ogx_mmlux_et-abstract_algebra": [],
    "ogx_mmlux_et-anatomy": [],
    "ogx_mmlux_et-astronomy": [],
    "ogx_mmlux_et-business_ethics": [],
    "ogx_mmlux_et-clinical_knowledge": [],
    "ogx_mmlux_et-college_biology": [],
    "ogx_mmlux_et-college_chemistry": [],
    "ogx_mmlux_et-college_computer_science": [],
    "ogx_mmlux_et-college_mathematics": [],
    "ogx_mmlux_et-college_medicine": [],
    "ogx_mmlux_et-college_physics": [],
    "ogx_mmlux_et-computer_security": [],
    "ogx_mmlux_et-conceptual_physics": [],
    "ogx_mmlux_et-econometrics": [],
    "ogx_mmlux_et-electrical_engineering": [],
    "ogx_mmlux_et-elementary_mathematics": [],
    "ogx_mmlux_et-formal_logic": [],
    "ogx_mmlux_et-global_facts": [],
    "ogx_mmlux_et-high_school_biology": [],
    "ogx_mmlux_et-high_school_chemistry": [],
    "ogx_mmlux_et-high_school_computer_science": [],
    "ogx_mmlux_et-high_school_european_history": [],
    "ogx_mmlux_et-high_school_geography": [],
    "ogx_mmlux_et-high_school_government_and_politics": [],
    "ogx_mmlux_et-high_school_macroeconomics": [],
    "ogx_mmlux_et-high_school_mathematics": [],
    "ogx_mmlux_et-high_school_microeconomics": [],
    "ogx_mmlux_et-high_school_physics": [],
    "ogx_mmlux_et-high_school_psychology": [],
    "ogx_mmlux_et-high_school_statistics": [],
    "ogx_mmlux_et-high_school_us_history": [],
    "ogx_mmlux_et-high_school_world_history": [],
    "ogx_mmlux_et-human_aging": [],
    "ogx_mmlux_et-human_sexuality": [],
    "ogx_mmlux_et-international_law": [],
    "ogx_mmlux_et-jurisprudence": [],
    "ogx_mmlux_et-logical_fallacies": [],
    "ogx_mmlux_et-machine_learning": [],
    "ogx_mmlux_et-management": [],
    "ogx_mmlux_et-marketing": [],
    "ogx_mmlux_et-medical_genetics": [],
    "ogx_mmlux_et-miscellaneous": [],
    "ogx_mmlux_et-moral_disputes": [],
    "ogx_mmlux_et-moral_scenarios": [],
    "ogx_mmlux_et-nutrition": [],
    "ogx_mmlux_et-philosophy": [],
    "ogx_mmlux_et-prehistory": [],
    "ogx_mmlux_et-professional_accounting": [],
    "ogx_mmlux_et-professional_law": [],
    "ogx_mmlux_et-professional_medicine": [],
    "ogx_mmlux_et-professional_psychology": [],
    "ogx_mmlux_et-public_relations": [],
    "ogx_mmlux_et-security_studies": [],
    "ogx_mmlux_et-sociology": [],
    "ogx_mmlux_et-us_foreign_policy": [],
    "ogx_mmlux_et-virology": [],
    "ogx_mmlux_et-world_religions": [],
    "ogx_mmlux_fi-abstract_algebra": [],
    "ogx_mmlux_fi-anatomy": [],
    "ogx_mmlux_fi-astronomy": [],
    "ogx_mmlux_fi-business_ethics": [],
    "ogx_mmlux_fi-clinical_knowledge": [],
    "ogx_mmlux_fi-college_biology": [],
    "ogx_mmlux_fi-college_chemistry": [],
    "ogx_mmlux_fi-college_computer_science": [],
    "ogx_mmlux_fi-college_mathematics": [],
    "ogx_mmlux_fi-college_medicine": [],
    "ogx_mmlux_fi-college_physics": [],
    "ogx_mmlux_fi-computer_security": [],
    "ogx_mmlux_fi-conceptual_physics": [],
    "ogx_mmlux_fi-econometrics": [],
    "ogx_mmlux_fi-electrical_engineering": [],
    "ogx_mmlux_fi-elementary_mathematics": [],
    "ogx_mmlux_fi-formal_logic": [],
    "ogx_mmlux_fi-global_facts": [],
    "ogx_mmlux_fi-high_school_biology": [],
    "ogx_mmlux_fi-high_school_chemistry": [],
    "ogx_mmlux_fi-high_school_computer_science": [],
    "ogx_mmlux_fi-high_school_european_history": [],
    "ogx_mmlux_fi-high_school_geography": [],
    "ogx_mmlux_fi-high_school_government_and_politics": [],
    "ogx_mmlux_fi-high_school_macroeconomics": [],
    "ogx_mmlux_fi-high_school_mathematics": [],
    "ogx_mmlux_fi-high_school_microeconomics": [],
    "ogx_mmlux_fi-high_school_physics": [],
    "ogx_mmlux_fi-high_school_psychology": [],
    "ogx_mmlux_fi-high_school_statistics": [],
    "ogx_mmlux_fi-high_school_us_history": [],
    "ogx_mmlux_fi-high_school_world_history": [],
    "ogx_mmlux_fi-human_aging": [],
    "ogx_mmlux_fi-human_sexuality": [],
    "ogx_mmlux_fi-international_law": [],
    "ogx_mmlux_fi-jurisprudence": [],
    "ogx_mmlux_fi-logical_fallacies": [],
    "ogx_mmlux_fi-machine_learning": [],
    "ogx_mmlux_fi-management": [],
    "ogx_mmlux_fi-marketing": [],
    "ogx_mmlux_fi-medical_genetics": [],
    "ogx_mmlux_fi-miscellaneous": [],
    "ogx_mmlux_fi-moral_disputes": [],
    "ogx_mmlux_fi-moral_scenarios": [],
    "ogx_mmlux_fi-nutrition": [],
    "ogx_mmlux_fi-philosophy": [],
    "ogx_mmlux_fi-prehistory": [],
    "ogx_mmlux_fi-professional_accounting": [],
    "ogx_mmlux_fi-professional_law": [],
    "ogx_mmlux_fi-professional_medicine": [],
    "ogx_mmlux_fi-professional_psychology": [],
    "ogx_mmlux_fi-public_relations": [],
    "ogx_mmlux_fi-security_studies": [],
    "ogx_mmlux_fi-sociology": [],
    "ogx_mmlux_fi-us_foreign_policy": [],
    "ogx_mmlux_fi-virology": [],
    "ogx_mmlux_fi-world_religions": [],
    "ogx_mmlux_fr-abstract_algebra": [],
    "ogx_mmlux_fr-anatomy": [],
    "ogx_mmlux_fr-astronomy": [],
    "ogx_mmlux_fr-business_ethics": [],
    "ogx_mmlux_fr-clinical_knowledge": [],
    "ogx_mmlux_fr-college_biology": [],
    "ogx_mmlux_fr-college_chemistry": [],
    "ogx_mmlux_fr-college_computer_science": [],
    "ogx_mmlux_fr-college_mathematics": [],
    "ogx_mmlux_fr-college_medicine": [],
    "ogx_mmlux_fr-college_physics": [],
    "ogx_mmlux_fr-computer_security": [],
    "ogx_mmlux_fr-conceptual_physics": [],
    "ogx_mmlux_fr-econometrics": [],
    "ogx_mmlux_fr-electrical_engineering": [],
    "ogx_mmlux_fr-elementary_mathematics": [],
    "ogx_mmlux_fr-formal_logic": [],
    "ogx_mmlux_fr-global_facts": [],
    "ogx_mmlux_fr-high_school_biology": [],
    "ogx_mmlux_fr-high_school_chemistry": [],
    "ogx_mmlux_fr-high_school_computer_science": [],
    "ogx_mmlux_fr-high_school_european_history": [],
    "ogx_mmlux_fr-high_school_geography": [],
    "ogx_mmlux_fr-high_school_government_and_politics": [],
    "ogx_mmlux_fr-high_school_macroeconomics": [],
    "ogx_mmlux_fr-high_school_mathematics": [],
    "ogx_mmlux_fr-high_school_microeconomics": [],
    "ogx_mmlux_fr-high_school_physics": [],
    "ogx_mmlux_fr-high_school_psychology": [],
    "ogx_mmlux_fr-high_school_statistics": [],
    "ogx_mmlux_fr-high_school_us_history": [],
    "ogx_mmlux_fr-high_school_world_history": [],
    "ogx_mmlux_fr-human_aging": [],
    "ogx_mmlux_fr-human_sexuality": [],
    "ogx_mmlux_fr-international_law": [],
    "ogx_mmlux_fr-jurisprudence": [],
    "ogx_mmlux_fr-logical_fallacies": [],
    "ogx_mmlux_fr-machine_learning": [],
    "ogx_mmlux_fr-management": [],
    "ogx_mmlux_fr-marketing": [],
    "ogx_mmlux_fr-medical_genetics": [],
    "ogx_mmlux_fr-miscellaneous": [],
    "ogx_mmlux_fr-moral_disputes": [],
    "ogx_mmlux_fr-moral_scenarios": [],
    "ogx_mmlux_fr-nutrition": [],
    "ogx_mmlux_fr-philosophy": [],
    "ogx_mmlux_fr-prehistory": [],
    "ogx_mmlux_fr-professional_accounting": [],
    "ogx_mmlux_fr-professional_law": [],
    "ogx_mmlux_fr-professional_medicine": [],
    "ogx_mmlux_fr-professional_psychology": [],
    "ogx_mmlux_fr-public_relations": [],
    "ogx_mmlux_fr-security_studies": [],
    "ogx_mmlux_fr-sociology": [],
    "ogx_mmlux_fr-us_foreign_policy": [],
    "ogx_mmlux_fr-virology": [],
    "ogx_mmlux_fr-world_religions": [],
    "ogx_mmlux_hu-abstract_algebra": [],
    "ogx_mmlux_hu-anatomy": [],
    "ogx_mmlux_hu-astronomy": [],
    "ogx_mmlux_hu-business_ethics": [],
    "ogx_mmlux_hu-clinical_knowledge": [],
    "ogx_mmlux_hu-college_biology": [],
    "ogx_mmlux_hu-college_chemistry": [],
    "ogx_mmlux_hu-college_computer_science": [],
    "ogx_mmlux_hu-college_mathematics": [],
    "ogx_mmlux_hu-college_medicine": [],
    "ogx_mmlux_hu-college_physics": [],
    "ogx_mmlux_hu-computer_security": [],
    "ogx_mmlux_hu-conceptual_physics": [],
    "ogx_mmlux_hu-econometrics": [],
    "ogx_mmlux_hu-electrical_engineering": [],
    "ogx_mmlux_hu-elementary_mathematics": [],
    "ogx_mmlux_hu-formal_logic": [],
    "ogx_mmlux_hu-global_facts": [],
    "ogx_mmlux_hu-high_school_biology": [],
    "ogx_mmlux_hu-high_school_chemistry": [],
    "ogx_mmlux_hu-high_school_computer_science": [],
    "ogx_mmlux_hu-high_school_european_history": [],
    "ogx_mmlux_hu-high_school_geography": [],
    "ogx_mmlux_hu-high_school_government_and_politics": [],
    "ogx_mmlux_hu-high_school_macroeconomics": [],
    "ogx_mmlux_hu-high_school_mathematics": [],
    "ogx_mmlux_hu-high_school_microeconomics": [],
    "ogx_mmlux_hu-high_school_physics": [],
    "ogx_mmlux_hu-high_school_psychology": [],
    "ogx_mmlux_hu-high_school_statistics": [],
    "ogx_mmlux_hu-high_school_us_history": [],
    "ogx_mmlux_hu-high_school_world_history": [],
    "ogx_mmlux_hu-human_aging": [],
    "ogx_mmlux_hu-human_sexuality": [],
    "ogx_mmlux_hu-international_law": [],
    "ogx_mmlux_hu-jurisprudence": [],
    "ogx_mmlux_hu-logical_fallacies": [],
    "ogx_mmlux_hu-machine_learning": [],
    "ogx_mmlux_hu-management": [],
    "ogx_mmlux_hu-marketing": [],
    "ogx_mmlux_hu-medical_genetics": [],
    "ogx_mmlux_hu-miscellaneous": [],
    "ogx_mmlux_hu-moral_disputes": [],
    "ogx_mmlux_hu-moral_scenarios": [],
    "ogx_mmlux_hu-nutrition": [],
    "ogx_mmlux_hu-philosophy": [],
    "ogx_mmlux_hu-prehistory": [],
    "ogx_mmlux_hu-professional_accounting": [],
    "ogx_mmlux_hu-professional_law": [],
    "ogx_mmlux_hu-professional_medicine": [],
    "ogx_mmlux_hu-professional_psychology": [],
    "ogx_mmlux_hu-public_relations": [],
    "ogx_mmlux_hu-security_studies": [],
    "ogx_mmlux_hu-sociology": [],
    "ogx_mmlux_hu-us_foreign_policy": [],
    "ogx_mmlux_hu-virology": [],
    "ogx_mmlux_hu-world_religions": [],
    "ogx_mmlux_it-abstract_algebra": [],
    "ogx_mmlux_it-anatomy": [],
    "ogx_mmlux_it-astronomy": [],
    "ogx_mmlux_it-business_ethics": [],
    "ogx_mmlux_it-clinical_knowledge": [],
    "ogx_mmlux_it-college_biology": [],
    "ogx_mmlux_it-college_chemistry": [],
    "ogx_mmlux_it-college_computer_science": [],
    "ogx_mmlux_it-college_mathematics": [],
    "ogx_mmlux_it-college_medicine": [],
    "ogx_mmlux_it-college_physics": [],
    "ogx_mmlux_it-computer_security": [],
    "ogx_mmlux_it-conceptual_physics": [],
    "ogx_mmlux_it-econometrics": [],
    "ogx_mmlux_it-electrical_engineering": [],
    "ogx_mmlux_it-elementary_mathematics": [],
    "ogx_mmlux_it-formal_logic": [],
    "ogx_mmlux_it-global_facts": [],
    "ogx_mmlux_it-high_school_biology": [],
    "ogx_mmlux_it-high_school_chemistry": [],
    "ogx_mmlux_it-high_school_computer_science": [],
    "ogx_mmlux_it-high_school_european_history": [],
    "ogx_mmlux_it-high_school_geography": [],
    "ogx_mmlux_it-high_school_government_and_politics": [],
    "ogx_mmlux_it-high_school_macroeconomics": [],
    "ogx_mmlux_it-high_school_mathematics": [],
    "ogx_mmlux_it-high_school_microeconomics": [],
    "ogx_mmlux_it-high_school_physics": [],
    "ogx_mmlux_it-high_school_psychology": [],
    "ogx_mmlux_it-high_school_statistics": [],
    "ogx_mmlux_it-high_school_us_history": [],
    "ogx_mmlux_it-high_school_world_history": [],
    "ogx_mmlux_it-human_aging": [],
    "ogx_mmlux_it-human_sexuality": [],
    "ogx_mmlux_it-international_law": [],
    "ogx_mmlux_it-jurisprudence": [],
    "ogx_mmlux_it-logical_fallacies": [],
    "ogx_mmlux_it-machine_learning": [],
    "ogx_mmlux_it-management": [],
    "ogx_mmlux_it-marketing": [],
    "ogx_mmlux_it-medical_genetics": [],
    "ogx_mmlux_it-miscellaneous": [],
    "ogx_mmlux_it-moral_disputes": [],
    "ogx_mmlux_it-moral_scenarios": [],
    "ogx_mmlux_it-nutrition": [],
    "ogx_mmlux_it-philosophy": [],
    "ogx_mmlux_it-prehistory": [],
    "ogx_mmlux_it-professional_accounting": [],
    "ogx_mmlux_it-professional_law": [],
    "ogx_mmlux_it-professional_medicine": [],
    "ogx_mmlux_it-professional_psychology": [],
    "ogx_mmlux_it-public_relations": [],
    "ogx_mmlux_it-security_studies": [],
    "ogx_mmlux_it-sociology": [],
    "ogx_mmlux_it-us_foreign_policy": [],
    "ogx_mmlux_it-virology": [],
    "ogx_mmlux_it-world_religions": [],
    "ogx_mmlux_lt-abstract_algebra": [],
    "ogx_mmlux_lt-anatomy": [],
    "ogx_mmlux_lt-astronomy": [],
    "ogx_mmlux_lt-business_ethics": [],
    "ogx_mmlux_lt-clinical_knowledge": [],
    "ogx_mmlux_lt-college_biology": [],
    "ogx_mmlux_lt-college_chemistry": [],
    "ogx_mmlux_lt-college_computer_science": [],
    "ogx_mmlux_lt-college_mathematics": [],
    "ogx_mmlux_lt-college_medicine": [],
    "ogx_mmlux_lt-college_physics": [],
    "ogx_mmlux_lt-computer_security": [],
    "ogx_mmlux_lt-conceptual_physics": [],
    "ogx_mmlux_lt-econometrics": [],
    "ogx_mmlux_lt-electrical_engineering": [],
    "ogx_mmlux_lt-elementary_mathematics": [],
    "ogx_mmlux_lt-formal_logic": [],
    "ogx_mmlux_lt-global_facts": [],
    "ogx_mmlux_lt-high_school_biology": [],
    "ogx_mmlux_lt-high_school_chemistry": [],
    "ogx_mmlux_lt-high_school_computer_science": [],
    "ogx_mmlux_lt-high_school_european_history": [],
    "ogx_mmlux_lt-high_school_geography": [],
    "ogx_mmlux_lt-high_school_government_and_politics": [],
    "ogx_mmlux_lt-high_school_macroeconomics": [],
    "ogx_mmlux_lt-high_school_mathematics": [],
    "ogx_mmlux_lt-high_school_microeconomics": [],
    "ogx_mmlux_lt-high_school_physics": [],
    "ogx_mmlux_lt-high_school_psychology": [],
    "ogx_mmlux_lt-high_school_statistics": [],
    "ogx_mmlux_lt-high_school_us_history": [],
    "ogx_mmlux_lt-high_school_world_history": [],
    "ogx_mmlux_lt-human_aging": [],
    "ogx_mmlux_lt-human_sexuality": [],
    "ogx_mmlux_lt-international_law": [],
    "ogx_mmlux_lt-jurisprudence": [],
    "ogx_mmlux_lt-logical_fallacies": [],
    "ogx_mmlux_lt-machine_learning": [],
    "ogx_mmlux_lt-management": [],
    "ogx_mmlux_lt-marketing": [],
    "ogx_mmlux_lt-medical_genetics": [],
    "ogx_mmlux_lt-miscellaneous": [],
    "ogx_mmlux_lt-moral_disputes": [],
    "ogx_mmlux_lt-moral_scenarios": [],
    "ogx_mmlux_lt-nutrition": [],
    "ogx_mmlux_lt-philosophy": [],
    "ogx_mmlux_lt-prehistory": [],
    "ogx_mmlux_lt-professional_accounting": [],
    "ogx_mmlux_lt-professional_law": [],
    "ogx_mmlux_lt-professional_medicine": [],
    "ogx_mmlux_lt-professional_psychology": [],
    "ogx_mmlux_lt-public_relations": [],
    "ogx_mmlux_lt-security_studies": [],
    "ogx_mmlux_lt-sociology": [],
    "ogx_mmlux_lt-us_foreign_policy": [],
    "ogx_mmlux_lt-virology": [],
    "ogx_mmlux_lt-world_religions": [],
    "ogx_mmlux_lv-abstract_algebra": [],
    "ogx_mmlux_lv-anatomy": [],
    "ogx_mmlux_lv-astronomy": [],
    "ogx_mmlux_lv-business_ethics": [],
    "ogx_mmlux_lv-clinical_knowledge": [],
    "ogx_mmlux_lv-college_biology": [],
    "ogx_mmlux_lv-college_chemistry": [],
    "ogx_mmlux_lv-college_computer_science": [],
    "ogx_mmlux_lv-college_mathematics": [],
    "ogx_mmlux_lv-college_medicine": [],
    "ogx_mmlux_lv-college_physics": [],
    "ogx_mmlux_lv-computer_security": [],
    "ogx_mmlux_lv-conceptual_physics": [],
    "ogx_mmlux_lv-econometrics": [],
    "ogx_mmlux_lv-electrical_engineering": [],
    "ogx_mmlux_lv-elementary_mathematics": [],
    "ogx_mmlux_lv-formal_logic": [],
    "ogx_mmlux_lv-global_facts": [],
    "ogx_mmlux_lv-high_school_biology": [],
    "ogx_mmlux_lv-high_school_chemistry": [],
    "ogx_mmlux_lv-high_school_computer_science": [],
    "ogx_mmlux_lv-high_school_european_history": [],
    "ogx_mmlux_lv-high_school_geography": [],
    "ogx_mmlux_lv-high_school_government_and_politics": [],
    "ogx_mmlux_lv-high_school_macroeconomics": [],
    "ogx_mmlux_lv-high_school_mathematics": [],
    "ogx_mmlux_lv-high_school_microeconomics": [],
    "ogx_mmlux_lv-high_school_physics": [],
    "ogx_mmlux_lv-high_school_psychology": [],
    "ogx_mmlux_lv-high_school_statistics": [],
    "ogx_mmlux_lv-high_school_us_history": [],
    "ogx_mmlux_lv-high_school_world_history": [],
    "ogx_mmlux_lv-human_aging": [],
    "ogx_mmlux_lv-human_sexuality": [],
    "ogx_mmlux_lv-international_law": [],
    "ogx_mmlux_lv-jurisprudence": [],
    "ogx_mmlux_lv-logical_fallacies": [],
    "ogx_mmlux_lv-machine_learning": [],
    "ogx_mmlux_lv-management": [],
    "ogx_mmlux_lv-marketing": [],
    "ogx_mmlux_lv-medical_genetics": [],
    "ogx_mmlux_lv-miscellaneous": [],
    "ogx_mmlux_lv-moral_disputes": [],
    "ogx_mmlux_lv-moral_scenarios": [],
    "ogx_mmlux_lv-nutrition": [],
    "ogx_mmlux_lv-philosophy": [],
    "ogx_mmlux_lv-prehistory": [],
    "ogx_mmlux_lv-professional_accounting": [],
    "ogx_mmlux_lv-professional_law": [],
    "ogx_mmlux_lv-professional_medicine": [],
    "ogx_mmlux_lv-professional_psychology": [],
    "ogx_mmlux_lv-public_relations": [],
    "ogx_mmlux_lv-security_studies": [],
    "ogx_mmlux_lv-sociology": [],
    "ogx_mmlux_lv-us_foreign_policy": [],
    "ogx_mmlux_lv-virology": [],
    "ogx_mmlux_lv-world_religions": [],
    "ogx_mmlux_nl-abstract_algebra": [],
    "ogx_mmlux_nl-anatomy": [],
    "ogx_mmlux_nl-astronomy": [],
    "ogx_mmlux_nl-business_ethics": [],
    "ogx_mmlux_nl-clinical_knowledge": [],
    "ogx_mmlux_nl-college_biology": [],
    "ogx_mmlux_nl-college_chemistry": [],
    "ogx_mmlux_nl-college_computer_science": [],
    "ogx_mmlux_nl-college_mathematics": [],
    "ogx_mmlux_nl-college_medicine": [],
    "ogx_mmlux_nl-college_physics": [],
    "ogx_mmlux_nl-computer_security": [],
    "ogx_mmlux_nl-conceptual_physics": [],
    "ogx_mmlux_nl-econometrics": [],
    "ogx_mmlux_nl-electrical_engineering": [],
    "ogx_mmlux_nl-elementary_mathematics": [],
    "ogx_mmlux_nl-formal_logic": [],
    "ogx_mmlux_nl-global_facts": [],
    "ogx_mmlux_nl-high_school_biology": [],
    "ogx_mmlux_nl-high_school_chemistry": [],
    "ogx_mmlux_nl-high_school_computer_science": [],
    "ogx_mmlux_nl-high_school_european_history": [],
    "ogx_mmlux_nl-high_school_geography": [],
    "ogx_mmlux_nl-high_school_government_and_politics": [],
    "ogx_mmlux_nl-high_school_macroeconomics": [],
    "ogx_mmlux_nl-high_school_mathematics": [],
    "ogx_mmlux_nl-high_school_microeconomics": [],
    "ogx_mmlux_nl-high_school_physics": [],
    "ogx_mmlux_nl-high_school_psychology": [],
    "ogx_mmlux_nl-high_school_statistics": [],
    "ogx_mmlux_nl-high_school_us_history": [],
    "ogx_mmlux_nl-high_school_world_history": [],
    "ogx_mmlux_nl-human_aging": [],
    "ogx_mmlux_nl-human_sexuality": [],
    "ogx_mmlux_nl-international_law": [],
    "ogx_mmlux_nl-jurisprudence": [],
    "ogx_mmlux_nl-logical_fallacies": [],
    "ogx_mmlux_nl-machine_learning": [],
    "ogx_mmlux_nl-management": [],
    "ogx_mmlux_nl-marketing": [],
    "ogx_mmlux_nl-medical_genetics": [],
    "ogx_mmlux_nl-miscellaneous": [],
    "ogx_mmlux_nl-moral_disputes": [],
    "ogx_mmlux_nl-moral_scenarios": [],
    "ogx_mmlux_nl-nutrition": [],
    "ogx_mmlux_nl-philosophy": [],
    "ogx_mmlux_nl-prehistory": [],
    "ogx_mmlux_nl-professional_accounting": [],
    "ogx_mmlux_nl-professional_law": [],
    "ogx_mmlux_nl-professional_medicine": [],
    "ogx_mmlux_nl-professional_psychology": [],
    "ogx_mmlux_nl-public_relations": [],
    "ogx_mmlux_nl-security_studies": [],
    "ogx_mmlux_nl-sociology": [],
    "ogx_mmlux_nl-us_foreign_policy": [],
    "ogx_mmlux_nl-virology": [],
    "ogx_mmlux_nl-world_religions": [],
    "ogx_mmlux_pl-abstract_algebra": [],
    "ogx_mmlux_pl-anatomy": [],
    "ogx_mmlux_pl-astronomy": [],
    "ogx_mmlux_pl-business_ethics": [],
    "ogx_mmlux_pl-clinical_knowledge": [],
    "ogx_mmlux_pl-college_biology": [],
    "ogx_mmlux_pl-college_chemistry": [],
    "ogx_mmlux_pl-college_computer_science": [],
    "ogx_mmlux_pl-college_mathematics": [],
    "ogx_mmlux_pl-college_medicine": [],
    "ogx_mmlux_pl-college_physics": [],
    "ogx_mmlux_pl-computer_security": [],
    "ogx_mmlux_pl-conceptual_physics": [],
    "ogx_mmlux_pl-econometrics": [],
    "ogx_mmlux_pl-electrical_engineering": [],
    "ogx_mmlux_pl-elementary_mathematics": [],
    "ogx_mmlux_pl-formal_logic": [],
    "ogx_mmlux_pl-global_facts": [],
    "ogx_mmlux_pl-high_school_biology": [],
    "ogx_mmlux_pl-high_school_chemistry": [],
    "ogx_mmlux_pl-high_school_computer_science": [],
    "ogx_mmlux_pl-high_school_european_history": [],
    "ogx_mmlux_pl-high_school_geography": [],
    "ogx_mmlux_pl-high_school_government_and_politics": [],
    "ogx_mmlux_pl-high_school_macroeconomics": [],
    "ogx_mmlux_pl-high_school_mathematics": [],
    "ogx_mmlux_pl-high_school_microeconomics": [],
    "ogx_mmlux_pl-high_school_physics": [],
    "ogx_mmlux_pl-high_school_psychology": [],
    "ogx_mmlux_pl-high_school_statistics": [],
    "ogx_mmlux_pl-high_school_us_history": [],
    "ogx_mmlux_pl-high_school_world_history": [],
    "ogx_mmlux_pl-human_aging": [],
    "ogx_mmlux_pl-human_sexuality": [],
    "ogx_mmlux_pl-international_law": [],
    "ogx_mmlux_pl-jurisprudence": [],
    "ogx_mmlux_pl-logical_fallacies": [],
    "ogx_mmlux_pl-machine_learning": [],
    "ogx_mmlux_pl-management": [],
    "ogx_mmlux_pl-marketing": [],
    "ogx_mmlux_pl-medical_genetics": [],
    "ogx_mmlux_pl-miscellaneous": [],
    "ogx_mmlux_pl-moral_disputes": [],
    "ogx_mmlux_pl-moral_scenarios": [],
    "ogx_mmlux_pl-nutrition": [],
    "ogx_mmlux_pl-philosophy": [],
    "ogx_mmlux_pl-prehistory": [],
    "ogx_mmlux_pl-professional_accounting": [],
    "ogx_mmlux_pl-professional_law": [],
    "ogx_mmlux_pl-professional_medicine": [],
    "ogx_mmlux_pl-professional_psychology": [],
    "ogx_mmlux_pl-public_relations": [],
    "ogx_mmlux_pl-security_studies": [],
    "ogx_mmlux_pl-sociology": [],
    "ogx_mmlux_pl-us_foreign_policy": [],
    "ogx_mmlux_pl-virology": [],
    "ogx_mmlux_pl-world_religions": [],
    "ogx_mmlux_pt-pt-abstract_algebra": [],
    "ogx_mmlux_pt-pt-anatomy": [],
    "ogx_mmlux_pt-pt-astronomy": [],
    "ogx_mmlux_pt-pt-business_ethics": [],
    "ogx_mmlux_pt-pt-clinical_knowledge": [],
    "ogx_mmlux_pt-pt-college_biology": [],
    "ogx_mmlux_pt-pt-college_chemistry": [],
    "ogx_mmlux_pt-pt-college_computer_science": [],
    "ogx_mmlux_pt-pt-college_mathematics": [],
    "ogx_mmlux_pt-pt-college_medicine": [],
    "ogx_mmlux_pt-pt-college_physics": [],
    "ogx_mmlux_pt-pt-computer_security": [],
    "ogx_mmlux_pt-pt-conceptual_physics": [],
    "ogx_mmlux_pt-pt-econometrics": [],
    "ogx_mmlux_pt-pt-electrical_engineering": [],
    "ogx_mmlux_pt-pt-elementary_mathematics": [],
    "ogx_mmlux_pt-pt-formal_logic": [],
    "ogx_mmlux_pt-pt-global_facts": [],
    "ogx_mmlux_pt-pt-high_school_biology": [],
    "ogx_mmlux_pt-pt-high_school_chemistry": [],
    "ogx_mmlux_pt-pt-high_school_computer_science": [],
    "ogx_mmlux_pt-pt-high_school_european_history": [],
    "ogx_mmlux_pt-pt-high_school_geography": [],
    "ogx_mmlux_pt-pt-high_school_government_and_politics": [],
    "ogx_mmlux_pt-pt-high_school_macroeconomics": [],
    "ogx_mmlux_pt-pt-high_school_mathematics": [],
    "ogx_mmlux_pt-pt-high_school_microeconomics": [],
    "ogx_mmlux_pt-pt-high_school_physics": [],
    "ogx_mmlux_pt-pt-high_school_psychology": [],
    "ogx_mmlux_pt-pt-high_school_statistics": [],
    "ogx_mmlux_pt-pt-high_school_us_history": [],
    "ogx_mmlux_pt-pt-high_school_world_history": [],
    "ogx_mmlux_pt-pt-human_aging": [],
    "ogx_mmlux_pt-pt-human_sexuality": [],
    "ogx_mmlux_pt-pt-international_law": [],
    "ogx_mmlux_pt-pt-jurisprudence": [],
    "ogx_mmlux_pt-pt-logical_fallacies": [],
    "ogx_mmlux_pt-pt-machine_learning": [],
    "ogx_mmlux_pt-pt-management": [],
    "ogx_mmlux_pt-pt-marketing": [],
    "ogx_mmlux_pt-pt-medical_genetics": [],
    "ogx_mmlux_pt-pt-miscellaneous": [],
    "ogx_mmlux_pt-pt-moral_disputes": [],
    "ogx_mmlux_pt-pt-moral_scenarios": [],
    "ogx_mmlux_pt-pt-nutrition": [],
    "ogx_mmlux_pt-pt-philosophy": [],
    "ogx_mmlux_pt-pt-prehistory": [],
    "ogx_mmlux_pt-pt-professional_accounting": [],
    "ogx_mmlux_pt-pt-professional_law": [],
    "ogx_mmlux_pt-pt-professional_medicine": [],
    "ogx_mmlux_pt-pt-professional_psychology": [],
    "ogx_mmlux_pt-pt-public_relations": [],
    "ogx_mmlux_pt-pt-security_studies": [],
    "ogx_mmlux_pt-pt-sociology": [],
    "ogx_mmlux_pt-pt-us_foreign_policy": [],
    "ogx_mmlux_pt-pt-virology": [],
    "ogx_mmlux_pt-pt-world_religions": [],
    "ogx_mmlux_ro-abstract_algebra": [],
    "ogx_mmlux_ro-anatomy": [],
    "ogx_mmlux_ro-astronomy": [],
    "ogx_mmlux_ro-business_ethics": [],
    "ogx_mmlux_ro-clinical_knowledge": [],
    "ogx_mmlux_ro-college_biology": [],
    "ogx_mmlux_ro-college_chemistry": [],
    "ogx_mmlux_ro-college_computer_science": [],
    "ogx_mmlux_ro-college_mathematics": [],
    "ogx_mmlux_ro-college_medicine": [],
    "ogx_mmlux_ro-college_physics": [],
    "ogx_mmlux_ro-computer_security": [],
    "ogx_mmlux_ro-conceptual_physics": [],
    "ogx_mmlux_ro-econometrics": [],
    "ogx_mmlux_ro-electrical_engineering": [],
    "ogx_mmlux_ro-elementary_mathematics": [],
    "ogx_mmlux_ro-formal_logic": [],
    "ogx_mmlux_ro-global_facts": [],
    "ogx_mmlux_ro-high_school_biology": [],
    "ogx_mmlux_ro-high_school_chemistry": [],
    "ogx_mmlux_ro-high_school_computer_science": [],
    "ogx_mmlux_ro-high_school_european_history": [],
    "ogx_mmlux_ro-high_school_geography": [],
    "ogx_mmlux_ro-high_school_government_and_politics": [],
    "ogx_mmlux_ro-high_school_macroeconomics": [],
    "ogx_mmlux_ro-high_school_mathematics": [],
    "ogx_mmlux_ro-high_school_microeconomics": [],
    "ogx_mmlux_ro-high_school_physics": [],
    "ogx_mmlux_ro-high_school_psychology": [],
    "ogx_mmlux_ro-high_school_statistics": [],
    "ogx_mmlux_ro-high_school_us_history": [],
    "ogx_mmlux_ro-high_school_world_history": [],
    "ogx_mmlux_ro-human_aging": [],
    "ogx_mmlux_ro-human_sexuality": [],
    "ogx_mmlux_ro-international_law": [],
    "ogx_mmlux_ro-jurisprudence": [],
    "ogx_mmlux_ro-logical_fallacies": [],
    "ogx_mmlux_ro-machine_learning": [],
    "ogx_mmlux_ro-management": [],
    "ogx_mmlux_ro-marketing": [],
    "ogx_mmlux_ro-medical_genetics": [],
    "ogx_mmlux_ro-miscellaneous": [],
    "ogx_mmlux_ro-moral_disputes": [],
    "ogx_mmlux_ro-moral_scenarios": [],
    "ogx_mmlux_ro-nutrition": [],
    "ogx_mmlux_ro-philosophy": [],
    "ogx_mmlux_ro-prehistory": [],
    "ogx_mmlux_ro-professional_accounting": [],
    "ogx_mmlux_ro-professional_law": [],
    "ogx_mmlux_ro-professional_medicine": [],
    "ogx_mmlux_ro-professional_psychology": [],
    "ogx_mmlux_ro-public_relations": [],
    "ogx_mmlux_ro-security_studies": [],
    "ogx_mmlux_ro-sociology": [],
    "ogx_mmlux_ro-us_foreign_policy": [],
    "ogx_mmlux_ro-virology": [],
    "ogx_mmlux_ro-world_religions": [],
    "ogx_mmlux_sk-abstract_algebra": [],
    "ogx_mmlux_sk-anatomy": [],
    "ogx_mmlux_sk-astronomy": [],
    "ogx_mmlux_sk-business_ethics": [],
    "ogx_mmlux_sk-clinical_knowledge": [],
    "ogx_mmlux_sk-college_biology": [],
    "ogx_mmlux_sk-college_chemistry": [],
    "ogx_mmlux_sk-college_computer_science": [],
    "ogx_mmlux_sk-college_mathematics": [],
    "ogx_mmlux_sk-college_medicine": [],
    "ogx_mmlux_sk-college_physics": [],
    "ogx_mmlux_sk-computer_security": [],
    "ogx_mmlux_sk-conceptual_physics": [],
    "ogx_mmlux_sk-econometrics": [],
    "ogx_mmlux_sk-electrical_engineering": [],
    "ogx_mmlux_sk-elementary_mathematics": [],
    "ogx_mmlux_sk-formal_logic": [],
    "ogx_mmlux_sk-global_facts": [],
    "ogx_mmlux_sk-high_school_biology": [],
    "ogx_mmlux_sk-high_school_chemistry": [],
    "ogx_mmlux_sk-high_school_computer_science": [],
    "ogx_mmlux_sk-high_school_european_history": [],
    "ogx_mmlux_sk-high_school_geography": [],
    "ogx_mmlux_sk-high_school_government_and_politics": [],
    "ogx_mmlux_sk-high_school_macroeconomics": [],
    "ogx_mmlux_sk-high_school_mathematics": [],
    "ogx_mmlux_sk-high_school_microeconomics": [],
    "ogx_mmlux_sk-high_school_physics": [],
    "ogx_mmlux_sk-high_school_psychology": [],
    "ogx_mmlux_sk-high_school_statistics": [],
    "ogx_mmlux_sk-high_school_us_history": [],
    "ogx_mmlux_sk-high_school_world_history": [],
    "ogx_mmlux_sk-human_aging": [],
    "ogx_mmlux_sk-human_sexuality": [],
    "ogx_mmlux_sk-international_law": [],
    "ogx_mmlux_sk-jurisprudence": [],
    "ogx_mmlux_sk-logical_fallacies": [],
    "ogx_mmlux_sk-machine_learning": [],
    "ogx_mmlux_sk-management": [],
    "ogx_mmlux_sk-marketing": [],
    "ogx_mmlux_sk-medical_genetics": [],
    "ogx_mmlux_sk-miscellaneous": [],
    "ogx_mmlux_sk-moral_disputes": [],
    "ogx_mmlux_sk-moral_scenarios": [],
    "ogx_mmlux_sk-nutrition": [],
    "ogx_mmlux_sk-philosophy": [],
    "ogx_mmlux_sk-prehistory": [],
    "ogx_mmlux_sk-professional_accounting": [],
    "ogx_mmlux_sk-professional_law": [],
    "ogx_mmlux_sk-professional_medicine": [],
    "ogx_mmlux_sk-professional_psychology": [],
    "ogx_mmlux_sk-public_relations": [],
    "ogx_mmlux_sk-security_studies": [],
    "ogx_mmlux_sk-sociology": [],
    "ogx_mmlux_sk-us_foreign_policy": [],
    "ogx_mmlux_sk-virology": [],
    "ogx_mmlux_sk-world_religions": [],
    "ogx_mmlux_sl-abstract_algebra": [],
    "ogx_mmlux_sl-anatomy": [],
    "ogx_mmlux_sl-astronomy": [],
    "ogx_mmlux_sl-business_ethics": [],
    "ogx_mmlux_sl-clinical_knowledge": [],
    "ogx_mmlux_sl-college_biology": [],
    "ogx_mmlux_sl-college_chemistry": [],
    "ogx_mmlux_sl-college_computer_science": [],
    "ogx_mmlux_sl-college_mathematics": [],
    "ogx_mmlux_sl-college_medicine": [],
    "ogx_mmlux_sl-college_physics": [],
    "ogx_mmlux_sl-computer_security": [],
    "ogx_mmlux_sl-conceptual_physics": [],
    "ogx_mmlux_sl-econometrics": [],
    "ogx_mmlux_sl-electrical_engineering": [],
    "ogx_mmlux_sl-elementary_mathematics": [],
    "ogx_mmlux_sl-formal_logic": [],
    "ogx_mmlux_sl-global_facts": [],
    "ogx_mmlux_sl-high_school_biology": [],
    "ogx_mmlux_sl-high_school_chemistry": [],
    "ogx_mmlux_sl-high_school_computer_science": [],
    "ogx_mmlux_sl-high_school_european_history": [],
    "ogx_mmlux_sl-high_school_geography": [],
    "ogx_mmlux_sl-high_school_government_and_politics": [],
    "ogx_mmlux_sl-high_school_macroeconomics": [],
    "ogx_mmlux_sl-high_school_mathematics": [],
    "ogx_mmlux_sl-high_school_microeconomics": [],
    "ogx_mmlux_sl-high_school_physics": [],
    "ogx_mmlux_sl-high_school_psychology": [],
    "ogx_mmlux_sl-high_school_statistics": [],
    "ogx_mmlux_sl-high_school_us_history": [],
    "ogx_mmlux_sl-high_school_world_history": [],
    "ogx_mmlux_sl-human_aging": [],
    "ogx_mmlux_sl-human_sexuality": [],
    "ogx_mmlux_sl-international_law": [],
    "ogx_mmlux_sl-jurisprudence": [],
    "ogx_mmlux_sl-logical_fallacies": [],
    "ogx_mmlux_sl-machine_learning": [],
    "ogx_mmlux_sl-management": [],
    "ogx_mmlux_sl-marketing": [],
    "ogx_mmlux_sl-medical_genetics": [],
    "ogx_mmlux_sl-miscellaneous": [],
    "ogx_mmlux_sl-moral_disputes": [],
    "ogx_mmlux_sl-moral_scenarios": [],
    "ogx_mmlux_sl-nutrition": [],
    "ogx_mmlux_sl-philosophy": [],
    "ogx_mmlux_sl-prehistory": [],
    "ogx_mmlux_sl-professional_accounting": [],
    "ogx_mmlux_sl-professional_law": [],
    "ogx_mmlux_sl-professional_medicine": [],
    "ogx_mmlux_sl-professional_psychology": [],
    "ogx_mmlux_sl-public_relations": [],
    "ogx_mmlux_sl-security_studies": [],
    "ogx_mmlux_sl-sociology": [],
    "ogx_mmlux_sl-us_foreign_policy": [],
    "ogx_mmlux_sl-virology": [],
    "ogx_mmlux_sl-world_religions": [],
    "ogx_mmlux_sv-abstract_algebra": [],
    "ogx_mmlux_sv-anatomy": [],
    "ogx_mmlux_sv-astronomy": [],
    "ogx_mmlux_sv-business_ethics": [],
    "ogx_mmlux_sv-clinical_knowledge": [],
    "ogx_mmlux_sv-college_biology": [],
    "ogx_mmlux_sv-college_chemistry": [],
    "ogx_mmlux_sv-college_computer_science": [],
    "ogx_mmlux_sv-college_mathematics": [],
    "ogx_mmlux_sv-college_medicine": [],
    "ogx_mmlux_sv-college_physics": [],
    "ogx_mmlux_sv-computer_security": [],
    "ogx_mmlux_sv-conceptual_physics": [],
    "ogx_mmlux_sv-econometrics": [],
    "ogx_mmlux_sv-electrical_engineering": [],
    "ogx_mmlux_sv-elementary_mathematics": [],
    "ogx_mmlux_sv-formal_logic": [],
    "ogx_mmlux_sv-global_facts": [],
    "ogx_mmlux_sv-high_school_biology": [],
    "ogx_mmlux_sv-high_school_chemistry": [],
    "ogx_mmlux_sv-high_school_computer_science": [],
    "ogx_mmlux_sv-high_school_european_history": [],
    "ogx_mmlux_sv-high_school_geography": [],
    "ogx_mmlux_sv-high_school_government_and_politics": [],
    "ogx_mmlux_sv-high_school_macroeconomics": [],
    "ogx_mmlux_sv-high_school_mathematics": [],
    "ogx_mmlux_sv-high_school_microeconomics": [],
    "ogx_mmlux_sv-high_school_physics": [],
    "ogx_mmlux_sv-high_school_psychology": [],
    "ogx_mmlux_sv-high_school_statistics": [],
    "ogx_mmlux_sv-high_school_us_history": [],
    "ogx_mmlux_sv-high_school_world_history": [],
    "ogx_mmlux_sv-human_aging": [],
    "ogx_mmlux_sv-human_sexuality": [],
    "ogx_mmlux_sv-international_law": [],
    "ogx_mmlux_sv-jurisprudence": [],
    "ogx_mmlux_sv-logical_fallacies": [],
    "ogx_mmlux_sv-machine_learning": [],
    "ogx_mmlux_sv-management": [],
    "ogx_mmlux_sv-marketing": [],
    "ogx_mmlux_sv-medical_genetics": [],
    "ogx_mmlux_sv-miscellaneous": [],
    "ogx_mmlux_sv-moral_disputes": [],
    "ogx_mmlux_sv-moral_scenarios": [],
    "ogx_mmlux_sv-nutrition": [],
    "ogx_mmlux_sv-philosophy": [],
    "ogx_mmlux_sv-prehistory": [],
    "ogx_mmlux_sv-professional_accounting": [],
    "ogx_mmlux_sv-professional_law": [],
    "ogx_mmlux_sv-professional_medicine": [],
    "ogx_mmlux_sv-professional_psychology": [],
    "ogx_mmlux_sv-public_relations": [],
    "ogx_mmlux_sv-security_studies": [],
    "ogx_mmlux_sv-sociology": [],
    "ogx_mmlux_sv-us_foreign_policy": [],
    "ogx_mmlux_sv-virology": [],
    "ogx_mmlux_sv-world_religions": []
  },
  "configs": {
    "ogx_mmlux_bg-abstract_algebra": {
      "task": "ogx_mmlux_bg-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-anatomy": {
      "task": "ogx_mmlux_bg-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-astronomy": {
      "task": "ogx_mmlux_bg-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-business_ethics": {
      "task": "ogx_mmlux_bg-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "task": "ogx_mmlux_bg-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_biology": {
      "task": "ogx_mmlux_bg-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_chemistry": {
      "task": "ogx_mmlux_bg-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_computer_science": {
      "task": "ogx_mmlux_bg-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_mathematics": {
      "task": "ogx_mmlux_bg-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_medicine": {
      "task": "ogx_mmlux_bg-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_physics": {
      "task": "ogx_mmlux_bg-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-computer_security": {
      "task": "ogx_mmlux_bg-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "task": "ogx_mmlux_bg-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-econometrics": {
      "task": "ogx_mmlux_bg-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "task": "ogx_mmlux_bg-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "task": "ogx_mmlux_bg-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-formal_logic": {
      "task": "ogx_mmlux_bg-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-global_facts": {
      "task": "ogx_mmlux_bg-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_biology": {
      "task": "ogx_mmlux_bg-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "task": "ogx_mmlux_bg-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "task": "ogx_mmlux_bg-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "task": "ogx_mmlux_bg-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_geography": {
      "task": "ogx_mmlux_bg-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "task": "ogx_mmlux_bg-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "task": "ogx_mmlux_bg-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "task": "ogx_mmlux_bg-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "task": "ogx_mmlux_bg-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_physics": {
      "task": "ogx_mmlux_bg-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "task": "ogx_mmlux_bg-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "task": "ogx_mmlux_bg-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "task": "ogx_mmlux_bg-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "task": "ogx_mmlux_bg-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-human_aging": {
      "task": "ogx_mmlux_bg-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-human_sexuality": {
      "task": "ogx_mmlux_bg-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-international_law": {
      "task": "ogx_mmlux_bg-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-jurisprudence": {
      "task": "ogx_mmlux_bg-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "task": "ogx_mmlux_bg-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-machine_learning": {
      "task": "ogx_mmlux_bg-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-management": {
      "task": "ogx_mmlux_bg-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-marketing": {
      "task": "ogx_mmlux_bg-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-medical_genetics": {
      "task": "ogx_mmlux_bg-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-miscellaneous": {
      "task": "ogx_mmlux_bg-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "      ( )  miscellaneous.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-moral_disputes": {
      "task": "ogx_mmlux_bg-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "task": "ogx_mmlux_bg-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-nutrition": {
      "task": "ogx_mmlux_bg-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "        .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-philosophy": {
      "task": "ogx_mmlux_bg-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "        .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-prehistory": {
      "task": "ogx_mmlux_bg-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_accounting": {
      "task": "ogx_mmlux_bg-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_law": {
      "task": "ogx_mmlux_bg-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "      ,    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_medicine": {
      "task": "ogx_mmlux_bg-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_psychology": {
      "task": "ogx_mmlux_bg-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-public_relations": {
      "task": "ogx_mmlux_bg-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "          .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-security_studies": {
      "task": "ogx_mmlux_bg-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-sociology": {
      "task": "ogx_mmlux_bg-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "task": "ogx_mmlux_bg-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "      ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-virology": {
      "task": "ogx_mmlux_bg-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-world_religions": {
      "task": "ogx_mmlux_bg-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "task": "ogx_mmlux_cs-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o abstraktn algebe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-anatomy": {
      "task": "ogx_mmlux_cs-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o anatomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-astronomy": {
      "task": "ogx_mmlux_cs-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o astronomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-business_ethics": {
      "task": "ogx_mmlux_cs-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o etice podnikn.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "task": "ogx_mmlux_cs-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o klinickch znalostech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_biology": {
      "task": "ogx_mmlux_cs-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o vysokokolsk biologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_chemistry": {
      "task": "ogx_mmlux_cs-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o vysokokolsk chemii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_computer_science": {
      "task": "ogx_mmlux_cs-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o vysokokolsk informatice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_mathematics": {
      "task": "ogx_mmlux_cs-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o vysokokolsk matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_medicine": {
      "task": "ogx_mmlux_cs-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o vysokokolsk medicn.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_physics": {
      "task": "ogx_mmlux_cs-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd z vysokokolsk fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-computer_security": {
      "task": "ogx_mmlux_cs-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o potaov bezpenosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "task": "ogx_mmlux_cs-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd z konceptuln fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-econometrics": {
      "task": "ogx_mmlux_cs-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "task": "ogx_mmlux_cs-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o elektrotechnice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "task": "ogx_mmlux_cs-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o elementrn matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-formal_logic": {
      "task": "ogx_mmlux_cs-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o formln logice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-global_facts": {
      "task": "ogx_mmlux_cs-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o globlnch faktech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_biology": {
      "task": "ogx_mmlux_cs-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk biologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "task": "ogx_mmlux_cs-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk chemii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "task": "ogx_mmlux_cs-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk informatice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "task": "ogx_mmlux_cs-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd z djin Evropy pro stedn koly.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_geography": {
      "task": "ogx_mmlux_cs-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolskm zempisu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "task": "ogx_mmlux_cs-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk vld a politice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "task": "ogx_mmlux_cs-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd z makroekonomie pro stedn koly.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "task": "ogx_mmlux_cs-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "task": "ogx_mmlux_cs-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd z mikroekonomie pro stedn koly.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_physics": {
      "task": "ogx_mmlux_cs-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd ze stedokolsk fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "task": "ogx_mmlux_cs-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk psychologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "task": "ogx_mmlux_cs-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk statistice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "task": "ogx_mmlux_cs-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsledujc otzky s vbrem odpovd se tkaj stedokolsk historie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "task": "ogx_mmlux_cs-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd ze svtovch djin pro stedn koly.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-human_aging": {
      "task": "ogx_mmlux_cs-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o strnut lovka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-human_sexuality": {
      "task": "ogx_mmlux_cs-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o lidsk sexualit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-international_law": {
      "task": "ogx_mmlux_cs-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o mezinrodnm prvu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-jurisprudence": {
      "task": "ogx_mmlux_cs-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o prvu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "task": "ogx_mmlux_cs-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o logickch klamech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-machine_learning": {
      "task": "ogx_mmlux_cs-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o strojovm uen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-management": {
      "task": "ogx_mmlux_cs-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsledujc otzky (s odpovmi) se tkaj managementu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-marketing": {
      "task": "ogx_mmlux_cs-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsledujc otzky (s odpovmi) se tkaj marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-medical_genetics": {
      "task": "ogx_mmlux_cs-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o lkask genetice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-miscellaneous": {
      "task": "ogx_mmlux_cs-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsledujc otzky s vbrem odpovdi se tkaj tmatu miscellaneous.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-moral_disputes": {
      "task": "ogx_mmlux_cs-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsledujc otzky s vbrem odpovd se tkaj morlnch spor.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "task": "ogx_mmlux_cs-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o morlnch scnch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-nutrition": {
      "task": "ogx_mmlux_cs-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o viv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-philosophy": {
      "task": "ogx_mmlux_cs-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-prehistory": {
      "task": "ogx_mmlux_cs-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o pravku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_accounting": {
      "task": "ogx_mmlux_cs-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o odbornm etnictv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_law": {
      "task": "ogx_mmlux_cs-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o profesnm prvu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_medicine": {
      "task": "ogx_mmlux_cs-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o profesionln medicn.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_psychology": {
      "task": "ogx_mmlux_cs-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o odborn psychologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-public_relations": {
      "task": "ogx_mmlux_cs-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o vztazch s veejnost.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-security_studies": {
      "task": "ogx_mmlux_cs-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o bezpenostnch studich.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-sociology": {
      "task": "ogx_mmlux_cs-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o sociologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "task": "ogx_mmlux_cs-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsledujc otzky s vbrem odpovd se tkaj zahranin politiky USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-virology": {
      "task": "ogx_mmlux_cs-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o virologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-world_religions": {
      "task": "ogx_mmlux_cs-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o svtovch nboenstvch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-abstract_algebra": {
      "task": "ogx_mmlux_da-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om abstrakt algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-anatomy": {
      "task": "ogx_mmlux_da-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om anatomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-astronomy": {
      "task": "ogx_mmlux_da-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om astronomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-business_ethics": {
      "task": "ogx_mmlux_da-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om forretningsetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "task": "ogx_mmlux_da-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om klinisk viden.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_biology": {
      "task": "ogx_mmlux_da-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om universitetsbiologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_chemistry": {
      "task": "ogx_mmlux_da-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om kemi p college.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_computer_science": {
      "task": "ogx_mmlux_da-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om computervidenskab p college.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_mathematics": {
      "task": "ogx_mmlux_da-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om universitetsmatematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_medicine": {
      "task": "ogx_mmlux_da-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om universitetsmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_physics": {
      "task": "ogx_mmlux_da-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om universitetsfysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-computer_security": {
      "task": "ogx_mmlux_da-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om computersikkerhed.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-conceptual_physics": {
      "task": "ogx_mmlux_da-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om konceptuel fysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-econometrics": {
      "task": "ogx_mmlux_da-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om konometri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-electrical_engineering": {
      "task": "ogx_mmlux_da-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om elektroteknik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "task": "ogx_mmlux_da-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om elementr matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-formal_logic": {
      "task": "ogx_mmlux_da-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om formel logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-global_facts": {
      "task": "ogx_mmlux_da-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om globale fakta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_biology": {
      "task": "ogx_mmlux_da-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om biologi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "task": "ogx_mmlux_da-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om kemi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "task": "ogx_mmlux_da-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om computervidenskab i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_european_history": {
      "task": "ogx_mmlux_da-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om europisk historie i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_geography": {
      "task": "ogx_mmlux_da-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om geografi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "task": "ogx_mmlux_da-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om regering og politik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "task": "ogx_mmlux_da-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om makrokonomi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "task": "ogx_mmlux_da-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om matematik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "task": "ogx_mmlux_da-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det flgende er multiple choice-sprgsml (med svar) om mikrokonomi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_physics": {
      "task": "ogx_mmlux_da-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om fysik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_psychology": {
      "task": "ogx_mmlux_da-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om psykologi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_statistics": {
      "task": "ogx_mmlux_da-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om statistik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_us_history": {
      "task": "ogx_mmlux_da-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om amerikansk historie i high school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_world_history": {
      "task": "ogx_mmlux_da-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om verdenshistorie i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-human_aging": {
      "task": "ogx_mmlux_da-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om menneskets aldring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-human_sexuality": {
      "task": "ogx_mmlux_da-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om menneskelig seksualitet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-international_law": {
      "task": "ogx_mmlux_da-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om international lov.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-jurisprudence": {
      "task": "ogx_mmlux_da-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om retsvidenskab.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-logical_fallacies": {
      "task": "ogx_mmlux_da-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om logiske fejlslutninger.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-machine_learning": {
      "task": "ogx_mmlux_da-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om maskinlring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-management": {
      "task": "ogx_mmlux_da-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om ledelse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-marketing": {
      "task": "ogx_mmlux_da-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-medical_genetics": {
      "task": "ogx_mmlux_da-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om medicinsk genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-miscellaneous": {
      "task": "ogx_mmlux_da-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-moral_disputes": {
      "task": "ogx_mmlux_da-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om moralske tvister.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-moral_scenarios": {
      "task": "ogx_mmlux_da-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om moralske scenarier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-nutrition": {
      "task": "ogx_mmlux_da-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om ernring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-philosophy": {
      "task": "ogx_mmlux_da-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om filosofi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-prehistory": {
      "task": "ogx_mmlux_da-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det flgende er multiple choice-sprgsml (med svar) om forhistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_accounting": {
      "task": "ogx_mmlux_da-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om professionelt regnskab.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_law": {
      "task": "ogx_mmlux_da-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om erhvervsret.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_medicine": {
      "task": "ogx_mmlux_da-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om professionel medicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_psychology": {
      "task": "ogx_mmlux_da-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om professionel psykologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-public_relations": {
      "task": "ogx_mmlux_da-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-security_studies": {
      "task": "ogx_mmlux_da-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om sikkerhedsstudier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-sociology": {
      "task": "ogx_mmlux_da-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om sociologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "task": "ogx_mmlux_da-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om amerikansk udenrigspolitik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-virology": {
      "task": "ogx_mmlux_da-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om virologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-world_religions": {
      "task": "ogx_mmlux_da-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det flgende er multiple choice-sprgsml (med svar) om verdensreligioner.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-abstract_algebra": {
      "task": "ogx_mmlux_de-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur abstrakten Algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-anatomy": {
      "task": "ogx_mmlux_de-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-astronomy": {
      "task": "ogx_mmlux_de-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-business_ethics": {
      "task": "ogx_mmlux_de-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Unternehmensethik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "task": "ogx_mmlux_de-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu klinischen Kenntnissen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_biology": {
      "task": "ogx_mmlux_de-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Biologie an der Universitt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_chemistry": {
      "task": "ogx_mmlux_de-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Chemie an Hochschulen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_computer_science": {
      "task": "ogx_mmlux_de-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulinformatik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_mathematics": {
      "task": "ogx_mmlux_de-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulmathematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_medicine": {
      "task": "ogx_mmlux_de-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Hochschulmedizin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_physics": {
      "task": "ogx_mmlux_de-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulphysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-computer_security": {
      "task": "ogx_mmlux_de-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Computersicherheit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-conceptual_physics": {
      "task": "ogx_mmlux_de-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur konzeptionellen Physik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-econometrics": {
      "task": "ogx_mmlux_de-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur konometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-electrical_engineering": {
      "task": "ogx_mmlux_de-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Elektrotechnik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "task": "ogx_mmlux_de-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur elementaren Mathematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-formal_logic": {
      "task": "ogx_mmlux_de-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur formalen Logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-global_facts": {
      "task": "ogx_mmlux_de-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu globalen Fakten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_biology": {
      "task": "ogx_mmlux_de-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Biologie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "task": "ogx_mmlux_de-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Chemie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "task": "ogx_mmlux_de-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Informatik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_european_history": {
      "task": "ogx_mmlux_de-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur europischen Geschichte in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_geography": {
      "task": "ogx_mmlux_de-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Geografie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "task": "ogx_mmlux_de-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Regierung und Politik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "task": "ogx_mmlux_de-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Makrokonomie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "task": "ogx_mmlux_de-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Mathematik in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "task": "ogx_mmlux_de-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Mikrokonomie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_physics": {
      "task": "ogx_mmlux_de-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Physik in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_psychology": {
      "task": "ogx_mmlux_de-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Schulpsychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_statistics": {
      "task": "ogx_mmlux_de-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Statistik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_us_history": {
      "task": "ogx_mmlux_de-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Geschichte der USA in der High School.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_world_history": {
      "task": "ogx_mmlux_de-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Weltgeschichte in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-human_aging": {
      "task": "ogx_mmlux_de-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum menschlichen Altern.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-human_sexuality": {
      "task": "ogx_mmlux_de-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur menschlichen Sexualitt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-international_law": {
      "task": "ogx_mmlux_de-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum internationalen Recht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-jurisprudence": {
      "task": "ogx_mmlux_de-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Rechtswissenschaft.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-logical_fallacies": {
      "task": "ogx_mmlux_de-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu logischen Fehlschlssen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-machine_learning": {
      "task": "ogx_mmlux_de-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum maschinellen Lernen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-management": {
      "task": "ogx_mmlux_de-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-marketing": {
      "task": "ogx_mmlux_de-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-medical_genetics": {
      "task": "ogx_mmlux_de-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur medizinischen Genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-miscellaneous": {
      "task": "ogx_mmlux_de-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Verschiedenes.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-moral_disputes": {
      "task": "ogx_mmlux_de-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu moralischen Streitigkeiten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-moral_scenarios": {
      "task": "ogx_mmlux_de-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu moralischen Szenarien.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-nutrition": {
      "task": "ogx_mmlux_de-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Ernhrung.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-philosophy": {
      "task": "ogx_mmlux_de-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Philosophie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-prehistory": {
      "task": "ogx_mmlux_de-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Vorgeschichte.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_accounting": {
      "task": "ogx_mmlux_de-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema professionelle Buchhaltung.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_law": {
      "task": "ogx_mmlux_de-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Berufsrecht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_medicine": {
      "task": "ogx_mmlux_de-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Berufsmedizin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_psychology": {
      "task": "ogx_mmlux_de-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Berufspsychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-public_relations": {
      "task": "ogx_mmlux_de-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema ffentlichkeitsarbeit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-security_studies": {
      "task": "ogx_mmlux_de-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Es folgen Multiple-Choice-Fragen (mit Antworten) zu Sicherheitsstudien.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-sociology": {
      "task": "ogx_mmlux_de-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Soziologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "task": "ogx_mmlux_de-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Auenpolitik der USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-virology": {
      "task": "ogx_mmlux_de-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-world_religions": {
      "task": "ogx_mmlux_de-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu den Weltreligionen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-abstract_algebra": {
      "task": "ogx_mmlux_el-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-anatomy": {
      "task": "ogx_mmlux_el-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-astronomy": {
      "task": "ogx_mmlux_el-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-business_ethics": {
      "task": "ogx_mmlux_el-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "task": "ogx_mmlux_el-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_biology": {
      "task": "ogx_mmlux_el-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_chemistry": {
      "task": "ogx_mmlux_el-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_computer_science": {
      "task": "ogx_mmlux_el-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )        .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_mathematics": {
      "task": "ogx_mmlux_el-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_medicine": {
      "task": "ogx_mmlux_el-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_physics": {
      "task": "ogx_mmlux_el-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-computer_security": {
      "task": "ogx_mmlux_el-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-conceptual_physics": {
      "task": "ogx_mmlux_el-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-econometrics": {
      "task": "ogx_mmlux_el-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-electrical_engineering": {
      "task": "ogx_mmlux_el-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "task": "ogx_mmlux_el-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-formal_logic": {
      "task": "ogx_mmlux_el-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-global_facts": {
      "task": "ogx_mmlux_el-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_biology": {
      "task": "ogx_mmlux_el-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "task": "ogx_mmlux_el-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "task": "ogx_mmlux_el-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )        .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_european_history": {
      "task": "ogx_mmlux_el-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_geography": {
      "task": "ogx_mmlux_el-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "task": "ogx_mmlux_el-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "task": "ogx_mmlux_el-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "task": "ogx_mmlux_el-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "task": "ogx_mmlux_el-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_physics": {
      "task": "ogx_mmlux_el-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_psychology": {
      "task": "ogx_mmlux_el-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_statistics": {
      "task": "ogx_mmlux_el-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_us_history": {
      "task": "ogx_mmlux_el-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_world_history": {
      "task": "ogx_mmlux_el-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-human_aging": {
      "task": "ogx_mmlux_el-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-human_sexuality": {
      "task": "ogx_mmlux_el-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-international_law": {
      "task": "ogx_mmlux_el-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-jurisprudence": {
      "task": "ogx_mmlux_el-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-logical_fallacies": {
      "task": "ogx_mmlux_el-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-machine_learning": {
      "task": "ogx_mmlux_el-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-management": {
      "task": "ogx_mmlux_el-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-marketing": {
      "task": "ogx_mmlux_el-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-medical_genetics": {
      "task": "ogx_mmlux_el-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-miscellaneous": {
      "task": "ogx_mmlux_el-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-moral_disputes": {
      "task": "ogx_mmlux_el-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-moral_scenarios": {
      "task": "ogx_mmlux_el-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-nutrition": {
      "task": "ogx_mmlux_el-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-philosophy": {
      "task": "ogx_mmlux_el-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-prehistory": {
      "task": "ogx_mmlux_el-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_accounting": {
      "task": "ogx_mmlux_el-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_law": {
      "task": "ogx_mmlux_el-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_medicine": {
      "task": "ogx_mmlux_el-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_psychology": {
      "task": "ogx_mmlux_el-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-public_relations": {
      "task": "ogx_mmlux_el-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-security_studies": {
      "task": "ogx_mmlux_el-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-sociology": {
      "task": "ogx_mmlux_el-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "task": "ogx_mmlux_el-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-virology": {
      "task": "ogx_mmlux_el-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-world_religions": {
      "task": "ogx_mmlux_el-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-abstract_algebra": {
      "task": "ogx_mmlux_es-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre lgebra abstracta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-anatomy": {
      "task": "ogx_mmlux_es-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre anatoma.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-astronomy": {
      "task": "ogx_mmlux_es-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre astronoma.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-business_ethics": {
      "task": "ogx_mmlux_es-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre tica empresarial.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "task": "ogx_mmlux_es-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A continuacin se presentan preguntas tipo test (con respuesta) sobre conocimientos clnicos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_biology": {
      "task": "ogx_mmlux_es-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre biologa universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_chemistry": {
      "task": "ogx_mmlux_es-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre qumica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_computer_science": {
      "task": "ogx_mmlux_es-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre informtica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_mathematics": {
      "task": "ogx_mmlux_es-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemticas universitarias.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_medicine": {
      "task": "ogx_mmlux_es-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre medicina universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_physics": {
      "task": "ogx_mmlux_es-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre fsica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-computer_security": {
      "task": "ogx_mmlux_es-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre seguridad informtica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-conceptual_physics": {
      "task": "ogx_mmlux_es-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre fsica conceptual.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-econometrics": {
      "task": "ogx_mmlux_es-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre econometra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-electrical_engineering": {
      "task": "ogx_mmlux_es-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre ingeniera elctrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "task": "ogx_mmlux_es-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemticas elementales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-formal_logic": {
      "task": "ogx_mmlux_es-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre lgica formal.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-global_facts": {
      "task": "ogx_mmlux_es-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre hechos globales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_biology": {
      "task": "ogx_mmlux_es-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre biologa de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "task": "ogx_mmlux_es-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre qumica de bachillerato.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "task": "ogx_mmlux_es-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre informtica en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_european_history": {
      "task": "ogx_mmlux_es-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre historia europea de bachillerato.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_geography": {
      "task": "ogx_mmlux_es-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre geografa de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "task": "ogx_mmlux_es-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre el gobierno y la poltica en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "task": "ogx_mmlux_es-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre macroeconoma en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "task": "ogx_mmlux_es-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemticas de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "task": "ogx_mmlux_es-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre microeconoma en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_physics": {
      "task": "ogx_mmlux_es-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre fsica de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_psychology": {
      "task": "ogx_mmlux_es-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre psicologa en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_statistics": {
      "task": "ogx_mmlux_es-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre estadstica de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_us_history": {
      "task": "ogx_mmlux_es-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre la historia de EE.UU. en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_world_history": {
      "task": "ogx_mmlux_es-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre la historia mundial de la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-human_aging": {
      "task": "ogx_mmlux_es-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre el envejecimiento humano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-human_sexuality": {
      "task": "ogx_mmlux_es-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre la sexualidad humana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-international_law": {
      "task": "ogx_mmlux_es-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre Derecho internacional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-jurisprudence": {
      "task": "ogx_mmlux_es-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre jurisprudencia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-logical_fallacies": {
      "task": "ogx_mmlux_es-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre falacias lgicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-machine_learning": {
      "task": "ogx_mmlux_es-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre aprendizaje automtico.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-management": {
      "task": "ogx_mmlux_es-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre gestin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-marketing": {
      "task": "ogx_mmlux_es-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-medical_genetics": {
      "task": "ogx_mmlux_es-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre gentica mdica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-miscellaneous": {
      "task": "ogx_mmlux_es-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre miscelnea.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-moral_disputes": {
      "task": "ogx_mmlux_es-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre disputas morales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-moral_scenarios": {
      "task": "ogx_mmlux_es-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre escenarios morales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-nutrition": {
      "task": "ogx_mmlux_es-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre nutricin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-philosophy": {
      "task": "ogx_mmlux_es-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre filosofa.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-prehistory": {
      "task": "ogx_mmlux_es-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre la prehistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_accounting": {
      "task": "ogx_mmlux_es-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre contabilidad profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_law": {
      "task": "ogx_mmlux_es-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A continuacin se presentan preguntas tipo test (con respuesta) sobre Derecho profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_medicine": {
      "task": "ogx_mmlux_es-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre medicina profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_psychology": {
      "task": "ogx_mmlux_es-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre psicologa profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-public_relations": {
      "task": "ogx_mmlux_es-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre relaciones pblicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-security_studies": {
      "task": "ogx_mmlux_es-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre estudios de seguridad.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-sociology": {
      "task": "ogx_mmlux_es-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre sociologa.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "task": "ogx_mmlux_es-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre la poltica exterior estadounidense.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-virology": {
      "task": "ogx_mmlux_es-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre virologa.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-world_religions": {
      "task": "ogx_mmlux_es-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre las religiones del mundo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-abstract_algebra": {
      "task": "ogx_mmlux_et-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) abstraktse algebra kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-anatomy": {
      "task": "ogx_mmlux_et-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) anatoomia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-astronomy": {
      "task": "ogx_mmlux_et-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) astronoomia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-business_ethics": {
      "task": "ogx_mmlux_et-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) rieetika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "task": "ogx_mmlux_et-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kliiniliste teadmiste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_biology": {
      "task": "ogx_mmlux_et-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kolledi bioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_chemistry": {
      "task": "ogx_mmlux_et-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kolledi keemia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_computer_science": {
      "task": "ogx_mmlux_et-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) krgkooli informaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_mathematics": {
      "task": "ogx_mmlux_et-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kolledi matemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_medicine": {
      "task": "ogx_mmlux_et-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kolledi meditsiini kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_physics": {
      "task": "ogx_mmlux_et-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kolledi fsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-computer_security": {
      "task": "ogx_mmlux_et-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) arvutiturbe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-conceptual_physics": {
      "task": "ogx_mmlux_et-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kontseptuaalse fsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-econometrics": {
      "task": "ogx_mmlux_et-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) konomeetria kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-electrical_engineering": {
      "task": "ogx_mmlux_et-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) elektrotehnika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "task": "ogx_mmlux_et-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) elementaarmatemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-formal_logic": {
      "task": "ogx_mmlux_et-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) formaalloogika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-global_facts": {
      "task": "ogx_mmlux_et-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) globaalsete faktide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_biology": {
      "task": "ogx_mmlux_et-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli bioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "task": "ogx_mmlux_et-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli keemia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "task": "ogx_mmlux_et-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli informaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_european_history": {
      "task": "ogx_mmlux_et-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli Euroopa ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_geography": {
      "task": "ogx_mmlux_et-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli geograafia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "task": "ogx_mmlux_et-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli valitsuse ja poliitika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "task": "ogx_mmlux_et-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli makromajanduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "task": "ogx_mmlux_et-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli matemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "task": "ogx_mmlux_et-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli mikrokonoomika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_physics": {
      "task": "ogx_mmlux_et-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkoolifsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_psychology": {
      "task": "ogx_mmlux_et-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkoolipshholoogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_statistics": {
      "task": "ogx_mmlux_et-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli statistika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_us_history": {
      "task": "ogx_mmlux_et-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) meie keskkooli ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_world_history": {
      "task": "ogx_mmlux_et-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli maailma ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-human_aging": {
      "task": "ogx_mmlux_et-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) inimese vananemise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-human_sexuality": {
      "task": "ogx_mmlux_et-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) inimese seksuaalsuse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-international_law": {
      "task": "ogx_mmlux_et-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) rahvusvahelise iguse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-jurisprudence": {
      "task": "ogx_mmlux_et-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) igusteaduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-logical_fallacies": {
      "task": "ogx_mmlux_et-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) loogiliste eksituste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-machine_learning": {
      "task": "ogx_mmlux_et-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) masinppe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-management": {
      "task": "ogx_mmlux_et-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) juhtimise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-marketing": {
      "task": "ogx_mmlux_et-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) turunduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-medical_genetics": {
      "task": "ogx_mmlux_et-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) meditsiinigeneetika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-miscellaneous": {
      "task": "ogx_mmlux_et-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) mitmesuguste ksimuste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-moral_disputes": {
      "task": "ogx_mmlux_et-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) moraalsete vaidluste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-moral_scenarios": {
      "task": "ogx_mmlux_et-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) moraalsete stsenaariumide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-nutrition": {
      "task": "ogx_mmlux_et-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) toitumise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-philosophy": {
      "task": "ogx_mmlux_et-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) filosoofia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-prehistory": {
      "task": "ogx_mmlux_et-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) eelajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_accounting": {
      "task": "ogx_mmlux_et-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kutsealase raamatupidamise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_law": {
      "task": "ogx_mmlux_et-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kutseiguse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_medicine": {
      "task": "ogx_mmlux_et-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) erialase meditsiini kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_psychology": {
      "task": "ogx_mmlux_et-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) erialase pshholoogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-public_relations": {
      "task": "ogx_mmlux_et-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) avalike suhete kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-security_studies": {
      "task": "ogx_mmlux_et-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) julgeolekuppe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-sociology": {
      "task": "ogx_mmlux_et-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) sotsioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "task": "ogx_mmlux_et-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) meie vlispoliitika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-virology": {
      "task": "ogx_mmlux_et-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) viroloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-world_religions": {
      "task": "ogx_mmlux_et-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) maailmareligioonide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "task": "ogx_mmlux_fi-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) abstraktista algebrasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-anatomy": {
      "task": "ogx_mmlux_fi-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) anatomiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-astronomy": {
      "task": "ogx_mmlux_fi-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) thtitieteest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-business_ethics": {
      "task": "ogx_mmlux_fi-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) liike-elmn etiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "task": "ogx_mmlux_fi-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) kliinisest tietmyksest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_biology": {
      "task": "ogx_mmlux_fi-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) yliopistobiologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_chemistry": {
      "task": "ogx_mmlux_fi-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) yliopistokemiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_computer_science": {
      "task": "ogx_mmlux_fi-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) yliopistojen tietotekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_mathematics": {
      "task": "ogx_mmlux_fi-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) yliopistomatematiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_medicine": {
      "task": "ogx_mmlux_fi-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) yliopistolketieteest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_physics": {
      "task": "ogx_mmlux_fi-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) yliopistofysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-computer_security": {
      "task": "ogx_mmlux_fi-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) tietoturvasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "task": "ogx_mmlux_fi-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ksitteellisest fysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-econometrics": {
      "task": "ogx_mmlux_fi-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ekonometriasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "task": "ogx_mmlux_fi-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) shktekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "task": "ogx_mmlux_fi-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) matematiikan alkeista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-formal_logic": {
      "task": "ogx_mmlux_fi-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) muodollisesta logiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-global_facts": {
      "task": "ogx_mmlux_fi-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) globaaleista tosiasioista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_biology": {
      "task": "ogx_mmlux_fi-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion biologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "task": "ogx_mmlux_fi-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion kemiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "task": "ogx_mmlux_fi-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion tietotekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "task": "ogx_mmlux_fi-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion Euroopan historiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_geography": {
      "task": "ogx_mmlux_fi-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion maantiedosta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "task": "ogx_mmlux_fi-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion hallituksesta ja politiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "task": "ogx_mmlux_fi-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion makrotaloudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "task": "ogx_mmlux_fi-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion matematiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "task": "ogx_mmlux_fi-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion mikrotaloustieteest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_physics": {
      "task": "ogx_mmlux_fi-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion fysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "task": "ogx_mmlux_fi-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion psykologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "task": "ogx_mmlux_fi-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion tilastoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "task": "ogx_mmlux_fi-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion historiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "task": "ogx_mmlux_fi-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion maailmanhistoriasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-human_aging": {
      "task": "ogx_mmlux_fi-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ihmisen ikntymisest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-human_sexuality": {
      "task": "ogx_mmlux_fi-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ihmisen seksuaalisuudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-international_law": {
      "task": "ogx_mmlux_fi-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) kansainvlisest oikeudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-jurisprudence": {
      "task": "ogx_mmlux_fi-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) oikeustieteest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "task": "ogx_mmlux_fi-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) loogisista virheist.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-machine_learning": {
      "task": "ogx_mmlux_fi-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) koneoppimisesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-management": {
      "task": "ogx_mmlux_fi-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) johtamisesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-marketing": {
      "task": "ogx_mmlux_fi-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) markkinoinnista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-medical_genetics": {
      "task": "ogx_mmlux_fi-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) lketieteellisest genetiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-miscellaneous": {
      "task": "ogx_mmlux_fi-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) aiheesta sekalaiset.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-moral_disputes": {
      "task": "ogx_mmlux_fi-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) moraalisista kiistoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "task": "ogx_mmlux_fi-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) moraalisista skenaarioista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-nutrition": {
      "task": "ogx_mmlux_fi-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ravitsemuksesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-philosophy": {
      "task": "ogx_mmlux_fi-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) filosofiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-prehistory": {
      "task": "ogx_mmlux_fi-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on esihistoriaa koskevia monivalintakysymyksi (vastauksineen).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_accounting": {
      "task": "ogx_mmlux_fi-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ammattimaisesta kirjanpidosta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_law": {
      "task": "ogx_mmlux_fi-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ammattioikeudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_medicine": {
      "task": "ogx_mmlux_fi-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) ammatillisesta lketieteest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_psychology": {
      "task": "ogx_mmlux_fi-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ammattipsykologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-public_relations": {
      "task": "ogx_mmlux_fi-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) suhdetoiminnasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-security_studies": {
      "task": "ogx_mmlux_fi-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) turvallisuustutkimuksesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-sociology": {
      "task": "ogx_mmlux_fi-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on sosiologiaa koskevia monivalintakysymyksi (vastauksineen).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "task": "ogx_mmlux_fi-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavat ovat monivalintakysymyksi (vastauksineen) Yhdysvaltojen ulkopolitiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-virology": {
      "task": "ogx_mmlux_fi-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) virologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-world_religions": {
      "task": "ogx_mmlux_fi-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) maailmanuskonnoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "task": "ogx_mmlux_fr-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'algbre abstraite.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-anatomy": {
      "task": "ogx_mmlux_fr-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-astronomy": {
      "task": "ogx_mmlux_fr-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-business_ethics": {
      "task": "ogx_mmlux_fr-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'thique des affaires.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "task": "ogx_mmlux_fr-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les connaissances cliniques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_biology": {
      "task": "ogx_mmlux_fr-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la biologie au collge.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_chemistry": {
      "task": "ogx_mmlux_fr-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la chimie au collge.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_computer_science": {
      "task": "ogx_mmlux_fr-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'informatique au collge.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_mathematics": {
      "task": "ogx_mmlux_fr-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les mathmatiques au collge.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_medicine": {
      "task": "ogx_mmlux_fr-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la mdecine universitaire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_physics": {
      "task": "ogx_mmlux_fr-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la physique au collge.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-computer_security": {
      "task": "ogx_mmlux_fr-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la scurit informatique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "task": "ogx_mmlux_fr-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la physique conceptuelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-econometrics": {
      "task": "ogx_mmlux_fr-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'conomtrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "task": "ogx_mmlux_fr-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le gnie lectrique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "task": "ogx_mmlux_fr-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les mathmatiques lmentaires.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-formal_logic": {
      "task": "ogx_mmlux_fr-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la logique formelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-global_facts": {
      "task": "ogx_mmlux_fr-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les faits mondiaux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_biology": {
      "task": "ogx_mmlux_fr-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la biologie au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "task": "ogx_mmlux_fr-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la chimie au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "task": "ogx_mmlux_fr-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'informatique au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "task": "ogx_mmlux_fr-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'histoire de l'Europe au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_geography": {
      "task": "ogx_mmlux_fr-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la gographie au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "task": "ogx_mmlux_fr-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le gouvernement et la politique au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "task": "ogx_mmlux_fr-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la macroconomie au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "task": "ogx_mmlux_fr-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les mathmatiques au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "task": "ogx_mmlux_fr-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la microconomie au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_physics": {
      "task": "ogx_mmlux_fr-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la physique au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "task": "ogx_mmlux_fr-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la psychologie au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "task": "ogx_mmlux_fr-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les statistiques de l'enseignement secondaire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "task": "ogx_mmlux_fr-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'histoire des tats-Unis au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "task": "ogx_mmlux_fr-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'histoire du monde au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-human_aging": {
      "task": "ogx_mmlux_fr-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le vieillissement humain.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-human_sexuality": {
      "task": "ogx_mmlux_fr-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la sexualit humaine.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-international_law": {
      "task": "ogx_mmlux_fr-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le droit international.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-jurisprudence": {
      "task": "ogx_mmlux_fr-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la jurisprudence.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "task": "ogx_mmlux_fr-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les sophismes logiques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-machine_learning": {
      "task": "ogx_mmlux_fr-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'apprentissage automatique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-management": {
      "task": "ogx_mmlux_fr-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-marketing": {
      "task": "ogx_mmlux_fr-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-medical_genetics": {
      "task": "ogx_mmlux_fr-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la gntique mdicale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-miscellaneous": {
      "task": "ogx_mmlux_fr-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les divers.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-moral_disputes": {
      "task": "ogx_mmlux_fr-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les diffrends moraux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "task": "ogx_mmlux_fr-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur des scnarios moraux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-nutrition": {
      "task": "ogx_mmlux_fr-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la nutrition.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-philosophy": {
      "task": "ogx_mmlux_fr-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la philosophie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-prehistory": {
      "task": "ogx_mmlux_fr-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la prhistoire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_accounting": {
      "task": "ogx_mmlux_fr-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la comptabilit professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_law": {
      "task": "ogx_mmlux_fr-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le droit professionnel.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_medicine": {
      "task": "ogx_mmlux_fr-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la mdecine professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_psychology": {
      "task": "ogx_mmlux_fr-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la psychologie professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-public_relations": {
      "task": "ogx_mmlux_fr-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les relations publiques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-security_studies": {
      "task": "ogx_mmlux_fr-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les tudes de scurit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-sociology": {
      "task": "ogx_mmlux_fr-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "task": "ogx_mmlux_fr-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Voici des questions  choix multiples (avec rponses) sur la politique trangre des tats-Unis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-virology": {
      "task": "ogx_mmlux_fr-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-world_religions": {
      "task": "ogx_mmlux_fr-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Voici des questions  choix multiples (avec rponses) sur les religions du monde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "task": "ogx_mmlux_hu-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) az absztrakt algebrrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-anatomy": {
      "task": "ogx_mmlux_hu-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) az anatmirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-astronomy": {
      "task": "ogx_mmlux_hu-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a csillagszatrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-business_ethics": {
      "task": "ogx_mmlux_hu-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az zleti etikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "task": "ogx_mmlux_hu-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbiakban a klinikai ismeretekkel kapcsolatos feleletvlaszts krdsek (vlaszokkal) kvetkeznek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_biology": {
      "task": "ogx_mmlux_hu-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a fiskolai biolgirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_chemistry": {
      "task": "ogx_mmlux_hu-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a fiskolai kmirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_computer_science": {
      "task": "ogx_mmlux_hu-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a fiskolai informatikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_mathematics": {
      "task": "ogx_mmlux_hu-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a fiskolai matematikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_medicine": {
      "task": "ogx_mmlux_hu-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a fiskolai orvostudomnyrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_physics": {
      "task": "ogx_mmlux_hu-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) az egyetemi fizikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-computer_security": {
      "task": "ogx_mmlux_hu-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a szmtgpes biztonsgrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "task": "ogx_mmlux_hu-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a fogalmi fizikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-econometrics": {
      "task": "ogx_mmlux_hu-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbiakban az konometrival kapcsolatos feleletvlaszts krdsek (vlaszokkal) kvetkeznek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "task": "ogx_mmlux_hu-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a villamosmrnki tudomnyokrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "task": "ogx_mmlux_hu-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az elemi matematikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-formal_logic": {
      "task": "ogx_mmlux_hu-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a formlis logikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-global_facts": {
      "task": "ogx_mmlux_hu-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a globlis tnyekrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_biology": {
      "task": "ogx_mmlux_hu-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai biolgirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "task": "ogx_mmlux_hu-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai kmirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "task": "ogx_mmlux_hu-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai informatikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "task": "ogx_mmlux_hu-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai eurpai trtnelemrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_geography": {
      "task": "ogx_mmlux_hu-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai fldrajzrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "task": "ogx_mmlux_hu-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a kzpiskolai kormnyzatrl s politikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "task": "ogx_mmlux_hu-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai makrokonmirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "task": "ogx_mmlux_hu-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai matematikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "task": "ogx_mmlux_hu-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai mikrokonmirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_physics": {
      "task": "ogx_mmlux_hu-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai fizikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "task": "ogx_mmlux_hu-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a kzpiskolai pszicholgirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "task": "ogx_mmlux_hu-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbiakban a kzpiskolai statisztikval kapcsolatos feleletvlaszts krdsek (vlaszokkal) tallhatk.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "task": "ogx_mmlux_hu-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai trtnelemrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "task": "ogx_mmlux_hu-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai vilgtrtnelemrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-human_aging": {
      "task": "ogx_mmlux_hu-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az emberi regedssel kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-human_sexuality": {
      "task": "ogx_mmlux_hu-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az emberi szexualitsrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-international_law": {
      "task": "ogx_mmlux_hu-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a nemzetkzi jogrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-jurisprudence": {
      "task": "ogx_mmlux_hu-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a jogtudomnyrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "task": "ogx_mmlux_hu-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbiakban a logikai tvedsekkel kapcsolatos feleletvlaszts krdsek (vlaszokkal) tallhatk.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-machine_learning": {
      "task": "ogx_mmlux_hu-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a gpi tanulsrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-management": {
      "task": "ogx_mmlux_hu-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a menedzsmentrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-marketing": {
      "task": "ogx_mmlux_hu-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a marketingrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-medical_genetics": {
      "task": "ogx_mmlux_hu-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az orvosi genetikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-miscellaneous": {
      "task": "ogx_mmlux_hu-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a klnfle krdsekrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-moral_disputes": {
      "task": "ogx_mmlux_hu-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az erklcsi vitkrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "task": "ogx_mmlux_hu-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbiakban erklcsi forgatknyvekkel kapcsolatos feleletvlaszts krdsek (vlaszokkal) kvetkeznek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-nutrition": {
      "task": "ogx_mmlux_hu-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a tpllkozssal kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-philosophy": {
      "task": "ogx_mmlux_hu-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a filozfirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-prehistory": {
      "task": "ogx_mmlux_hu-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az strtnetrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_accounting": {
      "task": "ogx_mmlux_hu-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a szakmai szmvitelrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_law": {
      "task": "ogx_mmlux_hu-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a szakmai joggal kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_medicine": {
      "task": "ogx_mmlux_hu-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a hivatsos orvoslsrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_psychology": {
      "task": "ogx_mmlux_hu-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a szakpszicholgirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-public_relations": {
      "task": "ogx_mmlux_hu-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a public relationsrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-security_studies": {
      "task": "ogx_mmlux_hu-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a biztonsgi tanulmnyokrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-sociology": {
      "task": "ogx_mmlux_hu-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a szociolgirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "task": "ogx_mmlux_hu-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) az amerikai klpolitikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-virology": {
      "task": "ogx_mmlux_hu-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a virolgirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-world_religions": {
      "task": "ogx_mmlux_hu-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a vilgvallsokrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-abstract_algebra": {
      "task": "ogx_mmlux_it-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'algebra astratta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-anatomy": {
      "task": "ogx_mmlux_it-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'anatomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-astronomy": {
      "task": "ogx_mmlux_it-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'astronomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-business_ethics": {
      "task": "ogx_mmlux_it-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'etica aziendale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "task": "ogx_mmlux_it-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla conoscenza clinica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_biology": {
      "task": "ogx_mmlux_it-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla biologia universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_chemistry": {
      "task": "ogx_mmlux_it-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla chimica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_computer_science": {
      "task": "ogx_mmlux_it-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'informatica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_mathematics": {
      "task": "ogx_mmlux_it-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_medicine": {
      "task": "ogx_mmlux_it-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla medicina universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_physics": {
      "task": "ogx_mmlux_it-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-computer_security": {
      "task": "ogx_mmlux_it-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sicurezza informatica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-conceptual_physics": {
      "task": "ogx_mmlux_it-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica concettuale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-econometrics": {
      "task": "ogx_mmlux_it-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'econometria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-electrical_engineering": {
      "task": "ogx_mmlux_it-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'ingegneria elettrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "task": "ogx_mmlux_it-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica elementare.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-formal_logic": {
      "task": "ogx_mmlux_it-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla logica formale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-global_facts": {
      "task": "ogx_mmlux_it-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sui fatti globali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_biology": {
      "task": "ogx_mmlux_it-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla biologia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "task": "ogx_mmlux_it-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla chimica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "task": "ogx_mmlux_it-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'informatica per le scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_european_history": {
      "task": "ogx_mmlux_it-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia europea delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_geography": {
      "task": "ogx_mmlux_it-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla geografia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "task": "ogx_mmlux_it-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul governo e la politica nelle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "task": "ogx_mmlux_it-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla macroeconomia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "task": "ogx_mmlux_it-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "task": "ogx_mmlux_it-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla microeconomia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_physics": {
      "task": "ogx_mmlux_it-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_psychology": {
      "task": "ogx_mmlux_it-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla psicologia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_statistics": {
      "task": "ogx_mmlux_it-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla statistica della scuola superiore.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_us_history": {
      "task": "ogx_mmlux_it-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia degli Stati Uniti al liceo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_world_history": {
      "task": "ogx_mmlux_it-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia mondiale delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-human_aging": {
      "task": "ogx_mmlux_it-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'invecchiamento umano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-human_sexuality": {
      "task": "ogx_mmlux_it-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sessualit umana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-international_law": {
      "task": "ogx_mmlux_it-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul diritto internazionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-jurisprudence": {
      "task": "ogx_mmlux_it-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla giurisprudenza.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-logical_fallacies": {
      "task": "ogx_mmlux_it-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle fallacie logiche.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-machine_learning": {
      "task": "ogx_mmlux_it-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'apprendimento automatico.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-management": {
      "task": "ogx_mmlux_it-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla gestione.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-marketing": {
      "task": "ogx_mmlux_it-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-medical_genetics": {
      "task": "ogx_mmlux_it-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla genetica medica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-miscellaneous": {
      "task": "ogx_mmlux_it-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) su varie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-moral_disputes": {
      "task": "ogx_mmlux_it-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle controversie morali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-moral_scenarios": {
      "task": "ogx_mmlux_it-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) su scenari morali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-nutrition": {
      "task": "ogx_mmlux_it-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'alimentazione.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-philosophy": {
      "task": "ogx_mmlux_it-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla filosofia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-prehistory": {
      "task": "ogx_mmlux_it-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla preistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_accounting": {
      "task": "ogx_mmlux_it-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla contabilit professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_law": {
      "task": "ogx_mmlux_it-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul diritto professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_medicine": {
      "task": "ogx_mmlux_it-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla medicina professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_psychology": {
      "task": "ogx_mmlux_it-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla psicologia professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-public_relations": {
      "task": "ogx_mmlux_it-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle relazioni pubbliche.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-security_studies": {
      "task": "ogx_mmlux_it-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sugli studi sulla sicurezza.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-sociology": {
      "task": "ogx_mmlux_it-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sociologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "task": "ogx_mmlux_it-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla politica estera degli Stati Uniti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-virology": {
      "task": "ogx_mmlux_it-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla virologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-world_religions": {
      "task": "ogx_mmlux_it-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle religioni del mondo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "task": "ogx_mmlux_lt-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie abstrakij algebr.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-anatomy": {
      "task": "ogx_mmlux_lt-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie anatomij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-astronomy": {
      "task": "ogx_mmlux_lt-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie astronomij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-business_ethics": {
      "task": "ogx_mmlux_lt-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie verslo etik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "task": "ogx_mmlux_lt-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie klinikines inias.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_biology": {
      "task": "ogx_mmlux_lt-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos biologij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_chemistry": {
      "task": "ogx_mmlux_lt-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos chemij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_computer_science": {
      "task": "ogx_mmlux_lt-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos informatik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_mathematics": {
      "task": "ogx_mmlux_lt-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_medicine": {
      "task": "ogx_mmlux_lt-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie koledo medicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_physics": {
      "task": "ogx_mmlux_lt-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos fizik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-computer_security": {
      "task": "ogx_mmlux_lt-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kompiuteri saugum.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "task": "ogx_mmlux_lt-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie konceptualij fizik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-econometrics": {
      "task": "ogx_mmlux_lt-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie ekonometrij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "task": "ogx_mmlux_lt-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie elektrotechnik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "task": "ogx_mmlux_lt-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai su atsakymais apie elementarij matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-formal_logic": {
      "task": "ogx_mmlux_lt-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie formalij logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-global_facts": {
      "task": "ogx_mmlux_lt-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie visuotinius faktus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_biology": {
      "task": "ogx_mmlux_lt-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurins mokyklos biologij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "task": "ogx_mmlux_lt-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie chemij vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "task": "ogx_mmlux_lt-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie informatik vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "task": "ogx_mmlux_lt-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie Europos istorij vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_geography": {
      "task": "ogx_mmlux_lt-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie geografij vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "task": "ogx_mmlux_lt-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vyriausyb ir politik vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "task": "ogx_mmlux_lt-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie makroekonomik vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "task": "ogx_mmlux_lt-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurins mokyklos matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "task": "ogx_mmlux_lt-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mikroekonomik vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_physics": {
      "task": "ogx_mmlux_lt-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie fizik vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "task": "ogx_mmlux_lt-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie psichologij vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "task": "ogx_mmlux_lt-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurins mokyklos statistik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "task": "ogx_mmlux_lt-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie JAV vidurins mokyklos istorij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "task": "ogx_mmlux_lt-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie pasaulio istorij vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-human_aging": {
      "task": "ogx_mmlux_lt-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mogaus senjim.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-human_sexuality": {
      "task": "ogx_mmlux_lt-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mogaus lytikum.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-international_law": {
      "task": "ogx_mmlux_lt-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie tarptautin teis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-jurisprudence": {
      "task": "ogx_mmlux_lt-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie jurisprudencij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "task": "ogx_mmlux_lt-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie logines klaidas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-machine_learning": {
      "task": "ogx_mmlux_lt-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mainin mokymsi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-management": {
      "task": "ogx_mmlux_lt-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie valdym.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-marketing": {
      "task": "ogx_mmlux_lt-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie rinkodar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-medical_genetics": {
      "task": "ogx_mmlux_lt-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie medicinin genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-miscellaneous": {
      "task": "ogx_mmlux_lt-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vairius dalykus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-moral_disputes": {
      "task": "ogx_mmlux_lt-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie moralinius ginus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "task": "ogx_mmlux_lt-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie moralinius scenarijus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-nutrition": {
      "task": "ogx_mmlux_lt-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mityb.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-philosophy": {
      "task": "ogx_mmlux_lt-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie filosofij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-prehistory": {
      "task": "ogx_mmlux_lt-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie prieistor.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_accounting": {
      "task": "ogx_mmlux_lt-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesin apskait.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_law": {
      "task": "ogx_mmlux_lt-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesin teis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_medicine": {
      "task": "ogx_mmlux_lt-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesin medicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_psychology": {
      "task": "ogx_mmlux_lt-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesin psichologij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-public_relations": {
      "task": "ogx_mmlux_lt-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vieuosius ryius.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-security_studies": {
      "task": "ogx_mmlux_lt-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie saugumo studijas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-sociology": {
      "task": "ogx_mmlux_lt-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie sociologij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "task": "ogx_mmlux_lt-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie JAV usienio politik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-virology": {
      "task": "ogx_mmlux_lt-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie virusologij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-world_religions": {
      "task": "ogx_mmlux_lt-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie pasaulio religijas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "task": "ogx_mmlux_lv-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par abstrakto algebru.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-anatomy": {
      "task": "ogx_mmlux_lv-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem par anatomiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-astronomy": {
      "task": "ogx_mmlux_lv-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par astronomiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-business_ethics": {
      "task": "ogx_mmlux_lv-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par uzmjdarbbas tiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "task": "ogx_mmlux_lv-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par klniskajm zinanm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_biology": {
      "task": "ogx_mmlux_lv-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par koledas bioloiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_chemistry": {
      "task": "ogx_mmlux_lv-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par koledas miju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_computer_science": {
      "task": "ogx_mmlux_lv-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par datorzintnm koled.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_mathematics": {
      "task": "ogx_mmlux_lv-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par koledas matemtiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_medicine": {
      "task": "ogx_mmlux_lv-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par koledas medicnu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_physics": {
      "task": "ogx_mmlux_lv-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par koledas fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-computer_security": {
      "task": "ogx_mmlux_lv-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par datoru drobu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "task": "ogx_mmlux_lv-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par konceptulo fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-econometrics": {
      "task": "ogx_mmlux_lv-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par ekonometriju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "task": "ogx_mmlux_lv-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par elektrotehniku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "task": "ogx_mmlux_lv-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par elementro matemtiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-formal_logic": {
      "task": "ogx_mmlux_lv-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem par formlo loiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-global_facts": {
      "task": "ogx_mmlux_lv-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par pasaules faktiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_biology": {
      "task": "ogx_mmlux_lv-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas bioloiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "task": "ogx_mmlux_lv-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas miju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "task": "ogx_mmlux_lv-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas informtiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "task": "ogx_mmlux_lv-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas Eiropas vsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_geography": {
      "task": "ogx_mmlux_lv-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas eogrfiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "task": "ogx_mmlux_lv-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par valsts prvaldi un politiku vidusskol.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "task": "ogx_mmlux_lv-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par makroekonomiku vidusskol.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "task": "ogx_mmlux_lv-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas matemtiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "task": "ogx_mmlux_lv-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par mikroekonomiku vidusskol.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_physics": {
      "task": "ogx_mmlux_lv-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "task": "ogx_mmlux_lv-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas psiholoiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "task": "ogx_mmlux_lv-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas statistiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "task": "ogx_mmlux_lv-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par ASV vidusskolas vsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "task": "ogx_mmlux_lv-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par pasaules vsturi vidusskol.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-human_aging": {
      "task": "ogx_mmlux_lv-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par cilvka novecoanu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-human_sexuality": {
      "task": "ogx_mmlux_lv-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par cilvka seksualitti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-international_law": {
      "task": "ogx_mmlux_lv-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par starptautiskajm tiesbm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-jurisprudence": {
      "task": "ogx_mmlux_lv-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmk ir jautjumi ar atbilu variantiem (ar atbildm) par jurisprudenci.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "task": "ogx_mmlux_lv-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par loiskajm kdm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-machine_learning": {
      "task": "ogx_mmlux_lv-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par manmcanos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-management": {
      "task": "ogx_mmlux_lv-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmk ir jautjumi ar atbilu variantiem (ar atbildm) par vadbu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-marketing": {
      "task": "ogx_mmlux_lv-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par mrketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-medical_genetics": {
      "task": "ogx_mmlux_lv-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par medicnas entiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-miscellaneous": {
      "task": "ogx_mmlux_lv-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par dadiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-moral_disputes": {
      "task": "ogx_mmlux_lv-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par morles strdiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "task": "ogx_mmlux_lv-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par morles scenrijiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-nutrition": {
      "task": "ogx_mmlux_lv-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par uzturu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-philosophy": {
      "task": "ogx_mmlux_lv-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par filozofiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-prehistory": {
      "task": "ogx_mmlux_lv-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par aizvsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_accounting": {
      "task": "ogx_mmlux_lv-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par profesionlo grmatvedbu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_law": {
      "task": "ogx_mmlux_lv-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par profesionlajm tiesbm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_medicine": {
      "task": "ogx_mmlux_lv-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par profesionlo medicnu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_psychology": {
      "task": "ogx_mmlux_lv-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par profesionlo psiholoiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-public_relations": {
      "task": "ogx_mmlux_lv-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par sabiedriskajm attiecbm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-security_studies": {
      "task": "ogx_mmlux_lv-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par drobas studijm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-sociology": {
      "task": "ogx_mmlux_lv-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmk ir jautjumi ar atbilu variantiem par socioloiju (ar atbildm).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "task": "ogx_mmlux_lv-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem par ASV rpolitiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-virology": {
      "task": "ogx_mmlux_lv-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem par virusoloiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-world_religions": {
      "task": "ogx_mmlux_lv-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par pasaules reliijm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "task": "ogx_mmlux_nl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over abstracte algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-anatomy": {
      "task": "ogx_mmlux_nl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-astronomy": {
      "task": "ogx_mmlux_nl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-business_ethics": {
      "task": "ogx_mmlux_nl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over bedrijfsethiek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "task": "ogx_mmlux_nl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over klinische kennis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_biology": {
      "task": "ogx_mmlux_nl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over biologie op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_chemistry": {
      "task": "ogx_mmlux_nl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over scheikunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_computer_science": {
      "task": "ogx_mmlux_nl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over informatica op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_mathematics": {
      "task": "ogx_mmlux_nl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wiskunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_medicine": {
      "task": "ogx_mmlux_nl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over geneeskunde aan de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_physics": {
      "task": "ogx_mmlux_nl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over natuurkunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-computer_security": {
      "task": "ogx_mmlux_nl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over computerbeveiliging.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "task": "ogx_mmlux_nl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over conceptuele fysica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-econometrics": {
      "task": "ogx_mmlux_nl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over econometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "task": "ogx_mmlux_nl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over elektrotechniek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "task": "ogx_mmlux_nl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over elementaire wiskunde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-formal_logic": {
      "task": "ogx_mmlux_nl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over formele logica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-global_facts": {
      "task": "ogx_mmlux_nl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over globale feiten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_biology": {
      "task": "ogx_mmlux_nl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over biologie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "task": "ogx_mmlux_nl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over scheikunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "task": "ogx_mmlux_nl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over informatica op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "task": "ogx_mmlux_nl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over Europese geschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_geography": {
      "task": "ogx_mmlux_nl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over aardrijkskunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "task": "ogx_mmlux_nl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over bestuur en politiek op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "task": "ogx_mmlux_nl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over macro-economie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "task": "ogx_mmlux_nl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wiskunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "task": "ogx_mmlux_nl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over micro-economie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_physics": {
      "task": "ogx_mmlux_nl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over natuurkunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "task": "ogx_mmlux_nl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over psychologie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "task": "ogx_mmlux_nl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over statistiek op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "task": "ogx_mmlux_nl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over geschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "task": "ogx_mmlux_nl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wereldgeschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-human_aging": {
      "task": "ogx_mmlux_nl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over menselijke veroudering.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-human_sexuality": {
      "task": "ogx_mmlux_nl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over menselijke seksualiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-international_law": {
      "task": "ogx_mmlux_nl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over internationaal recht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-jurisprudence": {
      "task": "ogx_mmlux_nl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over jurisprudentie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "task": "ogx_mmlux_nl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over logische drogredenen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-machine_learning": {
      "task": "ogx_mmlux_nl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over machinaal leren.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-management": {
      "task": "ogx_mmlux_nl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-marketing": {
      "task": "ogx_mmlux_nl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-medical_genetics": {
      "task": "ogx_mmlux_nl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over medische genetica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-miscellaneous": {
      "task": "ogx_mmlux_nl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over diversen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-moral_disputes": {
      "task": "ogx_mmlux_nl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over morele geschillen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "task": "ogx_mmlux_nl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over morele scenario's.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-nutrition": {
      "task": "ogx_mmlux_nl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over voeding.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-philosophy": {
      "task": "ogx_mmlux_nl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over filosofie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-prehistory": {
      "task": "ogx_mmlux_nl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over de prehistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_accounting": {
      "task": "ogx_mmlux_nl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over professioneel boekhouden.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_law": {
      "task": "ogx_mmlux_nl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over het beroepsrecht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_medicine": {
      "task": "ogx_mmlux_nl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over professionele geneeskunde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_psychology": {
      "task": "ogx_mmlux_nl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over professionele psychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-public_relations": {
      "task": "ogx_mmlux_nl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-security_studies": {
      "task": "ogx_mmlux_nl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over veiligheidsstudies.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-sociology": {
      "task": "ogx_mmlux_nl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "task": "ogx_mmlux_nl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over het buitenlands beleid van de Verenigde Staten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-virology": {
      "task": "ogx_mmlux_nl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-world_religions": {
      "task": "ogx_mmlux_nl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wereldreligies.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "task": "ogx_mmlux_pl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce algebry abstrakcyjnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-anatomy": {
      "task": "ogx_mmlux_pl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce anatomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-astronomy": {
      "task": "ogx_mmlux_pl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce astronomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-business_ethics": {
      "task": "ogx_mmlux_pl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce etyki biznesu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "task": "ogx_mmlux_pl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce wiedzy klinicznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_biology": {
      "task": "ogx_mmlux_pl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce biologii na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_chemistry": {
      "task": "ogx_mmlux_pl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce chemii na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_computer_science": {
      "task": "ogx_mmlux_pl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce informatyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_mathematics": {
      "task": "ogx_mmlux_pl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce matematyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_medicine": {
      "task": "ogx_mmlux_pl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce medycyny uniwersyteckiej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_physics": {
      "task": "ogx_mmlux_pl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce fizyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-computer_security": {
      "task": "ogx_mmlux_pl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce bezpieczestwa komputerowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "task": "ogx_mmlux_pl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce fizyki konceptualnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-econometrics": {
      "task": "ogx_mmlux_pl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "task": "ogx_mmlux_pl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce inynierii elektrycznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "task": "ogx_mmlux_pl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce matematyki elementarnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-formal_logic": {
      "task": "ogx_mmlux_pl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce logiki formalnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-global_facts": {
      "task": "ogx_mmlux_pl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce globalnych faktw.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_biology": {
      "task": "ogx_mmlux_pl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce biologii w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "task": "ogx_mmlux_pl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce chemii w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "task": "ogx_mmlux_pl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce informatyki w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "task": "ogx_mmlux_pl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce historii Europy w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_geography": {
      "task": "ogx_mmlux_pl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce geografii w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "task": "ogx_mmlux_pl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce rzdw i polityki w szkoach rednich.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "task": "ogx_mmlux_pl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce makroekonomii w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "task": "ogx_mmlux_pl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce matematyki w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "task": "ogx_mmlux_pl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce mikroekonomii w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_physics": {
      "task": "ogx_mmlux_pl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce fizyki w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "task": "ogx_mmlux_pl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce psychologii w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "task": "ogx_mmlux_pl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce statystyki w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "task": "ogx_mmlux_pl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce historii Stanw Zjednoczonych w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "task": "ogx_mmlux_pl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce historii wiata w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-human_aging": {
      "task": "ogx_mmlux_pl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce starzenia si czowieka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-human_sexuality": {
      "task": "ogx_mmlux_pl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce ludzkiej seksualnoci.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-international_law": {
      "task": "ogx_mmlux_pl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce prawa midzynarodowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-jurisprudence": {
      "task": "ogx_mmlux_pl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce orzecznictwa.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "task": "ogx_mmlux_pl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce bdw logicznych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-machine_learning": {
      "task": "ogx_mmlux_pl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce uczenia maszynowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-management": {
      "task": "ogx_mmlux_pl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce zarzdzania.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-marketing": {
      "task": "ogx_mmlux_pl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-medical_genetics": {
      "task": "ogx_mmlux_pl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce genetyki medycznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-miscellaneous": {
      "task": "ogx_mmlux_pl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce rnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-moral_disputes": {
      "task": "ogx_mmlux_pl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce sporw moralnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "task": "ogx_mmlux_pl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce scenariuszy moralnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-nutrition": {
      "task": "ogx_mmlux_pl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce odywiania.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-philosophy": {
      "task": "ogx_mmlux_pl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-prehistory": {
      "task": "ogx_mmlux_pl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce prehistorii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_accounting": {
      "task": "ogx_mmlux_pl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce profesjonalnej ksigowoci.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_law": {
      "task": "ogx_mmlux_pl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce prawa zawodowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_medicine": {
      "task": "ogx_mmlux_pl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce medycyny profesjonalnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_psychology": {
      "task": "ogx_mmlux_pl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce psychologii zawodowej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-public_relations": {
      "task": "ogx_mmlux_pl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-security_studies": {
      "task": "ogx_mmlux_pl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce studiw nad bezpieczestwem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-sociology": {
      "task": "ogx_mmlux_pl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce socjologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "task": "ogx_mmlux_pl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce polityki zagranicznej Stanw Zjednoczonych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-virology": {
      "task": "ogx_mmlux_pl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce wirusologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-world_religions": {
      "task": "ogx_mmlux_pl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce religii wiata.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "task": "ogx_mmlux_pt-pt-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre lgebra abstrata.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "task": "ogx_mmlux_pt-pt-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre anatomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "task": "ogx_mmlux_pt-pt-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre astronomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "task": "ogx_mmlux_pt-pt-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre tica empresarial.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "task": "ogx_mmlux_pt-pt-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre conhecimentos clnicos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "task": "ogx_mmlux_pt-pt-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes so de escolha mltipla (com respostas) sobre biologia universitria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "task": "ogx_mmlux_pt-pt-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes so de escolha mltipla (com respostas) sobre qumica universitria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "task": "ogx_mmlux_pt-pt-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre informtica universitria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "task": "ogx_mmlux_pt-pt-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre matemtica universitria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "task": "ogx_mmlux_pt-pt-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre medicina universitria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "task": "ogx_mmlux_pt-pt-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes so de escolha mltipla (com respostas) sobre fsica universitria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "task": "ogx_mmlux_pt-pt-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre segurana informtica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "task": "ogx_mmlux_pt-pt-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre fsica concetual.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "task": "ogx_mmlux_pt-pt-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre econometria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "task": "ogx_mmlux_pt-pt-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre engenharia elctrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "task": "ogx_mmlux_pt-pt-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre matemtica elementar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "task": "ogx_mmlux_pt-pt-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre lgica formal.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "task": "ogx_mmlux_pt-pt-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre factos globais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "task": "ogx_mmlux_pt-pt-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre biologia do ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "task": "ogx_mmlux_pt-pt-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre qumica no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "task": "ogx_mmlux_pt-pt-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre informtica no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "task": "ogx_mmlux_pt-pt-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre histria europeia no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "task": "ogx_mmlux_pt-pt-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre geografia do ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "task": "ogx_mmlux_pt-pt-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre governo e poltica no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "task": "ogx_mmlux_pt-pt-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre macroeconomia no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "task": "ogx_mmlux_pt-pt-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre matemtica do ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "task": "ogx_mmlux_pt-pt-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre microeconomia no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "task": "ogx_mmlux_pt-pt-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre fsica do ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "task": "ogx_mmlux_pt-pt-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre psicologia no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "task": "ogx_mmlux_pt-pt-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre estatstica no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "task": "ogx_mmlux_pt-pt-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre Histria dos EUA no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "task": "ogx_mmlux_pt-pt-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre histria mundial no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "task": "ogx_mmlux_pt-pt-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre o envelhecimento humano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "task": "ogx_mmlux_pt-pt-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre a sexualidade humana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-international_law": {
      "task": "ogx_mmlux_pt-pt-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre direito internacional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "task": "ogx_mmlux_pt-pt-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre jurisprudncia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "task": "ogx_mmlux_pt-pt-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre falcias lgicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "task": "ogx_mmlux_pt-pt-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre aprendizagem automtica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-management": {
      "task": "ogx_mmlux_pt-pt-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre gesto.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-marketing": {
      "task": "ogx_mmlux_pt-pt-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "task": "ogx_mmlux_pt-pt-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre gentica mdica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "task": "ogx_mmlux_pt-pt-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre miscelnea.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "task": "ogx_mmlux_pt-pt-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre disputas morais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "task": "ogx_mmlux_pt-pt-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre cenrios morais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "task": "ogx_mmlux_pt-pt-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre nutrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "task": "ogx_mmlux_pt-pt-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre filosofia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "task": "ogx_mmlux_pt-pt-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre a pr-histria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "task": "ogx_mmlux_pt-pt-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre contabilidade profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "task": "ogx_mmlux_pt-pt-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre direito profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "task": "ogx_mmlux_pt-pt-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre medicina profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "task": "ogx_mmlux_pt-pt-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre psicologia profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "task": "ogx_mmlux_pt-pt-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre relaes pblicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "task": "ogx_mmlux_pt-pt-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre estudos de segurana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-sociology": {
      "task": "ogx_mmlux_pt-pt-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre sociologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "task": "ogx_mmlux_pt-pt-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes so de escolha mltipla (com respostas) sobre a poltica externa dos EUA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-virology": {
      "task": "ogx_mmlux_pt-pt-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre virologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "task": "ogx_mmlux_pt-pt-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre as religies do mundo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "task": "ogx_mmlux_ro-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre algebra abstract.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-anatomy": {
      "task": "ogx_mmlux_ro-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-astronomy": {
      "task": "ogx_mmlux_ro-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu rspunsuri multiple (cu rspunsuri) despre astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-business_ethics": {
      "task": "ogx_mmlux_ro-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre etica n afaceri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "task": "ogx_mmlux_ro-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre cunotinele clinice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_biology": {
      "task": "ogx_mmlux_ro-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre biologia universitar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_chemistry": {
      "task": "ogx_mmlux_ro-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre chimia universitar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_computer_science": {
      "task": "ogx_mmlux_ro-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre informatic universitar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_mathematics": {
      "task": "ogx_mmlux_ro-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre matematica universitar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_medicine": {
      "task": "ogx_mmlux_ro-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre medicina universitar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_physics": {
      "task": "ogx_mmlux_ro-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre fizica universitar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-computer_security": {
      "task": "ogx_mmlux_ro-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre securitatea calculatoarelor.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "task": "ogx_mmlux_ro-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre fizica conceptual.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-econometrics": {
      "task": "ogx_mmlux_ro-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre econometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "task": "ogx_mmlux_ro-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre inginerie electric.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "task": "ogx_mmlux_ro-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre matematic elementar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-formal_logic": {
      "task": "ogx_mmlux_ro-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre logica formal.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-global_facts": {
      "task": "ogx_mmlux_ro-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre fapte globale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_biology": {
      "task": "ogx_mmlux_ro-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre biologia de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "task": "ogx_mmlux_ro-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre chimia de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "task": "ogx_mmlux_ro-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre informatic la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "task": "ogx_mmlux_ro-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre istoria european la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_geography": {
      "task": "ogx_mmlux_ro-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre geografia liceului.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "task": "ogx_mmlux_ro-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre guvernare i politic n liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "task": "ogx_mmlux_ro-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre macroeconomie la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "task": "ogx_mmlux_ro-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre matematica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "task": "ogx_mmlux_ro-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre microeconomie la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_physics": {
      "task": "ogx_mmlux_ro-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre fizica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "task": "ogx_mmlux_ro-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre psihologia liceului.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "task": "ogx_mmlux_ro-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre statistica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "task": "ogx_mmlux_ro-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre istoria noastr la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "task": "ogx_mmlux_ro-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre istoria universal de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-human_aging": {
      "task": "ogx_mmlux_ro-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre mbtrnirea uman.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-human_sexuality": {
      "task": "ogx_mmlux_ro-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre sexualitatea uman.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-international_law": {
      "task": "ogx_mmlux_ro-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre dreptul internaional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-jurisprudence": {
      "task": "ogx_mmlux_ro-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre jurispruden.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "task": "ogx_mmlux_ro-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre erori logice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-machine_learning": {
      "task": "ogx_mmlux_ro-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre nvarea automat.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-management": {
      "task": "ogx_mmlux_ro-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-marketing": {
      "task": "ogx_mmlux_ro-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-medical_genetics": {
      "task": "ogx_mmlux_ro-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre genetica medical.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-miscellaneous": {
      "task": "ogx_mmlux_ro-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-moral_disputes": {
      "task": "ogx_mmlux_ro-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre disputele morale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "task": "ogx_mmlux_ro-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre scenarii morale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-nutrition": {
      "task": "ogx_mmlux_ro-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre nutriie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-philosophy": {
      "task": "ogx_mmlux_ro-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre filosofie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-prehistory": {
      "task": "ogx_mmlux_ro-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre preistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_accounting": {
      "task": "ogx_mmlux_ro-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre contabilitatea profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_law": {
      "task": "ogx_mmlux_ro-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre dreptul profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_medicine": {
      "task": "ogx_mmlux_ro-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre medicina profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_psychology": {
      "task": "ogx_mmlux_ro-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre psihologia profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-public_relations": {
      "task": "ogx_mmlux_ro-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre relaiile publice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-security_studies": {
      "task": "ogx_mmlux_ro-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre studiile de securitate.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-sociology": {
      "task": "ogx_mmlux_ro-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "task": "ogx_mmlux_ro-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre politica extern a SUA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-virology": {
      "task": "ogx_mmlux_ro-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre virusologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-world_religions": {
      "task": "ogx_mmlux_ro-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre religiile lumii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "task": "ogx_mmlux_sk-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o abstraktnej algebre.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-anatomy": {
      "task": "ogx_mmlux_sk-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o anatmii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-astronomy": {
      "task": "ogx_mmlux_sk-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o astronmii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-business_ethics": {
      "task": "ogx_mmlux_sk-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o etike v podnikan.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "task": "ogx_mmlux_sk-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o klinickch znalostiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_biology": {
      "task": "ogx_mmlux_sk-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o vysokokolskej biolgii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_chemistry": {
      "task": "ogx_mmlux_sk-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o vysokokolskej chmii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_computer_science": {
      "task": "ogx_mmlux_sk-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o informatike na vysokej kole.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_mathematics": {
      "task": "ogx_mmlux_sk-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o vysokokolskej matematike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_medicine": {
      "task": "ogx_mmlux_sk-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o vysokokolskej medicne.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_physics": {
      "task": "ogx_mmlux_sk-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o vysokokolskej fyzike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-computer_security": {
      "task": "ogx_mmlux_sk-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o potaovej bezpenosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "task": "ogx_mmlux_sk-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o konceptulnej fyzike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-econometrics": {
      "task": "ogx_mmlux_sk-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "task": "ogx_mmlux_sk-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o elektrotechnike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "task": "ogx_mmlux_sk-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o elementrnej matematike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-formal_logic": {
      "task": "ogx_mmlux_sk-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o formlnej logike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-global_facts": {
      "task": "ogx_mmlux_sk-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o globlnych faktoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_biology": {
      "task": "ogx_mmlux_sk-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o stredokolskej biolgii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "task": "ogx_mmlux_sk-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o stredokolskej chmii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "task": "ogx_mmlux_sk-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o stredokolskej informatike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "task": "ogx_mmlux_sk-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o stredokolskch eurpskych dejinch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_geography": {
      "task": "ogx_mmlux_sk-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o stredokolskom zemepise.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "task": "ogx_mmlux_sk-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky (s odpoveami) sa tkaj vldy a politiky na strednch kolch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "task": "ogx_mmlux_sk-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o stredokolskej makroekonmii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "task": "ogx_mmlux_sk-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky (s odpoveami) sa tkaj stredokolskej matematiky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "task": "ogx_mmlux_sk-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) z mikroekonmie pre stredn koly.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_physics": {
      "task": "ogx_mmlux_sk-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) zo stredokolskej fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "task": "ogx_mmlux_sk-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o stredokolskej psycholgii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "task": "ogx_mmlux_sk-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky (s odpoveami) sa tkaj stredokolskej tatistiky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "task": "ogx_mmlux_sk-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o stredokolskej histrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "task": "ogx_mmlux_sk-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) zo svetovch dejn na strednej kole.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-human_aging": {
      "task": "ogx_mmlux_sk-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o starnut loveka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-human_sexuality": {
      "task": "ogx_mmlux_sk-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o udskej sexualite.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-international_law": {
      "task": "ogx_mmlux_sk-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o medzinrodnom prve.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-jurisprudence": {
      "task": "ogx_mmlux_sk-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky (s odpoveami) sa tkaj prvnej vedy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "task": "ogx_mmlux_sk-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o logickch klamoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-machine_learning": {
      "task": "ogx_mmlux_sk-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o strojovom uen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-management": {
      "task": "ogx_mmlux_sk-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o manamente.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-marketing": {
      "task": "ogx_mmlux_sk-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-medical_genetics": {
      "task": "ogx_mmlux_sk-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o lekrskej genetike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-miscellaneous": {
      "task": "ogx_mmlux_sk-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky s vberom odpovede sa tkaj rzneho.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-moral_disputes": {
      "task": "ogx_mmlux_sk-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o morlnych sporoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "task": "ogx_mmlux_sk-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o morlnych scenroch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-nutrition": {
      "task": "ogx_mmlux_sk-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o vive.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-philosophy": {
      "task": "ogx_mmlux_sk-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-prehistory": {
      "task": "ogx_mmlux_sk-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o prehistrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_accounting": {
      "task": "ogx_mmlux_sk-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o odbornom tovnctve.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_law": {
      "task": "ogx_mmlux_sk-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky (s odpoveami) sa tkaj profesijnho prva.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_medicine": {
      "task": "ogx_mmlux_sk-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky (s odpoveami) sa tkaj profesionlnej medicny.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_psychology": {
      "task": "ogx_mmlux_sk-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o profesionlnej psycholgii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-public_relations": {
      "task": "ogx_mmlux_sk-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o vzahoch s verejnosou.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-security_studies": {
      "task": "ogx_mmlux_sk-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o bezpenostnch tdich.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-sociology": {
      "task": "ogx_mmlux_sk-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o sociolgii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "task": "ogx_mmlux_sk-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky s vberom odpovede sa tkaj zahraninej politiky USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-virology": {
      "task": "ogx_mmlux_sk-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o virolgii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-world_religions": {
      "task": "ogx_mmlux_sk-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o svetovch nboenstvch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "task": "ogx_mmlux_sl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o abstraktni algebri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-anatomy": {
      "task": "ogx_mmlux_sl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o anatomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-astronomy": {
      "task": "ogx_mmlux_sl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o astronomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-business_ethics": {
      "task": "ogx_mmlux_sl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o poslovni etiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "task": "ogx_mmlux_sl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o klininem znanju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_biology": {
      "task": "ogx_mmlux_sl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o biologiji na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_chemistry": {
      "task": "ogx_mmlux_sl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o kemiji na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_computer_science": {
      "task": "ogx_mmlux_sl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o raunalnitvu na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_mathematics": {
      "task": "ogx_mmlux_sl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o matematiki na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_medicine": {
      "task": "ogx_mmlux_sl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o univerzitetni medicini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_physics": {
      "task": "ogx_mmlux_sl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o fiziki na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-computer_security": {
      "task": "ogx_mmlux_sl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o raunalniki varnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "task": "ogx_mmlux_sl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o konceptualni fiziki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-econometrics": {
      "task": "ogx_mmlux_sl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o ekonometriji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "task": "ogx_mmlux_sl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o elektrotehniki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "task": "ogx_mmlux_sl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o osnovni matematiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-formal_logic": {
      "task": "ogx_mmlux_sl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o formalni logiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-global_facts": {
      "task": "ogx_mmlux_sl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o globalnih dejstvih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_biology": {
      "task": "ogx_mmlux_sl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o srednjeolski biologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "task": "ogx_mmlux_sl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o kemiji v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "task": "ogx_mmlux_sl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o raunalnitvu v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "task": "ogx_mmlux_sl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o evropski zgodovini v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_geography": {
      "task": "ogx_mmlux_sl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o geografiji v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "task": "ogx_mmlux_sl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o vladi in politiki v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "task": "ogx_mmlux_sl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o srednjeolski makroekonomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "task": "ogx_mmlux_sl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o matematiki v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "task": "ogx_mmlux_sl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o srednjeolski mikroekonomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_physics": {
      "task": "ogx_mmlux_sl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) s podroja srednjeolske fizike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "task": "ogx_mmlux_sl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o srednjeolski psihologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "task": "ogx_mmlux_sl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o srednjeolski statistiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "task": "ogx_mmlux_sl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o srednjeolski zgodovini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "task": "ogx_mmlux_sl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o svetovni zgodovini v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-human_aging": {
      "task": "ogx_mmlux_sl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o staranju loveka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-human_sexuality": {
      "task": "ogx_mmlux_sl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o loveki spolnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-international_law": {
      "task": "ogx_mmlux_sl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o mednarodnem pravu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-jurisprudence": {
      "task": "ogx_mmlux_sl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o sodni praksi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "task": "ogx_mmlux_sl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o loginih zmotah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-machine_learning": {
      "task": "ogx_mmlux_sl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o strojnem uenju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-management": {
      "task": "ogx_mmlux_sl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o upravljanju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-marketing": {
      "task": "ogx_mmlux_sl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o trenju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-medical_genetics": {
      "task": "ogx_mmlux_sl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o medicinski genetiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-miscellaneous": {
      "task": "ogx_mmlux_sl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o raznih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-moral_disputes": {
      "task": "ogx_mmlux_sl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o moralnih sporih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "task": "ogx_mmlux_sl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o moralnih scenarijih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-nutrition": {
      "task": "ogx_mmlux_sl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o prehrani.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-philosophy": {
      "task": "ogx_mmlux_sl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o filozofiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-prehistory": {
      "task": "ogx_mmlux_sl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o prazgodovini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_accounting": {
      "task": "ogx_mmlux_sl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o strokovnem raunovodstvu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_law": {
      "task": "ogx_mmlux_sl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o poklicnem pravu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_medicine": {
      "task": "ogx_mmlux_sl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o poklicni medicini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_psychology": {
      "task": "ogx_mmlux_sl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o poklicni psihologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-public_relations": {
      "task": "ogx_mmlux_sl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o odnosih z javnostmi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-security_studies": {
      "task": "ogx_mmlux_sl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o varnostnih tudijah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-sociology": {
      "task": "ogx_mmlux_sl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o sociologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "task": "ogx_mmlux_sl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o zunanji politiki ZDA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-virology": {
      "task": "ogx_mmlux_sl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o virologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-world_religions": {
      "task": "ogx_mmlux_sl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o svetovnih religijah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "task": "ogx_mmlux_sv-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om abstrakt algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-anatomy": {
      "task": "ogx_mmlux_sv-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om anatomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-astronomy": {
      "task": "ogx_mmlux_sv-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om astronomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-business_ethics": {
      "task": "ogx_mmlux_sv-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om affrsetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "task": "ogx_mmlux_sv-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om klinisk kunskap.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_biology": {
      "task": "ogx_mmlux_sv-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om biologi p hgskoleniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_chemistry": {
      "task": "ogx_mmlux_sv-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om kemi p hgskoleniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_computer_science": {
      "task": "ogx_mmlux_sv-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om datavetenskap p hgskoleniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_mathematics": {
      "task": "ogx_mmlux_sv-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om matematik p hgskoleniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_medicine": {
      "task": "ogx_mmlux_sv-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om universitetsmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_physics": {
      "task": "ogx_mmlux_sv-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om hgskolefysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-computer_security": {
      "task": "ogx_mmlux_sv-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om dataskerhet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "task": "ogx_mmlux_sv-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om konceptuell fysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-econometrics": {
      "task": "ogx_mmlux_sv-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om ekonometri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "task": "ogx_mmlux_sv-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om elektroteknik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "task": "ogx_mmlux_sv-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om elementr matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-formal_logic": {
      "task": "ogx_mmlux_sv-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om formell logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-global_facts": {
      "task": "ogx_mmlux_sv-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om globala fakta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_biology": {
      "task": "ogx_mmlux_sv-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om biologi p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "task": "ogx_mmlux_sv-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om kemi p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "task": "ogx_mmlux_sv-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om datavetenskap p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "task": "ogx_mmlux_sv-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om europeisk historia p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_geography": {
      "task": "ogx_mmlux_sv-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om geografi p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "task": "ogx_mmlux_sv-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om regering och politik p gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "task": "ogx_mmlux_sv-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om makroekonomi p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "task": "ogx_mmlux_sv-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om matematik p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "task": "ogx_mmlux_sv-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om mikroekonomi p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_physics": {
      "task": "ogx_mmlux_sv-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om fysik p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "task": "ogx_mmlux_sv-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om psykologi p gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "task": "ogx_mmlux_sv-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om statistik p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "task": "ogx_mmlux_sv-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om historia i USA p gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "task": "ogx_mmlux_sv-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om vrldshistoria p gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-human_aging": {
      "task": "ogx_mmlux_sv-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om mnniskans ldrande.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-human_sexuality": {
      "task": "ogx_mmlux_sv-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om mnsklig sexualitet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-international_law": {
      "task": "ogx_mmlux_sv-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om internationell rtt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-jurisprudence": {
      "task": "ogx_mmlux_sv-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om rttsvetenskap.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "task": "ogx_mmlux_sv-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om logiska felslut.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-machine_learning": {
      "task": "ogx_mmlux_sv-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om maskininlrning.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-management": {
      "task": "ogx_mmlux_sv-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-marketing": {
      "task": "ogx_mmlux_sv-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om marknadsfring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-medical_genetics": {
      "task": "ogx_mmlux_sv-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om medicinsk genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-miscellaneous": {
      "task": "ogx_mmlux_sv-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-moral_disputes": {
      "task": "ogx_mmlux_sv-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om moraliska tvister.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "task": "ogx_mmlux_sv-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om moraliska scenarier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-nutrition": {
      "task": "ogx_mmlux_sv-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om nringslra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-philosophy": {
      "task": "ogx_mmlux_sv-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om filosofi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-prehistory": {
      "task": "ogx_mmlux_sv-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om frhistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_accounting": {
      "task": "ogx_mmlux_sv-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om professionell redovisning.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_law": {
      "task": "ogx_mmlux_sv-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om yrkesrtt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_medicine": {
      "task": "ogx_mmlux_sv-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om yrkesmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_psychology": {
      "task": "ogx_mmlux_sv-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om professionell psykologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-public_relations": {
      "task": "ogx_mmlux_sv-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-security_studies": {
      "task": "ogx_mmlux_sv-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om skerhetsstudier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-sociology": {
      "task": "ogx_mmlux_sv-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om sociologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "task": "ogx_mmlux_sv-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om USA:s utrikespolitik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-virology": {
      "task": "ogx_mmlux_sv-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om virologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-world_religions": {
      "task": "ogx_mmlux_sv-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om vrldsreligioner.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    }
  },
  "versions": {
    "ogx_mmlux_bg-abstract_algebra": 0,
    "ogx_mmlux_bg-anatomy": 0,
    "ogx_mmlux_bg-astronomy": 0,
    "ogx_mmlux_bg-business_ethics": 0,
    "ogx_mmlux_bg-clinical_knowledge": 0,
    "ogx_mmlux_bg-college_biology": 0,
    "ogx_mmlux_bg-college_chemistry": 0,
    "ogx_mmlux_bg-college_computer_science": 0,
    "ogx_mmlux_bg-college_mathematics": 0,
    "ogx_mmlux_bg-college_medicine": 0,
    "ogx_mmlux_bg-college_physics": 0,
    "ogx_mmlux_bg-computer_security": 0,
    "ogx_mmlux_bg-conceptual_physics": 0,
    "ogx_mmlux_bg-econometrics": 0,
    "ogx_mmlux_bg-electrical_engineering": 0,
    "ogx_mmlux_bg-elementary_mathematics": 0,
    "ogx_mmlux_bg-formal_logic": 0,
    "ogx_mmlux_bg-global_facts": 0,
    "ogx_mmlux_bg-high_school_biology": 0,
    "ogx_mmlux_bg-high_school_chemistry": 0,
    "ogx_mmlux_bg-high_school_computer_science": 0,
    "ogx_mmlux_bg-high_school_european_history": 0,
    "ogx_mmlux_bg-high_school_geography": 0,
    "ogx_mmlux_bg-high_school_government_and_politics": 0,
    "ogx_mmlux_bg-high_school_macroeconomics": 0,
    "ogx_mmlux_bg-high_school_mathematics": 0,
    "ogx_mmlux_bg-high_school_microeconomics": 0,
    "ogx_mmlux_bg-high_school_physics": 0,
    "ogx_mmlux_bg-high_school_psychology": 0,
    "ogx_mmlux_bg-high_school_statistics": 0,
    "ogx_mmlux_bg-high_school_us_history": 0,
    "ogx_mmlux_bg-high_school_world_history": 0,
    "ogx_mmlux_bg-human_aging": 0,
    "ogx_mmlux_bg-human_sexuality": 0,
    "ogx_mmlux_bg-international_law": 0,
    "ogx_mmlux_bg-jurisprudence": 0,
    "ogx_mmlux_bg-logical_fallacies": 0,
    "ogx_mmlux_bg-machine_learning": 0,
    "ogx_mmlux_bg-management": 0,
    "ogx_mmlux_bg-marketing": 0,
    "ogx_mmlux_bg-medical_genetics": 0,
    "ogx_mmlux_bg-miscellaneous": 0,
    "ogx_mmlux_bg-moral_disputes": 0,
    "ogx_mmlux_bg-moral_scenarios": 0,
    "ogx_mmlux_bg-nutrition": 0,
    "ogx_mmlux_bg-philosophy": 0,
    "ogx_mmlux_bg-prehistory": 0,
    "ogx_mmlux_bg-professional_accounting": 0,
    "ogx_mmlux_bg-professional_law": 0,
    "ogx_mmlux_bg-professional_medicine": 0,
    "ogx_mmlux_bg-professional_psychology": 0,
    "ogx_mmlux_bg-public_relations": 0,
    "ogx_mmlux_bg-security_studies": 0,
    "ogx_mmlux_bg-sociology": 0,
    "ogx_mmlux_bg-us_foreign_policy": 0,
    "ogx_mmlux_bg-virology": 0,
    "ogx_mmlux_bg-world_religions": 0,
    "ogx_mmlux_cs-abstract_algebra": 0,
    "ogx_mmlux_cs-anatomy": 0,
    "ogx_mmlux_cs-astronomy": 0,
    "ogx_mmlux_cs-business_ethics": 0,
    "ogx_mmlux_cs-clinical_knowledge": 0,
    "ogx_mmlux_cs-college_biology": 0,
    "ogx_mmlux_cs-college_chemistry": 0,
    "ogx_mmlux_cs-college_computer_science": 0,
    "ogx_mmlux_cs-college_mathematics": 0,
    "ogx_mmlux_cs-college_medicine": 0,
    "ogx_mmlux_cs-college_physics": 0,
    "ogx_mmlux_cs-computer_security": 0,
    "ogx_mmlux_cs-conceptual_physics": 0,
    "ogx_mmlux_cs-econometrics": 0,
    "ogx_mmlux_cs-electrical_engineering": 0,
    "ogx_mmlux_cs-elementary_mathematics": 0,
    "ogx_mmlux_cs-formal_logic": 0,
    "ogx_mmlux_cs-global_facts": 0,
    "ogx_mmlux_cs-high_school_biology": 0,
    "ogx_mmlux_cs-high_school_chemistry": 0,
    "ogx_mmlux_cs-high_school_computer_science": 0,
    "ogx_mmlux_cs-high_school_european_history": 0,
    "ogx_mmlux_cs-high_school_geography": 0,
    "ogx_mmlux_cs-high_school_government_and_politics": 0,
    "ogx_mmlux_cs-high_school_macroeconomics": 0,
    "ogx_mmlux_cs-high_school_mathematics": 0,
    "ogx_mmlux_cs-high_school_microeconomics": 0,
    "ogx_mmlux_cs-high_school_physics": 0,
    "ogx_mmlux_cs-high_school_psychology": 0,
    "ogx_mmlux_cs-high_school_statistics": 0,
    "ogx_mmlux_cs-high_school_us_history": 0,
    "ogx_mmlux_cs-high_school_world_history": 0,
    "ogx_mmlux_cs-human_aging": 0,
    "ogx_mmlux_cs-human_sexuality": 0,
    "ogx_mmlux_cs-international_law": 0,
    "ogx_mmlux_cs-jurisprudence": 0,
    "ogx_mmlux_cs-logical_fallacies": 0,
    "ogx_mmlux_cs-machine_learning": 0,
    "ogx_mmlux_cs-management": 0,
    "ogx_mmlux_cs-marketing": 0,
    "ogx_mmlux_cs-medical_genetics": 0,
    "ogx_mmlux_cs-miscellaneous": 0,
    "ogx_mmlux_cs-moral_disputes": 0,
    "ogx_mmlux_cs-moral_scenarios": 0,
    "ogx_mmlux_cs-nutrition": 0,
    "ogx_mmlux_cs-philosophy": 0,
    "ogx_mmlux_cs-prehistory": 0,
    "ogx_mmlux_cs-professional_accounting": 0,
    "ogx_mmlux_cs-professional_law": 0,
    "ogx_mmlux_cs-professional_medicine": 0,
    "ogx_mmlux_cs-professional_psychology": 0,
    "ogx_mmlux_cs-public_relations": 0,
    "ogx_mmlux_cs-security_studies": 0,
    "ogx_mmlux_cs-sociology": 0,
    "ogx_mmlux_cs-us_foreign_policy": 0,
    "ogx_mmlux_cs-virology": 0,
    "ogx_mmlux_cs-world_religions": 0,
    "ogx_mmlux_da-abstract_algebra": 0,
    "ogx_mmlux_da-anatomy": 0,
    "ogx_mmlux_da-astronomy": 0,
    "ogx_mmlux_da-business_ethics": 0,
    "ogx_mmlux_da-clinical_knowledge": 0,
    "ogx_mmlux_da-college_biology": 0,
    "ogx_mmlux_da-college_chemistry": 0,
    "ogx_mmlux_da-college_computer_science": 0,
    "ogx_mmlux_da-college_mathematics": 0,
    "ogx_mmlux_da-college_medicine": 0,
    "ogx_mmlux_da-college_physics": 0,
    "ogx_mmlux_da-computer_security": 0,
    "ogx_mmlux_da-conceptual_physics": 0,
    "ogx_mmlux_da-econometrics": 0,
    "ogx_mmlux_da-electrical_engineering": 0,
    "ogx_mmlux_da-elementary_mathematics": 0,
    "ogx_mmlux_da-formal_logic": 0,
    "ogx_mmlux_da-global_facts": 0,
    "ogx_mmlux_da-high_school_biology": 0,
    "ogx_mmlux_da-high_school_chemistry": 0,
    "ogx_mmlux_da-high_school_computer_science": 0,
    "ogx_mmlux_da-high_school_european_history": 0,
    "ogx_mmlux_da-high_school_geography": 0,
    "ogx_mmlux_da-high_school_government_and_politics": 0,
    "ogx_mmlux_da-high_school_macroeconomics": 0,
    "ogx_mmlux_da-high_school_mathematics": 0,
    "ogx_mmlux_da-high_school_microeconomics": 0,
    "ogx_mmlux_da-high_school_physics": 0,
    "ogx_mmlux_da-high_school_psychology": 0,
    "ogx_mmlux_da-high_school_statistics": 0,
    "ogx_mmlux_da-high_school_us_history": 0,
    "ogx_mmlux_da-high_school_world_history": 0,
    "ogx_mmlux_da-human_aging": 0,
    "ogx_mmlux_da-human_sexuality": 0,
    "ogx_mmlux_da-international_law": 0,
    "ogx_mmlux_da-jurisprudence": 0,
    "ogx_mmlux_da-logical_fallacies": 0,
    "ogx_mmlux_da-machine_learning": 0,
    "ogx_mmlux_da-management": 0,
    "ogx_mmlux_da-marketing": 0,
    "ogx_mmlux_da-medical_genetics": 0,
    "ogx_mmlux_da-miscellaneous": 0,
    "ogx_mmlux_da-moral_disputes": 0,
    "ogx_mmlux_da-moral_scenarios": 0,
    "ogx_mmlux_da-nutrition": 0,
    "ogx_mmlux_da-philosophy": 0,
    "ogx_mmlux_da-prehistory": 0,
    "ogx_mmlux_da-professional_accounting": 0,
    "ogx_mmlux_da-professional_law": 0,
    "ogx_mmlux_da-professional_medicine": 0,
    "ogx_mmlux_da-professional_psychology": 0,
    "ogx_mmlux_da-public_relations": 0,
    "ogx_mmlux_da-security_studies": 0,
    "ogx_mmlux_da-sociology": 0,
    "ogx_mmlux_da-us_foreign_policy": 0,
    "ogx_mmlux_da-virology": 0,
    "ogx_mmlux_da-world_religions": 0,
    "ogx_mmlux_de-abstract_algebra": 0,
    "ogx_mmlux_de-anatomy": 0,
    "ogx_mmlux_de-astronomy": 0,
    "ogx_mmlux_de-business_ethics": 0,
    "ogx_mmlux_de-clinical_knowledge": 0,
    "ogx_mmlux_de-college_biology": 0,
    "ogx_mmlux_de-college_chemistry": 0,
    "ogx_mmlux_de-college_computer_science": 0,
    "ogx_mmlux_de-college_mathematics": 0,
    "ogx_mmlux_de-college_medicine": 0,
    "ogx_mmlux_de-college_physics": 0,
    "ogx_mmlux_de-computer_security": 0,
    "ogx_mmlux_de-conceptual_physics": 0,
    "ogx_mmlux_de-econometrics": 0,
    "ogx_mmlux_de-electrical_engineering": 0,
    "ogx_mmlux_de-elementary_mathematics": 0,
    "ogx_mmlux_de-formal_logic": 0,
    "ogx_mmlux_de-global_facts": 0,
    "ogx_mmlux_de-high_school_biology": 0,
    "ogx_mmlux_de-high_school_chemistry": 0,
    "ogx_mmlux_de-high_school_computer_science": 0,
    "ogx_mmlux_de-high_school_european_history": 0,
    "ogx_mmlux_de-high_school_geography": 0,
    "ogx_mmlux_de-high_school_government_and_politics": 0,
    "ogx_mmlux_de-high_school_macroeconomics": 0,
    "ogx_mmlux_de-high_school_mathematics": 0,
    "ogx_mmlux_de-high_school_microeconomics": 0,
    "ogx_mmlux_de-high_school_physics": 0,
    "ogx_mmlux_de-high_school_psychology": 0,
    "ogx_mmlux_de-high_school_statistics": 0,
    "ogx_mmlux_de-high_school_us_history": 0,
    "ogx_mmlux_de-high_school_world_history": 0,
    "ogx_mmlux_de-human_aging": 0,
    "ogx_mmlux_de-human_sexuality": 0,
    "ogx_mmlux_de-international_law": 0,
    "ogx_mmlux_de-jurisprudence": 0,
    "ogx_mmlux_de-logical_fallacies": 0,
    "ogx_mmlux_de-machine_learning": 0,
    "ogx_mmlux_de-management": 0,
    "ogx_mmlux_de-marketing": 0,
    "ogx_mmlux_de-medical_genetics": 0,
    "ogx_mmlux_de-miscellaneous": 0,
    "ogx_mmlux_de-moral_disputes": 0,
    "ogx_mmlux_de-moral_scenarios": 0,
    "ogx_mmlux_de-nutrition": 0,
    "ogx_mmlux_de-philosophy": 0,
    "ogx_mmlux_de-prehistory": 0,
    "ogx_mmlux_de-professional_accounting": 0,
    "ogx_mmlux_de-professional_law": 0,
    "ogx_mmlux_de-professional_medicine": 0,
    "ogx_mmlux_de-professional_psychology": 0,
    "ogx_mmlux_de-public_relations": 0,
    "ogx_mmlux_de-security_studies": 0,
    "ogx_mmlux_de-sociology": 0,
    "ogx_mmlux_de-us_foreign_policy": 0,
    "ogx_mmlux_de-virology": 0,
    "ogx_mmlux_de-world_religions": 0,
    "ogx_mmlux_el-abstract_algebra": 0,
    "ogx_mmlux_el-anatomy": 0,
    "ogx_mmlux_el-astronomy": 0,
    "ogx_mmlux_el-business_ethics": 0,
    "ogx_mmlux_el-clinical_knowledge": 0,
    "ogx_mmlux_el-college_biology": 0,
    "ogx_mmlux_el-college_chemistry": 0,
    "ogx_mmlux_el-college_computer_science": 0,
    "ogx_mmlux_el-college_mathematics": 0,
    "ogx_mmlux_el-college_medicine": 0,
    "ogx_mmlux_el-college_physics": 0,
    "ogx_mmlux_el-computer_security": 0,
    "ogx_mmlux_el-conceptual_physics": 0,
    "ogx_mmlux_el-econometrics": 0,
    "ogx_mmlux_el-electrical_engineering": 0,
    "ogx_mmlux_el-elementary_mathematics": 0,
    "ogx_mmlux_el-formal_logic": 0,
    "ogx_mmlux_el-global_facts": 0,
    "ogx_mmlux_el-high_school_biology": 0,
    "ogx_mmlux_el-high_school_chemistry": 0,
    "ogx_mmlux_el-high_school_computer_science": 0,
    "ogx_mmlux_el-high_school_european_history": 0,
    "ogx_mmlux_el-high_school_geography": 0,
    "ogx_mmlux_el-high_school_government_and_politics": 0,
    "ogx_mmlux_el-high_school_macroeconomics": 0,
    "ogx_mmlux_el-high_school_mathematics": 0,
    "ogx_mmlux_el-high_school_microeconomics": 0,
    "ogx_mmlux_el-high_school_physics": 0,
    "ogx_mmlux_el-high_school_psychology": 0,
    "ogx_mmlux_el-high_school_statistics": 0,
    "ogx_mmlux_el-high_school_us_history": 0,
    "ogx_mmlux_el-high_school_world_history": 0,
    "ogx_mmlux_el-human_aging": 0,
    "ogx_mmlux_el-human_sexuality": 0,
    "ogx_mmlux_el-international_law": 0,
    "ogx_mmlux_el-jurisprudence": 0,
    "ogx_mmlux_el-logical_fallacies": 0,
    "ogx_mmlux_el-machine_learning": 0,
    "ogx_mmlux_el-management": 0,
    "ogx_mmlux_el-marketing": 0,
    "ogx_mmlux_el-medical_genetics": 0,
    "ogx_mmlux_el-miscellaneous": 0,
    "ogx_mmlux_el-moral_disputes": 0,
    "ogx_mmlux_el-moral_scenarios": 0,
    "ogx_mmlux_el-nutrition": 0,
    "ogx_mmlux_el-philosophy": 0,
    "ogx_mmlux_el-prehistory": 0,
    "ogx_mmlux_el-professional_accounting": 0,
    "ogx_mmlux_el-professional_law": 0,
    "ogx_mmlux_el-professional_medicine": 0,
    "ogx_mmlux_el-professional_psychology": 0,
    "ogx_mmlux_el-public_relations": 0,
    "ogx_mmlux_el-security_studies": 0,
    "ogx_mmlux_el-sociology": 0,
    "ogx_mmlux_el-us_foreign_policy": 0,
    "ogx_mmlux_el-virology": 0,
    "ogx_mmlux_el-world_religions": 0,
    "ogx_mmlux_es-abstract_algebra": 0,
    "ogx_mmlux_es-anatomy": 0,
    "ogx_mmlux_es-astronomy": 0,
    "ogx_mmlux_es-business_ethics": 0,
    "ogx_mmlux_es-clinical_knowledge": 0,
    "ogx_mmlux_es-college_biology": 0,
    "ogx_mmlux_es-college_chemistry": 0,
    "ogx_mmlux_es-college_computer_science": 0,
    "ogx_mmlux_es-college_mathematics": 0,
    "ogx_mmlux_es-college_medicine": 0,
    "ogx_mmlux_es-college_physics": 0,
    "ogx_mmlux_es-computer_security": 0,
    "ogx_mmlux_es-conceptual_physics": 0,
    "ogx_mmlux_es-econometrics": 0,
    "ogx_mmlux_es-electrical_engineering": 0,
    "ogx_mmlux_es-elementary_mathematics": 0,
    "ogx_mmlux_es-formal_logic": 0,
    "ogx_mmlux_es-global_facts": 0,
    "ogx_mmlux_es-high_school_biology": 0,
    "ogx_mmlux_es-high_school_chemistry": 0,
    "ogx_mmlux_es-high_school_computer_science": 0,
    "ogx_mmlux_es-high_school_european_history": 0,
    "ogx_mmlux_es-high_school_geography": 0,
    "ogx_mmlux_es-high_school_government_and_politics": 0,
    "ogx_mmlux_es-high_school_macroeconomics": 0,
    "ogx_mmlux_es-high_school_mathematics": 0,
    "ogx_mmlux_es-high_school_microeconomics": 0,
    "ogx_mmlux_es-high_school_physics": 0,
    "ogx_mmlux_es-high_school_psychology": 0,
    "ogx_mmlux_es-high_school_statistics": 0,
    "ogx_mmlux_es-high_school_us_history": 0,
    "ogx_mmlux_es-high_school_world_history": 0,
    "ogx_mmlux_es-human_aging": 0,
    "ogx_mmlux_es-human_sexuality": 0,
    "ogx_mmlux_es-international_law": 0,
    "ogx_mmlux_es-jurisprudence": 0,
    "ogx_mmlux_es-logical_fallacies": 0,
    "ogx_mmlux_es-machine_learning": 0,
    "ogx_mmlux_es-management": 0,
    "ogx_mmlux_es-marketing": 0,
    "ogx_mmlux_es-medical_genetics": 0,
    "ogx_mmlux_es-miscellaneous": 0,
    "ogx_mmlux_es-moral_disputes": 0,
    "ogx_mmlux_es-moral_scenarios": 0,
    "ogx_mmlux_es-nutrition": 0,
    "ogx_mmlux_es-philosophy": 0,
    "ogx_mmlux_es-prehistory": 0,
    "ogx_mmlux_es-professional_accounting": 0,
    "ogx_mmlux_es-professional_law": 0,
    "ogx_mmlux_es-professional_medicine": 0,
    "ogx_mmlux_es-professional_psychology": 0,
    "ogx_mmlux_es-public_relations": 0,
    "ogx_mmlux_es-security_studies": 0,
    "ogx_mmlux_es-sociology": 0,
    "ogx_mmlux_es-us_foreign_policy": 0,
    "ogx_mmlux_es-virology": 0,
    "ogx_mmlux_es-world_religions": 0,
    "ogx_mmlux_et-abstract_algebra": 0,
    "ogx_mmlux_et-anatomy": 0,
    "ogx_mmlux_et-astronomy": 0,
    "ogx_mmlux_et-business_ethics": 0,
    "ogx_mmlux_et-clinical_knowledge": 0,
    "ogx_mmlux_et-college_biology": 0,
    "ogx_mmlux_et-college_chemistry": 0,
    "ogx_mmlux_et-college_computer_science": 0,
    "ogx_mmlux_et-college_mathematics": 0,
    "ogx_mmlux_et-college_medicine": 0,
    "ogx_mmlux_et-college_physics": 0,
    "ogx_mmlux_et-computer_security": 0,
    "ogx_mmlux_et-conceptual_physics": 0,
    "ogx_mmlux_et-econometrics": 0,
    "ogx_mmlux_et-electrical_engineering": 0,
    "ogx_mmlux_et-elementary_mathematics": 0,
    "ogx_mmlux_et-formal_logic": 0,
    "ogx_mmlux_et-global_facts": 0,
    "ogx_mmlux_et-high_school_biology": 0,
    "ogx_mmlux_et-high_school_chemistry": 0,
    "ogx_mmlux_et-high_school_computer_science": 0,
    "ogx_mmlux_et-high_school_european_history": 0,
    "ogx_mmlux_et-high_school_geography": 0,
    "ogx_mmlux_et-high_school_government_and_politics": 0,
    "ogx_mmlux_et-high_school_macroeconomics": 0,
    "ogx_mmlux_et-high_school_mathematics": 0,
    "ogx_mmlux_et-high_school_microeconomics": 0,
    "ogx_mmlux_et-high_school_physics": 0,
    "ogx_mmlux_et-high_school_psychology": 0,
    "ogx_mmlux_et-high_school_statistics": 0,
    "ogx_mmlux_et-high_school_us_history": 0,
    "ogx_mmlux_et-high_school_world_history": 0,
    "ogx_mmlux_et-human_aging": 0,
    "ogx_mmlux_et-human_sexuality": 0,
    "ogx_mmlux_et-international_law": 0,
    "ogx_mmlux_et-jurisprudence": 0,
    "ogx_mmlux_et-logical_fallacies": 0,
    "ogx_mmlux_et-machine_learning": 0,
    "ogx_mmlux_et-management": 0,
    "ogx_mmlux_et-marketing": 0,
    "ogx_mmlux_et-medical_genetics": 0,
    "ogx_mmlux_et-miscellaneous": 0,
    "ogx_mmlux_et-moral_disputes": 0,
    "ogx_mmlux_et-moral_scenarios": 0,
    "ogx_mmlux_et-nutrition": 0,
    "ogx_mmlux_et-philosophy": 0,
    "ogx_mmlux_et-prehistory": 0,
    "ogx_mmlux_et-professional_accounting": 0,
    "ogx_mmlux_et-professional_law": 0,
    "ogx_mmlux_et-professional_medicine": 0,
    "ogx_mmlux_et-professional_psychology": 0,
    "ogx_mmlux_et-public_relations": 0,
    "ogx_mmlux_et-security_studies": 0,
    "ogx_mmlux_et-sociology": 0,
    "ogx_mmlux_et-us_foreign_policy": 0,
    "ogx_mmlux_et-virology": 0,
    "ogx_mmlux_et-world_religions": 0,
    "ogx_mmlux_fi-abstract_algebra": 0,
    "ogx_mmlux_fi-anatomy": 0,
    "ogx_mmlux_fi-astronomy": 0,
    "ogx_mmlux_fi-business_ethics": 0,
    "ogx_mmlux_fi-clinical_knowledge": 0,
    "ogx_mmlux_fi-college_biology": 0,
    "ogx_mmlux_fi-college_chemistry": 0,
    "ogx_mmlux_fi-college_computer_science": 0,
    "ogx_mmlux_fi-college_mathematics": 0,
    "ogx_mmlux_fi-college_medicine": 0,
    "ogx_mmlux_fi-college_physics": 0,
    "ogx_mmlux_fi-computer_security": 0,
    "ogx_mmlux_fi-conceptual_physics": 0,
    "ogx_mmlux_fi-econometrics": 0,
    "ogx_mmlux_fi-electrical_engineering": 0,
    "ogx_mmlux_fi-elementary_mathematics": 0,
    "ogx_mmlux_fi-formal_logic": 0,
    "ogx_mmlux_fi-global_facts": 0,
    "ogx_mmlux_fi-high_school_biology": 0,
    "ogx_mmlux_fi-high_school_chemistry": 0,
    "ogx_mmlux_fi-high_school_computer_science": 0,
    "ogx_mmlux_fi-high_school_european_history": 0,
    "ogx_mmlux_fi-high_school_geography": 0,
    "ogx_mmlux_fi-high_school_government_and_politics": 0,
    "ogx_mmlux_fi-high_school_macroeconomics": 0,
    "ogx_mmlux_fi-high_school_mathematics": 0,
    "ogx_mmlux_fi-high_school_microeconomics": 0,
    "ogx_mmlux_fi-high_school_physics": 0,
    "ogx_mmlux_fi-high_school_psychology": 0,
    "ogx_mmlux_fi-high_school_statistics": 0,
    "ogx_mmlux_fi-high_school_us_history": 0,
    "ogx_mmlux_fi-high_school_world_history": 0,
    "ogx_mmlux_fi-human_aging": 0,
    "ogx_mmlux_fi-human_sexuality": 0,
    "ogx_mmlux_fi-international_law": 0,
    "ogx_mmlux_fi-jurisprudence": 0,
    "ogx_mmlux_fi-logical_fallacies": 0,
    "ogx_mmlux_fi-machine_learning": 0,
    "ogx_mmlux_fi-management": 0,
    "ogx_mmlux_fi-marketing": 0,
    "ogx_mmlux_fi-medical_genetics": 0,
    "ogx_mmlux_fi-miscellaneous": 0,
    "ogx_mmlux_fi-moral_disputes": 0,
    "ogx_mmlux_fi-moral_scenarios": 0,
    "ogx_mmlux_fi-nutrition": 0,
    "ogx_mmlux_fi-philosophy": 0,
    "ogx_mmlux_fi-prehistory": 0,
    "ogx_mmlux_fi-professional_accounting": 0,
    "ogx_mmlux_fi-professional_law": 0,
    "ogx_mmlux_fi-professional_medicine": 0,
    "ogx_mmlux_fi-professional_psychology": 0,
    "ogx_mmlux_fi-public_relations": 0,
    "ogx_mmlux_fi-security_studies": 0,
    "ogx_mmlux_fi-sociology": 0,
    "ogx_mmlux_fi-us_foreign_policy": 0,
    "ogx_mmlux_fi-virology": 0,
    "ogx_mmlux_fi-world_religions": 0,
    "ogx_mmlux_fr-abstract_algebra": 0,
    "ogx_mmlux_fr-anatomy": 0,
    "ogx_mmlux_fr-astronomy": 0,
    "ogx_mmlux_fr-business_ethics": 0,
    "ogx_mmlux_fr-clinical_knowledge": 0,
    "ogx_mmlux_fr-college_biology": 0,
    "ogx_mmlux_fr-college_chemistry": 0,
    "ogx_mmlux_fr-college_computer_science": 0,
    "ogx_mmlux_fr-college_mathematics": 0,
    "ogx_mmlux_fr-college_medicine": 0,
    "ogx_mmlux_fr-college_physics": 0,
    "ogx_mmlux_fr-computer_security": 0,
    "ogx_mmlux_fr-conceptual_physics": 0,
    "ogx_mmlux_fr-econometrics": 0,
    "ogx_mmlux_fr-electrical_engineering": 0,
    "ogx_mmlux_fr-elementary_mathematics": 0,
    "ogx_mmlux_fr-formal_logic": 0,
    "ogx_mmlux_fr-global_facts": 0,
    "ogx_mmlux_fr-high_school_biology": 0,
    "ogx_mmlux_fr-high_school_chemistry": 0,
    "ogx_mmlux_fr-high_school_computer_science": 0,
    "ogx_mmlux_fr-high_school_european_history": 0,
    "ogx_mmlux_fr-high_school_geography": 0,
    "ogx_mmlux_fr-high_school_government_and_politics": 0,
    "ogx_mmlux_fr-high_school_macroeconomics": 0,
    "ogx_mmlux_fr-high_school_mathematics": 0,
    "ogx_mmlux_fr-high_school_microeconomics": 0,
    "ogx_mmlux_fr-high_school_physics": 0,
    "ogx_mmlux_fr-high_school_psychology": 0,
    "ogx_mmlux_fr-high_school_statistics": 0,
    "ogx_mmlux_fr-high_school_us_history": 0,
    "ogx_mmlux_fr-high_school_world_history": 0,
    "ogx_mmlux_fr-human_aging": 0,
    "ogx_mmlux_fr-human_sexuality": 0,
    "ogx_mmlux_fr-international_law": 0,
    "ogx_mmlux_fr-jurisprudence": 0,
    "ogx_mmlux_fr-logical_fallacies": 0,
    "ogx_mmlux_fr-machine_learning": 0,
    "ogx_mmlux_fr-management": 0,
    "ogx_mmlux_fr-marketing": 0,
    "ogx_mmlux_fr-medical_genetics": 0,
    "ogx_mmlux_fr-miscellaneous": 0,
    "ogx_mmlux_fr-moral_disputes": 0,
    "ogx_mmlux_fr-moral_scenarios": 0,
    "ogx_mmlux_fr-nutrition": 0,
    "ogx_mmlux_fr-philosophy": 0,
    "ogx_mmlux_fr-prehistory": 0,
    "ogx_mmlux_fr-professional_accounting": 0,
    "ogx_mmlux_fr-professional_law": 0,
    "ogx_mmlux_fr-professional_medicine": 0,
    "ogx_mmlux_fr-professional_psychology": 0,
    "ogx_mmlux_fr-public_relations": 0,
    "ogx_mmlux_fr-security_studies": 0,
    "ogx_mmlux_fr-sociology": 0,
    "ogx_mmlux_fr-us_foreign_policy": 0,
    "ogx_mmlux_fr-virology": 0,
    "ogx_mmlux_fr-world_religions": 0,
    "ogx_mmlux_hu-abstract_algebra": 0,
    "ogx_mmlux_hu-anatomy": 0,
    "ogx_mmlux_hu-astronomy": 0,
    "ogx_mmlux_hu-business_ethics": 0,
    "ogx_mmlux_hu-clinical_knowledge": 0,
    "ogx_mmlux_hu-college_biology": 0,
    "ogx_mmlux_hu-college_chemistry": 0,
    "ogx_mmlux_hu-college_computer_science": 0,
    "ogx_mmlux_hu-college_mathematics": 0,
    "ogx_mmlux_hu-college_medicine": 0,
    "ogx_mmlux_hu-college_physics": 0,
    "ogx_mmlux_hu-computer_security": 0,
    "ogx_mmlux_hu-conceptual_physics": 0,
    "ogx_mmlux_hu-econometrics": 0,
    "ogx_mmlux_hu-electrical_engineering": 0,
    "ogx_mmlux_hu-elementary_mathematics": 0,
    "ogx_mmlux_hu-formal_logic": 0,
    "ogx_mmlux_hu-global_facts": 0,
    "ogx_mmlux_hu-high_school_biology": 0,
    "ogx_mmlux_hu-high_school_chemistry": 0,
    "ogx_mmlux_hu-high_school_computer_science": 0,
    "ogx_mmlux_hu-high_school_european_history": 0,
    "ogx_mmlux_hu-high_school_geography": 0,
    "ogx_mmlux_hu-high_school_government_and_politics": 0,
    "ogx_mmlux_hu-high_school_macroeconomics": 0,
    "ogx_mmlux_hu-high_school_mathematics": 0,
    "ogx_mmlux_hu-high_school_microeconomics": 0,
    "ogx_mmlux_hu-high_school_physics": 0,
    "ogx_mmlux_hu-high_school_psychology": 0,
    "ogx_mmlux_hu-high_school_statistics": 0,
    "ogx_mmlux_hu-high_school_us_history": 0,
    "ogx_mmlux_hu-high_school_world_history": 0,
    "ogx_mmlux_hu-human_aging": 0,
    "ogx_mmlux_hu-human_sexuality": 0,
    "ogx_mmlux_hu-international_law": 0,
    "ogx_mmlux_hu-jurisprudence": 0,
    "ogx_mmlux_hu-logical_fallacies": 0,
    "ogx_mmlux_hu-machine_learning": 0,
    "ogx_mmlux_hu-management": 0,
    "ogx_mmlux_hu-marketing": 0,
    "ogx_mmlux_hu-medical_genetics": 0,
    "ogx_mmlux_hu-miscellaneous": 0,
    "ogx_mmlux_hu-moral_disputes": 0,
    "ogx_mmlux_hu-moral_scenarios": 0,
    "ogx_mmlux_hu-nutrition": 0,
    "ogx_mmlux_hu-philosophy": 0,
    "ogx_mmlux_hu-prehistory": 0,
    "ogx_mmlux_hu-professional_accounting": 0,
    "ogx_mmlux_hu-professional_law": 0,
    "ogx_mmlux_hu-professional_medicine": 0,
    "ogx_mmlux_hu-professional_psychology": 0,
    "ogx_mmlux_hu-public_relations": 0,
    "ogx_mmlux_hu-security_studies": 0,
    "ogx_mmlux_hu-sociology": 0,
    "ogx_mmlux_hu-us_foreign_policy": 0,
    "ogx_mmlux_hu-virology": 0,
    "ogx_mmlux_hu-world_religions": 0,
    "ogx_mmlux_it-abstract_algebra": 0,
    "ogx_mmlux_it-anatomy": 0,
    "ogx_mmlux_it-astronomy": 0,
    "ogx_mmlux_it-business_ethics": 0,
    "ogx_mmlux_it-clinical_knowledge": 0,
    "ogx_mmlux_it-college_biology": 0,
    "ogx_mmlux_it-college_chemistry": 0,
    "ogx_mmlux_it-college_computer_science": 0,
    "ogx_mmlux_it-college_mathematics": 0,
    "ogx_mmlux_it-college_medicine": 0,
    "ogx_mmlux_it-college_physics": 0,
    "ogx_mmlux_it-computer_security": 0,
    "ogx_mmlux_it-conceptual_physics": 0,
    "ogx_mmlux_it-econometrics": 0,
    "ogx_mmlux_it-electrical_engineering": 0,
    "ogx_mmlux_it-elementary_mathematics": 0,
    "ogx_mmlux_it-formal_logic": 0,
    "ogx_mmlux_it-global_facts": 0,
    "ogx_mmlux_it-high_school_biology": 0,
    "ogx_mmlux_it-high_school_chemistry": 0,
    "ogx_mmlux_it-high_school_computer_science": 0,
    "ogx_mmlux_it-high_school_european_history": 0,
    "ogx_mmlux_it-high_school_geography": 0,
    "ogx_mmlux_it-high_school_government_and_politics": 0,
    "ogx_mmlux_it-high_school_macroeconomics": 0,
    "ogx_mmlux_it-high_school_mathematics": 0,
    "ogx_mmlux_it-high_school_microeconomics": 0,
    "ogx_mmlux_it-high_school_physics": 0,
    "ogx_mmlux_it-high_school_psychology": 0,
    "ogx_mmlux_it-high_school_statistics": 0,
    "ogx_mmlux_it-high_school_us_history": 0,
    "ogx_mmlux_it-high_school_world_history": 0,
    "ogx_mmlux_it-human_aging": 0,
    "ogx_mmlux_it-human_sexuality": 0,
    "ogx_mmlux_it-international_law": 0,
    "ogx_mmlux_it-jurisprudence": 0,
    "ogx_mmlux_it-logical_fallacies": 0,
    "ogx_mmlux_it-machine_learning": 0,
    "ogx_mmlux_it-management": 0,
    "ogx_mmlux_it-marketing": 0,
    "ogx_mmlux_it-medical_genetics": 0,
    "ogx_mmlux_it-miscellaneous": 0,
    "ogx_mmlux_it-moral_disputes": 0,
    "ogx_mmlux_it-moral_scenarios": 0,
    "ogx_mmlux_it-nutrition": 0,
    "ogx_mmlux_it-philosophy": 0,
    "ogx_mmlux_it-prehistory": 0,
    "ogx_mmlux_it-professional_accounting": 0,
    "ogx_mmlux_it-professional_law": 0,
    "ogx_mmlux_it-professional_medicine": 0,
    "ogx_mmlux_it-professional_psychology": 0,
    "ogx_mmlux_it-public_relations": 0,
    "ogx_mmlux_it-security_studies": 0,
    "ogx_mmlux_it-sociology": 0,
    "ogx_mmlux_it-us_foreign_policy": 0,
    "ogx_mmlux_it-virology": 0,
    "ogx_mmlux_it-world_religions": 0,
    "ogx_mmlux_lt-abstract_algebra": 0,
    "ogx_mmlux_lt-anatomy": 0,
    "ogx_mmlux_lt-astronomy": 0,
    "ogx_mmlux_lt-business_ethics": 0,
    "ogx_mmlux_lt-clinical_knowledge": 0,
    "ogx_mmlux_lt-college_biology": 0,
    "ogx_mmlux_lt-college_chemistry": 0,
    "ogx_mmlux_lt-college_computer_science": 0,
    "ogx_mmlux_lt-college_mathematics": 0,
    "ogx_mmlux_lt-college_medicine": 0,
    "ogx_mmlux_lt-college_physics": 0,
    "ogx_mmlux_lt-computer_security": 0,
    "ogx_mmlux_lt-conceptual_physics": 0,
    "ogx_mmlux_lt-econometrics": 0,
    "ogx_mmlux_lt-electrical_engineering": 0,
    "ogx_mmlux_lt-elementary_mathematics": 0,
    "ogx_mmlux_lt-formal_logic": 0,
    "ogx_mmlux_lt-global_facts": 0,
    "ogx_mmlux_lt-high_school_biology": 0,
    "ogx_mmlux_lt-high_school_chemistry": 0,
    "ogx_mmlux_lt-high_school_computer_science": 0,
    "ogx_mmlux_lt-high_school_european_history": 0,
    "ogx_mmlux_lt-high_school_geography": 0,
    "ogx_mmlux_lt-high_school_government_and_politics": 0,
    "ogx_mmlux_lt-high_school_macroeconomics": 0,
    "ogx_mmlux_lt-high_school_mathematics": 0,
    "ogx_mmlux_lt-high_school_microeconomics": 0,
    "ogx_mmlux_lt-high_school_physics": 0,
    "ogx_mmlux_lt-high_school_psychology": 0,
    "ogx_mmlux_lt-high_school_statistics": 0,
    "ogx_mmlux_lt-high_school_us_history": 0,
    "ogx_mmlux_lt-high_school_world_history": 0,
    "ogx_mmlux_lt-human_aging": 0,
    "ogx_mmlux_lt-human_sexuality": 0,
    "ogx_mmlux_lt-international_law": 0,
    "ogx_mmlux_lt-jurisprudence": 0,
    "ogx_mmlux_lt-logical_fallacies": 0,
    "ogx_mmlux_lt-machine_learning": 0,
    "ogx_mmlux_lt-management": 0,
    "ogx_mmlux_lt-marketing": 0,
    "ogx_mmlux_lt-medical_genetics": 0,
    "ogx_mmlux_lt-miscellaneous": 0,
    "ogx_mmlux_lt-moral_disputes": 0,
    "ogx_mmlux_lt-moral_scenarios": 0,
    "ogx_mmlux_lt-nutrition": 0,
    "ogx_mmlux_lt-philosophy": 0,
    "ogx_mmlux_lt-prehistory": 0,
    "ogx_mmlux_lt-professional_accounting": 0,
    "ogx_mmlux_lt-professional_law": 0,
    "ogx_mmlux_lt-professional_medicine": 0,
    "ogx_mmlux_lt-professional_psychology": 0,
    "ogx_mmlux_lt-public_relations": 0,
    "ogx_mmlux_lt-security_studies": 0,
    "ogx_mmlux_lt-sociology": 0,
    "ogx_mmlux_lt-us_foreign_policy": 0,
    "ogx_mmlux_lt-virology": 0,
    "ogx_mmlux_lt-world_religions": 0,
    "ogx_mmlux_lv-abstract_algebra": 0,
    "ogx_mmlux_lv-anatomy": 0,
    "ogx_mmlux_lv-astronomy": 0,
    "ogx_mmlux_lv-business_ethics": 0,
    "ogx_mmlux_lv-clinical_knowledge": 0,
    "ogx_mmlux_lv-college_biology": 0,
    "ogx_mmlux_lv-college_chemistry": 0,
    "ogx_mmlux_lv-college_computer_science": 0,
    "ogx_mmlux_lv-college_mathematics": 0,
    "ogx_mmlux_lv-college_medicine": 0,
    "ogx_mmlux_lv-college_physics": 0,
    "ogx_mmlux_lv-computer_security": 0,
    "ogx_mmlux_lv-conceptual_physics": 0,
    "ogx_mmlux_lv-econometrics": 0,
    "ogx_mmlux_lv-electrical_engineering": 0,
    "ogx_mmlux_lv-elementary_mathematics": 0,
    "ogx_mmlux_lv-formal_logic": 0,
    "ogx_mmlux_lv-global_facts": 0,
    "ogx_mmlux_lv-high_school_biology": 0,
    "ogx_mmlux_lv-high_school_chemistry": 0,
    "ogx_mmlux_lv-high_school_computer_science": 0,
    "ogx_mmlux_lv-high_school_european_history": 0,
    "ogx_mmlux_lv-high_school_geography": 0,
    "ogx_mmlux_lv-high_school_government_and_politics": 0,
    "ogx_mmlux_lv-high_school_macroeconomics": 0,
    "ogx_mmlux_lv-high_school_mathematics": 0,
    "ogx_mmlux_lv-high_school_microeconomics": 0,
    "ogx_mmlux_lv-high_school_physics": 0,
    "ogx_mmlux_lv-high_school_psychology": 0,
    "ogx_mmlux_lv-high_school_statistics": 0,
    "ogx_mmlux_lv-high_school_us_history": 0,
    "ogx_mmlux_lv-high_school_world_history": 0,
    "ogx_mmlux_lv-human_aging": 0,
    "ogx_mmlux_lv-human_sexuality": 0,
    "ogx_mmlux_lv-international_law": 0,
    "ogx_mmlux_lv-jurisprudence": 0,
    "ogx_mmlux_lv-logical_fallacies": 0,
    "ogx_mmlux_lv-machine_learning": 0,
    "ogx_mmlux_lv-management": 0,
    "ogx_mmlux_lv-marketing": 0,
    "ogx_mmlux_lv-medical_genetics": 0,
    "ogx_mmlux_lv-miscellaneous": 0,
    "ogx_mmlux_lv-moral_disputes": 0,
    "ogx_mmlux_lv-moral_scenarios": 0,
    "ogx_mmlux_lv-nutrition": 0,
    "ogx_mmlux_lv-philosophy": 0,
    "ogx_mmlux_lv-prehistory": 0,
    "ogx_mmlux_lv-professional_accounting": 0,
    "ogx_mmlux_lv-professional_law": 0,
    "ogx_mmlux_lv-professional_medicine": 0,
    "ogx_mmlux_lv-professional_psychology": 0,
    "ogx_mmlux_lv-public_relations": 0,
    "ogx_mmlux_lv-security_studies": 0,
    "ogx_mmlux_lv-sociology": 0,
    "ogx_mmlux_lv-us_foreign_policy": 0,
    "ogx_mmlux_lv-virology": 0,
    "ogx_mmlux_lv-world_religions": 0,
    "ogx_mmlux_nl-abstract_algebra": 0,
    "ogx_mmlux_nl-anatomy": 0,
    "ogx_mmlux_nl-astronomy": 0,
    "ogx_mmlux_nl-business_ethics": 0,
    "ogx_mmlux_nl-clinical_knowledge": 0,
    "ogx_mmlux_nl-college_biology": 0,
    "ogx_mmlux_nl-college_chemistry": 0,
    "ogx_mmlux_nl-college_computer_science": 0,
    "ogx_mmlux_nl-college_mathematics": 0,
    "ogx_mmlux_nl-college_medicine": 0,
    "ogx_mmlux_nl-college_physics": 0,
    "ogx_mmlux_nl-computer_security": 0,
    "ogx_mmlux_nl-conceptual_physics": 0,
    "ogx_mmlux_nl-econometrics": 0,
    "ogx_mmlux_nl-electrical_engineering": 0,
    "ogx_mmlux_nl-elementary_mathematics": 0,
    "ogx_mmlux_nl-formal_logic": 0,
    "ogx_mmlux_nl-global_facts": 0,
    "ogx_mmlux_nl-high_school_biology": 0,
    "ogx_mmlux_nl-high_school_chemistry": 0,
    "ogx_mmlux_nl-high_school_computer_science": 0,
    "ogx_mmlux_nl-high_school_european_history": 0,
    "ogx_mmlux_nl-high_school_geography": 0,
    "ogx_mmlux_nl-high_school_government_and_politics": 0,
    "ogx_mmlux_nl-high_school_macroeconomics": 0,
    "ogx_mmlux_nl-high_school_mathematics": 0,
    "ogx_mmlux_nl-high_school_microeconomics": 0,
    "ogx_mmlux_nl-high_school_physics": 0,
    "ogx_mmlux_nl-high_school_psychology": 0,
    "ogx_mmlux_nl-high_school_statistics": 0,
    "ogx_mmlux_nl-high_school_us_history": 0,
    "ogx_mmlux_nl-high_school_world_history": 0,
    "ogx_mmlux_nl-human_aging": 0,
    "ogx_mmlux_nl-human_sexuality": 0,
    "ogx_mmlux_nl-international_law": 0,
    "ogx_mmlux_nl-jurisprudence": 0,
    "ogx_mmlux_nl-logical_fallacies": 0,
    "ogx_mmlux_nl-machine_learning": 0,
    "ogx_mmlux_nl-management": 0,
    "ogx_mmlux_nl-marketing": 0,
    "ogx_mmlux_nl-medical_genetics": 0,
    "ogx_mmlux_nl-miscellaneous": 0,
    "ogx_mmlux_nl-moral_disputes": 0,
    "ogx_mmlux_nl-moral_scenarios": 0,
    "ogx_mmlux_nl-nutrition": 0,
    "ogx_mmlux_nl-philosophy": 0,
    "ogx_mmlux_nl-prehistory": 0,
    "ogx_mmlux_nl-professional_accounting": 0,
    "ogx_mmlux_nl-professional_law": 0,
    "ogx_mmlux_nl-professional_medicine": 0,
    "ogx_mmlux_nl-professional_psychology": 0,
    "ogx_mmlux_nl-public_relations": 0,
    "ogx_mmlux_nl-security_studies": 0,
    "ogx_mmlux_nl-sociology": 0,
    "ogx_mmlux_nl-us_foreign_policy": 0,
    "ogx_mmlux_nl-virology": 0,
    "ogx_mmlux_nl-world_religions": 0,
    "ogx_mmlux_pl-abstract_algebra": 0,
    "ogx_mmlux_pl-anatomy": 0,
    "ogx_mmlux_pl-astronomy": 0,
    "ogx_mmlux_pl-business_ethics": 0,
    "ogx_mmlux_pl-clinical_knowledge": 0,
    "ogx_mmlux_pl-college_biology": 0,
    "ogx_mmlux_pl-college_chemistry": 0,
    "ogx_mmlux_pl-college_computer_science": 0,
    "ogx_mmlux_pl-college_mathematics": 0,
    "ogx_mmlux_pl-college_medicine": 0,
    "ogx_mmlux_pl-college_physics": 0,
    "ogx_mmlux_pl-computer_security": 0,
    "ogx_mmlux_pl-conceptual_physics": 0,
    "ogx_mmlux_pl-econometrics": 0,
    "ogx_mmlux_pl-electrical_engineering": 0,
    "ogx_mmlux_pl-elementary_mathematics": 0,
    "ogx_mmlux_pl-formal_logic": 0,
    "ogx_mmlux_pl-global_facts": 0,
    "ogx_mmlux_pl-high_school_biology": 0,
    "ogx_mmlux_pl-high_school_chemistry": 0,
    "ogx_mmlux_pl-high_school_computer_science": 0,
    "ogx_mmlux_pl-high_school_european_history": 0,
    "ogx_mmlux_pl-high_school_geography": 0,
    "ogx_mmlux_pl-high_school_government_and_politics": 0,
    "ogx_mmlux_pl-high_school_macroeconomics": 0,
    "ogx_mmlux_pl-high_school_mathematics": 0,
    "ogx_mmlux_pl-high_school_microeconomics": 0,
    "ogx_mmlux_pl-high_school_physics": 0,
    "ogx_mmlux_pl-high_school_psychology": 0,
    "ogx_mmlux_pl-high_school_statistics": 0,
    "ogx_mmlux_pl-high_school_us_history": 0,
    "ogx_mmlux_pl-high_school_world_history": 0,
    "ogx_mmlux_pl-human_aging": 0,
    "ogx_mmlux_pl-human_sexuality": 0,
    "ogx_mmlux_pl-international_law": 0,
    "ogx_mmlux_pl-jurisprudence": 0,
    "ogx_mmlux_pl-logical_fallacies": 0,
    "ogx_mmlux_pl-machine_learning": 0,
    "ogx_mmlux_pl-management": 0,
    "ogx_mmlux_pl-marketing": 0,
    "ogx_mmlux_pl-medical_genetics": 0,
    "ogx_mmlux_pl-miscellaneous": 0,
    "ogx_mmlux_pl-moral_disputes": 0,
    "ogx_mmlux_pl-moral_scenarios": 0,
    "ogx_mmlux_pl-nutrition": 0,
    "ogx_mmlux_pl-philosophy": 0,
    "ogx_mmlux_pl-prehistory": 0,
    "ogx_mmlux_pl-professional_accounting": 0,
    "ogx_mmlux_pl-professional_law": 0,
    "ogx_mmlux_pl-professional_medicine": 0,
    "ogx_mmlux_pl-professional_psychology": 0,
    "ogx_mmlux_pl-public_relations": 0,
    "ogx_mmlux_pl-security_studies": 0,
    "ogx_mmlux_pl-sociology": 0,
    "ogx_mmlux_pl-us_foreign_policy": 0,
    "ogx_mmlux_pl-virology": 0,
    "ogx_mmlux_pl-world_religions": 0,
    "ogx_mmlux_pt-pt-abstract_algebra": 0,
    "ogx_mmlux_pt-pt-anatomy": 0,
    "ogx_mmlux_pt-pt-astronomy": 0,
    "ogx_mmlux_pt-pt-business_ethics": 0,
    "ogx_mmlux_pt-pt-clinical_knowledge": 0,
    "ogx_mmlux_pt-pt-college_biology": 0,
    "ogx_mmlux_pt-pt-college_chemistry": 0,
    "ogx_mmlux_pt-pt-college_computer_science": 0,
    "ogx_mmlux_pt-pt-college_mathematics": 0,
    "ogx_mmlux_pt-pt-college_medicine": 0,
    "ogx_mmlux_pt-pt-college_physics": 0,
    "ogx_mmlux_pt-pt-computer_security": 0,
    "ogx_mmlux_pt-pt-conceptual_physics": 0,
    "ogx_mmlux_pt-pt-econometrics": 0,
    "ogx_mmlux_pt-pt-electrical_engineering": 0,
    "ogx_mmlux_pt-pt-elementary_mathematics": 0,
    "ogx_mmlux_pt-pt-formal_logic": 0,
    "ogx_mmlux_pt-pt-global_facts": 0,
    "ogx_mmlux_pt-pt-high_school_biology": 0,
    "ogx_mmlux_pt-pt-high_school_chemistry": 0,
    "ogx_mmlux_pt-pt-high_school_computer_science": 0,
    "ogx_mmlux_pt-pt-high_school_european_history": 0,
    "ogx_mmlux_pt-pt-high_school_geography": 0,
    "ogx_mmlux_pt-pt-high_school_government_and_politics": 0,
    "ogx_mmlux_pt-pt-high_school_macroeconomics": 0,
    "ogx_mmlux_pt-pt-high_school_mathematics": 0,
    "ogx_mmlux_pt-pt-high_school_microeconomics": 0,
    "ogx_mmlux_pt-pt-high_school_physics": 0,
    "ogx_mmlux_pt-pt-high_school_psychology": 0,
    "ogx_mmlux_pt-pt-high_school_statistics": 0,
    "ogx_mmlux_pt-pt-high_school_us_history": 0,
    "ogx_mmlux_pt-pt-high_school_world_history": 0,
    "ogx_mmlux_pt-pt-human_aging": 0,
    "ogx_mmlux_pt-pt-human_sexuality": 0,
    "ogx_mmlux_pt-pt-international_law": 0,
    "ogx_mmlux_pt-pt-jurisprudence": 0,
    "ogx_mmlux_pt-pt-logical_fallacies": 0,
    "ogx_mmlux_pt-pt-machine_learning": 0,
    "ogx_mmlux_pt-pt-management": 0,
    "ogx_mmlux_pt-pt-marketing": 0,
    "ogx_mmlux_pt-pt-medical_genetics": 0,
    "ogx_mmlux_pt-pt-miscellaneous": 0,
    "ogx_mmlux_pt-pt-moral_disputes": 0,
    "ogx_mmlux_pt-pt-moral_scenarios": 0,
    "ogx_mmlux_pt-pt-nutrition": 0,
    "ogx_mmlux_pt-pt-philosophy": 0,
    "ogx_mmlux_pt-pt-prehistory": 0,
    "ogx_mmlux_pt-pt-professional_accounting": 0,
    "ogx_mmlux_pt-pt-professional_law": 0,
    "ogx_mmlux_pt-pt-professional_medicine": 0,
    "ogx_mmlux_pt-pt-professional_psychology": 0,
    "ogx_mmlux_pt-pt-public_relations": 0,
    "ogx_mmlux_pt-pt-security_studies": 0,
    "ogx_mmlux_pt-pt-sociology": 0,
    "ogx_mmlux_pt-pt-us_foreign_policy": 0,
    "ogx_mmlux_pt-pt-virology": 0,
    "ogx_mmlux_pt-pt-world_religions": 0,
    "ogx_mmlux_ro-abstract_algebra": 0,
    "ogx_mmlux_ro-anatomy": 0,
    "ogx_mmlux_ro-astronomy": 0,
    "ogx_mmlux_ro-business_ethics": 0,
    "ogx_mmlux_ro-clinical_knowledge": 0,
    "ogx_mmlux_ro-college_biology": 0,
    "ogx_mmlux_ro-college_chemistry": 0,
    "ogx_mmlux_ro-college_computer_science": 0,
    "ogx_mmlux_ro-college_mathematics": 0,
    "ogx_mmlux_ro-college_medicine": 0,
    "ogx_mmlux_ro-college_physics": 0,
    "ogx_mmlux_ro-computer_security": 0,
    "ogx_mmlux_ro-conceptual_physics": 0,
    "ogx_mmlux_ro-econometrics": 0,
    "ogx_mmlux_ro-electrical_engineering": 0,
    "ogx_mmlux_ro-elementary_mathematics": 0,
    "ogx_mmlux_ro-formal_logic": 0,
    "ogx_mmlux_ro-global_facts": 0,
    "ogx_mmlux_ro-high_school_biology": 0,
    "ogx_mmlux_ro-high_school_chemistry": 0,
    "ogx_mmlux_ro-high_school_computer_science": 0,
    "ogx_mmlux_ro-high_school_european_history": 0,
    "ogx_mmlux_ro-high_school_geography": 0,
    "ogx_mmlux_ro-high_school_government_and_politics": 0,
    "ogx_mmlux_ro-high_school_macroeconomics": 0,
    "ogx_mmlux_ro-high_school_mathematics": 0,
    "ogx_mmlux_ro-high_school_microeconomics": 0,
    "ogx_mmlux_ro-high_school_physics": 0,
    "ogx_mmlux_ro-high_school_psychology": 0,
    "ogx_mmlux_ro-high_school_statistics": 0,
    "ogx_mmlux_ro-high_school_us_history": 0,
    "ogx_mmlux_ro-high_school_world_history": 0,
    "ogx_mmlux_ro-human_aging": 0,
    "ogx_mmlux_ro-human_sexuality": 0,
    "ogx_mmlux_ro-international_law": 0,
    "ogx_mmlux_ro-jurisprudence": 0,
    "ogx_mmlux_ro-logical_fallacies": 0,
    "ogx_mmlux_ro-machine_learning": 0,
    "ogx_mmlux_ro-management": 0,
    "ogx_mmlux_ro-marketing": 0,
    "ogx_mmlux_ro-medical_genetics": 0,
    "ogx_mmlux_ro-miscellaneous": 0,
    "ogx_mmlux_ro-moral_disputes": 0,
    "ogx_mmlux_ro-moral_scenarios": 0,
    "ogx_mmlux_ro-nutrition": 0,
    "ogx_mmlux_ro-philosophy": 0,
    "ogx_mmlux_ro-prehistory": 0,
    "ogx_mmlux_ro-professional_accounting": 0,
    "ogx_mmlux_ro-professional_law": 0,
    "ogx_mmlux_ro-professional_medicine": 0,
    "ogx_mmlux_ro-professional_psychology": 0,
    "ogx_mmlux_ro-public_relations": 0,
    "ogx_mmlux_ro-security_studies": 0,
    "ogx_mmlux_ro-sociology": 0,
    "ogx_mmlux_ro-us_foreign_policy": 0,
    "ogx_mmlux_ro-virology": 0,
    "ogx_mmlux_ro-world_religions": 0,
    "ogx_mmlux_sk-abstract_algebra": 0,
    "ogx_mmlux_sk-anatomy": 0,
    "ogx_mmlux_sk-astronomy": 0,
    "ogx_mmlux_sk-business_ethics": 0,
    "ogx_mmlux_sk-clinical_knowledge": 0,
    "ogx_mmlux_sk-college_biology": 0,
    "ogx_mmlux_sk-college_chemistry": 0,
    "ogx_mmlux_sk-college_computer_science": 0,
    "ogx_mmlux_sk-college_mathematics": 0,
    "ogx_mmlux_sk-college_medicine": 0,
    "ogx_mmlux_sk-college_physics": 0,
    "ogx_mmlux_sk-computer_security": 0,
    "ogx_mmlux_sk-conceptual_physics": 0,
    "ogx_mmlux_sk-econometrics": 0,
    "ogx_mmlux_sk-electrical_engineering": 0,
    "ogx_mmlux_sk-elementary_mathematics": 0,
    "ogx_mmlux_sk-formal_logic": 0,
    "ogx_mmlux_sk-global_facts": 0,
    "ogx_mmlux_sk-high_school_biology": 0,
    "ogx_mmlux_sk-high_school_chemistry": 0,
    "ogx_mmlux_sk-high_school_computer_science": 0,
    "ogx_mmlux_sk-high_school_european_history": 0,
    "ogx_mmlux_sk-high_school_geography": 0,
    "ogx_mmlux_sk-high_school_government_and_politics": 0,
    "ogx_mmlux_sk-high_school_macroeconomics": 0,
    "ogx_mmlux_sk-high_school_mathematics": 0,
    "ogx_mmlux_sk-high_school_microeconomics": 0,
    "ogx_mmlux_sk-high_school_physics": 0,
    "ogx_mmlux_sk-high_school_psychology": 0,
    "ogx_mmlux_sk-high_school_statistics": 0,
    "ogx_mmlux_sk-high_school_us_history": 0,
    "ogx_mmlux_sk-high_school_world_history": 0,
    "ogx_mmlux_sk-human_aging": 0,
    "ogx_mmlux_sk-human_sexuality": 0,
    "ogx_mmlux_sk-international_law": 0,
    "ogx_mmlux_sk-jurisprudence": 0,
    "ogx_mmlux_sk-logical_fallacies": 0,
    "ogx_mmlux_sk-machine_learning": 0,
    "ogx_mmlux_sk-management": 0,
    "ogx_mmlux_sk-marketing": 0,
    "ogx_mmlux_sk-medical_genetics": 0,
    "ogx_mmlux_sk-miscellaneous": 0,
    "ogx_mmlux_sk-moral_disputes": 0,
    "ogx_mmlux_sk-moral_scenarios": 0,
    "ogx_mmlux_sk-nutrition": 0,
    "ogx_mmlux_sk-philosophy": 0,
    "ogx_mmlux_sk-prehistory": 0,
    "ogx_mmlux_sk-professional_accounting": 0,
    "ogx_mmlux_sk-professional_law": 0,
    "ogx_mmlux_sk-professional_medicine": 0,
    "ogx_mmlux_sk-professional_psychology": 0,
    "ogx_mmlux_sk-public_relations": 0,
    "ogx_mmlux_sk-security_studies": 0,
    "ogx_mmlux_sk-sociology": 0,
    "ogx_mmlux_sk-us_foreign_policy": 0,
    "ogx_mmlux_sk-virology": 0,
    "ogx_mmlux_sk-world_religions": 0,
    "ogx_mmlux_sl-abstract_algebra": 0,
    "ogx_mmlux_sl-anatomy": 0,
    "ogx_mmlux_sl-astronomy": 0,
    "ogx_mmlux_sl-business_ethics": 0,
    "ogx_mmlux_sl-clinical_knowledge": 0,
    "ogx_mmlux_sl-college_biology": 0,
    "ogx_mmlux_sl-college_chemistry": 0,
    "ogx_mmlux_sl-college_computer_science": 0,
    "ogx_mmlux_sl-college_mathematics": 0,
    "ogx_mmlux_sl-college_medicine": 0,
    "ogx_mmlux_sl-college_physics": 0,
    "ogx_mmlux_sl-computer_security": 0,
    "ogx_mmlux_sl-conceptual_physics": 0,
    "ogx_mmlux_sl-econometrics": 0,
    "ogx_mmlux_sl-electrical_engineering": 0,
    "ogx_mmlux_sl-elementary_mathematics": 0,
    "ogx_mmlux_sl-formal_logic": 0,
    "ogx_mmlux_sl-global_facts": 0,
    "ogx_mmlux_sl-high_school_biology": 0,
    "ogx_mmlux_sl-high_school_chemistry": 0,
    "ogx_mmlux_sl-high_school_computer_science": 0,
    "ogx_mmlux_sl-high_school_european_history": 0,
    "ogx_mmlux_sl-high_school_geography": 0,
    "ogx_mmlux_sl-high_school_government_and_politics": 0,
    "ogx_mmlux_sl-high_school_macroeconomics": 0,
    "ogx_mmlux_sl-high_school_mathematics": 0,
    "ogx_mmlux_sl-high_school_microeconomics": 0,
    "ogx_mmlux_sl-high_school_physics": 0,
    "ogx_mmlux_sl-high_school_psychology": 0,
    "ogx_mmlux_sl-high_school_statistics": 0,
    "ogx_mmlux_sl-high_school_us_history": 0,
    "ogx_mmlux_sl-high_school_world_history": 0,
    "ogx_mmlux_sl-human_aging": 0,
    "ogx_mmlux_sl-human_sexuality": 0,
    "ogx_mmlux_sl-international_law": 0,
    "ogx_mmlux_sl-jurisprudence": 0,
    "ogx_mmlux_sl-logical_fallacies": 0,
    "ogx_mmlux_sl-machine_learning": 0,
    "ogx_mmlux_sl-management": 0,
    "ogx_mmlux_sl-marketing": 0,
    "ogx_mmlux_sl-medical_genetics": 0,
    "ogx_mmlux_sl-miscellaneous": 0,
    "ogx_mmlux_sl-moral_disputes": 0,
    "ogx_mmlux_sl-moral_scenarios": 0,
    "ogx_mmlux_sl-nutrition": 0,
    "ogx_mmlux_sl-philosophy": 0,
    "ogx_mmlux_sl-prehistory": 0,
    "ogx_mmlux_sl-professional_accounting": 0,
    "ogx_mmlux_sl-professional_law": 0,
    "ogx_mmlux_sl-professional_medicine": 0,
    "ogx_mmlux_sl-professional_psychology": 0,
    "ogx_mmlux_sl-public_relations": 0,
    "ogx_mmlux_sl-security_studies": 0,
    "ogx_mmlux_sl-sociology": 0,
    "ogx_mmlux_sl-us_foreign_policy": 0,
    "ogx_mmlux_sl-virology": 0,
    "ogx_mmlux_sl-world_religions": 0,
    "ogx_mmlux_sv-abstract_algebra": 0,
    "ogx_mmlux_sv-anatomy": 0,
    "ogx_mmlux_sv-astronomy": 0,
    "ogx_mmlux_sv-business_ethics": 0,
    "ogx_mmlux_sv-clinical_knowledge": 0,
    "ogx_mmlux_sv-college_biology": 0,
    "ogx_mmlux_sv-college_chemistry": 0,
    "ogx_mmlux_sv-college_computer_science": 0,
    "ogx_mmlux_sv-college_mathematics": 0,
    "ogx_mmlux_sv-college_medicine": 0,
    "ogx_mmlux_sv-college_physics": 0,
    "ogx_mmlux_sv-computer_security": 0,
    "ogx_mmlux_sv-conceptual_physics": 0,
    "ogx_mmlux_sv-econometrics": 0,
    "ogx_mmlux_sv-electrical_engineering": 0,
    "ogx_mmlux_sv-elementary_mathematics": 0,
    "ogx_mmlux_sv-formal_logic": 0,
    "ogx_mmlux_sv-global_facts": 0,
    "ogx_mmlux_sv-high_school_biology": 0,
    "ogx_mmlux_sv-high_school_chemistry": 0,
    "ogx_mmlux_sv-high_school_computer_science": 0,
    "ogx_mmlux_sv-high_school_european_history": 0,
    "ogx_mmlux_sv-high_school_geography": 0,
    "ogx_mmlux_sv-high_school_government_and_politics": 0,
    "ogx_mmlux_sv-high_school_macroeconomics": 0,
    "ogx_mmlux_sv-high_school_mathematics": 0,
    "ogx_mmlux_sv-high_school_microeconomics": 0,
    "ogx_mmlux_sv-high_school_physics": 0,
    "ogx_mmlux_sv-high_school_psychology": 0,
    "ogx_mmlux_sv-high_school_statistics": 0,
    "ogx_mmlux_sv-high_school_us_history": 0,
    "ogx_mmlux_sv-high_school_world_history": 0,
    "ogx_mmlux_sv-human_aging": 0,
    "ogx_mmlux_sv-human_sexuality": 0,
    "ogx_mmlux_sv-international_law": 0,
    "ogx_mmlux_sv-jurisprudence": 0,
    "ogx_mmlux_sv-logical_fallacies": 0,
    "ogx_mmlux_sv-machine_learning": 0,
    "ogx_mmlux_sv-management": 0,
    "ogx_mmlux_sv-marketing": 0,
    "ogx_mmlux_sv-medical_genetics": 0,
    "ogx_mmlux_sv-miscellaneous": 0,
    "ogx_mmlux_sv-moral_disputes": 0,
    "ogx_mmlux_sv-moral_scenarios": 0,
    "ogx_mmlux_sv-nutrition": 0,
    "ogx_mmlux_sv-philosophy": 0,
    "ogx_mmlux_sv-prehistory": 0,
    "ogx_mmlux_sv-professional_accounting": 0,
    "ogx_mmlux_sv-professional_law": 0,
    "ogx_mmlux_sv-professional_medicine": 0,
    "ogx_mmlux_sv-professional_psychology": 0,
    "ogx_mmlux_sv-public_relations": 0,
    "ogx_mmlux_sv-security_studies": 0,
    "ogx_mmlux_sv-sociology": 0,
    "ogx_mmlux_sv-us_foreign_policy": 0,
    "ogx_mmlux_sv-virology": 0,
    "ogx_mmlux_sv-world_religions": 0
  },
  "n-shot": {
    "ogx_mmlux_bg-abstract_algebra": 5,
    "ogx_mmlux_bg-anatomy": 5,
    "ogx_mmlux_bg-astronomy": 5,
    "ogx_mmlux_bg-business_ethics": 5,
    "ogx_mmlux_bg-clinical_knowledge": 5,
    "ogx_mmlux_bg-college_biology": 5,
    "ogx_mmlux_bg-college_chemistry": 5,
    "ogx_mmlux_bg-college_computer_science": 5,
    "ogx_mmlux_bg-college_mathematics": 5,
    "ogx_mmlux_bg-college_medicine": 5,
    "ogx_mmlux_bg-college_physics": 5,
    "ogx_mmlux_bg-computer_security": 5,
    "ogx_mmlux_bg-conceptual_physics": 5,
    "ogx_mmlux_bg-econometrics": 5,
    "ogx_mmlux_bg-electrical_engineering": 5,
    "ogx_mmlux_bg-elementary_mathematics": 5,
    "ogx_mmlux_bg-formal_logic": 5,
    "ogx_mmlux_bg-global_facts": 5,
    "ogx_mmlux_bg-high_school_biology": 5,
    "ogx_mmlux_bg-high_school_chemistry": 5,
    "ogx_mmlux_bg-high_school_computer_science": 5,
    "ogx_mmlux_bg-high_school_european_history": 5,
    "ogx_mmlux_bg-high_school_geography": 5,
    "ogx_mmlux_bg-high_school_government_and_politics": 5,
    "ogx_mmlux_bg-high_school_macroeconomics": 5,
    "ogx_mmlux_bg-high_school_mathematics": 5,
    "ogx_mmlux_bg-high_school_microeconomics": 5,
    "ogx_mmlux_bg-high_school_physics": 5,
    "ogx_mmlux_bg-high_school_psychology": 5,
    "ogx_mmlux_bg-high_school_statistics": 5,
    "ogx_mmlux_bg-high_school_us_history": 5,
    "ogx_mmlux_bg-high_school_world_history": 5,
    "ogx_mmlux_bg-human_aging": 5,
    "ogx_mmlux_bg-human_sexuality": 5,
    "ogx_mmlux_bg-international_law": 5,
    "ogx_mmlux_bg-jurisprudence": 5,
    "ogx_mmlux_bg-logical_fallacies": 5,
    "ogx_mmlux_bg-machine_learning": 5,
    "ogx_mmlux_bg-management": 5,
    "ogx_mmlux_bg-marketing": 5,
    "ogx_mmlux_bg-medical_genetics": 5,
    "ogx_mmlux_bg-miscellaneous": 5,
    "ogx_mmlux_bg-moral_disputes": 5,
    "ogx_mmlux_bg-moral_scenarios": 5,
    "ogx_mmlux_bg-nutrition": 5,
    "ogx_mmlux_bg-philosophy": 5,
    "ogx_mmlux_bg-prehistory": 5,
    "ogx_mmlux_bg-professional_accounting": 5,
    "ogx_mmlux_bg-professional_law": 5,
    "ogx_mmlux_bg-professional_medicine": 5,
    "ogx_mmlux_bg-professional_psychology": 5,
    "ogx_mmlux_bg-public_relations": 5,
    "ogx_mmlux_bg-security_studies": 5,
    "ogx_mmlux_bg-sociology": 5,
    "ogx_mmlux_bg-us_foreign_policy": 5,
    "ogx_mmlux_bg-virology": 5,
    "ogx_mmlux_bg-world_religions": 5,
    "ogx_mmlux_cs-abstract_algebra": 5,
    "ogx_mmlux_cs-anatomy": 5,
    "ogx_mmlux_cs-astronomy": 5,
    "ogx_mmlux_cs-business_ethics": 5,
    "ogx_mmlux_cs-clinical_knowledge": 5,
    "ogx_mmlux_cs-college_biology": 5,
    "ogx_mmlux_cs-college_chemistry": 5,
    "ogx_mmlux_cs-college_computer_science": 5,
    "ogx_mmlux_cs-college_mathematics": 5,
    "ogx_mmlux_cs-college_medicine": 5,
    "ogx_mmlux_cs-college_physics": 5,
    "ogx_mmlux_cs-computer_security": 5,
    "ogx_mmlux_cs-conceptual_physics": 5,
    "ogx_mmlux_cs-econometrics": 5,
    "ogx_mmlux_cs-electrical_engineering": 5,
    "ogx_mmlux_cs-elementary_mathematics": 5,
    "ogx_mmlux_cs-formal_logic": 5,
    "ogx_mmlux_cs-global_facts": 5,
    "ogx_mmlux_cs-high_school_biology": 5,
    "ogx_mmlux_cs-high_school_chemistry": 5,
    "ogx_mmlux_cs-high_school_computer_science": 5,
    "ogx_mmlux_cs-high_school_european_history": 5,
    "ogx_mmlux_cs-high_school_geography": 5,
    "ogx_mmlux_cs-high_school_government_and_politics": 5,
    "ogx_mmlux_cs-high_school_macroeconomics": 5,
    "ogx_mmlux_cs-high_school_mathematics": 5,
    "ogx_mmlux_cs-high_school_microeconomics": 5,
    "ogx_mmlux_cs-high_school_physics": 5,
    "ogx_mmlux_cs-high_school_psychology": 5,
    "ogx_mmlux_cs-high_school_statistics": 5,
    "ogx_mmlux_cs-high_school_us_history": 5,
    "ogx_mmlux_cs-high_school_world_history": 5,
    "ogx_mmlux_cs-human_aging": 5,
    "ogx_mmlux_cs-human_sexuality": 5,
    "ogx_mmlux_cs-international_law": 5,
    "ogx_mmlux_cs-jurisprudence": 5,
    "ogx_mmlux_cs-logical_fallacies": 5,
    "ogx_mmlux_cs-machine_learning": 5,
    "ogx_mmlux_cs-management": 5,
    "ogx_mmlux_cs-marketing": 5,
    "ogx_mmlux_cs-medical_genetics": 5,
    "ogx_mmlux_cs-miscellaneous": 5,
    "ogx_mmlux_cs-moral_disputes": 5,
    "ogx_mmlux_cs-moral_scenarios": 5,
    "ogx_mmlux_cs-nutrition": 5,
    "ogx_mmlux_cs-philosophy": 5,
    "ogx_mmlux_cs-prehistory": 5,
    "ogx_mmlux_cs-professional_accounting": 5,
    "ogx_mmlux_cs-professional_law": 5,
    "ogx_mmlux_cs-professional_medicine": 5,
    "ogx_mmlux_cs-professional_psychology": 5,
    "ogx_mmlux_cs-public_relations": 5,
    "ogx_mmlux_cs-security_studies": 5,
    "ogx_mmlux_cs-sociology": 5,
    "ogx_mmlux_cs-us_foreign_policy": 5,
    "ogx_mmlux_cs-virology": 5,
    "ogx_mmlux_cs-world_religions": 5,
    "ogx_mmlux_da-abstract_algebra": 5,
    "ogx_mmlux_da-anatomy": 5,
    "ogx_mmlux_da-astronomy": 5,
    "ogx_mmlux_da-business_ethics": 5,
    "ogx_mmlux_da-clinical_knowledge": 5,
    "ogx_mmlux_da-college_biology": 5,
    "ogx_mmlux_da-college_chemistry": 5,
    "ogx_mmlux_da-college_computer_science": 5,
    "ogx_mmlux_da-college_mathematics": 5,
    "ogx_mmlux_da-college_medicine": 5,
    "ogx_mmlux_da-college_physics": 5,
    "ogx_mmlux_da-computer_security": 5,
    "ogx_mmlux_da-conceptual_physics": 5,
    "ogx_mmlux_da-econometrics": 5,
    "ogx_mmlux_da-electrical_engineering": 5,
    "ogx_mmlux_da-elementary_mathematics": 5,
    "ogx_mmlux_da-formal_logic": 5,
    "ogx_mmlux_da-global_facts": 5,
    "ogx_mmlux_da-high_school_biology": 5,
    "ogx_mmlux_da-high_school_chemistry": 5,
    "ogx_mmlux_da-high_school_computer_science": 5,
    "ogx_mmlux_da-high_school_european_history": 5,
    "ogx_mmlux_da-high_school_geography": 5,
    "ogx_mmlux_da-high_school_government_and_politics": 5,
    "ogx_mmlux_da-high_school_macroeconomics": 5,
    "ogx_mmlux_da-high_school_mathematics": 5,
    "ogx_mmlux_da-high_school_microeconomics": 5,
    "ogx_mmlux_da-high_school_physics": 5,
    "ogx_mmlux_da-high_school_psychology": 5,
    "ogx_mmlux_da-high_school_statistics": 5,
    "ogx_mmlux_da-high_school_us_history": 5,
    "ogx_mmlux_da-high_school_world_history": 5,
    "ogx_mmlux_da-human_aging": 5,
    "ogx_mmlux_da-human_sexuality": 5,
    "ogx_mmlux_da-international_law": 5,
    "ogx_mmlux_da-jurisprudence": 5,
    "ogx_mmlux_da-logical_fallacies": 5,
    "ogx_mmlux_da-machine_learning": 5,
    "ogx_mmlux_da-management": 5,
    "ogx_mmlux_da-marketing": 5,
    "ogx_mmlux_da-medical_genetics": 5,
    "ogx_mmlux_da-miscellaneous": 5,
    "ogx_mmlux_da-moral_disputes": 5,
    "ogx_mmlux_da-moral_scenarios": 5,
    "ogx_mmlux_da-nutrition": 5,
    "ogx_mmlux_da-philosophy": 5,
    "ogx_mmlux_da-prehistory": 5,
    "ogx_mmlux_da-professional_accounting": 5,
    "ogx_mmlux_da-professional_law": 5,
    "ogx_mmlux_da-professional_medicine": 5,
    "ogx_mmlux_da-professional_psychology": 5,
    "ogx_mmlux_da-public_relations": 5,
    "ogx_mmlux_da-security_studies": 5,
    "ogx_mmlux_da-sociology": 5,
    "ogx_mmlux_da-us_foreign_policy": 5,
    "ogx_mmlux_da-virology": 5,
    "ogx_mmlux_da-world_religions": 5,
    "ogx_mmlux_de-abstract_algebra": 5,
    "ogx_mmlux_de-anatomy": 5,
    "ogx_mmlux_de-astronomy": 5,
    "ogx_mmlux_de-business_ethics": 5,
    "ogx_mmlux_de-clinical_knowledge": 5,
    "ogx_mmlux_de-college_biology": 5,
    "ogx_mmlux_de-college_chemistry": 5,
    "ogx_mmlux_de-college_computer_science": 5,
    "ogx_mmlux_de-college_mathematics": 5,
    "ogx_mmlux_de-college_medicine": 5,
    "ogx_mmlux_de-college_physics": 5,
    "ogx_mmlux_de-computer_security": 5,
    "ogx_mmlux_de-conceptual_physics": 5,
    "ogx_mmlux_de-econometrics": 5,
    "ogx_mmlux_de-electrical_engineering": 5,
    "ogx_mmlux_de-elementary_mathematics": 5,
    "ogx_mmlux_de-formal_logic": 5,
    "ogx_mmlux_de-global_facts": 5,
    "ogx_mmlux_de-high_school_biology": 5,
    "ogx_mmlux_de-high_school_chemistry": 5,
    "ogx_mmlux_de-high_school_computer_science": 5,
    "ogx_mmlux_de-high_school_european_history": 5,
    "ogx_mmlux_de-high_school_geography": 5,
    "ogx_mmlux_de-high_school_government_and_politics": 5,
    "ogx_mmlux_de-high_school_macroeconomics": 5,
    "ogx_mmlux_de-high_school_mathematics": 5,
    "ogx_mmlux_de-high_school_microeconomics": 5,
    "ogx_mmlux_de-high_school_physics": 5,
    "ogx_mmlux_de-high_school_psychology": 5,
    "ogx_mmlux_de-high_school_statistics": 5,
    "ogx_mmlux_de-high_school_us_history": 5,
    "ogx_mmlux_de-high_school_world_history": 5,
    "ogx_mmlux_de-human_aging": 5,
    "ogx_mmlux_de-human_sexuality": 5,
    "ogx_mmlux_de-international_law": 5,
    "ogx_mmlux_de-jurisprudence": 5,
    "ogx_mmlux_de-logical_fallacies": 5,
    "ogx_mmlux_de-machine_learning": 5,
    "ogx_mmlux_de-management": 5,
    "ogx_mmlux_de-marketing": 5,
    "ogx_mmlux_de-medical_genetics": 5,
    "ogx_mmlux_de-miscellaneous": 5,
    "ogx_mmlux_de-moral_disputes": 5,
    "ogx_mmlux_de-moral_scenarios": 5,
    "ogx_mmlux_de-nutrition": 5,
    "ogx_mmlux_de-philosophy": 5,
    "ogx_mmlux_de-prehistory": 5,
    "ogx_mmlux_de-professional_accounting": 5,
    "ogx_mmlux_de-professional_law": 5,
    "ogx_mmlux_de-professional_medicine": 5,
    "ogx_mmlux_de-professional_psychology": 5,
    "ogx_mmlux_de-public_relations": 5,
    "ogx_mmlux_de-security_studies": 5,
    "ogx_mmlux_de-sociology": 5,
    "ogx_mmlux_de-us_foreign_policy": 5,
    "ogx_mmlux_de-virology": 5,
    "ogx_mmlux_de-world_religions": 5,
    "ogx_mmlux_el-abstract_algebra": 5,
    "ogx_mmlux_el-anatomy": 5,
    "ogx_mmlux_el-astronomy": 5,
    "ogx_mmlux_el-business_ethics": 5,
    "ogx_mmlux_el-clinical_knowledge": 5,
    "ogx_mmlux_el-college_biology": 5,
    "ogx_mmlux_el-college_chemistry": 5,
    "ogx_mmlux_el-college_computer_science": 5,
    "ogx_mmlux_el-college_mathematics": 5,
    "ogx_mmlux_el-college_medicine": 5,
    "ogx_mmlux_el-college_physics": 5,
    "ogx_mmlux_el-computer_security": 5,
    "ogx_mmlux_el-conceptual_physics": 5,
    "ogx_mmlux_el-econometrics": 5,
    "ogx_mmlux_el-electrical_engineering": 5,
    "ogx_mmlux_el-elementary_mathematics": 5,
    "ogx_mmlux_el-formal_logic": 5,
    "ogx_mmlux_el-global_facts": 5,
    "ogx_mmlux_el-high_school_biology": 5,
    "ogx_mmlux_el-high_school_chemistry": 5,
    "ogx_mmlux_el-high_school_computer_science": 5,
    "ogx_mmlux_el-high_school_european_history": 5,
    "ogx_mmlux_el-high_school_geography": 5,
    "ogx_mmlux_el-high_school_government_and_politics": 5,
    "ogx_mmlux_el-high_school_macroeconomics": 5,
    "ogx_mmlux_el-high_school_mathematics": 5,
    "ogx_mmlux_el-high_school_microeconomics": 5,
    "ogx_mmlux_el-high_school_physics": 5,
    "ogx_mmlux_el-high_school_psychology": 5,
    "ogx_mmlux_el-high_school_statistics": 5,
    "ogx_mmlux_el-high_school_us_history": 5,
    "ogx_mmlux_el-high_school_world_history": 5,
    "ogx_mmlux_el-human_aging": 5,
    "ogx_mmlux_el-human_sexuality": 5,
    "ogx_mmlux_el-international_law": 5,
    "ogx_mmlux_el-jurisprudence": 5,
    "ogx_mmlux_el-logical_fallacies": 5,
    "ogx_mmlux_el-machine_learning": 5,
    "ogx_mmlux_el-management": 5,
    "ogx_mmlux_el-marketing": 5,
    "ogx_mmlux_el-medical_genetics": 5,
    "ogx_mmlux_el-miscellaneous": 5,
    "ogx_mmlux_el-moral_disputes": 5,
    "ogx_mmlux_el-moral_scenarios": 5,
    "ogx_mmlux_el-nutrition": 5,
    "ogx_mmlux_el-philosophy": 5,
    "ogx_mmlux_el-prehistory": 5,
    "ogx_mmlux_el-professional_accounting": 5,
    "ogx_mmlux_el-professional_law": 5,
    "ogx_mmlux_el-professional_medicine": 5,
    "ogx_mmlux_el-professional_psychology": 5,
    "ogx_mmlux_el-public_relations": 5,
    "ogx_mmlux_el-security_studies": 5,
    "ogx_mmlux_el-sociology": 5,
    "ogx_mmlux_el-us_foreign_policy": 5,
    "ogx_mmlux_el-virology": 5,
    "ogx_mmlux_el-world_religions": 5,
    "ogx_mmlux_es-abstract_algebra": 5,
    "ogx_mmlux_es-anatomy": 5,
    "ogx_mmlux_es-astronomy": 5,
    "ogx_mmlux_es-business_ethics": 5,
    "ogx_mmlux_es-clinical_knowledge": 5,
    "ogx_mmlux_es-college_biology": 5,
    "ogx_mmlux_es-college_chemistry": 5,
    "ogx_mmlux_es-college_computer_science": 5,
    "ogx_mmlux_es-college_mathematics": 5,
    "ogx_mmlux_es-college_medicine": 5,
    "ogx_mmlux_es-college_physics": 5,
    "ogx_mmlux_es-computer_security": 5,
    "ogx_mmlux_es-conceptual_physics": 5,
    "ogx_mmlux_es-econometrics": 5,
    "ogx_mmlux_es-electrical_engineering": 5,
    "ogx_mmlux_es-elementary_mathematics": 5,
    "ogx_mmlux_es-formal_logic": 5,
    "ogx_mmlux_es-global_facts": 5,
    "ogx_mmlux_es-high_school_biology": 5,
    "ogx_mmlux_es-high_school_chemistry": 5,
    "ogx_mmlux_es-high_school_computer_science": 5,
    "ogx_mmlux_es-high_school_european_history": 5,
    "ogx_mmlux_es-high_school_geography": 5,
    "ogx_mmlux_es-high_school_government_and_politics": 5,
    "ogx_mmlux_es-high_school_macroeconomics": 5,
    "ogx_mmlux_es-high_school_mathematics": 5,
    "ogx_mmlux_es-high_school_microeconomics": 5,
    "ogx_mmlux_es-high_school_physics": 5,
    "ogx_mmlux_es-high_school_psychology": 5,
    "ogx_mmlux_es-high_school_statistics": 5,
    "ogx_mmlux_es-high_school_us_history": 5,
    "ogx_mmlux_es-high_school_world_history": 5,
    "ogx_mmlux_es-human_aging": 5,
    "ogx_mmlux_es-human_sexuality": 5,
    "ogx_mmlux_es-international_law": 5,
    "ogx_mmlux_es-jurisprudence": 5,
    "ogx_mmlux_es-logical_fallacies": 5,
    "ogx_mmlux_es-machine_learning": 5,
    "ogx_mmlux_es-management": 5,
    "ogx_mmlux_es-marketing": 5,
    "ogx_mmlux_es-medical_genetics": 5,
    "ogx_mmlux_es-miscellaneous": 5,
    "ogx_mmlux_es-moral_disputes": 5,
    "ogx_mmlux_es-moral_scenarios": 5,
    "ogx_mmlux_es-nutrition": 5,
    "ogx_mmlux_es-philosophy": 5,
    "ogx_mmlux_es-prehistory": 5,
    "ogx_mmlux_es-professional_accounting": 5,
    "ogx_mmlux_es-professional_law": 5,
    "ogx_mmlux_es-professional_medicine": 5,
    "ogx_mmlux_es-professional_psychology": 5,
    "ogx_mmlux_es-public_relations": 5,
    "ogx_mmlux_es-security_studies": 5,
    "ogx_mmlux_es-sociology": 5,
    "ogx_mmlux_es-us_foreign_policy": 5,
    "ogx_mmlux_es-virology": 5,
    "ogx_mmlux_es-world_religions": 5,
    "ogx_mmlux_et-abstract_algebra": 5,
    "ogx_mmlux_et-anatomy": 5,
    "ogx_mmlux_et-astronomy": 5,
    "ogx_mmlux_et-business_ethics": 5,
    "ogx_mmlux_et-clinical_knowledge": 5,
    "ogx_mmlux_et-college_biology": 5,
    "ogx_mmlux_et-college_chemistry": 5,
    "ogx_mmlux_et-college_computer_science": 5,
    "ogx_mmlux_et-college_mathematics": 5,
    "ogx_mmlux_et-college_medicine": 5,
    "ogx_mmlux_et-college_physics": 5,
    "ogx_mmlux_et-computer_security": 5,
    "ogx_mmlux_et-conceptual_physics": 5,
    "ogx_mmlux_et-econometrics": 5,
    "ogx_mmlux_et-electrical_engineering": 5,
    "ogx_mmlux_et-elementary_mathematics": 5,
    "ogx_mmlux_et-formal_logic": 5,
    "ogx_mmlux_et-global_facts": 5,
    "ogx_mmlux_et-high_school_biology": 5,
    "ogx_mmlux_et-high_school_chemistry": 5,
    "ogx_mmlux_et-high_school_computer_science": 5,
    "ogx_mmlux_et-high_school_european_history": 5,
    "ogx_mmlux_et-high_school_geography": 5,
    "ogx_mmlux_et-high_school_government_and_politics": 5,
    "ogx_mmlux_et-high_school_macroeconomics": 5,
    "ogx_mmlux_et-high_school_mathematics": 5,
    "ogx_mmlux_et-high_school_microeconomics": 5,
    "ogx_mmlux_et-high_school_physics": 5,
    "ogx_mmlux_et-high_school_psychology": 5,
    "ogx_mmlux_et-high_school_statistics": 5,
    "ogx_mmlux_et-high_school_us_history": 5,
    "ogx_mmlux_et-high_school_world_history": 5,
    "ogx_mmlux_et-human_aging": 5,
    "ogx_mmlux_et-human_sexuality": 5,
    "ogx_mmlux_et-international_law": 5,
    "ogx_mmlux_et-jurisprudence": 5,
    "ogx_mmlux_et-logical_fallacies": 5,
    "ogx_mmlux_et-machine_learning": 5,
    "ogx_mmlux_et-management": 5,
    "ogx_mmlux_et-marketing": 5,
    "ogx_mmlux_et-medical_genetics": 5,
    "ogx_mmlux_et-miscellaneous": 5,
    "ogx_mmlux_et-moral_disputes": 5,
    "ogx_mmlux_et-moral_scenarios": 5,
    "ogx_mmlux_et-nutrition": 5,
    "ogx_mmlux_et-philosophy": 5,
    "ogx_mmlux_et-prehistory": 5,
    "ogx_mmlux_et-professional_accounting": 5,
    "ogx_mmlux_et-professional_law": 5,
    "ogx_mmlux_et-professional_medicine": 5,
    "ogx_mmlux_et-professional_psychology": 5,
    "ogx_mmlux_et-public_relations": 5,
    "ogx_mmlux_et-security_studies": 5,
    "ogx_mmlux_et-sociology": 5,
    "ogx_mmlux_et-us_foreign_policy": 5,
    "ogx_mmlux_et-virology": 5,
    "ogx_mmlux_et-world_religions": 5,
    "ogx_mmlux_fi-abstract_algebra": 5,
    "ogx_mmlux_fi-anatomy": 5,
    "ogx_mmlux_fi-astronomy": 5,
    "ogx_mmlux_fi-business_ethics": 5,
    "ogx_mmlux_fi-clinical_knowledge": 5,
    "ogx_mmlux_fi-college_biology": 5,
    "ogx_mmlux_fi-college_chemistry": 5,
    "ogx_mmlux_fi-college_computer_science": 5,
    "ogx_mmlux_fi-college_mathematics": 5,
    "ogx_mmlux_fi-college_medicine": 5,
    "ogx_mmlux_fi-college_physics": 5,
    "ogx_mmlux_fi-computer_security": 5,
    "ogx_mmlux_fi-conceptual_physics": 5,
    "ogx_mmlux_fi-econometrics": 5,
    "ogx_mmlux_fi-electrical_engineering": 5,
    "ogx_mmlux_fi-elementary_mathematics": 5,
    "ogx_mmlux_fi-formal_logic": 5,
    "ogx_mmlux_fi-global_facts": 5,
    "ogx_mmlux_fi-high_school_biology": 5,
    "ogx_mmlux_fi-high_school_chemistry": 5,
    "ogx_mmlux_fi-high_school_computer_science": 5,
    "ogx_mmlux_fi-high_school_european_history": 5,
    "ogx_mmlux_fi-high_school_geography": 5,
    "ogx_mmlux_fi-high_school_government_and_politics": 5,
    "ogx_mmlux_fi-high_school_macroeconomics": 5,
    "ogx_mmlux_fi-high_school_mathematics": 5,
    "ogx_mmlux_fi-high_school_microeconomics": 5,
    "ogx_mmlux_fi-high_school_physics": 5,
    "ogx_mmlux_fi-high_school_psychology": 5,
    "ogx_mmlux_fi-high_school_statistics": 5,
    "ogx_mmlux_fi-high_school_us_history": 5,
    "ogx_mmlux_fi-high_school_world_history": 5,
    "ogx_mmlux_fi-human_aging": 5,
    "ogx_mmlux_fi-human_sexuality": 5,
    "ogx_mmlux_fi-international_law": 5,
    "ogx_mmlux_fi-jurisprudence": 5,
    "ogx_mmlux_fi-logical_fallacies": 5,
    "ogx_mmlux_fi-machine_learning": 5,
    "ogx_mmlux_fi-management": 5,
    "ogx_mmlux_fi-marketing": 5,
    "ogx_mmlux_fi-medical_genetics": 5,
    "ogx_mmlux_fi-miscellaneous": 5,
    "ogx_mmlux_fi-moral_disputes": 5,
    "ogx_mmlux_fi-moral_scenarios": 5,
    "ogx_mmlux_fi-nutrition": 5,
    "ogx_mmlux_fi-philosophy": 5,
    "ogx_mmlux_fi-prehistory": 5,
    "ogx_mmlux_fi-professional_accounting": 5,
    "ogx_mmlux_fi-professional_law": 5,
    "ogx_mmlux_fi-professional_medicine": 5,
    "ogx_mmlux_fi-professional_psychology": 5,
    "ogx_mmlux_fi-public_relations": 5,
    "ogx_mmlux_fi-security_studies": 5,
    "ogx_mmlux_fi-sociology": 5,
    "ogx_mmlux_fi-us_foreign_policy": 5,
    "ogx_mmlux_fi-virology": 5,
    "ogx_mmlux_fi-world_religions": 5,
    "ogx_mmlux_fr-abstract_algebra": 5,
    "ogx_mmlux_fr-anatomy": 5,
    "ogx_mmlux_fr-astronomy": 5,
    "ogx_mmlux_fr-business_ethics": 5,
    "ogx_mmlux_fr-clinical_knowledge": 5,
    "ogx_mmlux_fr-college_biology": 5,
    "ogx_mmlux_fr-college_chemistry": 5,
    "ogx_mmlux_fr-college_computer_science": 5,
    "ogx_mmlux_fr-college_mathematics": 5,
    "ogx_mmlux_fr-college_medicine": 5,
    "ogx_mmlux_fr-college_physics": 5,
    "ogx_mmlux_fr-computer_security": 5,
    "ogx_mmlux_fr-conceptual_physics": 5,
    "ogx_mmlux_fr-econometrics": 5,
    "ogx_mmlux_fr-electrical_engineering": 5,
    "ogx_mmlux_fr-elementary_mathematics": 5,
    "ogx_mmlux_fr-formal_logic": 5,
    "ogx_mmlux_fr-global_facts": 5,
    "ogx_mmlux_fr-high_school_biology": 5,
    "ogx_mmlux_fr-high_school_chemistry": 5,
    "ogx_mmlux_fr-high_school_computer_science": 5,
    "ogx_mmlux_fr-high_school_european_history": 5,
    "ogx_mmlux_fr-high_school_geography": 5,
    "ogx_mmlux_fr-high_school_government_and_politics": 5,
    "ogx_mmlux_fr-high_school_macroeconomics": 5,
    "ogx_mmlux_fr-high_school_mathematics": 5,
    "ogx_mmlux_fr-high_school_microeconomics": 5,
    "ogx_mmlux_fr-high_school_physics": 5,
    "ogx_mmlux_fr-high_school_psychology": 5,
    "ogx_mmlux_fr-high_school_statistics": 5,
    "ogx_mmlux_fr-high_school_us_history": 5,
    "ogx_mmlux_fr-high_school_world_history": 5,
    "ogx_mmlux_fr-human_aging": 5,
    "ogx_mmlux_fr-human_sexuality": 5,
    "ogx_mmlux_fr-international_law": 5,
    "ogx_mmlux_fr-jurisprudence": 5,
    "ogx_mmlux_fr-logical_fallacies": 5,
    "ogx_mmlux_fr-machine_learning": 5,
    "ogx_mmlux_fr-management": 5,
    "ogx_mmlux_fr-marketing": 5,
    "ogx_mmlux_fr-medical_genetics": 5,
    "ogx_mmlux_fr-miscellaneous": 5,
    "ogx_mmlux_fr-moral_disputes": 5,
    "ogx_mmlux_fr-moral_scenarios": 5,
    "ogx_mmlux_fr-nutrition": 5,
    "ogx_mmlux_fr-philosophy": 5,
    "ogx_mmlux_fr-prehistory": 5,
    "ogx_mmlux_fr-professional_accounting": 5,
    "ogx_mmlux_fr-professional_law": 5,
    "ogx_mmlux_fr-professional_medicine": 5,
    "ogx_mmlux_fr-professional_psychology": 5,
    "ogx_mmlux_fr-public_relations": 5,
    "ogx_mmlux_fr-security_studies": 5,
    "ogx_mmlux_fr-sociology": 5,
    "ogx_mmlux_fr-us_foreign_policy": 5,
    "ogx_mmlux_fr-virology": 5,
    "ogx_mmlux_fr-world_religions": 5,
    "ogx_mmlux_hu-abstract_algebra": 5,
    "ogx_mmlux_hu-anatomy": 5,
    "ogx_mmlux_hu-astronomy": 5,
    "ogx_mmlux_hu-business_ethics": 5,
    "ogx_mmlux_hu-clinical_knowledge": 5,
    "ogx_mmlux_hu-college_biology": 5,
    "ogx_mmlux_hu-college_chemistry": 5,
    "ogx_mmlux_hu-college_computer_science": 5,
    "ogx_mmlux_hu-college_mathematics": 5,
    "ogx_mmlux_hu-college_medicine": 5,
    "ogx_mmlux_hu-college_physics": 5,
    "ogx_mmlux_hu-computer_security": 5,
    "ogx_mmlux_hu-conceptual_physics": 5,
    "ogx_mmlux_hu-econometrics": 5,
    "ogx_mmlux_hu-electrical_engineering": 5,
    "ogx_mmlux_hu-elementary_mathematics": 5,
    "ogx_mmlux_hu-formal_logic": 5,
    "ogx_mmlux_hu-global_facts": 5,
    "ogx_mmlux_hu-high_school_biology": 5,
    "ogx_mmlux_hu-high_school_chemistry": 5,
    "ogx_mmlux_hu-high_school_computer_science": 5,
    "ogx_mmlux_hu-high_school_european_history": 5,
    "ogx_mmlux_hu-high_school_geography": 5,
    "ogx_mmlux_hu-high_school_government_and_politics": 5,
    "ogx_mmlux_hu-high_school_macroeconomics": 5,
    "ogx_mmlux_hu-high_school_mathematics": 5,
    "ogx_mmlux_hu-high_school_microeconomics": 5,
    "ogx_mmlux_hu-high_school_physics": 5,
    "ogx_mmlux_hu-high_school_psychology": 5,
    "ogx_mmlux_hu-high_school_statistics": 5,
    "ogx_mmlux_hu-high_school_us_history": 5,
    "ogx_mmlux_hu-high_school_world_history": 5,
    "ogx_mmlux_hu-human_aging": 5,
    "ogx_mmlux_hu-human_sexuality": 5,
    "ogx_mmlux_hu-international_law": 5,
    "ogx_mmlux_hu-jurisprudence": 5,
    "ogx_mmlux_hu-logical_fallacies": 5,
    "ogx_mmlux_hu-machine_learning": 5,
    "ogx_mmlux_hu-management": 5,
    "ogx_mmlux_hu-marketing": 5,
    "ogx_mmlux_hu-medical_genetics": 5,
    "ogx_mmlux_hu-miscellaneous": 5,
    "ogx_mmlux_hu-moral_disputes": 5,
    "ogx_mmlux_hu-moral_scenarios": 5,
    "ogx_mmlux_hu-nutrition": 5,
    "ogx_mmlux_hu-philosophy": 5,
    "ogx_mmlux_hu-prehistory": 5,
    "ogx_mmlux_hu-professional_accounting": 5,
    "ogx_mmlux_hu-professional_law": 5,
    "ogx_mmlux_hu-professional_medicine": 5,
    "ogx_mmlux_hu-professional_psychology": 5,
    "ogx_mmlux_hu-public_relations": 5,
    "ogx_mmlux_hu-security_studies": 5,
    "ogx_mmlux_hu-sociology": 5,
    "ogx_mmlux_hu-us_foreign_policy": 5,
    "ogx_mmlux_hu-virology": 5,
    "ogx_mmlux_hu-world_religions": 5,
    "ogx_mmlux_it-abstract_algebra": 5,
    "ogx_mmlux_it-anatomy": 5,
    "ogx_mmlux_it-astronomy": 5,
    "ogx_mmlux_it-business_ethics": 5,
    "ogx_mmlux_it-clinical_knowledge": 5,
    "ogx_mmlux_it-college_biology": 5,
    "ogx_mmlux_it-college_chemistry": 5,
    "ogx_mmlux_it-college_computer_science": 5,
    "ogx_mmlux_it-college_mathematics": 5,
    "ogx_mmlux_it-college_medicine": 5,
    "ogx_mmlux_it-college_physics": 5,
    "ogx_mmlux_it-computer_security": 5,
    "ogx_mmlux_it-conceptual_physics": 5,
    "ogx_mmlux_it-econometrics": 5,
    "ogx_mmlux_it-electrical_engineering": 5,
    "ogx_mmlux_it-elementary_mathematics": 5,
    "ogx_mmlux_it-formal_logic": 5,
    "ogx_mmlux_it-global_facts": 5,
    "ogx_mmlux_it-high_school_biology": 5,
    "ogx_mmlux_it-high_school_chemistry": 5,
    "ogx_mmlux_it-high_school_computer_science": 5,
    "ogx_mmlux_it-high_school_european_history": 5,
    "ogx_mmlux_it-high_school_geography": 5,
    "ogx_mmlux_it-high_school_government_and_politics": 5,
    "ogx_mmlux_it-high_school_macroeconomics": 5,
    "ogx_mmlux_it-high_school_mathematics": 5,
    "ogx_mmlux_it-high_school_microeconomics": 5,
    "ogx_mmlux_it-high_school_physics": 5,
    "ogx_mmlux_it-high_school_psychology": 5,
    "ogx_mmlux_it-high_school_statistics": 5,
    "ogx_mmlux_it-high_school_us_history": 5,
    "ogx_mmlux_it-high_school_world_history": 5,
    "ogx_mmlux_it-human_aging": 5,
    "ogx_mmlux_it-human_sexuality": 5,
    "ogx_mmlux_it-international_law": 5,
    "ogx_mmlux_it-jurisprudence": 5,
    "ogx_mmlux_it-logical_fallacies": 5,
    "ogx_mmlux_it-machine_learning": 5,
    "ogx_mmlux_it-management": 5,
    "ogx_mmlux_it-marketing": 5,
    "ogx_mmlux_it-medical_genetics": 5,
    "ogx_mmlux_it-miscellaneous": 5,
    "ogx_mmlux_it-moral_disputes": 5,
    "ogx_mmlux_it-moral_scenarios": 5,
    "ogx_mmlux_it-nutrition": 5,
    "ogx_mmlux_it-philosophy": 5,
    "ogx_mmlux_it-prehistory": 5,
    "ogx_mmlux_it-professional_accounting": 5,
    "ogx_mmlux_it-professional_law": 5,
    "ogx_mmlux_it-professional_medicine": 5,
    "ogx_mmlux_it-professional_psychology": 5,
    "ogx_mmlux_it-public_relations": 5,
    "ogx_mmlux_it-security_studies": 5,
    "ogx_mmlux_it-sociology": 5,
    "ogx_mmlux_it-us_foreign_policy": 5,
    "ogx_mmlux_it-virology": 5,
    "ogx_mmlux_it-world_religions": 5,
    "ogx_mmlux_lt-abstract_algebra": 5,
    "ogx_mmlux_lt-anatomy": 5,
    "ogx_mmlux_lt-astronomy": 5,
    "ogx_mmlux_lt-business_ethics": 5,
    "ogx_mmlux_lt-clinical_knowledge": 5,
    "ogx_mmlux_lt-college_biology": 5,
    "ogx_mmlux_lt-college_chemistry": 5,
    "ogx_mmlux_lt-college_computer_science": 5,
    "ogx_mmlux_lt-college_mathematics": 5,
    "ogx_mmlux_lt-college_medicine": 5,
    "ogx_mmlux_lt-college_physics": 5,
    "ogx_mmlux_lt-computer_security": 5,
    "ogx_mmlux_lt-conceptual_physics": 5,
    "ogx_mmlux_lt-econometrics": 5,
    "ogx_mmlux_lt-electrical_engineering": 5,
    "ogx_mmlux_lt-elementary_mathematics": 5,
    "ogx_mmlux_lt-formal_logic": 5,
    "ogx_mmlux_lt-global_facts": 5,
    "ogx_mmlux_lt-high_school_biology": 5,
    "ogx_mmlux_lt-high_school_chemistry": 5,
    "ogx_mmlux_lt-high_school_computer_science": 5,
    "ogx_mmlux_lt-high_school_european_history": 5,
    "ogx_mmlux_lt-high_school_geography": 5,
    "ogx_mmlux_lt-high_school_government_and_politics": 5,
    "ogx_mmlux_lt-high_school_macroeconomics": 5,
    "ogx_mmlux_lt-high_school_mathematics": 5,
    "ogx_mmlux_lt-high_school_microeconomics": 5,
    "ogx_mmlux_lt-high_school_physics": 5,
    "ogx_mmlux_lt-high_school_psychology": 5,
    "ogx_mmlux_lt-high_school_statistics": 5,
    "ogx_mmlux_lt-high_school_us_history": 5,
    "ogx_mmlux_lt-high_school_world_history": 5,
    "ogx_mmlux_lt-human_aging": 5,
    "ogx_mmlux_lt-human_sexuality": 5,
    "ogx_mmlux_lt-international_law": 5,
    "ogx_mmlux_lt-jurisprudence": 5,
    "ogx_mmlux_lt-logical_fallacies": 5,
    "ogx_mmlux_lt-machine_learning": 5,
    "ogx_mmlux_lt-management": 5,
    "ogx_mmlux_lt-marketing": 5,
    "ogx_mmlux_lt-medical_genetics": 5,
    "ogx_mmlux_lt-miscellaneous": 5,
    "ogx_mmlux_lt-moral_disputes": 5,
    "ogx_mmlux_lt-moral_scenarios": 5,
    "ogx_mmlux_lt-nutrition": 5,
    "ogx_mmlux_lt-philosophy": 5,
    "ogx_mmlux_lt-prehistory": 5,
    "ogx_mmlux_lt-professional_accounting": 5,
    "ogx_mmlux_lt-professional_law": 5,
    "ogx_mmlux_lt-professional_medicine": 5,
    "ogx_mmlux_lt-professional_psychology": 5,
    "ogx_mmlux_lt-public_relations": 5,
    "ogx_mmlux_lt-security_studies": 5,
    "ogx_mmlux_lt-sociology": 5,
    "ogx_mmlux_lt-us_foreign_policy": 5,
    "ogx_mmlux_lt-virology": 5,
    "ogx_mmlux_lt-world_religions": 5,
    "ogx_mmlux_lv-abstract_algebra": 5,
    "ogx_mmlux_lv-anatomy": 5,
    "ogx_mmlux_lv-astronomy": 5,
    "ogx_mmlux_lv-business_ethics": 5,
    "ogx_mmlux_lv-clinical_knowledge": 5,
    "ogx_mmlux_lv-college_biology": 5,
    "ogx_mmlux_lv-college_chemistry": 5,
    "ogx_mmlux_lv-college_computer_science": 5,
    "ogx_mmlux_lv-college_mathematics": 5,
    "ogx_mmlux_lv-college_medicine": 5,
    "ogx_mmlux_lv-college_physics": 5,
    "ogx_mmlux_lv-computer_security": 5,
    "ogx_mmlux_lv-conceptual_physics": 5,
    "ogx_mmlux_lv-econometrics": 5,
    "ogx_mmlux_lv-electrical_engineering": 5,
    "ogx_mmlux_lv-elementary_mathematics": 5,
    "ogx_mmlux_lv-formal_logic": 5,
    "ogx_mmlux_lv-global_facts": 5,
    "ogx_mmlux_lv-high_school_biology": 5,
    "ogx_mmlux_lv-high_school_chemistry": 5,
    "ogx_mmlux_lv-high_school_computer_science": 5,
    "ogx_mmlux_lv-high_school_european_history": 5,
    "ogx_mmlux_lv-high_school_geography": 5,
    "ogx_mmlux_lv-high_school_government_and_politics": 5,
    "ogx_mmlux_lv-high_school_macroeconomics": 5,
    "ogx_mmlux_lv-high_school_mathematics": 5,
    "ogx_mmlux_lv-high_school_microeconomics": 5,
    "ogx_mmlux_lv-high_school_physics": 5,
    "ogx_mmlux_lv-high_school_psychology": 5,
    "ogx_mmlux_lv-high_school_statistics": 5,
    "ogx_mmlux_lv-high_school_us_history": 5,
    "ogx_mmlux_lv-high_school_world_history": 5,
    "ogx_mmlux_lv-human_aging": 5,
    "ogx_mmlux_lv-human_sexuality": 5,
    "ogx_mmlux_lv-international_law": 5,
    "ogx_mmlux_lv-jurisprudence": 5,
    "ogx_mmlux_lv-logical_fallacies": 5,
    "ogx_mmlux_lv-machine_learning": 5,
    "ogx_mmlux_lv-management": 5,
    "ogx_mmlux_lv-marketing": 5,
    "ogx_mmlux_lv-medical_genetics": 5,
    "ogx_mmlux_lv-miscellaneous": 5,
    "ogx_mmlux_lv-moral_disputes": 5,
    "ogx_mmlux_lv-moral_scenarios": 5,
    "ogx_mmlux_lv-nutrition": 5,
    "ogx_mmlux_lv-philosophy": 5,
    "ogx_mmlux_lv-prehistory": 5,
    "ogx_mmlux_lv-professional_accounting": 5,
    "ogx_mmlux_lv-professional_law": 5,
    "ogx_mmlux_lv-professional_medicine": 5,
    "ogx_mmlux_lv-professional_psychology": 5,
    "ogx_mmlux_lv-public_relations": 5,
    "ogx_mmlux_lv-security_studies": 5,
    "ogx_mmlux_lv-sociology": 5,
    "ogx_mmlux_lv-us_foreign_policy": 5,
    "ogx_mmlux_lv-virology": 5,
    "ogx_mmlux_lv-world_religions": 5,
    "ogx_mmlux_nl-abstract_algebra": 5,
    "ogx_mmlux_nl-anatomy": 5,
    "ogx_mmlux_nl-astronomy": 5,
    "ogx_mmlux_nl-business_ethics": 5,
    "ogx_mmlux_nl-clinical_knowledge": 5,
    "ogx_mmlux_nl-college_biology": 5,
    "ogx_mmlux_nl-college_chemistry": 5,
    "ogx_mmlux_nl-college_computer_science": 5,
    "ogx_mmlux_nl-college_mathematics": 5,
    "ogx_mmlux_nl-college_medicine": 5,
    "ogx_mmlux_nl-college_physics": 5,
    "ogx_mmlux_nl-computer_security": 5,
    "ogx_mmlux_nl-conceptual_physics": 5,
    "ogx_mmlux_nl-econometrics": 5,
    "ogx_mmlux_nl-electrical_engineering": 5,
    "ogx_mmlux_nl-elementary_mathematics": 5,
    "ogx_mmlux_nl-formal_logic": 5,
    "ogx_mmlux_nl-global_facts": 5,
    "ogx_mmlux_nl-high_school_biology": 5,
    "ogx_mmlux_nl-high_school_chemistry": 5,
    "ogx_mmlux_nl-high_school_computer_science": 5,
    "ogx_mmlux_nl-high_school_european_history": 5,
    "ogx_mmlux_nl-high_school_geography": 5,
    "ogx_mmlux_nl-high_school_government_and_politics": 5,
    "ogx_mmlux_nl-high_school_macroeconomics": 5,
    "ogx_mmlux_nl-high_school_mathematics": 5,
    "ogx_mmlux_nl-high_school_microeconomics": 5,
    "ogx_mmlux_nl-high_school_physics": 5,
    "ogx_mmlux_nl-high_school_psychology": 5,
    "ogx_mmlux_nl-high_school_statistics": 5,
    "ogx_mmlux_nl-high_school_us_history": 5,
    "ogx_mmlux_nl-high_school_world_history": 5,
    "ogx_mmlux_nl-human_aging": 5,
    "ogx_mmlux_nl-human_sexuality": 5,
    "ogx_mmlux_nl-international_law": 5,
    "ogx_mmlux_nl-jurisprudence": 5,
    "ogx_mmlux_nl-logical_fallacies": 5,
    "ogx_mmlux_nl-machine_learning": 5,
    "ogx_mmlux_nl-management": 5,
    "ogx_mmlux_nl-marketing": 5,
    "ogx_mmlux_nl-medical_genetics": 5,
    "ogx_mmlux_nl-miscellaneous": 5,
    "ogx_mmlux_nl-moral_disputes": 5,
    "ogx_mmlux_nl-moral_scenarios": 5,
    "ogx_mmlux_nl-nutrition": 5,
    "ogx_mmlux_nl-philosophy": 5,
    "ogx_mmlux_nl-prehistory": 5,
    "ogx_mmlux_nl-professional_accounting": 5,
    "ogx_mmlux_nl-professional_law": 5,
    "ogx_mmlux_nl-professional_medicine": 5,
    "ogx_mmlux_nl-professional_psychology": 5,
    "ogx_mmlux_nl-public_relations": 5,
    "ogx_mmlux_nl-security_studies": 5,
    "ogx_mmlux_nl-sociology": 5,
    "ogx_mmlux_nl-us_foreign_policy": 5,
    "ogx_mmlux_nl-virology": 5,
    "ogx_mmlux_nl-world_religions": 5,
    "ogx_mmlux_pl-abstract_algebra": 5,
    "ogx_mmlux_pl-anatomy": 5,
    "ogx_mmlux_pl-astronomy": 5,
    "ogx_mmlux_pl-business_ethics": 5,
    "ogx_mmlux_pl-clinical_knowledge": 5,
    "ogx_mmlux_pl-college_biology": 5,
    "ogx_mmlux_pl-college_chemistry": 5,
    "ogx_mmlux_pl-college_computer_science": 5,
    "ogx_mmlux_pl-college_mathematics": 5,
    "ogx_mmlux_pl-college_medicine": 5,
    "ogx_mmlux_pl-college_physics": 5,
    "ogx_mmlux_pl-computer_security": 5,
    "ogx_mmlux_pl-conceptual_physics": 5,
    "ogx_mmlux_pl-econometrics": 5,
    "ogx_mmlux_pl-electrical_engineering": 5,
    "ogx_mmlux_pl-elementary_mathematics": 5,
    "ogx_mmlux_pl-formal_logic": 5,
    "ogx_mmlux_pl-global_facts": 5,
    "ogx_mmlux_pl-high_school_biology": 5,
    "ogx_mmlux_pl-high_school_chemistry": 5,
    "ogx_mmlux_pl-high_school_computer_science": 5,
    "ogx_mmlux_pl-high_school_european_history": 5,
    "ogx_mmlux_pl-high_school_geography": 5,
    "ogx_mmlux_pl-high_school_government_and_politics": 5,
    "ogx_mmlux_pl-high_school_macroeconomics": 5,
    "ogx_mmlux_pl-high_school_mathematics": 5,
    "ogx_mmlux_pl-high_school_microeconomics": 5,
    "ogx_mmlux_pl-high_school_physics": 5,
    "ogx_mmlux_pl-high_school_psychology": 5,
    "ogx_mmlux_pl-high_school_statistics": 5,
    "ogx_mmlux_pl-high_school_us_history": 5,
    "ogx_mmlux_pl-high_school_world_history": 5,
    "ogx_mmlux_pl-human_aging": 5,
    "ogx_mmlux_pl-human_sexuality": 5,
    "ogx_mmlux_pl-international_law": 5,
    "ogx_mmlux_pl-jurisprudence": 5,
    "ogx_mmlux_pl-logical_fallacies": 5,
    "ogx_mmlux_pl-machine_learning": 5,
    "ogx_mmlux_pl-management": 5,
    "ogx_mmlux_pl-marketing": 5,
    "ogx_mmlux_pl-medical_genetics": 5,
    "ogx_mmlux_pl-miscellaneous": 5,
    "ogx_mmlux_pl-moral_disputes": 5,
    "ogx_mmlux_pl-moral_scenarios": 5,
    "ogx_mmlux_pl-nutrition": 5,
    "ogx_mmlux_pl-philosophy": 5,
    "ogx_mmlux_pl-prehistory": 5,
    "ogx_mmlux_pl-professional_accounting": 5,
    "ogx_mmlux_pl-professional_law": 5,
    "ogx_mmlux_pl-professional_medicine": 5,
    "ogx_mmlux_pl-professional_psychology": 5,
    "ogx_mmlux_pl-public_relations": 5,
    "ogx_mmlux_pl-security_studies": 5,
    "ogx_mmlux_pl-sociology": 5,
    "ogx_mmlux_pl-us_foreign_policy": 5,
    "ogx_mmlux_pl-virology": 5,
    "ogx_mmlux_pl-world_religions": 5,
    "ogx_mmlux_pt-pt-abstract_algebra": 5,
    "ogx_mmlux_pt-pt-anatomy": 5,
    "ogx_mmlux_pt-pt-astronomy": 5,
    "ogx_mmlux_pt-pt-business_ethics": 5,
    "ogx_mmlux_pt-pt-clinical_knowledge": 5,
    "ogx_mmlux_pt-pt-college_biology": 5,
    "ogx_mmlux_pt-pt-college_chemistry": 5,
    "ogx_mmlux_pt-pt-college_computer_science": 5,
    "ogx_mmlux_pt-pt-college_mathematics": 5,
    "ogx_mmlux_pt-pt-college_medicine": 5,
    "ogx_mmlux_pt-pt-college_physics": 5,
    "ogx_mmlux_pt-pt-computer_security": 5,
    "ogx_mmlux_pt-pt-conceptual_physics": 5,
    "ogx_mmlux_pt-pt-econometrics": 5,
    "ogx_mmlux_pt-pt-electrical_engineering": 5,
    "ogx_mmlux_pt-pt-elementary_mathematics": 5,
    "ogx_mmlux_pt-pt-formal_logic": 5,
    "ogx_mmlux_pt-pt-global_facts": 5,
    "ogx_mmlux_pt-pt-high_school_biology": 5,
    "ogx_mmlux_pt-pt-high_school_chemistry": 5,
    "ogx_mmlux_pt-pt-high_school_computer_science": 5,
    "ogx_mmlux_pt-pt-high_school_european_history": 5,
    "ogx_mmlux_pt-pt-high_school_geography": 5,
    "ogx_mmlux_pt-pt-high_school_government_and_politics": 5,
    "ogx_mmlux_pt-pt-high_school_macroeconomics": 5,
    "ogx_mmlux_pt-pt-high_school_mathematics": 5,
    "ogx_mmlux_pt-pt-high_school_microeconomics": 5,
    "ogx_mmlux_pt-pt-high_school_physics": 5,
    "ogx_mmlux_pt-pt-high_school_psychology": 5,
    "ogx_mmlux_pt-pt-high_school_statistics": 5,
    "ogx_mmlux_pt-pt-high_school_us_history": 5,
    "ogx_mmlux_pt-pt-high_school_world_history": 5,
    "ogx_mmlux_pt-pt-human_aging": 5,
    "ogx_mmlux_pt-pt-human_sexuality": 5,
    "ogx_mmlux_pt-pt-international_law": 5,
    "ogx_mmlux_pt-pt-jurisprudence": 5,
    "ogx_mmlux_pt-pt-logical_fallacies": 5,
    "ogx_mmlux_pt-pt-machine_learning": 5,
    "ogx_mmlux_pt-pt-management": 5,
    "ogx_mmlux_pt-pt-marketing": 5,
    "ogx_mmlux_pt-pt-medical_genetics": 5,
    "ogx_mmlux_pt-pt-miscellaneous": 5,
    "ogx_mmlux_pt-pt-moral_disputes": 5,
    "ogx_mmlux_pt-pt-moral_scenarios": 5,
    "ogx_mmlux_pt-pt-nutrition": 5,
    "ogx_mmlux_pt-pt-philosophy": 5,
    "ogx_mmlux_pt-pt-prehistory": 5,
    "ogx_mmlux_pt-pt-professional_accounting": 5,
    "ogx_mmlux_pt-pt-professional_law": 5,
    "ogx_mmlux_pt-pt-professional_medicine": 5,
    "ogx_mmlux_pt-pt-professional_psychology": 5,
    "ogx_mmlux_pt-pt-public_relations": 5,
    "ogx_mmlux_pt-pt-security_studies": 5,
    "ogx_mmlux_pt-pt-sociology": 5,
    "ogx_mmlux_pt-pt-us_foreign_policy": 5,
    "ogx_mmlux_pt-pt-virology": 5,
    "ogx_mmlux_pt-pt-world_religions": 5,
    "ogx_mmlux_ro-abstract_algebra": 5,
    "ogx_mmlux_ro-anatomy": 5,
    "ogx_mmlux_ro-astronomy": 5,
    "ogx_mmlux_ro-business_ethics": 5,
    "ogx_mmlux_ro-clinical_knowledge": 5,
    "ogx_mmlux_ro-college_biology": 5,
    "ogx_mmlux_ro-college_chemistry": 5,
    "ogx_mmlux_ro-college_computer_science": 5,
    "ogx_mmlux_ro-college_mathematics": 5,
    "ogx_mmlux_ro-college_medicine": 5,
    "ogx_mmlux_ro-college_physics": 5,
    "ogx_mmlux_ro-computer_security": 5,
    "ogx_mmlux_ro-conceptual_physics": 5,
    "ogx_mmlux_ro-econometrics": 5,
    "ogx_mmlux_ro-electrical_engineering": 5,
    "ogx_mmlux_ro-elementary_mathematics": 5,
    "ogx_mmlux_ro-formal_logic": 5,
    "ogx_mmlux_ro-global_facts": 5,
    "ogx_mmlux_ro-high_school_biology": 5,
    "ogx_mmlux_ro-high_school_chemistry": 5,
    "ogx_mmlux_ro-high_school_computer_science": 5,
    "ogx_mmlux_ro-high_school_european_history": 5,
    "ogx_mmlux_ro-high_school_geography": 5,
    "ogx_mmlux_ro-high_school_government_and_politics": 5,
    "ogx_mmlux_ro-high_school_macroeconomics": 5,
    "ogx_mmlux_ro-high_school_mathematics": 5,
    "ogx_mmlux_ro-high_school_microeconomics": 5,
    "ogx_mmlux_ro-high_school_physics": 5,
    "ogx_mmlux_ro-high_school_psychology": 5,
    "ogx_mmlux_ro-high_school_statistics": 5,
    "ogx_mmlux_ro-high_school_us_history": 5,
    "ogx_mmlux_ro-high_school_world_history": 5,
    "ogx_mmlux_ro-human_aging": 5,
    "ogx_mmlux_ro-human_sexuality": 5,
    "ogx_mmlux_ro-international_law": 5,
    "ogx_mmlux_ro-jurisprudence": 5,
    "ogx_mmlux_ro-logical_fallacies": 5,
    "ogx_mmlux_ro-machine_learning": 5,
    "ogx_mmlux_ro-management": 5,
    "ogx_mmlux_ro-marketing": 5,
    "ogx_mmlux_ro-medical_genetics": 5,
    "ogx_mmlux_ro-miscellaneous": 5,
    "ogx_mmlux_ro-moral_disputes": 5,
    "ogx_mmlux_ro-moral_scenarios": 5,
    "ogx_mmlux_ro-nutrition": 5,
    "ogx_mmlux_ro-philosophy": 5,
    "ogx_mmlux_ro-prehistory": 5,
    "ogx_mmlux_ro-professional_accounting": 5,
    "ogx_mmlux_ro-professional_law": 5,
    "ogx_mmlux_ro-professional_medicine": 5,
    "ogx_mmlux_ro-professional_psychology": 5,
    "ogx_mmlux_ro-public_relations": 5,
    "ogx_mmlux_ro-security_studies": 5,
    "ogx_mmlux_ro-sociology": 5,
    "ogx_mmlux_ro-us_foreign_policy": 5,
    "ogx_mmlux_ro-virology": 5,
    "ogx_mmlux_ro-world_religions": 5,
    "ogx_mmlux_sk-abstract_algebra": 5,
    "ogx_mmlux_sk-anatomy": 5,
    "ogx_mmlux_sk-astronomy": 5,
    "ogx_mmlux_sk-business_ethics": 5,
    "ogx_mmlux_sk-clinical_knowledge": 5,
    "ogx_mmlux_sk-college_biology": 5,
    "ogx_mmlux_sk-college_chemistry": 5,
    "ogx_mmlux_sk-college_computer_science": 5,
    "ogx_mmlux_sk-college_mathematics": 5,
    "ogx_mmlux_sk-college_medicine": 5,
    "ogx_mmlux_sk-college_physics": 5,
    "ogx_mmlux_sk-computer_security": 5,
    "ogx_mmlux_sk-conceptual_physics": 5,
    "ogx_mmlux_sk-econometrics": 5,
    "ogx_mmlux_sk-electrical_engineering": 5,
    "ogx_mmlux_sk-elementary_mathematics": 5,
    "ogx_mmlux_sk-formal_logic": 5,
    "ogx_mmlux_sk-global_facts": 5,
    "ogx_mmlux_sk-high_school_biology": 5,
    "ogx_mmlux_sk-high_school_chemistry": 5,
    "ogx_mmlux_sk-high_school_computer_science": 5,
    "ogx_mmlux_sk-high_school_european_history": 5,
    "ogx_mmlux_sk-high_school_geography": 5,
    "ogx_mmlux_sk-high_school_government_and_politics": 5,
    "ogx_mmlux_sk-high_school_macroeconomics": 5,
    "ogx_mmlux_sk-high_school_mathematics": 5,
    "ogx_mmlux_sk-high_school_microeconomics": 5,
    "ogx_mmlux_sk-high_school_physics": 5,
    "ogx_mmlux_sk-high_school_psychology": 5,
    "ogx_mmlux_sk-high_school_statistics": 5,
    "ogx_mmlux_sk-high_school_us_history": 5,
    "ogx_mmlux_sk-high_school_world_history": 5,
    "ogx_mmlux_sk-human_aging": 5,
    "ogx_mmlux_sk-human_sexuality": 5,
    "ogx_mmlux_sk-international_law": 5,
    "ogx_mmlux_sk-jurisprudence": 5,
    "ogx_mmlux_sk-logical_fallacies": 5,
    "ogx_mmlux_sk-machine_learning": 5,
    "ogx_mmlux_sk-management": 5,
    "ogx_mmlux_sk-marketing": 5,
    "ogx_mmlux_sk-medical_genetics": 5,
    "ogx_mmlux_sk-miscellaneous": 5,
    "ogx_mmlux_sk-moral_disputes": 5,
    "ogx_mmlux_sk-moral_scenarios": 5,
    "ogx_mmlux_sk-nutrition": 5,
    "ogx_mmlux_sk-philosophy": 5,
    "ogx_mmlux_sk-prehistory": 5,
    "ogx_mmlux_sk-professional_accounting": 5,
    "ogx_mmlux_sk-professional_law": 5,
    "ogx_mmlux_sk-professional_medicine": 5,
    "ogx_mmlux_sk-professional_psychology": 5,
    "ogx_mmlux_sk-public_relations": 5,
    "ogx_mmlux_sk-security_studies": 5,
    "ogx_mmlux_sk-sociology": 5,
    "ogx_mmlux_sk-us_foreign_policy": 5,
    "ogx_mmlux_sk-virology": 5,
    "ogx_mmlux_sk-world_religions": 5,
    "ogx_mmlux_sl-abstract_algebra": 5,
    "ogx_mmlux_sl-anatomy": 5,
    "ogx_mmlux_sl-astronomy": 5,
    "ogx_mmlux_sl-business_ethics": 5,
    "ogx_mmlux_sl-clinical_knowledge": 5,
    "ogx_mmlux_sl-college_biology": 5,
    "ogx_mmlux_sl-college_chemistry": 5,
    "ogx_mmlux_sl-college_computer_science": 5,
    "ogx_mmlux_sl-college_mathematics": 5,
    "ogx_mmlux_sl-college_medicine": 5,
    "ogx_mmlux_sl-college_physics": 5,
    "ogx_mmlux_sl-computer_security": 5,
    "ogx_mmlux_sl-conceptual_physics": 5,
    "ogx_mmlux_sl-econometrics": 5,
    "ogx_mmlux_sl-electrical_engineering": 5,
    "ogx_mmlux_sl-elementary_mathematics": 5,
    "ogx_mmlux_sl-formal_logic": 5,
    "ogx_mmlux_sl-global_facts": 5,
    "ogx_mmlux_sl-high_school_biology": 5,
    "ogx_mmlux_sl-high_school_chemistry": 5,
    "ogx_mmlux_sl-high_school_computer_science": 5,
    "ogx_mmlux_sl-high_school_european_history": 5,
    "ogx_mmlux_sl-high_school_geography": 5,
    "ogx_mmlux_sl-high_school_government_and_politics": 5,
    "ogx_mmlux_sl-high_school_macroeconomics": 5,
    "ogx_mmlux_sl-high_school_mathematics": 5,
    "ogx_mmlux_sl-high_school_microeconomics": 5,
    "ogx_mmlux_sl-high_school_physics": 5,
    "ogx_mmlux_sl-high_school_psychology": 5,
    "ogx_mmlux_sl-high_school_statistics": 5,
    "ogx_mmlux_sl-high_school_us_history": 5,
    "ogx_mmlux_sl-high_school_world_history": 5,
    "ogx_mmlux_sl-human_aging": 5,
    "ogx_mmlux_sl-human_sexuality": 5,
    "ogx_mmlux_sl-international_law": 5,
    "ogx_mmlux_sl-jurisprudence": 5,
    "ogx_mmlux_sl-logical_fallacies": 5,
    "ogx_mmlux_sl-machine_learning": 5,
    "ogx_mmlux_sl-management": 5,
    "ogx_mmlux_sl-marketing": 5,
    "ogx_mmlux_sl-medical_genetics": 5,
    "ogx_mmlux_sl-miscellaneous": 5,
    "ogx_mmlux_sl-moral_disputes": 5,
    "ogx_mmlux_sl-moral_scenarios": 5,
    "ogx_mmlux_sl-nutrition": 5,
    "ogx_mmlux_sl-philosophy": 5,
    "ogx_mmlux_sl-prehistory": 5,
    "ogx_mmlux_sl-professional_accounting": 5,
    "ogx_mmlux_sl-professional_law": 5,
    "ogx_mmlux_sl-professional_medicine": 5,
    "ogx_mmlux_sl-professional_psychology": 5,
    "ogx_mmlux_sl-public_relations": 5,
    "ogx_mmlux_sl-security_studies": 5,
    "ogx_mmlux_sl-sociology": 5,
    "ogx_mmlux_sl-us_foreign_policy": 5,
    "ogx_mmlux_sl-virology": 5,
    "ogx_mmlux_sl-world_religions": 5,
    "ogx_mmlux_sv-abstract_algebra": 5,
    "ogx_mmlux_sv-anatomy": 5,
    "ogx_mmlux_sv-astronomy": 5,
    "ogx_mmlux_sv-business_ethics": 5,
    "ogx_mmlux_sv-clinical_knowledge": 5,
    "ogx_mmlux_sv-college_biology": 5,
    "ogx_mmlux_sv-college_chemistry": 5,
    "ogx_mmlux_sv-college_computer_science": 5,
    "ogx_mmlux_sv-college_mathematics": 5,
    "ogx_mmlux_sv-college_medicine": 5,
    "ogx_mmlux_sv-college_physics": 5,
    "ogx_mmlux_sv-computer_security": 5,
    "ogx_mmlux_sv-conceptual_physics": 5,
    "ogx_mmlux_sv-econometrics": 5,
    "ogx_mmlux_sv-electrical_engineering": 5,
    "ogx_mmlux_sv-elementary_mathematics": 5,
    "ogx_mmlux_sv-formal_logic": 5,
    "ogx_mmlux_sv-global_facts": 5,
    "ogx_mmlux_sv-high_school_biology": 5,
    "ogx_mmlux_sv-high_school_chemistry": 5,
    "ogx_mmlux_sv-high_school_computer_science": 5,
    "ogx_mmlux_sv-high_school_european_history": 5,
    "ogx_mmlux_sv-high_school_geography": 5,
    "ogx_mmlux_sv-high_school_government_and_politics": 5,
    "ogx_mmlux_sv-high_school_macroeconomics": 5,
    "ogx_mmlux_sv-high_school_mathematics": 5,
    "ogx_mmlux_sv-high_school_microeconomics": 5,
    "ogx_mmlux_sv-high_school_physics": 5,
    "ogx_mmlux_sv-high_school_psychology": 5,
    "ogx_mmlux_sv-high_school_statistics": 5,
    "ogx_mmlux_sv-high_school_us_history": 5,
    "ogx_mmlux_sv-high_school_world_history": 5,
    "ogx_mmlux_sv-human_aging": 5,
    "ogx_mmlux_sv-human_sexuality": 5,
    "ogx_mmlux_sv-international_law": 5,
    "ogx_mmlux_sv-jurisprudence": 5,
    "ogx_mmlux_sv-logical_fallacies": 5,
    "ogx_mmlux_sv-machine_learning": 5,
    "ogx_mmlux_sv-management": 5,
    "ogx_mmlux_sv-marketing": 5,
    "ogx_mmlux_sv-medical_genetics": 5,
    "ogx_mmlux_sv-miscellaneous": 5,
    "ogx_mmlux_sv-moral_disputes": 5,
    "ogx_mmlux_sv-moral_scenarios": 5,
    "ogx_mmlux_sv-nutrition": 5,
    "ogx_mmlux_sv-philosophy": 5,
    "ogx_mmlux_sv-prehistory": 5,
    "ogx_mmlux_sv-professional_accounting": 5,
    "ogx_mmlux_sv-professional_law": 5,
    "ogx_mmlux_sv-professional_medicine": 5,
    "ogx_mmlux_sv-professional_psychology": 5,
    "ogx_mmlux_sv-public_relations": 5,
    "ogx_mmlux_sv-security_studies": 5,
    "ogx_mmlux_sv-sociology": 5,
    "ogx_mmlux_sv-us_foreign_policy": 5,
    "ogx_mmlux_sv-virology": 5,
    "ogx_mmlux_sv-world_religions": 5
  },
  "higher_is_better": {
    "ogx_mmlux_bg-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_bg-anatomy": {
      "acc": true
    },
    "ogx_mmlux_bg-astronomy": {
      "acc": true
    },
    "ogx_mmlux_bg-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_bg-college_biology": {
      "acc": true
    },
    "ogx_mmlux_bg-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_bg-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_bg-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_bg-college_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-computer_security": {
      "acc": true
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-econometrics": {
      "acc": true
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_bg-global_facts": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_bg-human_aging": {
      "acc": true
    },
    "ogx_mmlux_bg-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_bg-international_law": {
      "acc": true
    },
    "ogx_mmlux_bg-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_bg-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_bg-management": {
      "acc": true
    },
    "ogx_mmlux_bg-marketing": {
      "acc": true
    },
    "ogx_mmlux_bg-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_bg-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_bg-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_bg-nutrition": {
      "acc": true
    },
    "ogx_mmlux_bg-philosophy": {
      "acc": true
    },
    "ogx_mmlux_bg-prehistory": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_law": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_bg-public_relations": {
      "acc": true
    },
    "ogx_mmlux_bg-security_studies": {
      "acc": true
    },
    "ogx_mmlux_bg-sociology": {
      "acc": true
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_bg-virology": {
      "acc": true
    },
    "ogx_mmlux_bg-world_religions": {
      "acc": true
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_cs-anatomy": {
      "acc": true
    },
    "ogx_mmlux_cs-astronomy": {
      "acc": true
    },
    "ogx_mmlux_cs-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_cs-college_biology": {
      "acc": true
    },
    "ogx_mmlux_cs-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_cs-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_cs-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_cs-college_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-computer_security": {
      "acc": true
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-econometrics": {
      "acc": true
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_cs-global_facts": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_cs-human_aging": {
      "acc": true
    },
    "ogx_mmlux_cs-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_cs-international_law": {
      "acc": true
    },
    "ogx_mmlux_cs-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_cs-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_cs-management": {
      "acc": true
    },
    "ogx_mmlux_cs-marketing": {
      "acc": true
    },
    "ogx_mmlux_cs-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_cs-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_cs-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_cs-nutrition": {
      "acc": true
    },
    "ogx_mmlux_cs-philosophy": {
      "acc": true
    },
    "ogx_mmlux_cs-prehistory": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_law": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_cs-public_relations": {
      "acc": true
    },
    "ogx_mmlux_cs-security_studies": {
      "acc": true
    },
    "ogx_mmlux_cs-sociology": {
      "acc": true
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_cs-virology": {
      "acc": true
    },
    "ogx_mmlux_cs-world_religions": {
      "acc": true
    },
    "ogx_mmlux_da-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_da-anatomy": {
      "acc": true
    },
    "ogx_mmlux_da-astronomy": {
      "acc": true
    },
    "ogx_mmlux_da-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_da-college_biology": {
      "acc": true
    },
    "ogx_mmlux_da-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_da-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_da-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_da-college_physics": {
      "acc": true
    },
    "ogx_mmlux_da-computer_security": {
      "acc": true
    },
    "ogx_mmlux_da-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_da-econometrics": {
      "acc": true
    },
    "ogx_mmlux_da-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_da-global_facts": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_da-human_aging": {
      "acc": true
    },
    "ogx_mmlux_da-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_da-international_law": {
      "acc": true
    },
    "ogx_mmlux_da-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_da-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_da-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_da-management": {
      "acc": true
    },
    "ogx_mmlux_da-marketing": {
      "acc": true
    },
    "ogx_mmlux_da-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_da-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_da-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_da-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_da-nutrition": {
      "acc": true
    },
    "ogx_mmlux_da-philosophy": {
      "acc": true
    },
    "ogx_mmlux_da-prehistory": {
      "acc": true
    },
    "ogx_mmlux_da-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_da-professional_law": {
      "acc": true
    },
    "ogx_mmlux_da-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_da-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_da-public_relations": {
      "acc": true
    },
    "ogx_mmlux_da-security_studies": {
      "acc": true
    },
    "ogx_mmlux_da-sociology": {
      "acc": true
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_da-virology": {
      "acc": true
    },
    "ogx_mmlux_da-world_religions": {
      "acc": true
    },
    "ogx_mmlux_de-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_de-anatomy": {
      "acc": true
    },
    "ogx_mmlux_de-astronomy": {
      "acc": true
    },
    "ogx_mmlux_de-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_de-college_biology": {
      "acc": true
    },
    "ogx_mmlux_de-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_de-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_de-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_de-college_physics": {
      "acc": true
    },
    "ogx_mmlux_de-computer_security": {
      "acc": true
    },
    "ogx_mmlux_de-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_de-econometrics": {
      "acc": true
    },
    "ogx_mmlux_de-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_de-global_facts": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_de-human_aging": {
      "acc": true
    },
    "ogx_mmlux_de-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_de-international_law": {
      "acc": true
    },
    "ogx_mmlux_de-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_de-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_de-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_de-management": {
      "acc": true
    },
    "ogx_mmlux_de-marketing": {
      "acc": true
    },
    "ogx_mmlux_de-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_de-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_de-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_de-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_de-nutrition": {
      "acc": true
    },
    "ogx_mmlux_de-philosophy": {
      "acc": true
    },
    "ogx_mmlux_de-prehistory": {
      "acc": true
    },
    "ogx_mmlux_de-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_de-professional_law": {
      "acc": true
    },
    "ogx_mmlux_de-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_de-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_de-public_relations": {
      "acc": true
    },
    "ogx_mmlux_de-security_studies": {
      "acc": true
    },
    "ogx_mmlux_de-sociology": {
      "acc": true
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_de-virology": {
      "acc": true
    },
    "ogx_mmlux_de-world_religions": {
      "acc": true
    },
    "ogx_mmlux_el-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_el-anatomy": {
      "acc": true
    },
    "ogx_mmlux_el-astronomy": {
      "acc": true
    },
    "ogx_mmlux_el-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_el-college_biology": {
      "acc": true
    },
    "ogx_mmlux_el-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_el-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_el-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_el-college_physics": {
      "acc": true
    },
    "ogx_mmlux_el-computer_security": {
      "acc": true
    },
    "ogx_mmlux_el-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_el-econometrics": {
      "acc": true
    },
    "ogx_mmlux_el-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_el-global_facts": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_el-human_aging": {
      "acc": true
    },
    "ogx_mmlux_el-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_el-international_law": {
      "acc": true
    },
    "ogx_mmlux_el-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_el-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_el-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_el-management": {
      "acc": true
    },
    "ogx_mmlux_el-marketing": {
      "acc": true
    },
    "ogx_mmlux_el-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_el-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_el-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_el-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_el-nutrition": {
      "acc": true
    },
    "ogx_mmlux_el-philosophy": {
      "acc": true
    },
    "ogx_mmlux_el-prehistory": {
      "acc": true
    },
    "ogx_mmlux_el-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_el-professional_law": {
      "acc": true
    },
    "ogx_mmlux_el-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_el-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_el-public_relations": {
      "acc": true
    },
    "ogx_mmlux_el-security_studies": {
      "acc": true
    },
    "ogx_mmlux_el-sociology": {
      "acc": true
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_el-virology": {
      "acc": true
    },
    "ogx_mmlux_el-world_religions": {
      "acc": true
    },
    "ogx_mmlux_es-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_es-anatomy": {
      "acc": true
    },
    "ogx_mmlux_es-astronomy": {
      "acc": true
    },
    "ogx_mmlux_es-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_es-college_biology": {
      "acc": true
    },
    "ogx_mmlux_es-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_es-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_es-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_es-college_physics": {
      "acc": true
    },
    "ogx_mmlux_es-computer_security": {
      "acc": true
    },
    "ogx_mmlux_es-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_es-econometrics": {
      "acc": true
    },
    "ogx_mmlux_es-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_es-global_facts": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_es-human_aging": {
      "acc": true
    },
    "ogx_mmlux_es-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_es-international_law": {
      "acc": true
    },
    "ogx_mmlux_es-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_es-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_es-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_es-management": {
      "acc": true
    },
    "ogx_mmlux_es-marketing": {
      "acc": true
    },
    "ogx_mmlux_es-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_es-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_es-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_es-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_es-nutrition": {
      "acc": true
    },
    "ogx_mmlux_es-philosophy": {
      "acc": true
    },
    "ogx_mmlux_es-prehistory": {
      "acc": true
    },
    "ogx_mmlux_es-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_es-professional_law": {
      "acc": true
    },
    "ogx_mmlux_es-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_es-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_es-public_relations": {
      "acc": true
    },
    "ogx_mmlux_es-security_studies": {
      "acc": true
    },
    "ogx_mmlux_es-sociology": {
      "acc": true
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_es-virology": {
      "acc": true
    },
    "ogx_mmlux_es-world_religions": {
      "acc": true
    },
    "ogx_mmlux_et-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_et-anatomy": {
      "acc": true
    },
    "ogx_mmlux_et-astronomy": {
      "acc": true
    },
    "ogx_mmlux_et-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_et-college_biology": {
      "acc": true
    },
    "ogx_mmlux_et-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_et-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_et-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_et-college_physics": {
      "acc": true
    },
    "ogx_mmlux_et-computer_security": {
      "acc": true
    },
    "ogx_mmlux_et-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_et-econometrics": {
      "acc": true
    },
    "ogx_mmlux_et-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_et-global_facts": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_et-human_aging": {
      "acc": true
    },
    "ogx_mmlux_et-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_et-international_law": {
      "acc": true
    },
    "ogx_mmlux_et-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_et-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_et-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_et-management": {
      "acc": true
    },
    "ogx_mmlux_et-marketing": {
      "acc": true
    },
    "ogx_mmlux_et-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_et-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_et-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_et-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_et-nutrition": {
      "acc": true
    },
    "ogx_mmlux_et-philosophy": {
      "acc": true
    },
    "ogx_mmlux_et-prehistory": {
      "acc": true
    },
    "ogx_mmlux_et-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_et-professional_law": {
      "acc": true
    },
    "ogx_mmlux_et-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_et-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_et-public_relations": {
      "acc": true
    },
    "ogx_mmlux_et-security_studies": {
      "acc": true
    },
    "ogx_mmlux_et-sociology": {
      "acc": true
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_et-virology": {
      "acc": true
    },
    "ogx_mmlux_et-world_religions": {
      "acc": true
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_fi-anatomy": {
      "acc": true
    },
    "ogx_mmlux_fi-astronomy": {
      "acc": true
    },
    "ogx_mmlux_fi-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_fi-college_biology": {
      "acc": true
    },
    "ogx_mmlux_fi-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fi-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fi-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_fi-college_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-computer_security": {
      "acc": true
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-econometrics": {
      "acc": true
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_fi-global_facts": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_fi-human_aging": {
      "acc": true
    },
    "ogx_mmlux_fi-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_fi-international_law": {
      "acc": true
    },
    "ogx_mmlux_fi-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_fi-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_fi-management": {
      "acc": true
    },
    "ogx_mmlux_fi-marketing": {
      "acc": true
    },
    "ogx_mmlux_fi-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_fi-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_fi-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_fi-nutrition": {
      "acc": true
    },
    "ogx_mmlux_fi-philosophy": {
      "acc": true
    },
    "ogx_mmlux_fi-prehistory": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_law": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_fi-public_relations": {
      "acc": true
    },
    "ogx_mmlux_fi-security_studies": {
      "acc": true
    },
    "ogx_mmlux_fi-sociology": {
      "acc": true
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_fi-virology": {
      "acc": true
    },
    "ogx_mmlux_fi-world_religions": {
      "acc": true
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_fr-anatomy": {
      "acc": true
    },
    "ogx_mmlux_fr-astronomy": {
      "acc": true
    },
    "ogx_mmlux_fr-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_fr-college_biology": {
      "acc": true
    },
    "ogx_mmlux_fr-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fr-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fr-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_fr-college_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-computer_security": {
      "acc": true
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-econometrics": {
      "acc": true
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_fr-global_facts": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_fr-human_aging": {
      "acc": true
    },
    "ogx_mmlux_fr-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_fr-international_law": {
      "acc": true
    },
    "ogx_mmlux_fr-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_fr-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_fr-management": {
      "acc": true
    },
    "ogx_mmlux_fr-marketing": {
      "acc": true
    },
    "ogx_mmlux_fr-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_fr-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_fr-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_fr-nutrition": {
      "acc": true
    },
    "ogx_mmlux_fr-philosophy": {
      "acc": true
    },
    "ogx_mmlux_fr-prehistory": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_law": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_fr-public_relations": {
      "acc": true
    },
    "ogx_mmlux_fr-security_studies": {
      "acc": true
    },
    "ogx_mmlux_fr-sociology": {
      "acc": true
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_fr-virology": {
      "acc": true
    },
    "ogx_mmlux_fr-world_religions": {
      "acc": true
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_hu-anatomy": {
      "acc": true
    },
    "ogx_mmlux_hu-astronomy": {
      "acc": true
    },
    "ogx_mmlux_hu-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_hu-college_biology": {
      "acc": true
    },
    "ogx_mmlux_hu-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_hu-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_hu-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_hu-college_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-computer_security": {
      "acc": true
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-econometrics": {
      "acc": true
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_hu-global_facts": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_hu-human_aging": {
      "acc": true
    },
    "ogx_mmlux_hu-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_hu-international_law": {
      "acc": true
    },
    "ogx_mmlux_hu-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_hu-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_hu-management": {
      "acc": true
    },
    "ogx_mmlux_hu-marketing": {
      "acc": true
    },
    "ogx_mmlux_hu-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_hu-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_hu-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_hu-nutrition": {
      "acc": true
    },
    "ogx_mmlux_hu-philosophy": {
      "acc": true
    },
    "ogx_mmlux_hu-prehistory": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_law": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_hu-public_relations": {
      "acc": true
    },
    "ogx_mmlux_hu-security_studies": {
      "acc": true
    },
    "ogx_mmlux_hu-sociology": {
      "acc": true
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_hu-virology": {
      "acc": true
    },
    "ogx_mmlux_hu-world_religions": {
      "acc": true
    },
    "ogx_mmlux_it-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_it-anatomy": {
      "acc": true
    },
    "ogx_mmlux_it-astronomy": {
      "acc": true
    },
    "ogx_mmlux_it-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_it-college_biology": {
      "acc": true
    },
    "ogx_mmlux_it-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_it-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_it-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_it-college_physics": {
      "acc": true
    },
    "ogx_mmlux_it-computer_security": {
      "acc": true
    },
    "ogx_mmlux_it-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_it-econometrics": {
      "acc": true
    },
    "ogx_mmlux_it-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_it-global_facts": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_it-human_aging": {
      "acc": true
    },
    "ogx_mmlux_it-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_it-international_law": {
      "acc": true
    },
    "ogx_mmlux_it-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_it-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_it-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_it-management": {
      "acc": true
    },
    "ogx_mmlux_it-marketing": {
      "acc": true
    },
    "ogx_mmlux_it-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_it-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_it-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_it-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_it-nutrition": {
      "acc": true
    },
    "ogx_mmlux_it-philosophy": {
      "acc": true
    },
    "ogx_mmlux_it-prehistory": {
      "acc": true
    },
    "ogx_mmlux_it-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_it-professional_law": {
      "acc": true
    },
    "ogx_mmlux_it-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_it-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_it-public_relations": {
      "acc": true
    },
    "ogx_mmlux_it-security_studies": {
      "acc": true
    },
    "ogx_mmlux_it-sociology": {
      "acc": true
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_it-virology": {
      "acc": true
    },
    "ogx_mmlux_it-world_religions": {
      "acc": true
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_lt-anatomy": {
      "acc": true
    },
    "ogx_mmlux_lt-astronomy": {
      "acc": true
    },
    "ogx_mmlux_lt-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_lt-college_biology": {
      "acc": true
    },
    "ogx_mmlux_lt-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lt-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lt-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_lt-college_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-computer_security": {
      "acc": true
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-econometrics": {
      "acc": true
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_lt-global_facts": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_lt-human_aging": {
      "acc": true
    },
    "ogx_mmlux_lt-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_lt-international_law": {
      "acc": true
    },
    "ogx_mmlux_lt-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_lt-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_lt-management": {
      "acc": true
    },
    "ogx_mmlux_lt-marketing": {
      "acc": true
    },
    "ogx_mmlux_lt-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_lt-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_lt-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_lt-nutrition": {
      "acc": true
    },
    "ogx_mmlux_lt-philosophy": {
      "acc": true
    },
    "ogx_mmlux_lt-prehistory": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_law": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_lt-public_relations": {
      "acc": true
    },
    "ogx_mmlux_lt-security_studies": {
      "acc": true
    },
    "ogx_mmlux_lt-sociology": {
      "acc": true
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_lt-virology": {
      "acc": true
    },
    "ogx_mmlux_lt-world_religions": {
      "acc": true
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_lv-anatomy": {
      "acc": true
    },
    "ogx_mmlux_lv-astronomy": {
      "acc": true
    },
    "ogx_mmlux_lv-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_lv-college_biology": {
      "acc": true
    },
    "ogx_mmlux_lv-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lv-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lv-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_lv-college_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-computer_security": {
      "acc": true
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-econometrics": {
      "acc": true
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_lv-global_facts": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_lv-human_aging": {
      "acc": true
    },
    "ogx_mmlux_lv-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_lv-international_law": {
      "acc": true
    },
    "ogx_mmlux_lv-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_lv-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_lv-management": {
      "acc": true
    },
    "ogx_mmlux_lv-marketing": {
      "acc": true
    },
    "ogx_mmlux_lv-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_lv-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_lv-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_lv-nutrition": {
      "acc": true
    },
    "ogx_mmlux_lv-philosophy": {
      "acc": true
    },
    "ogx_mmlux_lv-prehistory": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_law": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_lv-public_relations": {
      "acc": true
    },
    "ogx_mmlux_lv-security_studies": {
      "acc": true
    },
    "ogx_mmlux_lv-sociology": {
      "acc": true
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_lv-virology": {
      "acc": true
    },
    "ogx_mmlux_lv-world_religions": {
      "acc": true
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_nl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_nl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_nl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_nl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_nl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_nl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_nl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_nl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_nl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_nl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_nl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_nl-international_law": {
      "acc": true
    },
    "ogx_mmlux_nl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_nl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_nl-management": {
      "acc": true
    },
    "ogx_mmlux_nl-marketing": {
      "acc": true
    },
    "ogx_mmlux_nl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_nl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_nl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_nl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_nl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_nl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_nl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_nl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_nl-sociology": {
      "acc": true
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_nl-virology": {
      "acc": true
    },
    "ogx_mmlux_nl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_pl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_pl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_pl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_pl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_pl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_pl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_pl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_pl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_pl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_pl-international_law": {
      "acc": true
    },
    "ogx_mmlux_pl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_pl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_pl-management": {
      "acc": true
    },
    "ogx_mmlux_pl-marketing": {
      "acc": true
    },
    "ogx_mmlux_pl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_pl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_pl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_pl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_pl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_pl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_pl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_pl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_pl-sociology": {
      "acc": true
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_pl-virology": {
      "acc": true
    },
    "ogx_mmlux_pl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-international_law": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-management": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-marketing": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-sociology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-virology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "acc": true
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_ro-anatomy": {
      "acc": true
    },
    "ogx_mmlux_ro-astronomy": {
      "acc": true
    },
    "ogx_mmlux_ro-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_ro-college_biology": {
      "acc": true
    },
    "ogx_mmlux_ro-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_ro-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_ro-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_ro-college_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-computer_security": {
      "acc": true
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-econometrics": {
      "acc": true
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_ro-global_facts": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_ro-human_aging": {
      "acc": true
    },
    "ogx_mmlux_ro-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_ro-international_law": {
      "acc": true
    },
    "ogx_mmlux_ro-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_ro-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_ro-management": {
      "acc": true
    },
    "ogx_mmlux_ro-marketing": {
      "acc": true
    },
    "ogx_mmlux_ro-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_ro-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_ro-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_ro-nutrition": {
      "acc": true
    },
    "ogx_mmlux_ro-philosophy": {
      "acc": true
    },
    "ogx_mmlux_ro-prehistory": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_law": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_ro-public_relations": {
      "acc": true
    },
    "ogx_mmlux_ro-security_studies": {
      "acc": true
    },
    "ogx_mmlux_ro-sociology": {
      "acc": true
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_ro-virology": {
      "acc": true
    },
    "ogx_mmlux_ro-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sk-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sk-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sk-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sk-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sk-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sk-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sk-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sk-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sk-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sk-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sk-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sk-international_law": {
      "acc": true
    },
    "ogx_mmlux_sk-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sk-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sk-management": {
      "acc": true
    },
    "ogx_mmlux_sk-marketing": {
      "acc": true
    },
    "ogx_mmlux_sk-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sk-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sk-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sk-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sk-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sk-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sk-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sk-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sk-sociology": {
      "acc": true
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sk-virology": {
      "acc": true
    },
    "ogx_mmlux_sk-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sl-international_law": {
      "acc": true
    },
    "ogx_mmlux_sl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sl-management": {
      "acc": true
    },
    "ogx_mmlux_sl-marketing": {
      "acc": true
    },
    "ogx_mmlux_sl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sl-sociology": {
      "acc": true
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sl-virology": {
      "acc": true
    },
    "ogx_mmlux_sl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sv-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sv-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sv-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sv-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sv-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sv-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sv-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sv-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sv-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sv-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sv-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sv-international_law": {
      "acc": true
    },
    "ogx_mmlux_sv-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sv-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sv-management": {
      "acc": true
    },
    "ogx_mmlux_sv-marketing": {
      "acc": true
    },
    "ogx_mmlux_sv-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sv-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sv-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sv-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sv-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sv-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sv-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sv-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sv-sociology": {
      "acc": true
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sv-virology": {
      "acc": true
    },
    "ogx_mmlux_sv-world_religions": {
      "acc": true
    }
  },
  "n-samples": {
    "ogx_mmlux_sv-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sv-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sv-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sv-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sv-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sv-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sv-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sv-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sv-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sv-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sv-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sv-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sv-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sv-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sv-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sv-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sv-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sv-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sv-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sv-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sv-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sv-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sv-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sv-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sv-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sv-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sv-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sv-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sv-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sv-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sk-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sk-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sk-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sk-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sk-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sk-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sk-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sk-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sk-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sk-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sk-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sk-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sk-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sk-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sk-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sk-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sk-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sk-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sk-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sk-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sk-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sk-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sk-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sk-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sk-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sk-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sk-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sk-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sk-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_ro-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_ro-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_ro-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_ro-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_ro-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_ro-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_ro-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_ro-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_ro-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_ro-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_ro-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_ro-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_ro-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_ro-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_ro-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_ro-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_ro-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_ro-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_ro-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_ro-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_ro-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_ro-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_ro-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_ro-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_ro-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_ro-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_ro-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_ro-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_ro-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_pt-pt-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_pt-pt-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_pt-pt-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_pl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_pl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_pl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_pl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_pl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_pl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_pl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_pl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_pl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_pl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_pl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_pl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_pl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_pl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_pl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_pl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_pl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_pl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_pl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_pl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_pl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_pl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_pl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_pl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_pl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_pl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_pl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_pl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_pl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_nl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_nl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_nl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_nl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_nl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_nl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_nl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_nl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_nl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_nl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_nl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_nl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_nl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_nl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_nl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_nl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_nl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_nl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_nl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_nl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_nl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_nl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_nl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_nl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_nl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_nl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_nl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_nl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_nl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_lv-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_lv-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_lv-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_lv-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_lv-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_lv-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_lv-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_lv-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_lv-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_lv-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_lv-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_lv-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_lv-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_lv-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_lv-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_lv-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_lv-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_lv-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_lv-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_lv-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_lv-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_lv-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_lv-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_lv-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_lv-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_lv-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_lv-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_lv-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_lv-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_lt-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_lt-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_lt-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_lt-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_lt-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_lt-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_lt-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_lt-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_lt-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_lt-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_lt-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_lt-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_lt-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_lt-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_lt-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_lt-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_lt-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_lt-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_lt-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_lt-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_lt-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_lt-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_lt-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_lt-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_lt-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_lt-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_lt-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_lt-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_lt-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_it-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_it-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_it-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_it-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_it-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_it-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_it-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_it-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_it-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_it-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_it-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_it-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_it-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_it-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_it-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_it-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_it-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_it-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_it-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_it-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_it-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_it-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_it-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_it-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_it-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_it-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_it-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_it-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_it-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_it-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_it-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_it-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_it-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_it-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_it-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_it-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_it-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_it-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_it-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_hu-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_hu-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_hu-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_hu-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_hu-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_hu-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_hu-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_hu-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_hu-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_hu-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_hu-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_hu-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_hu-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_hu-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_hu-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_hu-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_hu-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_hu-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_hu-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_hu-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_hu-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_hu-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_hu-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_hu-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_hu-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_hu-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_hu-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_hu-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_hu-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_fr-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_fr-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_fr-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_fr-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_fr-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_fr-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_fr-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_fr-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_fr-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_fr-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_fr-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_fr-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_fr-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_fr-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_fr-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_fr-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_fr-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_fr-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_fr-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_fr-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_fr-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_fr-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_fr-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_fr-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_fr-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_fr-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_fr-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_fr-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_fr-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_fi-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_fi-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_fi-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_fi-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_fi-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_fi-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_fi-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_fi-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_fi-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_fi-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_fi-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_fi-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_fi-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_fi-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_fi-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_fi-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_fi-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_fi-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_fi-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_fi-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_fi-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_fi-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_fi-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_fi-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_fi-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_fi-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_fi-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_fi-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_fi-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_et-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_et-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_et-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_et-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_et-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_et-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_et-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_et-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_et-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_et-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_et-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_et-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_et-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_et-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_et-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_et-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_et-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_et-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_et-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_et-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_et-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_et-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_et-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_et-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_et-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_et-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_et-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_et-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_et-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_et-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_et-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_et-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_et-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_et-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_et-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_et-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_et-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_et-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_et-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_es-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_es-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_es-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_es-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_es-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_es-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_es-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_es-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_es-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_es-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_es-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_es-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_es-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_es-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_es-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_es-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_es-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_es-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_es-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_es-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_es-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_es-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_es-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_es-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_es-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_es-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_es-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_es-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_es-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_es-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_es-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_es-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_es-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_es-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_es-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_es-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_es-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_es-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_es-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_el-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_el-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_el-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_el-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_el-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_el-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_el-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_el-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_el-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_el-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_el-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_el-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_el-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_el-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_el-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_el-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_el-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_el-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_el-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_el-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_el-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_el-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_el-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_el-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_el-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_el-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_el-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_el-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_el-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_el-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_el-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_el-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_el-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_el-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_el-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_el-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_el-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_el-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_el-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_de-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_de-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_de-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_de-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_de-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_de-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_de-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_de-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_de-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_de-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_de-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_de-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_de-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_de-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_de-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_de-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_de-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_de-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_de-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_de-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_de-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_de-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_de-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_de-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_de-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_de-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_de-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_de-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_de-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_de-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_de-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_de-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_de-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_de-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_de-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_de-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_de-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_de-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_de-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_da-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_da-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_da-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_da-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_da-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_da-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_da-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_da-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_da-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_da-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_da-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_da-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_da-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_da-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_da-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_da-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_da-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_da-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_da-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_da-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_da-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_da-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_da-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_da-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_da-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_da-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_da-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_da-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_da-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_da-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_da-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_da-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_da-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_da-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_da-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_da-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_da-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_da-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_da-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_cs-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_cs-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_cs-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_cs-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_cs-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_cs-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_cs-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_cs-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_cs-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_cs-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_cs-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_cs-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_cs-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_cs-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_cs-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_cs-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_cs-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_cs-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_cs-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_cs-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_cs-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_cs-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_cs-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_cs-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_cs-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_cs-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_cs-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_cs-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_cs-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_bg-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_bg-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_bg-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_bg-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_bg-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_bg-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_bg-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_bg-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_bg-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_bg-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_bg-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_bg-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_bg-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_bg-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_bg-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_bg-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_bg-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_bg-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_bg-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_bg-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_bg-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_bg-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_bg-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_bg-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_bg-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_bg-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_bg-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_bg-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_bg-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_bg-abstract_algebra": {
      "original": 100,
      "effective": 100
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=openGPT-X/Teuken-7B-instruct-research-v0.4,dtype=bfloat16,trust_remote_code=True,nccl_timeout=3600,trust_remote_code=True",
    "model_num_parameters": 7452725248,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "1e971646850a86ca810dafecc90cb4efa8c8ea39",
    "batch_size": "auto:4",
    "batch_sizes": [
      8,
      32,
      32,
      64,
      64
    ],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "43468b99",
  "date": 1741208887.135506,
  "pretty_env_info": "PyTorch version: 2.6.0+cu124\nIs debug build: False\nCUDA used to build PyTorch: 12.4\nROCM used to build PyTorch: N/A\n\nOS: Ubuntu 22.04.5 LTS (x86_64)\nGCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\nClang version: Could not collect\nCMake version: Could not collect\nLibc version: glibc-2.35\n\nPython version: 3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0] (64-bit runtime)\nPython platform: Linux-5.15.0-133-generic-x86_64-with-glibc2.35\nIs CUDA available: True\nCUDA runtime version: 12.4.131\nCUDA_MODULE_LOADING set to: LAZY\nGPU models and configuration: \nGPU 0: NVIDIA H100 80GB HBM3\nGPU 1: NVIDIA H100 80GB HBM3\nGPU 2: NVIDIA H100 80GB HBM3\nGPU 3: NVIDIA H100 80GB HBM3\nGPU 4: NVIDIA H100 80GB HBM3\nGPU 5: NVIDIA H100 80GB HBM3\nGPU 6: NVIDIA H100 80GB HBM3\nGPU 7: NVIDIA H100 80GB HBM3\n\nNvidia driver version: 550.144.03\ncuDNN version: Could not collect\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nArchitecture:                         x86_64\nCPU op-mode(s):                       32-bit, 64-bit\nAddress sizes:                        52 bits physical, 57 bits virtual\nByte Order:                           Little Endian\nCPU(s):                               192\nOn-line CPU(s) list:                  0-191\nVendor ID:                            AuthenticAMD\nModel name:                           AMD EPYC 9654 96-Core Processor\nCPU family:                           25\nModel:                                17\nThread(s) per core:                   1\nCore(s) per socket:                   96\nSocket(s):                            2\nStepping:                             1\nFrequency boost:                      enabled\nCPU max MHz:                          3707.8120\nCPU min MHz:                          1500.0000\nBogoMIPS:                             4793.01\nFlags:                                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 invpcid_single hw_pstate ssbd mba ibrs ibpb stibp ibrs_enhanced vmmcall fsgsbase bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local avx512_bf16 clzero irperf xsaveerptr rdpru wbnoinvd amd_ppin cppc arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif v_spec_ctrl avx512vbmi umip pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg avx512_vpopcntdq la57 rdpid overflow_recov succor smca fsrm flush_l1d\nVirtualization:                       AMD-V\nL1d cache:                            6 MiB (192 instances)\nL1i cache:                            6 MiB (192 instances)\nL2 cache:                             192 MiB (192 instances)\nL3 cache:                             768 MiB (24 instances)\nNUMA node(s):                         2\nNUMA node0 CPU(s):                    0-95\nNUMA node1 CPU(s):                    96-191\nVulnerability Gather data sampling:   Not affected\nVulnerability Itlb multihit:          Not affected\nVulnerability L1tf:                   Not affected\nVulnerability Mds:                    Not affected\nVulnerability Meltdown:               Not affected\nVulnerability Mmio stale data:        Not affected\nVulnerability Reg file data sampling: Not affected\nVulnerability Retbleed:               Not affected\nVulnerability Spec rstack overflow:   Mitigation; safe RET\nVulnerability Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prctl and seccomp\nVulnerability Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointer sanitization\nVulnerability Spectre v2:             Mitigation; Enhanced / Automatic IBRS; IBPB conditional; STIBP disabled; RSB filling; PBRSB-eIBRS Not affected; BHI Not affected\nVulnerability Srbds:                  Not affected\nVulnerability Tsx async abort:        Not affected\n\nVersions of relevant libraries:\n[pip3] numpy==2.2.3\n[pip3] nvidia-cublas-cu12==12.4.5.8\n[pip3] nvidia-cuda-cupti-cu12==12.4.127\n[pip3] nvidia-cuda-nvrtc-cu12==12.4.127\n[pip3] nvidia-cuda-runtime-cu12==12.4.127\n[pip3] nvidia-cudnn-cu12==9.1.0.70\n[pip3] nvidia-cufft-cu12==11.2.1.3\n[pip3] nvidia-curand-cu12==10.3.5.147\n[pip3] nvidia-cusolver-cu12==11.6.1.9\n[pip3] nvidia-cusparse-cu12==12.3.1.170\n[pip3] nvidia-cusparselt-cu12==0.6.2\n[pip3] nvidia-nccl-cu12==2.21.5\n[pip3] nvidia-nvjitlink-cu12==12.4.127\n[pip3] nvidia-nvtx-cu12==12.4.127\n[pip3] torch==2.6.0\n[pip3] triton==3.2.0\n[conda] Could not collect",
  "transformers_version": "4.49.0",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<pad>",
    3
  ],
  "tokenizer_eos_token": [
    "</s>",
    2
  ],
  "tokenizer_bos_token": [
    "<s>",
    1
  ],
  "eot_token_id": 2,
  "max_length": 4096,
  "task_hashes": {},
  "model_source": "hf",
  "model_name": "openGPT-X/Teuken-7B-instruct-research-v0.4",
  "model_name_sanitized": "openGPT-X__Teuken-7B-instruct-research-v0.4",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": true,
  "chat_template": "System: A chat between a human and an artificial intelligence assistant.The assistant gives helpful and polite answers to the human's questions.{{- '\\n'}}\n{%- for message in messages %}\n{%- if (message['role']|lower == 'user') != (loop.index0 % 2 == 0) %}\n{{- raise_exception('Roles must alternate User/Assistant/User/Assistant/...') }}\n{%- endif %}\n{%-if message['role']|lower == 'user' %}\n{{- message['role']|capitalize + ': ' + message['content'] + '\\n' }}\n{%- elif message['role']|lower == 'assistant' %}\n{{- message['role']|capitalize + ': ' + message['content'] + eos_token + '\\n' }}\n{%- else %}\n{{- raise_exception('Only user and assistant roles are supported!') }}\n {%- endif %}\n{%- endfor %}{%-if add_generation_prompt %}\n{{- 'Assistant: '}}\n{%- endif %}\n",
  "chat_template_sha": "b1a4e0d8ff5c0beedd738e75f8bbe30520dbd9ce7a09df7020c20ce9e2379277",
  "start_time": 101133.147246281,
  "end_time": 105220.117171271,
  "total_evaluation_time_seconds": "4086.9699249900004"
}