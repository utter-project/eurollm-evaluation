{
  "results": {
    "ogx_mmlux_sv-world_religions": {
      "acc,none": 0.6549707602339181,
      "acc_stderr,none": 0.036459813773888065,
      "alias": "ogx_mmlux_sv-world_religions"
    },
    "ogx_mmlux_sv-virology": {
      "acc,none": 0.4457831325301205,
      "acc_stderr,none": 0.03869543323472101,
      "alias": "ogx_mmlux_sv-virology"
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "acc,none": 0.67,
      "acc_stderr,none": 0.047258156262526094,
      "alias": "ogx_mmlux_sv-us_foreign_policy"
    },
    "ogx_mmlux_sv-sociology": {
      "acc,none": 0.6567164179104478,
      "acc_stderr,none": 0.03357379665433431,
      "alias": "ogx_mmlux_sv-sociology"
    },
    "ogx_mmlux_sv-security_studies": {
      "acc,none": 0.6612244897959184,
      "acc_stderr,none": 0.030299506562154185,
      "alias": "ogx_mmlux_sv-security_studies"
    },
    "ogx_mmlux_sv-public_relations": {
      "acc,none": 0.509090909090909,
      "acc_stderr,none": 0.04788339768702861,
      "alias": "ogx_mmlux_sv-public_relations"
    },
    "ogx_mmlux_sv-professional_psychology": {
      "acc,none": 0.47058823529411764,
      "acc_stderr,none": 0.020192808271433795,
      "alias": "ogx_mmlux_sv-professional_psychology"
    },
    "ogx_mmlux_sv-professional_medicine": {
      "acc,none": 0.4632352941176471,
      "acc_stderr,none": 0.030290619180485694,
      "alias": "ogx_mmlux_sv-professional_medicine"
    },
    "ogx_mmlux_sv-professional_law": {
      "acc,none": 0.363754889178618,
      "acc_stderr,none": 0.012286991879902889,
      "alias": "ogx_mmlux_sv-professional_law"
    },
    "ogx_mmlux_sv-professional_accounting": {
      "acc,none": 0.3723404255319149,
      "acc_stderr,none": 0.028838921471251458,
      "alias": "ogx_mmlux_sv-professional_accounting"
    },
    "ogx_mmlux_sv-prehistory": {
      "acc,none": 0.5679012345679012,
      "acc_stderr,none": 0.02756301097160668,
      "alias": "ogx_mmlux_sv-prehistory"
    },
    "ogx_mmlux_sv-philosophy": {
      "acc,none": 0.5562700964630225,
      "acc_stderr,none": 0.028217683556652315,
      "alias": "ogx_mmlux_sv-philosophy"
    },
    "ogx_mmlux_sv-nutrition": {
      "acc,none": 0.545751633986928,
      "acc_stderr,none": 0.02850980780262658,
      "alias": "ogx_mmlux_sv-nutrition"
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "acc,none": 0.3754189944134078,
      "acc_stderr,none": 0.01619510424846353,
      "alias": "ogx_mmlux_sv-moral_scenarios"
    },
    "ogx_mmlux_sv-moral_disputes": {
      "acc,none": 0.5346820809248555,
      "acc_stderr,none": 0.02685425792825888,
      "alias": "ogx_mmlux_sv-moral_disputes"
    },
    "ogx_mmlux_sv-miscellaneous": {
      "acc,none": 0.6181353767560664,
      "acc_stderr,none": 0.017373732736677597,
      "alias": "ogx_mmlux_sv-miscellaneous"
    },
    "ogx_mmlux_sv-medical_genetics": {
      "acc,none": 0.55,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_sv-medical_genetics"
    },
    "ogx_mmlux_sv-marketing": {
      "acc,none": 0.7222222222222222,
      "acc_stderr,none": 0.029343114798094455,
      "alias": "ogx_mmlux_sv-marketing"
    },
    "ogx_mmlux_sv-management": {
      "acc,none": 0.7378640776699029,
      "acc_stderr,none": 0.04354631077260595,
      "alias": "ogx_mmlux_sv-management"
    },
    "ogx_mmlux_sv-machine_learning": {
      "acc,none": 0.32142857142857145,
      "acc_stderr,none": 0.0443280405529152,
      "alias": "ogx_mmlux_sv-machine_learning"
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "acc,none": 0.5337423312883436,
      "acc_stderr,none": 0.03919415545048411,
      "alias": "ogx_mmlux_sv-logical_fallacies"
    },
    "ogx_mmlux_sv-jurisprudence": {
      "acc,none": 0.5462962962962963,
      "acc_stderr,none": 0.048129173245368216,
      "alias": "ogx_mmlux_sv-jurisprudence"
    },
    "ogx_mmlux_sv-international_law": {
      "acc,none": 0.6694214876033058,
      "acc_stderr,none": 0.04294340845212094,
      "alias": "ogx_mmlux_sv-international_law"
    },
    "ogx_mmlux_sv-human_sexuality": {
      "acc,none": 0.6564885496183206,
      "acc_stderr,none": 0.041649760719448786,
      "alias": "ogx_mmlux_sv-human_sexuality"
    },
    "ogx_mmlux_sv-human_aging": {
      "acc,none": 0.5022421524663677,
      "acc_stderr,none": 0.033557465352232634,
      "alias": "ogx_mmlux_sv-human_aging"
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "acc,none": 0.6455696202531646,
      "acc_stderr,none": 0.03113730429718581,
      "alias": "ogx_mmlux_sv-high_school_world_history"
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "acc,none": 0.6568627450980392,
      "acc_stderr,none": 0.033321399446680854,
      "alias": "ogx_mmlux_sv-high_school_us_history"
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "acc,none": 0.4074074074074074,
      "acc_stderr,none": 0.03350991604696043,
      "alias": "ogx_mmlux_sv-high_school_statistics"
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "acc,none": 0.6256880733944954,
      "acc_stderr,none": 0.020748959408988327,
      "alias": "ogx_mmlux_sv-high_school_psychology"
    },
    "ogx_mmlux_sv-high_school_physics": {
      "acc,none": 0.2582781456953642,
      "acc_stderr,none": 0.035737053147634576,
      "alias": "ogx_mmlux_sv-high_school_physics"
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "acc,none": 0.47478991596638653,
      "acc_stderr,none": 0.032437180551374095,
      "alias": "ogx_mmlux_sv-high_school_microeconomics"
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "acc,none": 0.362962962962963,
      "acc_stderr,none": 0.029318203645206865,
      "alias": "ogx_mmlux_sv-high_school_mathematics"
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "acc,none": 0.4794871794871795,
      "acc_stderr,none": 0.025329663163489943,
      "alias": "ogx_mmlux_sv-high_school_macroeconomics"
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "acc,none": 0.5958549222797928,
      "acc_stderr,none": 0.035415085788840193,
      "alias": "ogx_mmlux_sv-high_school_government_and_politics"
    },
    "ogx_mmlux_sv-high_school_geography": {
      "acc,none": 0.6565656565656566,
      "acc_stderr,none": 0.03383201223244443,
      "alias": "ogx_mmlux_sv-high_school_geography"
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "acc,none": 0.7090909090909091,
      "acc_stderr,none": 0.03546563019624336,
      "alias": "ogx_mmlux_sv-high_school_european_history"
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_sv-high_school_computer_science"
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "acc,none": 0.42857142857142855,
      "acc_stderr,none": 0.03481904844438803,
      "alias": "ogx_mmlux_sv-high_school_chemistry"
    },
    "ogx_mmlux_sv-high_school_biology": {
      "acc,none": 0.5967741935483871,
      "acc_stderr,none": 0.027906150826041143,
      "alias": "ogx_mmlux_sv-high_school_biology"
    },
    "ogx_mmlux_sv-global_facts": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_sv-global_facts"
    },
    "ogx_mmlux_sv-formal_logic": {
      "acc,none": 0.36507936507936506,
      "acc_stderr,none": 0.043062412591271526,
      "alias": "ogx_mmlux_sv-formal_logic"
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "acc,none": 0.36507936507936506,
      "acc_stderr,none": 0.024796060602699944,
      "alias": "ogx_mmlux_sv-elementary_mathematics"
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "acc,none": 0.5379310344827586,
      "acc_stderr,none": 0.04154659671707548,
      "alias": "ogx_mmlux_sv-electrical_engineering"
    },
    "ogx_mmlux_sv-econometrics": {
      "acc,none": 0.3508771929824561,
      "acc_stderr,none": 0.044895393502706986,
      "alias": "ogx_mmlux_sv-econometrics"
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "acc,none": 0.42127659574468085,
      "acc_stderr,none": 0.03227834510146267,
      "alias": "ogx_mmlux_sv-conceptual_physics"
    },
    "ogx_mmlux_sv-computer_security": {
      "acc,none": 0.66,
      "acc_stderr,none": 0.04760952285695237,
      "alias": "ogx_mmlux_sv-computer_security"
    },
    "ogx_mmlux_sv-college_physics": {
      "acc,none": 0.3627450980392157,
      "acc_stderr,none": 0.04784060704105653,
      "alias": "ogx_mmlux_sv-college_physics"
    },
    "ogx_mmlux_sv-college_medicine": {
      "acc,none": 0.48554913294797686,
      "acc_stderr,none": 0.03810871630454764,
      "alias": "ogx_mmlux_sv-college_medicine"
    },
    "ogx_mmlux_sv-college_mathematics": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_sv-college_mathematics"
    },
    "ogx_mmlux_sv-college_computer_science": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_sv-college_computer_science"
    },
    "ogx_mmlux_sv-college_chemistry": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.04878317312145633,
      "alias": "ogx_mmlux_sv-college_chemistry"
    },
    "ogx_mmlux_sv-college_biology": {
      "acc,none": 0.5208333333333334,
      "acc_stderr,none": 0.041775789507399935,
      "alias": "ogx_mmlux_sv-college_biology"
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "acc,none": 0.5433962264150943,
      "acc_stderr,none": 0.030656748696739435,
      "alias": "ogx_mmlux_sv-clinical_knowledge"
    },
    "ogx_mmlux_sv-business_ethics": {
      "acc,none": 0.57,
      "acc_stderr,none": 0.04975698519562428,
      "alias": "ogx_mmlux_sv-business_ethics"
    },
    "ogx_mmlux_sv-astronomy": {
      "acc,none": 0.5986842105263158,
      "acc_stderr,none": 0.039889037033362836,
      "alias": "ogx_mmlux_sv-astronomy"
    },
    "ogx_mmlux_sv-anatomy": {
      "acc,none": 0.4740740740740741,
      "acc_stderr,none": 0.04313531696750574,
      "alias": "ogx_mmlux_sv-anatomy"
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_sv-abstract_algebra"
    },
    "ogx_mmlux_sl-world_religions": {
      "acc,none": 0.6257309941520468,
      "acc_stderr,none": 0.03711601185389481,
      "alias": "ogx_mmlux_sl-world_religions"
    },
    "ogx_mmlux_sl-virology": {
      "acc,none": 0.4036144578313253,
      "acc_stderr,none": 0.038194861407583984,
      "alias": "ogx_mmlux_sl-virology"
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237101,
      "alias": "ogx_mmlux_sl-us_foreign_policy"
    },
    "ogx_mmlux_sl-sociology": {
      "acc,none": 0.582089552238806,
      "acc_stderr,none": 0.034875586404620636,
      "alias": "ogx_mmlux_sl-sociology"
    },
    "ogx_mmlux_sl-security_studies": {
      "acc,none": 0.5836734693877551,
      "acc_stderr,none": 0.03155782816556162,
      "alias": "ogx_mmlux_sl-security_studies"
    },
    "ogx_mmlux_sl-public_relations": {
      "acc,none": 0.5272727272727272,
      "acc_stderr,none": 0.04782001791380061,
      "alias": "ogx_mmlux_sl-public_relations"
    },
    "ogx_mmlux_sl-professional_psychology": {
      "acc,none": 0.39705882352941174,
      "acc_stderr,none": 0.019794488900024113,
      "alias": "ogx_mmlux_sl-professional_psychology"
    },
    "ogx_mmlux_sl-professional_medicine": {
      "acc,none": 0.4007352941176471,
      "acc_stderr,none": 0.02976826352893311,
      "alias": "ogx_mmlux_sl-professional_medicine"
    },
    "ogx_mmlux_sl-professional_law": {
      "acc,none": 0.34159061277705344,
      "acc_stderr,none": 0.012112391320842852,
      "alias": "ogx_mmlux_sl-professional_law"
    },
    "ogx_mmlux_sl-professional_accounting": {
      "acc,none": 0.32978723404255317,
      "acc_stderr,none": 0.0280459469420424,
      "alias": "ogx_mmlux_sl-professional_accounting"
    },
    "ogx_mmlux_sl-prehistory": {
      "acc,none": 0.5154320987654321,
      "acc_stderr,none": 0.0278074900442762,
      "alias": "ogx_mmlux_sl-prehistory"
    },
    "ogx_mmlux_sl-philosophy": {
      "acc,none": 0.4630225080385852,
      "acc_stderr,none": 0.028320325830105915,
      "alias": "ogx_mmlux_sl-philosophy"
    },
    "ogx_mmlux_sl-nutrition": {
      "acc,none": 0.4738562091503268,
      "acc_stderr,none": 0.028590752958852394,
      "alias": "ogx_mmlux_sl-nutrition"
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "acc,none": 0.2759776536312849,
      "acc_stderr,none": 0.014950103002475349,
      "alias": "ogx_mmlux_sl-moral_scenarios"
    },
    "ogx_mmlux_sl-moral_disputes": {
      "acc,none": 0.5057803468208093,
      "acc_stderr,none": 0.026917296179149116,
      "alias": "ogx_mmlux_sl-moral_disputes"
    },
    "ogx_mmlux_sl-miscellaneous": {
      "acc,none": 0.5402298850574713,
      "acc_stderr,none": 0.01782199409693354,
      "alias": "ogx_mmlux_sl-miscellaneous"
    },
    "ogx_mmlux_sl-medical_genetics": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_sl-medical_genetics"
    },
    "ogx_mmlux_sl-marketing": {
      "acc,none": 0.6324786324786325,
      "acc_stderr,none": 0.031585391577456365,
      "alias": "ogx_mmlux_sl-marketing"
    },
    "ogx_mmlux_sl-management": {
      "acc,none": 0.5048543689320388,
      "acc_stderr,none": 0.049505043821289195,
      "alias": "ogx_mmlux_sl-management"
    },
    "ogx_mmlux_sl-machine_learning": {
      "acc,none": 0.26785714285714285,
      "acc_stderr,none": 0.04203277291467763,
      "alias": "ogx_mmlux_sl-machine_learning"
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "acc,none": 0.49079754601226994,
      "acc_stderr,none": 0.03927705600787443,
      "alias": "ogx_mmlux_sl-logical_fallacies"
    },
    "ogx_mmlux_sl-jurisprudence": {
      "acc,none": 0.5833333333333334,
      "acc_stderr,none": 0.04766075165356461,
      "alias": "ogx_mmlux_sl-jurisprudence"
    },
    "ogx_mmlux_sl-international_law": {
      "acc,none": 0.6528925619834711,
      "acc_stderr,none": 0.043457245702925335,
      "alias": "ogx_mmlux_sl-international_law"
    },
    "ogx_mmlux_sl-human_sexuality": {
      "acc,none": 0.5190839694656488,
      "acc_stderr,none": 0.04382094705550989,
      "alias": "ogx_mmlux_sl-human_sexuality"
    },
    "ogx_mmlux_sl-human_aging": {
      "acc,none": 0.452914798206278,
      "acc_stderr,none": 0.03340867501923324,
      "alias": "ogx_mmlux_sl-human_aging"
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "acc,none": 0.5527426160337553,
      "acc_stderr,none": 0.03236564251614192,
      "alias": "ogx_mmlux_sl-high_school_world_history"
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "acc,none": 0.5343137254901961,
      "acc_stderr,none": 0.035010383276358976,
      "alias": "ogx_mmlux_sl-high_school_us_history"
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "acc,none": 0.3055555555555556,
      "acc_stderr,none": 0.031415546294025445,
      "alias": "ogx_mmlux_sl-high_school_statistics"
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "acc,none": 0.5376146788990825,
      "acc_stderr,none": 0.021376575274397583,
      "alias": "ogx_mmlux_sl-high_school_psychology"
    },
    "ogx_mmlux_sl-high_school_physics": {
      "acc,none": 0.31788079470198677,
      "acc_stderr,none": 0.038020397601079024,
      "alias": "ogx_mmlux_sl-high_school_physics"
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "acc,none": 0.42016806722689076,
      "acc_stderr,none": 0.03206183783236152,
      "alias": "ogx_mmlux_sl-high_school_microeconomics"
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "acc,none": 0.3111111111111111,
      "acc_stderr,none": 0.028226446749683522,
      "alias": "ogx_mmlux_sl-high_school_mathematics"
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "acc,none": 0.4282051282051282,
      "acc_stderr,none": 0.02508830145469484,
      "alias": "ogx_mmlux_sl-high_school_macroeconomics"
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "acc,none": 0.49740932642487046,
      "acc_stderr,none": 0.03608390745384487,
      "alias": "ogx_mmlux_sl-high_school_government_and_politics"
    },
    "ogx_mmlux_sl-high_school_geography": {
      "acc,none": 0.48484848484848486,
      "acc_stderr,none": 0.03560716516531061,
      "alias": "ogx_mmlux_sl-high_school_geography"
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "acc,none": 0.5878787878787879,
      "acc_stderr,none": 0.03843566993588717,
      "alias": "ogx_mmlux_sl-high_school_european_history"
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.04975698519562428,
      "alias": "ogx_mmlux_sl-high_school_computer_science"
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "acc,none": 0.37438423645320196,
      "acc_stderr,none": 0.03405155380561952,
      "alias": "ogx_mmlux_sl-high_school_chemistry"
    },
    "ogx_mmlux_sl-high_school_biology": {
      "acc,none": 0.5258064516129032,
      "acc_stderr,none": 0.02840609505765332,
      "alias": "ogx_mmlux_sl-high_school_biology"
    },
    "ogx_mmlux_sl-global_facts": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_sl-global_facts"
    },
    "ogx_mmlux_sl-formal_logic": {
      "acc,none": 0.40476190476190477,
      "acc_stderr,none": 0.04390259265377563,
      "alias": "ogx_mmlux_sl-formal_logic"
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "acc,none": 0.35185185185185186,
      "acc_stderr,none": 0.024594975128920945,
      "alias": "ogx_mmlux_sl-elementary_mathematics"
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "acc,none": 0.47586206896551725,
      "acc_stderr,none": 0.041618085035015295,
      "alias": "ogx_mmlux_sl-electrical_engineering"
    },
    "ogx_mmlux_sl-econometrics": {
      "acc,none": 0.35964912280701755,
      "acc_stderr,none": 0.04514496132873633,
      "alias": "ogx_mmlux_sl-econometrics"
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "acc,none": 0.4127659574468085,
      "acc_stderr,none": 0.03218471141400351,
      "alias": "ogx_mmlux_sl-conceptual_physics"
    },
    "ogx_mmlux_sl-computer_security": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237101,
      "alias": "ogx_mmlux_sl-computer_security"
    },
    "ogx_mmlux_sl-college_physics": {
      "acc,none": 0.27450980392156865,
      "acc_stderr,none": 0.04440521906179327,
      "alias": "ogx_mmlux_sl-college_physics"
    },
    "ogx_mmlux_sl-college_medicine": {
      "acc,none": 0.3988439306358382,
      "acc_stderr,none": 0.03733626655383509,
      "alias": "ogx_mmlux_sl-college_medicine"
    },
    "ogx_mmlux_sl-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_sl-college_mathematics"
    },
    "ogx_mmlux_sl-college_computer_science": {
      "acc,none": 0.41,
      "acc_stderr,none": 0.049431107042371025,
      "alias": "ogx_mmlux_sl-college_computer_science"
    },
    "ogx_mmlux_sl-college_chemistry": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_sl-college_chemistry"
    },
    "ogx_mmlux_sl-college_biology": {
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.04122728707651281,
      "alias": "ogx_mmlux_sl-college_biology"
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "acc,none": 0.46037735849056605,
      "acc_stderr,none": 0.030676096599389184,
      "alias": "ogx_mmlux_sl-clinical_knowledge"
    },
    "ogx_mmlux_sl-business_ethics": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_sl-business_ethics"
    },
    "ogx_mmlux_sl-astronomy": {
      "acc,none": 0.4473684210526316,
      "acc_stderr,none": 0.04046336883978251,
      "alias": "ogx_mmlux_sl-astronomy"
    },
    "ogx_mmlux_sl-anatomy": {
      "acc,none": 0.42962962962962964,
      "acc_stderr,none": 0.04276349494376599,
      "alias": "ogx_mmlux_sl-anatomy"
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "acc,none": 0.24,
      "acc_stderr,none": 0.04292346959909281,
      "alias": "ogx_mmlux_sl-abstract_algebra"
    },
    "ogx_mmlux_sk-world_religions": {
      "acc,none": 0.6783625730994152,
      "acc_stderr,none": 0.03582529442573122,
      "alias": "ogx_mmlux_sk-world_religions"
    },
    "ogx_mmlux_sk-virology": {
      "acc,none": 0.463855421686747,
      "acc_stderr,none": 0.03882310850890593,
      "alias": "ogx_mmlux_sk-virology"
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "acc,none": 0.69,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_sk-us_foreign_policy"
    },
    "ogx_mmlux_sk-sociology": {
      "acc,none": 0.6915422885572139,
      "acc_stderr,none": 0.03265819588512698,
      "alias": "ogx_mmlux_sk-sociology"
    },
    "ogx_mmlux_sk-security_studies": {
      "acc,none": 0.6653061224489796,
      "acc_stderr,none": 0.03020923522624231,
      "alias": "ogx_mmlux_sk-security_studies"
    },
    "ogx_mmlux_sk-public_relations": {
      "acc,none": 0.5454545454545454,
      "acc_stderr,none": 0.04769300568972744,
      "alias": "ogx_mmlux_sk-public_relations"
    },
    "ogx_mmlux_sk-professional_psychology": {
      "acc,none": 0.4542483660130719,
      "acc_stderr,none": 0.02014297455379519,
      "alias": "ogx_mmlux_sk-professional_psychology"
    },
    "ogx_mmlux_sk-professional_medicine": {
      "acc,none": 0.4963235294117647,
      "acc_stderr,none": 0.030372015885428188,
      "alias": "ogx_mmlux_sk-professional_medicine"
    },
    "ogx_mmlux_sk-professional_law": {
      "acc,none": 0.38722294654498046,
      "acc_stderr,none": 0.012441155326854933,
      "alias": "ogx_mmlux_sk-professional_law"
    },
    "ogx_mmlux_sk-professional_accounting": {
      "acc,none": 0.38652482269503546,
      "acc_stderr,none": 0.029049190342543465,
      "alias": "ogx_mmlux_sk-professional_accounting"
    },
    "ogx_mmlux_sk-prehistory": {
      "acc,none": 0.5864197530864198,
      "acc_stderr,none": 0.027402042040269955,
      "alias": "ogx_mmlux_sk-prehistory"
    },
    "ogx_mmlux_sk-philosophy": {
      "acc,none": 0.5241157556270096,
      "acc_stderr,none": 0.028365041542564563,
      "alias": "ogx_mmlux_sk-philosophy"
    },
    "ogx_mmlux_sk-nutrition": {
      "acc,none": 0.5784313725490197,
      "acc_stderr,none": 0.028275490156791448,
      "alias": "ogx_mmlux_sk-nutrition"
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "acc,none": 0.3888268156424581,
      "acc_stderr,none": 0.016303899530796126,
      "alias": "ogx_mmlux_sk-moral_scenarios"
    },
    "ogx_mmlux_sk-moral_disputes": {
      "acc,none": 0.5404624277456648,
      "acc_stderr,none": 0.026830805998952243,
      "alias": "ogx_mmlux_sk-moral_disputes"
    },
    "ogx_mmlux_sk-miscellaneous": {
      "acc,none": 0.6257982120051085,
      "acc_stderr,none": 0.017304805072252034,
      "alias": "ogx_mmlux_sk-miscellaneous"
    },
    "ogx_mmlux_sk-medical_genetics": {
      "acc,none": 0.54,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_sk-medical_genetics"
    },
    "ogx_mmlux_sk-marketing": {
      "acc,none": 0.7478632478632479,
      "acc_stderr,none": 0.02844796547623102,
      "alias": "ogx_mmlux_sk-marketing"
    },
    "ogx_mmlux_sk-management": {
      "acc,none": 0.6893203883495146,
      "acc_stderr,none": 0.045821241601615506,
      "alias": "ogx_mmlux_sk-management"
    },
    "ogx_mmlux_sk-machine_learning": {
      "acc,none": 0.36607142857142855,
      "acc_stderr,none": 0.0457237235873743,
      "alias": "ogx_mmlux_sk-machine_learning"
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "acc,none": 0.5214723926380368,
      "acc_stderr,none": 0.0392474687675113,
      "alias": "ogx_mmlux_sk-logical_fallacies"
    },
    "ogx_mmlux_sk-jurisprudence": {
      "acc,none": 0.5833333333333334,
      "acc_stderr,none": 0.04766075165356461,
      "alias": "ogx_mmlux_sk-jurisprudence"
    },
    "ogx_mmlux_sk-international_law": {
      "acc,none": 0.6776859504132231,
      "acc_stderr,none": 0.042664163633521685,
      "alias": "ogx_mmlux_sk-international_law"
    },
    "ogx_mmlux_sk-human_sexuality": {
      "acc,none": 0.549618320610687,
      "acc_stderr,none": 0.04363643698524779,
      "alias": "ogx_mmlux_sk-human_sexuality"
    },
    "ogx_mmlux_sk-human_aging": {
      "acc,none": 0.5201793721973094,
      "acc_stderr,none": 0.033530461674123,
      "alias": "ogx_mmlux_sk-human_aging"
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "acc,none": 0.6244725738396625,
      "acc_stderr,none": 0.03152256243091156,
      "alias": "ogx_mmlux_sk-high_school_world_history"
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "acc,none": 0.6176470588235294,
      "acc_stderr,none": 0.03410785338904719,
      "alias": "ogx_mmlux_sk-high_school_us_history"
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "acc,none": 0.37037037037037035,
      "acc_stderr,none": 0.03293377139415191,
      "alias": "ogx_mmlux_sk-high_school_statistics"
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "acc,none": 0.6568807339449542,
      "acc_stderr,none": 0.02035477773608604,
      "alias": "ogx_mmlux_sk-high_school_psychology"
    },
    "ogx_mmlux_sk-high_school_physics": {
      "acc,none": 0.3509933774834437,
      "acc_stderr,none": 0.03896981964257375,
      "alias": "ogx_mmlux_sk-high_school_physics"
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "acc,none": 0.4831932773109244,
      "acc_stderr,none": 0.03246013680375308,
      "alias": "ogx_mmlux_sk-high_school_microeconomics"
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.028742040903948492,
      "alias": "ogx_mmlux_sk-high_school_mathematics"
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "acc,none": 0.5230769230769231,
      "acc_stderr,none": 0.025323990861736242,
      "alias": "ogx_mmlux_sk-high_school_macroeconomics"
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "acc,none": 0.6424870466321243,
      "acc_stderr,none": 0.034588160421810114,
      "alias": "ogx_mmlux_sk-high_school_government_and_politics"
    },
    "ogx_mmlux_sk-high_school_geography": {
      "acc,none": 0.6212121212121212,
      "acc_stderr,none": 0.03456088731993747,
      "alias": "ogx_mmlux_sk-high_school_geography"
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "acc,none": 0.6606060606060606,
      "acc_stderr,none": 0.03697442205031595,
      "alias": "ogx_mmlux_sk-high_school_european_history"
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "acc,none": 0.53,
      "acc_stderr,none": 0.050161355804659205,
      "alias": "ogx_mmlux_sk-high_school_computer_science"
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "acc,none": 0.45320197044334976,
      "acc_stderr,none": 0.03502544650845872,
      "alias": "ogx_mmlux_sk-high_school_chemistry"
    },
    "ogx_mmlux_sk-high_school_biology": {
      "acc,none": 0.6064516129032258,
      "acc_stderr,none": 0.027791878753132267,
      "alias": "ogx_mmlux_sk-high_school_biology"
    },
    "ogx_mmlux_sk-global_facts": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.04688261722621504,
      "alias": "ogx_mmlux_sk-global_facts"
    },
    "ogx_mmlux_sk-formal_logic": {
      "acc,none": 0.4126984126984127,
      "acc_stderr,none": 0.04403438954768176,
      "alias": "ogx_mmlux_sk-formal_logic"
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "acc,none": 0.36772486772486773,
      "acc_stderr,none": 0.024833839825562413,
      "alias": "ogx_mmlux_sk-elementary_mathematics"
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "acc,none": 0.5379310344827586,
      "acc_stderr,none": 0.04154659671707548,
      "alias": "ogx_mmlux_sk-electrical_engineering"
    },
    "ogx_mmlux_sk-econometrics": {
      "acc,none": 0.40350877192982454,
      "acc_stderr,none": 0.04615186962583703,
      "alias": "ogx_mmlux_sk-econometrics"
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "acc,none": 0.4425531914893617,
      "acc_stderr,none": 0.03246956919789958,
      "alias": "ogx_mmlux_sk-conceptual_physics"
    },
    "ogx_mmlux_sk-computer_security": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_sk-computer_security"
    },
    "ogx_mmlux_sk-college_physics": {
      "acc,none": 0.35294117647058826,
      "acc_stderr,none": 0.04755129616062945,
      "alias": "ogx_mmlux_sk-college_physics"
    },
    "ogx_mmlux_sk-college_medicine": {
      "acc,none": 0.5144508670520231,
      "acc_stderr,none": 0.03810871630454764,
      "alias": "ogx_mmlux_sk-college_medicine"
    },
    "ogx_mmlux_sk-college_mathematics": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_sk-college_mathematics"
    },
    "ogx_mmlux_sk-college_computer_science": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_sk-college_computer_science"
    },
    "ogx_mmlux_sk-college_chemistry": {
      "acc,none": 0.41,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_sk-college_chemistry"
    },
    "ogx_mmlux_sk-college_biology": {
      "acc,none": 0.5694444444444444,
      "acc_stderr,none": 0.04140685639111503,
      "alias": "ogx_mmlux_sk-college_biology"
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "acc,none": 0.5509433962264151,
      "acc_stderr,none": 0.030612730713641092,
      "alias": "ogx_mmlux_sk-clinical_knowledge"
    },
    "ogx_mmlux_sk-business_ethics": {
      "acc,none": 0.54,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_sk-business_ethics"
    },
    "ogx_mmlux_sk-astronomy": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.04068942293855797,
      "alias": "ogx_mmlux_sk-astronomy"
    },
    "ogx_mmlux_sk-anatomy": {
      "acc,none": 0.4666666666666667,
      "acc_stderr,none": 0.043097329010363554,
      "alias": "ogx_mmlux_sk-anatomy"
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_sk-abstract_algebra"
    },
    "ogx_mmlux_ro-world_religions": {
      "acc,none": 0.7543859649122807,
      "acc_stderr,none": 0.0330140594698725,
      "alias": "ogx_mmlux_ro-world_religions"
    },
    "ogx_mmlux_ro-virology": {
      "acc,none": 0.4819277108433735,
      "acc_stderr,none": 0.038899512528272166,
      "alias": "ogx_mmlux_ro-virology"
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_ro-us_foreign_policy"
    },
    "ogx_mmlux_ro-sociology": {
      "acc,none": 0.7164179104477612,
      "acc_stderr,none": 0.03187187537919798,
      "alias": "ogx_mmlux_ro-sociology"
    },
    "ogx_mmlux_ro-security_studies": {
      "acc,none": 0.6938775510204082,
      "acc_stderr,none": 0.029504896454595957,
      "alias": "ogx_mmlux_ro-security_studies"
    },
    "ogx_mmlux_ro-public_relations": {
      "acc,none": 0.5727272727272728,
      "acc_stderr,none": 0.047381987035454834,
      "alias": "ogx_mmlux_ro-public_relations"
    },
    "ogx_mmlux_ro-professional_psychology": {
      "acc,none": 0.545751633986928,
      "acc_stderr,none": 0.020142974553795212,
      "alias": "ogx_mmlux_ro-professional_psychology"
    },
    "ogx_mmlux_ro-professional_medicine": {
      "acc,none": 0.5625,
      "acc_stderr,none": 0.030134614954403924,
      "alias": "ogx_mmlux_ro-professional_medicine"
    },
    "ogx_mmlux_ro-professional_law": {
      "acc,none": 0.41851368970013036,
      "acc_stderr,none": 0.012599505608336461,
      "alias": "ogx_mmlux_ro-professional_law"
    },
    "ogx_mmlux_ro-professional_accounting": {
      "acc,none": 0.40070921985815605,
      "acc_stderr,none": 0.029233465745573096,
      "alias": "ogx_mmlux_ro-professional_accounting"
    },
    "ogx_mmlux_ro-prehistory": {
      "acc,none": 0.6234567901234568,
      "acc_stderr,none": 0.026959344518747787,
      "alias": "ogx_mmlux_ro-prehistory"
    },
    "ogx_mmlux_ro-philosophy": {
      "acc,none": 0.6077170418006431,
      "acc_stderr,none": 0.027731258647011987,
      "alias": "ogx_mmlux_ro-philosophy"
    },
    "ogx_mmlux_ro-nutrition": {
      "acc,none": 0.6209150326797386,
      "acc_stderr,none": 0.027780141207023337,
      "alias": "ogx_mmlux_ro-nutrition"
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "acc,none": 0.4491620111731844,
      "acc_stderr,none": 0.01663583834163192,
      "alias": "ogx_mmlux_ro-moral_scenarios"
    },
    "ogx_mmlux_ro-moral_disputes": {
      "acc,none": 0.6445086705202312,
      "acc_stderr,none": 0.025770292082977243,
      "alias": "ogx_mmlux_ro-moral_disputes"
    },
    "ogx_mmlux_ro-miscellaneous": {
      "acc,none": 0.7330779054916986,
      "acc_stderr,none": 0.01581845089477757,
      "alias": "ogx_mmlux_ro-miscellaneous"
    },
    "ogx_mmlux_ro-medical_genetics": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_ro-medical_genetics"
    },
    "ogx_mmlux_ro-marketing": {
      "acc,none": 0.7863247863247863,
      "acc_stderr,none": 0.026853450377009168,
      "alias": "ogx_mmlux_ro-marketing"
    },
    "ogx_mmlux_ro-management": {
      "acc,none": 0.6893203883495146,
      "acc_stderr,none": 0.04582124160161549,
      "alias": "ogx_mmlux_ro-management"
    },
    "ogx_mmlux_ro-machine_learning": {
      "acc,none": 0.36607142857142855,
      "acc_stderr,none": 0.0457237235873743,
      "alias": "ogx_mmlux_ro-machine_learning"
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "acc,none": 0.5828220858895705,
      "acc_stderr,none": 0.03874102859818083,
      "alias": "ogx_mmlux_ro-logical_fallacies"
    },
    "ogx_mmlux_ro-jurisprudence": {
      "acc,none": 0.6574074074074074,
      "acc_stderr,none": 0.045879047413018105,
      "alias": "ogx_mmlux_ro-jurisprudence"
    },
    "ogx_mmlux_ro-international_law": {
      "acc,none": 0.6942148760330579,
      "acc_stderr,none": 0.04205953933884122,
      "alias": "ogx_mmlux_ro-international_law"
    },
    "ogx_mmlux_ro-human_sexuality": {
      "acc,none": 0.6335877862595419,
      "acc_stderr,none": 0.042258754519696386,
      "alias": "ogx_mmlux_ro-human_sexuality"
    },
    "ogx_mmlux_ro-human_aging": {
      "acc,none": 0.6098654708520179,
      "acc_stderr,none": 0.03273766725459157,
      "alias": "ogx_mmlux_ro-human_aging"
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "acc,none": 0.7383966244725738,
      "acc_stderr,none": 0.028609516716994934,
      "alias": "ogx_mmlux_ro-high_school_world_history"
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "acc,none": 0.7549019607843137,
      "acc_stderr,none": 0.030190282453501943,
      "alias": "ogx_mmlux_ro-high_school_us_history"
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "acc,none": 0.4398148148148148,
      "acc_stderr,none": 0.03385177976044811,
      "alias": "ogx_mmlux_ro-high_school_statistics"
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "acc,none": 0.7431192660550459,
      "acc_stderr,none": 0.018732492928342472,
      "alias": "ogx_mmlux_ro-high_school_psychology"
    },
    "ogx_mmlux_ro-high_school_physics": {
      "acc,none": 0.31788079470198677,
      "acc_stderr,none": 0.038020397601079024,
      "alias": "ogx_mmlux_ro-high_school_physics"
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "acc,none": 0.5882352941176471,
      "acc_stderr,none": 0.03196876989195778,
      "alias": "ogx_mmlux_ro-high_school_microeconomics"
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "acc,none": 0.34814814814814815,
      "acc_stderr,none": 0.029045600290616258,
      "alias": "ogx_mmlux_ro-high_school_mathematics"
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "acc,none": 0.5743589743589743,
      "acc_stderr,none": 0.025069094387296514,
      "alias": "ogx_mmlux_ro-high_school_macroeconomics"
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "acc,none": 0.7409326424870466,
      "acc_stderr,none": 0.031618779179354094,
      "alias": "ogx_mmlux_ro-high_school_government_and_politics"
    },
    "ogx_mmlux_ro-high_school_geography": {
      "acc,none": 0.7575757575757576,
      "acc_stderr,none": 0.030532892233932036,
      "alias": "ogx_mmlux_ro-high_school_geography"
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "acc,none": 0.7454545454545455,
      "acc_stderr,none": 0.0340150671524904,
      "alias": "ogx_mmlux_ro-high_school_european_history"
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237101,
      "alias": "ogx_mmlux_ro-high_school_computer_science"
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "acc,none": 0.4088669950738916,
      "acc_stderr,none": 0.034590588158832314,
      "alias": "ogx_mmlux_ro-high_school_chemistry"
    },
    "ogx_mmlux_ro-high_school_biology": {
      "acc,none": 0.6580645161290323,
      "acc_stderr,none": 0.02698528957655275,
      "alias": "ogx_mmlux_ro-high_school_biology"
    },
    "ogx_mmlux_ro-global_facts": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_ro-global_facts"
    },
    "ogx_mmlux_ro-formal_logic": {
      "acc,none": 0.4444444444444444,
      "acc_stderr,none": 0.044444444444444495,
      "alias": "ogx_mmlux_ro-formal_logic"
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.02510742548113728,
      "alias": "ogx_mmlux_ro-elementary_mathematics"
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "acc,none": 0.5586206896551724,
      "acc_stderr,none": 0.04137931034482757,
      "alias": "ogx_mmlux_ro-electrical_engineering"
    },
    "ogx_mmlux_ro-econometrics": {
      "acc,none": 0.38596491228070173,
      "acc_stderr,none": 0.04579639422070434,
      "alias": "ogx_mmlux_ro-econometrics"
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "acc,none": 0.502127659574468,
      "acc_stderr,none": 0.03268572658667492,
      "alias": "ogx_mmlux_ro-conceptual_physics"
    },
    "ogx_mmlux_ro-computer_security": {
      "acc,none": 0.66,
      "acc_stderr,none": 0.04760952285695238,
      "alias": "ogx_mmlux_ro-computer_security"
    },
    "ogx_mmlux_ro-college_physics": {
      "acc,none": 0.4019607843137255,
      "acc_stderr,none": 0.048786087144669955,
      "alias": "ogx_mmlux_ro-college_physics"
    },
    "ogx_mmlux_ro-college_medicine": {
      "acc,none": 0.5838150289017341,
      "acc_stderr,none": 0.03758517775404947,
      "alias": "ogx_mmlux_ro-college_medicine"
    },
    "ogx_mmlux_ro-college_mathematics": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_ro-college_mathematics"
    },
    "ogx_mmlux_ro-college_computer_science": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_ro-college_computer_science"
    },
    "ogx_mmlux_ro-college_chemistry": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_ro-college_chemistry"
    },
    "ogx_mmlux_ro-college_biology": {
      "acc,none": 0.5833333333333334,
      "acc_stderr,none": 0.041227287076512825,
      "alias": "ogx_mmlux_ro-college_biology"
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "acc,none": 0.5886792452830188,
      "acc_stderr,none": 0.030285009259009794,
      "alias": "ogx_mmlux_ro-clinical_knowledge"
    },
    "ogx_mmlux_ro-business_ethics": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_ro-business_ethics"
    },
    "ogx_mmlux_ro-astronomy": {
      "acc,none": 0.5921052631578947,
      "acc_stderr,none": 0.03999309712777472,
      "alias": "ogx_mmlux_ro-astronomy"
    },
    "ogx_mmlux_ro-anatomy": {
      "acc,none": 0.5111111111111111,
      "acc_stderr,none": 0.04318275491977976,
      "alias": "ogx_mmlux_ro-anatomy"
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_ro-abstract_algebra"
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "acc,none": 0.7719298245614035,
      "acc_stderr,none": 0.03218093795602357,
      "alias": "ogx_mmlux_pt-pt-world_religions"
    },
    "ogx_mmlux_pt-pt-virology": {
      "acc,none": 0.4819277108433735,
      "acc_stderr,none": 0.038899512528272166,
      "alias": "ogx_mmlux_pt-pt-virology"
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.0440844002276808,
      "alias": "ogx_mmlux_pt-pt-us_foreign_policy"
    },
    "ogx_mmlux_pt-pt-sociology": {
      "acc,none": 0.7661691542288557,
      "acc_stderr,none": 0.029929415408348398,
      "alias": "ogx_mmlux_pt-pt-sociology"
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "acc,none": 0.6938775510204082,
      "acc_stderr,none": 0.029504896454595954,
      "alias": "ogx_mmlux_pt-pt-security_studies"
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "acc,none": 0.5909090909090909,
      "acc_stderr,none": 0.04709306978661896,
      "alias": "ogx_mmlux_pt-pt-public_relations"
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "acc,none": 0.5555555555555556,
      "acc_stderr,none": 0.02010258389588718,
      "alias": "ogx_mmlux_pt-pt-professional_psychology"
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "acc,none": 0.6176470588235294,
      "acc_stderr,none": 0.02952009569768777,
      "alias": "ogx_mmlux_pt-pt-professional_medicine"
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "acc,none": 0.4256844850065189,
      "acc_stderr,none": 0.012628393551811943,
      "alias": "ogx_mmlux_pt-pt-professional_law"
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "acc,none": 0.3900709219858156,
      "acc_stderr,none": 0.029097675599463933,
      "alias": "ogx_mmlux_pt-pt-professional_accounting"
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "acc,none": 0.6635802469135802,
      "acc_stderr,none": 0.026289734945952926,
      "alias": "ogx_mmlux_pt-pt-prehistory"
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "acc,none": 0.6302250803858521,
      "acc_stderr,none": 0.027417996705631,
      "alias": "ogx_mmlux_pt-pt-philosophy"
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "acc,none": 0.6078431372549019,
      "acc_stderr,none": 0.027956046165424516,
      "alias": "ogx_mmlux_pt-pt-nutrition"
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "acc,none": 0.4491620111731844,
      "acc_stderr,none": 0.016635838341631917,
      "alias": "ogx_mmlux_pt-pt-moral_scenarios"
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "acc,none": 0.6502890173410405,
      "acc_stderr,none": 0.02567428145653102,
      "alias": "ogx_mmlux_pt-pt-moral_disputes"
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "acc,none": 0.7394636015325671,
      "acc_stderr,none": 0.015696008563807092,
      "alias": "ogx_mmlux_pt-pt-miscellaneous"
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_pt-pt-medical_genetics"
    },
    "ogx_mmlux_pt-pt-marketing": {
      "acc,none": 0.782051282051282,
      "acc_stderr,none": 0.027046857630716688,
      "alias": "ogx_mmlux_pt-pt-marketing"
    },
    "ogx_mmlux_pt-pt-management": {
      "acc,none": 0.7281553398058253,
      "acc_stderr,none": 0.044052680241409216,
      "alias": "ogx_mmlux_pt-pt-management"
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "acc,none": 0.375,
      "acc_stderr,none": 0.04595091388086298,
      "alias": "ogx_mmlux_pt-pt-machine_learning"
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "acc,none": 0.6503067484662577,
      "acc_stderr,none": 0.03746668325470023,
      "alias": "ogx_mmlux_pt-pt-logical_fallacies"
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "acc,none": 0.7129629629629629,
      "acc_stderr,none": 0.043733130409147614,
      "alias": "ogx_mmlux_pt-pt-jurisprudence"
    },
    "ogx_mmlux_pt-pt-international_law": {
      "acc,none": 0.7272727272727273,
      "acc_stderr,none": 0.04065578140908705,
      "alias": "ogx_mmlux_pt-pt-international_law"
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "acc,none": 0.6717557251908397,
      "acc_stderr,none": 0.04118438565806298,
      "alias": "ogx_mmlux_pt-pt-human_sexuality"
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "acc,none": 0.6412556053811659,
      "acc_stderr,none": 0.03219079200419996,
      "alias": "ogx_mmlux_pt-pt-human_aging"
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "acc,none": 0.7341772151898734,
      "acc_stderr,none": 0.028756799629658332,
      "alias": "ogx_mmlux_pt-pt-high_school_world_history"
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "acc,none": 0.7450980392156863,
      "acc_stderr,none": 0.03058759135160424,
      "alias": "ogx_mmlux_pt-pt-high_school_us_history"
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "acc,none": 0.4305555555555556,
      "acc_stderr,none": 0.03376922151252336,
      "alias": "ogx_mmlux_pt-pt-high_school_statistics"
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "acc,none": 0.744954128440367,
      "acc_stderr,none": 0.01868850085653584,
      "alias": "ogx_mmlux_pt-pt-high_school_psychology"
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "acc,none": 0.31788079470198677,
      "acc_stderr,none": 0.038020397601079024,
      "alias": "ogx_mmlux_pt-pt-high_school_physics"
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "acc,none": 0.592436974789916,
      "acc_stderr,none": 0.031918633744784645,
      "alias": "ogx_mmlux_pt-pt-high_school_microeconomics"
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.0298696050953169,
      "alias": "ogx_mmlux_pt-pt-high_school_mathematics"
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "acc,none": 0.5923076923076923,
      "acc_stderr,none": 0.024915243985987857,
      "alias": "ogx_mmlux_pt-pt-high_school_macroeconomics"
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "acc,none": 0.7409326424870466,
      "acc_stderr,none": 0.031618779179354094,
      "alias": "ogx_mmlux_pt-pt-high_school_government_and_politics"
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "acc,none": 0.7424242424242424,
      "acc_stderr,none": 0.031156269519646836,
      "alias": "ogx_mmlux_pt-pt-high_school_geography"
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "acc,none": 0.7636363636363637,
      "acc_stderr,none": 0.033175059300091805,
      "alias": "ogx_mmlux_pt-pt-high_school_european_history"
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "acc,none": 0.65,
      "acc_stderr,none": 0.04793724854411019,
      "alias": "ogx_mmlux_pt-pt-high_school_computer_science"
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "acc,none": 0.45320197044334976,
      "acc_stderr,none": 0.03502544650845872,
      "alias": "ogx_mmlux_pt-pt-high_school_chemistry"
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "acc,none": 0.7064516129032258,
      "acc_stderr,none": 0.02590608702131929,
      "alias": "ogx_mmlux_pt-pt-high_school_biology"
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_pt-pt-global_facts"
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "acc,none": 0.4365079365079365,
      "acc_stderr,none": 0.04435932892851466,
      "alias": "ogx_mmlux_pt-pt-formal_logic"
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "acc,none": 0.3941798941798942,
      "acc_stderr,none": 0.025167982333894143,
      "alias": "ogx_mmlux_pt-pt-elementary_mathematics"
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.04082482904638628,
      "alias": "ogx_mmlux_pt-pt-electrical_engineering"
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "acc,none": 0.38596491228070173,
      "acc_stderr,none": 0.045796394220704355,
      "alias": "ogx_mmlux_pt-pt-econometrics"
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "acc,none": 0.5106382978723404,
      "acc_stderr,none": 0.03267862331014063,
      "alias": "ogx_mmlux_pt-pt-conceptual_physics"
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_pt-pt-computer_security"
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "acc,none": 0.39215686274509803,
      "acc_stderr,none": 0.04858083574266345,
      "alias": "ogx_mmlux_pt-pt-college_physics"
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "acc,none": 0.5549132947976878,
      "acc_stderr,none": 0.03789401760283647,
      "alias": "ogx_mmlux_pt-pt-college_medicine"
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_pt-pt-college_mathematics"
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "acc,none": 0.41,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_pt-pt-college_computer_science"
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_pt-pt-college_chemistry"
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "acc,none": 0.6458333333333334,
      "acc_stderr,none": 0.039994111357535424,
      "alias": "ogx_mmlux_pt-pt-college_biology"
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "acc,none": 0.5811320754716981,
      "acc_stderr,none": 0.03036505082911521,
      "alias": "ogx_mmlux_pt-pt-clinical_knowledge"
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "acc,none": 0.57,
      "acc_stderr,none": 0.04975698519562428,
      "alias": "ogx_mmlux_pt-pt-business_ethics"
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "acc,none": 0.6513157894736842,
      "acc_stderr,none": 0.03878139888797611,
      "alias": "ogx_mmlux_pt-pt-astronomy"
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "acc,none": 0.5259259259259259,
      "acc_stderr,none": 0.04313531696750575,
      "alias": "ogx_mmlux_pt-pt-anatomy"
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_pt-pt-abstract_algebra"
    },
    "ogx_mmlux_pl-world_religions": {
      "acc,none": 0.7192982456140351,
      "acc_stderr,none": 0.034462962170884265,
      "alias": "ogx_mmlux_pl-world_religions"
    },
    "ogx_mmlux_pl-virology": {
      "acc,none": 0.5180722891566265,
      "acc_stderr,none": 0.03889951252827216,
      "alias": "ogx_mmlux_pl-virology"
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "acc,none": 0.72,
      "acc_stderr,none": 0.04512608598542128,
      "alias": "ogx_mmlux_pl-us_foreign_policy"
    },
    "ogx_mmlux_pl-sociology": {
      "acc,none": 0.7412935323383084,
      "acc_stderr,none": 0.030965903123573023,
      "alias": "ogx_mmlux_pl-sociology"
    },
    "ogx_mmlux_pl-security_studies": {
      "acc,none": 0.6408163265306123,
      "acc_stderr,none": 0.030713560455108493,
      "alias": "ogx_mmlux_pl-security_studies"
    },
    "ogx_mmlux_pl-public_relations": {
      "acc,none": 0.5818181818181818,
      "acc_stderr,none": 0.04724577405731572,
      "alias": "ogx_mmlux_pl-public_relations"
    },
    "ogx_mmlux_pl-professional_psychology": {
      "acc,none": 0.5032679738562091,
      "acc_stderr,none": 0.020227402794434864,
      "alias": "ogx_mmlux_pl-professional_psychology"
    },
    "ogx_mmlux_pl-professional_medicine": {
      "acc,none": 0.5367647058823529,
      "acc_stderr,none": 0.03029061918048569,
      "alias": "ogx_mmlux_pl-professional_medicine"
    },
    "ogx_mmlux_pl-professional_law": {
      "acc,none": 0.39765319426336376,
      "acc_stderr,none": 0.012499840347460637,
      "alias": "ogx_mmlux_pl-professional_law"
    },
    "ogx_mmlux_pl-professional_accounting": {
      "acc,none": 0.35106382978723405,
      "acc_stderr,none": 0.028473501272963754,
      "alias": "ogx_mmlux_pl-professional_accounting"
    },
    "ogx_mmlux_pl-prehistory": {
      "acc,none": 0.6327160493827161,
      "acc_stderr,none": 0.026822801759507894,
      "alias": "ogx_mmlux_pl-prehistory"
    },
    "ogx_mmlux_pl-philosophy": {
      "acc,none": 0.6012861736334405,
      "acc_stderr,none": 0.0278093225857745,
      "alias": "ogx_mmlux_pl-philosophy"
    },
    "ogx_mmlux_pl-nutrition": {
      "acc,none": 0.5947712418300654,
      "acc_stderr,none": 0.028110928492809068,
      "alias": "ogx_mmlux_pl-nutrition"
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "acc,none": 0.4100558659217877,
      "acc_stderr,none": 0.016449708209026085,
      "alias": "ogx_mmlux_pl-moral_scenarios"
    },
    "ogx_mmlux_pl-moral_disputes": {
      "acc,none": 0.6040462427745664,
      "acc_stderr,none": 0.026329813341946243,
      "alias": "ogx_mmlux_pl-moral_disputes"
    },
    "ogx_mmlux_pl-miscellaneous": {
      "acc,none": 0.7049808429118773,
      "acc_stderr,none": 0.01630836377293272,
      "alias": "ogx_mmlux_pl-miscellaneous"
    },
    "ogx_mmlux_pl-medical_genetics": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.04960449637488583,
      "alias": "ogx_mmlux_pl-medical_genetics"
    },
    "ogx_mmlux_pl-marketing": {
      "acc,none": 0.7735042735042735,
      "acc_stderr,none": 0.02742100729539291,
      "alias": "ogx_mmlux_pl-marketing"
    },
    "ogx_mmlux_pl-management": {
      "acc,none": 0.7475728155339806,
      "acc_stderr,none": 0.04301250399690878,
      "alias": "ogx_mmlux_pl-management"
    },
    "ogx_mmlux_pl-machine_learning": {
      "acc,none": 0.3392857142857143,
      "acc_stderr,none": 0.0449394906861354,
      "alias": "ogx_mmlux_pl-machine_learning"
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "acc,none": 0.6196319018404908,
      "acc_stderr,none": 0.03814269893261837,
      "alias": "ogx_mmlux_pl-logical_fallacies"
    },
    "ogx_mmlux_pl-jurisprudence": {
      "acc,none": 0.5740740740740741,
      "acc_stderr,none": 0.0478034362693679,
      "alias": "ogx_mmlux_pl-jurisprudence"
    },
    "ogx_mmlux_pl-international_law": {
      "acc,none": 0.71900826446281,
      "acc_stderr,none": 0.04103203830514512,
      "alias": "ogx_mmlux_pl-international_law"
    },
    "ogx_mmlux_pl-human_sexuality": {
      "acc,none": 0.6793893129770993,
      "acc_stderr,none": 0.04093329229834278,
      "alias": "ogx_mmlux_pl-human_sexuality"
    },
    "ogx_mmlux_pl-human_aging": {
      "acc,none": 0.5605381165919282,
      "acc_stderr,none": 0.033310925110381785,
      "alias": "ogx_mmlux_pl-human_aging"
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "acc,none": 0.7172995780590717,
      "acc_stderr,none": 0.029312814153955903,
      "alias": "ogx_mmlux_pl-high_school_world_history"
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "acc,none": 0.6862745098039216,
      "acc_stderr,none": 0.03256685484460389,
      "alias": "ogx_mmlux_pl-high_school_us_history"
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "acc,none": 0.41203703703703703,
      "acc_stderr,none": 0.03356787758160835,
      "alias": "ogx_mmlux_pl-high_school_statistics"
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "acc,none": 0.691743119266055,
      "acc_stderr,none": 0.019798366698367258,
      "alias": "ogx_mmlux_pl-high_school_psychology"
    },
    "ogx_mmlux_pl-high_school_physics": {
      "acc,none": 0.31125827814569534,
      "acc_stderr,none": 0.03780445850526732,
      "alias": "ogx_mmlux_pl-high_school_physics"
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "acc,none": 0.5252100840336135,
      "acc_stderr,none": 0.03243718055137411,
      "alias": "ogx_mmlux_pl-high_school_microeconomics"
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "acc,none": 0.37777777777777777,
      "acc_stderr,none": 0.029560707392465715,
      "alias": "ogx_mmlux_pl-high_school_mathematics"
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "acc,none": 0.5461538461538461,
      "acc_stderr,none": 0.02524277098712619,
      "alias": "ogx_mmlux_pl-high_school_macroeconomics"
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "acc,none": 0.7202072538860104,
      "acc_stderr,none": 0.03239637046735703,
      "alias": "ogx_mmlux_pl-high_school_government_and_politics"
    },
    "ogx_mmlux_pl-high_school_geography": {
      "acc,none": 0.7272727272727273,
      "acc_stderr,none": 0.03173071239071724,
      "alias": "ogx_mmlux_pl-high_school_geography"
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "acc,none": 0.7333333333333333,
      "acc_stderr,none": 0.03453131801885417,
      "alias": "ogx_mmlux_pl-high_school_european_history"
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_pl-high_school_computer_science"
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "acc,none": 0.43842364532019706,
      "acc_stderr,none": 0.03491207857486519,
      "alias": "ogx_mmlux_pl-high_school_chemistry"
    },
    "ogx_mmlux_pl-high_school_biology": {
      "acc,none": 0.6258064516129033,
      "acc_stderr,none": 0.027528904299845704,
      "alias": "ogx_mmlux_pl-high_school_biology"
    },
    "ogx_mmlux_pl-global_facts": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_pl-global_facts"
    },
    "ogx_mmlux_pl-formal_logic": {
      "acc,none": 0.3412698412698413,
      "acc_stderr,none": 0.04240799327574925,
      "alias": "ogx_mmlux_pl-formal_logic"
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "acc,none": 0.36507936507936506,
      "acc_stderr,none": 0.024796060602699947,
      "alias": "ogx_mmlux_pl-elementary_mathematics"
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "acc,none": 0.496551724137931,
      "acc_stderr,none": 0.041665675771015785,
      "alias": "ogx_mmlux_pl-electrical_engineering"
    },
    "ogx_mmlux_pl-econometrics": {
      "acc,none": 0.3508771929824561,
      "acc_stderr,none": 0.044895393502706986,
      "alias": "ogx_mmlux_pl-econometrics"
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "acc,none": 0.4595744680851064,
      "acc_stderr,none": 0.032579014820998356,
      "alias": "ogx_mmlux_pl-conceptual_physics"
    },
    "ogx_mmlux_pl-computer_security": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.04560480215720684,
      "alias": "ogx_mmlux_pl-computer_security"
    },
    "ogx_mmlux_pl-college_physics": {
      "acc,none": 0.38235294117647056,
      "acc_stderr,none": 0.04835503696107223,
      "alias": "ogx_mmlux_pl-college_physics"
    },
    "ogx_mmlux_pl-college_medicine": {
      "acc,none": 0.5317919075144508,
      "acc_stderr,none": 0.03804749744364764,
      "alias": "ogx_mmlux_pl-college_medicine"
    },
    "ogx_mmlux_pl-college_mathematics": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_pl-college_mathematics"
    },
    "ogx_mmlux_pl-college_computer_science": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_pl-college_computer_science"
    },
    "ogx_mmlux_pl-college_chemistry": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_pl-college_chemistry"
    },
    "ogx_mmlux_pl-college_biology": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.04181210050035455,
      "alias": "ogx_mmlux_pl-college_biology"
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "acc,none": 0.5962264150943396,
      "acc_stderr,none": 0.03019761160019795,
      "alias": "ogx_mmlux_pl-clinical_knowledge"
    },
    "ogx_mmlux_pl-business_ethics": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_pl-business_ethics"
    },
    "ogx_mmlux_pl-astronomy": {
      "acc,none": 0.5657894736842105,
      "acc_stderr,none": 0.040335656678483205,
      "alias": "ogx_mmlux_pl-astronomy"
    },
    "ogx_mmlux_pl-anatomy": {
      "acc,none": 0.45185185185185184,
      "acc_stderr,none": 0.04299268905480864,
      "alias": "ogx_mmlux_pl-anatomy"
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_pl-abstract_algebra"
    },
    "ogx_mmlux_nl-world_religions": {
      "acc,none": 0.7309941520467836,
      "acc_stderr,none": 0.03401052620104089,
      "alias": "ogx_mmlux_nl-world_religions"
    },
    "ogx_mmlux_nl-virology": {
      "acc,none": 0.536144578313253,
      "acc_stderr,none": 0.03882310850890593,
      "alias": "ogx_mmlux_nl-virology"
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.04560480215720684,
      "alias": "ogx_mmlux_nl-us_foreign_policy"
    },
    "ogx_mmlux_nl-sociology": {
      "acc,none": 0.7761194029850746,
      "acc_stderr,none": 0.029475250236017183,
      "alias": "ogx_mmlux_nl-sociology"
    },
    "ogx_mmlux_nl-security_studies": {
      "acc,none": 0.6938775510204082,
      "acc_stderr,none": 0.029504896454595947,
      "alias": "ogx_mmlux_nl-security_studies"
    },
    "ogx_mmlux_nl-public_relations": {
      "acc,none": 0.5909090909090909,
      "acc_stderr,none": 0.04709306978661896,
      "alias": "ogx_mmlux_nl-public_relations"
    },
    "ogx_mmlux_nl-professional_psychology": {
      "acc,none": 0.5343137254901961,
      "acc_stderr,none": 0.020180144843307293,
      "alias": "ogx_mmlux_nl-professional_psychology"
    },
    "ogx_mmlux_nl-professional_medicine": {
      "acc,none": 0.5772058823529411,
      "acc_stderr,none": 0.03000856284500348,
      "alias": "ogx_mmlux_nl-professional_medicine"
    },
    "ogx_mmlux_nl-professional_law": {
      "acc,none": 0.39308996088657105,
      "acc_stderr,none": 0.01247489961387396,
      "alias": "ogx_mmlux_nl-professional_law"
    },
    "ogx_mmlux_nl-professional_accounting": {
      "acc,none": 0.4078014184397163,
      "acc_stderr,none": 0.029316011776343562,
      "alias": "ogx_mmlux_nl-professional_accounting"
    },
    "ogx_mmlux_nl-prehistory": {
      "acc,none": 0.6512345679012346,
      "acc_stderr,none": 0.02651759772446501,
      "alias": "ogx_mmlux_nl-prehistory"
    },
    "ogx_mmlux_nl-philosophy": {
      "acc,none": 0.6077170418006431,
      "acc_stderr,none": 0.027731258647011998,
      "alias": "ogx_mmlux_nl-philosophy"
    },
    "ogx_mmlux_nl-nutrition": {
      "acc,none": 0.6045751633986928,
      "acc_stderr,none": 0.02799672318063145,
      "alias": "ogx_mmlux_nl-nutrition"
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "acc,none": 0.38994413407821227,
      "acc_stderr,none": 0.016312376629213067,
      "alias": "ogx_mmlux_nl-moral_scenarios"
    },
    "ogx_mmlux_nl-moral_disputes": {
      "acc,none": 0.615606936416185,
      "acc_stderr,none": 0.026189666966272035,
      "alias": "ogx_mmlux_nl-moral_disputes"
    },
    "ogx_mmlux_nl-miscellaneous": {
      "acc,none": 0.7254150702426565,
      "acc_stderr,none": 0.015959829933084035,
      "alias": "ogx_mmlux_nl-miscellaneous"
    },
    "ogx_mmlux_nl-medical_genetics": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.04878317312145632,
      "alias": "ogx_mmlux_nl-medical_genetics"
    },
    "ogx_mmlux_nl-marketing": {
      "acc,none": 0.7692307692307693,
      "acc_stderr,none": 0.027601921381417604,
      "alias": "ogx_mmlux_nl-marketing"
    },
    "ogx_mmlux_nl-management": {
      "acc,none": 0.6893203883495146,
      "acc_stderr,none": 0.045821241601615506,
      "alias": "ogx_mmlux_nl-management"
    },
    "ogx_mmlux_nl-machine_learning": {
      "acc,none": 0.35714285714285715,
      "acc_stderr,none": 0.04547960999764376,
      "alias": "ogx_mmlux_nl-machine_learning"
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "acc,none": 0.588957055214724,
      "acc_stderr,none": 0.038656978537853624,
      "alias": "ogx_mmlux_nl-logical_fallacies"
    },
    "ogx_mmlux_nl-jurisprudence": {
      "acc,none": 0.6481481481481481,
      "acc_stderr,none": 0.04616631111801715,
      "alias": "ogx_mmlux_nl-jurisprudence"
    },
    "ogx_mmlux_nl-international_law": {
      "acc,none": 0.743801652892562,
      "acc_stderr,none": 0.03984979653302872,
      "alias": "ogx_mmlux_nl-international_law"
    },
    "ogx_mmlux_nl-human_sexuality": {
      "acc,none": 0.6793893129770993,
      "acc_stderr,none": 0.04093329229834278,
      "alias": "ogx_mmlux_nl-human_sexuality"
    },
    "ogx_mmlux_nl-human_aging": {
      "acc,none": 0.6233183856502242,
      "acc_stderr,none": 0.032521134899291884,
      "alias": "ogx_mmlux_nl-human_aging"
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "acc,none": 0.759493670886076,
      "acc_stderr,none": 0.027820781981149678,
      "alias": "ogx_mmlux_nl-high_school_world_history"
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "acc,none": 0.7401960784313726,
      "acc_stderr,none": 0.030778554678693264,
      "alias": "ogx_mmlux_nl-high_school_us_history"
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "acc,none": 0.4537037037037037,
      "acc_stderr,none": 0.033953227263757976,
      "alias": "ogx_mmlux_nl-high_school_statistics"
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "acc,none": 0.726605504587156,
      "acc_stderr,none": 0.019109299846098292,
      "alias": "ogx_mmlux_nl-high_school_psychology"
    },
    "ogx_mmlux_nl-high_school_physics": {
      "acc,none": 0.33112582781456956,
      "acc_stderr,none": 0.038425817186598696,
      "alias": "ogx_mmlux_nl-high_school_physics"
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "acc,none": 0.5504201680672269,
      "acc_stderr,none": 0.03231293497137707,
      "alias": "ogx_mmlux_nl-high_school_microeconomics"
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "acc,none": 0.35185185185185186,
      "acc_stderr,none": 0.02911661760608302,
      "alias": "ogx_mmlux_nl-high_school_mathematics"
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "acc,none": 0.5846153846153846,
      "acc_stderr,none": 0.02498535492310236,
      "alias": "ogx_mmlux_nl-high_school_macroeconomics"
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "acc,none": 0.7409326424870466,
      "acc_stderr,none": 0.03161877917935411,
      "alias": "ogx_mmlux_nl-high_school_government_and_politics"
    },
    "ogx_mmlux_nl-high_school_geography": {
      "acc,none": 0.7373737373737373,
      "acc_stderr,none": 0.031353050095330855,
      "alias": "ogx_mmlux_nl-high_school_geography"
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "acc,none": 0.7151515151515152,
      "acc_stderr,none": 0.035243908445117815,
      "alias": "ogx_mmlux_nl-high_school_european_history"
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_nl-high_school_computer_science"
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "acc,none": 0.4482758620689655,
      "acc_stderr,none": 0.03499113137676744,
      "alias": "ogx_mmlux_nl-high_school_chemistry"
    },
    "ogx_mmlux_nl-high_school_biology": {
      "acc,none": 0.6838709677419355,
      "acc_stderr,none": 0.02645087448904278,
      "alias": "ogx_mmlux_nl-high_school_biology"
    },
    "ogx_mmlux_nl-global_facts": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.04688261722621504,
      "alias": "ogx_mmlux_nl-global_facts"
    },
    "ogx_mmlux_nl-formal_logic": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.04360314860077459,
      "alias": "ogx_mmlux_nl-formal_logic"
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "acc,none": 0.3915343915343915,
      "acc_stderr,none": 0.025138091388851123,
      "alias": "ogx_mmlux_nl-elementary_mathematics"
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "acc,none": 0.5172413793103449,
      "acc_stderr,none": 0.04164188720169375,
      "alias": "ogx_mmlux_nl-electrical_engineering"
    },
    "ogx_mmlux_nl-econometrics": {
      "acc,none": 0.42105263157894735,
      "acc_stderr,none": 0.04644602091222317,
      "alias": "ogx_mmlux_nl-econometrics"
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "acc,none": 0.43829787234042555,
      "acc_stderr,none": 0.03243618636108101,
      "alias": "ogx_mmlux_nl-conceptual_physics"
    },
    "ogx_mmlux_nl-computer_security": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_nl-computer_security"
    },
    "ogx_mmlux_nl-college_physics": {
      "acc,none": 0.4411764705882353,
      "acc_stderr,none": 0.04940635630605659,
      "alias": "ogx_mmlux_nl-college_physics"
    },
    "ogx_mmlux_nl-college_medicine": {
      "acc,none": 0.5549132947976878,
      "acc_stderr,none": 0.03789401760283648,
      "alias": "ogx_mmlux_nl-college_medicine"
    },
    "ogx_mmlux_nl-college_mathematics": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_nl-college_mathematics"
    },
    "ogx_mmlux_nl-college_computer_science": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_nl-college_computer_science"
    },
    "ogx_mmlux_nl-college_chemistry": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_nl-college_chemistry"
    },
    "ogx_mmlux_nl-college_biology": {
      "acc,none": 0.6180555555555556,
      "acc_stderr,none": 0.040629907841466674,
      "alias": "ogx_mmlux_nl-college_biology"
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "acc,none": 0.5773584905660377,
      "acc_stderr,none": 0.030402331445769537,
      "alias": "ogx_mmlux_nl-clinical_knowledge"
    },
    "ogx_mmlux_nl-business_ethics": {
      "acc,none": 0.53,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_nl-business_ethics"
    },
    "ogx_mmlux_nl-astronomy": {
      "acc,none": 0.631578947368421,
      "acc_stderr,none": 0.039255233810529325,
      "alias": "ogx_mmlux_nl-astronomy"
    },
    "ogx_mmlux_nl-anatomy": {
      "acc,none": 0.5185185185185185,
      "acc_stderr,none": 0.043163785995113245,
      "alias": "ogx_mmlux_nl-anatomy"
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "acc,none": 0.24,
      "acc_stderr,none": 0.0429234695990928,
      "alias": "ogx_mmlux_nl-abstract_algebra"
    },
    "ogx_mmlux_lv-world_religions": {
      "acc,none": 0.5321637426900585,
      "acc_stderr,none": 0.03826882417660369,
      "alias": "ogx_mmlux_lv-world_religions"
    },
    "ogx_mmlux_lv-virology": {
      "acc,none": 0.39156626506024095,
      "acc_stderr,none": 0.03799857454479636,
      "alias": "ogx_mmlux_lv-virology"
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_lv-us_foreign_policy"
    },
    "ogx_mmlux_lv-sociology": {
      "acc,none": 0.4975124378109453,
      "acc_stderr,none": 0.03535490150137289,
      "alias": "ogx_mmlux_lv-sociology"
    },
    "ogx_mmlux_lv-security_studies": {
      "acc,none": 0.49387755102040815,
      "acc_stderr,none": 0.03200682020163907,
      "alias": "ogx_mmlux_lv-security_studies"
    },
    "ogx_mmlux_lv-public_relations": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.0469237132203465,
      "alias": "ogx_mmlux_lv-public_relations"
    },
    "ogx_mmlux_lv-professional_psychology": {
      "acc,none": 0.3872549019607843,
      "acc_stderr,none": 0.01970687580408563,
      "alias": "ogx_mmlux_lv-professional_psychology"
    },
    "ogx_mmlux_lv-professional_medicine": {
      "acc,none": 0.35294117647058826,
      "acc_stderr,none": 0.0290294228156814,
      "alias": "ogx_mmlux_lv-professional_medicine"
    },
    "ogx_mmlux_lv-professional_law": {
      "acc,none": 0.3005215123859192,
      "acc_stderr,none": 0.01170991888303912,
      "alias": "ogx_mmlux_lv-professional_law"
    },
    "ogx_mmlux_lv-professional_accounting": {
      "acc,none": 0.28368794326241137,
      "acc_stderr,none": 0.02689170942834396,
      "alias": "ogx_mmlux_lv-professional_accounting"
    },
    "ogx_mmlux_lv-prehistory": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.027125115513166872,
      "alias": "ogx_mmlux_lv-prehistory"
    },
    "ogx_mmlux_lv-philosophy": {
      "acc,none": 0.3890675241157556,
      "acc_stderr,none": 0.027690337536485372,
      "alias": "ogx_mmlux_lv-philosophy"
    },
    "ogx_mmlux_lv-nutrition": {
      "acc,none": 0.46078431372549017,
      "acc_stderr,none": 0.028541722692618874,
      "alias": "ogx_mmlux_lv-nutrition"
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "acc,none": 0.26256983240223464,
      "acc_stderr,none": 0.014716824273017763,
      "alias": "ogx_mmlux_lv-moral_scenarios"
    },
    "ogx_mmlux_lv-moral_disputes": {
      "acc,none": 0.41040462427745666,
      "acc_stderr,none": 0.026483392042098177,
      "alias": "ogx_mmlux_lv-moral_disputes"
    },
    "ogx_mmlux_lv-miscellaneous": {
      "acc,none": 0.40485312899106,
      "acc_stderr,none": 0.017553246467720256,
      "alias": "ogx_mmlux_lv-miscellaneous"
    },
    "ogx_mmlux_lv-medical_genetics": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_lv-medical_genetics"
    },
    "ogx_mmlux_lv-marketing": {
      "acc,none": 0.5384615384615384,
      "acc_stderr,none": 0.03265903381186195,
      "alias": "ogx_mmlux_lv-marketing"
    },
    "ogx_mmlux_lv-management": {
      "acc,none": 0.5242718446601942,
      "acc_stderr,none": 0.049449010929737795,
      "alias": "ogx_mmlux_lv-management"
    },
    "ogx_mmlux_lv-machine_learning": {
      "acc,none": 0.23214285714285715,
      "acc_stderr,none": 0.04007341809755805,
      "alias": "ogx_mmlux_lv-machine_learning"
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "acc,none": 0.4110429447852761,
      "acc_stderr,none": 0.038656978537853624,
      "alias": "ogx_mmlux_lv-logical_fallacies"
    },
    "ogx_mmlux_lv-jurisprudence": {
      "acc,none": 0.46296296296296297,
      "acc_stderr,none": 0.04820403072760627,
      "alias": "ogx_mmlux_lv-jurisprudence"
    },
    "ogx_mmlux_lv-international_law": {
      "acc,none": 0.5454545454545454,
      "acc_stderr,none": 0.045454545454545484,
      "alias": "ogx_mmlux_lv-international_law"
    },
    "ogx_mmlux_lv-human_sexuality": {
      "acc,none": 0.48091603053435117,
      "acc_stderr,none": 0.04382094705550988,
      "alias": "ogx_mmlux_lv-human_sexuality"
    },
    "ogx_mmlux_lv-human_aging": {
      "acc,none": 0.3452914798206278,
      "acc_stderr,none": 0.03191100192835794,
      "alias": "ogx_mmlux_lv-human_aging"
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "acc,none": 0.459915611814346,
      "acc_stderr,none": 0.03244246810187914,
      "alias": "ogx_mmlux_lv-high_school_world_history"
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "acc,none": 0.4117647058823529,
      "acc_stderr,none": 0.034542365853806094,
      "alias": "ogx_mmlux_lv-high_school_us_history"
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "acc,none": 0.2824074074074074,
      "acc_stderr,none": 0.030701372111510927,
      "alias": "ogx_mmlux_lv-high_school_statistics"
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "acc,none": 0.4091743119266055,
      "acc_stderr,none": 0.02108067026443373,
      "alias": "ogx_mmlux_lv-high_school_psychology"
    },
    "ogx_mmlux_lv-high_school_physics": {
      "acc,none": 0.2781456953642384,
      "acc_stderr,none": 0.03658603262763743,
      "alias": "ogx_mmlux_lv-high_school_physics"
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "acc,none": 0.3697478991596639,
      "acc_stderr,none": 0.031357095996135904,
      "alias": "ogx_mmlux_lv-high_school_microeconomics"
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "acc,none": 0.29259259259259257,
      "acc_stderr,none": 0.02773896963217609,
      "alias": "ogx_mmlux_lv-high_school_mathematics"
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "acc,none": 0.38974358974358975,
      "acc_stderr,none": 0.024726967886647074,
      "alias": "ogx_mmlux_lv-high_school_macroeconomics"
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "acc,none": 0.39896373056994816,
      "acc_stderr,none": 0.03533999094065696,
      "alias": "ogx_mmlux_lv-high_school_government_and_politics"
    },
    "ogx_mmlux_lv-high_school_geography": {
      "acc,none": 0.42424242424242425,
      "acc_stderr,none": 0.03521224908841583,
      "alias": "ogx_mmlux_lv-high_school_geography"
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "acc,none": 0.503030303030303,
      "acc_stderr,none": 0.03904272341431857,
      "alias": "ogx_mmlux_lv-high_school_european_history"
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.04999999999999999,
      "alias": "ogx_mmlux_lv-high_school_computer_science"
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "acc,none": 0.3448275862068966,
      "acc_stderr,none": 0.03344283744280458,
      "alias": "ogx_mmlux_lv-high_school_chemistry"
    },
    "ogx_mmlux_lv-high_school_biology": {
      "acc,none": 0.4064516129032258,
      "acc_stderr,none": 0.02794172734625631,
      "alias": "ogx_mmlux_lv-high_school_biology"
    },
    "ogx_mmlux_lv-global_facts": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252605,
      "alias": "ogx_mmlux_lv-global_facts"
    },
    "ogx_mmlux_lv-formal_logic": {
      "acc,none": 0.38095238095238093,
      "acc_stderr,none": 0.04343525428949097,
      "alias": "ogx_mmlux_lv-formal_logic"
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "acc,none": 0.30952380952380953,
      "acc_stderr,none": 0.023809523809523864,
      "alias": "ogx_mmlux_lv-elementary_mathematics"
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "acc,none": 0.4689655172413793,
      "acc_stderr,none": 0.04158632762097828,
      "alias": "ogx_mmlux_lv-electrical_engineering"
    },
    "ogx_mmlux_lv-econometrics": {
      "acc,none": 0.2719298245614035,
      "acc_stderr,none": 0.04185774424022057,
      "alias": "ogx_mmlux_lv-econometrics"
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "acc,none": 0.3148936170212766,
      "acc_stderr,none": 0.03036358219723816,
      "alias": "ogx_mmlux_lv-conceptual_physics"
    },
    "ogx_mmlux_lv-computer_security": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_lv-computer_security"
    },
    "ogx_mmlux_lv-college_physics": {
      "acc,none": 0.3235294117647059,
      "acc_stderr,none": 0.04655010411319617,
      "alias": "ogx_mmlux_lv-college_physics"
    },
    "ogx_mmlux_lv-college_medicine": {
      "acc,none": 0.3930635838150289,
      "acc_stderr,none": 0.0372424959581773,
      "alias": "ogx_mmlux_lv-college_medicine"
    },
    "ogx_mmlux_lv-college_mathematics": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_lv-college_mathematics"
    },
    "ogx_mmlux_lv-college_computer_science": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.04793724854411019,
      "alias": "ogx_mmlux_lv-college_computer_science"
    },
    "ogx_mmlux_lv-college_chemistry": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252604,
      "alias": "ogx_mmlux_lv-college_chemistry"
    },
    "ogx_mmlux_lv-college_biology": {
      "acc,none": 0.2986111111111111,
      "acc_stderr,none": 0.03827052357950756,
      "alias": "ogx_mmlux_lv-college_biology"
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "acc,none": 0.4490566037735849,
      "acc_stderr,none": 0.030612730713641092,
      "alias": "ogx_mmlux_lv-clinical_knowledge"
    },
    "ogx_mmlux_lv-business_ethics": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_lv-business_ethics"
    },
    "ogx_mmlux_lv-astronomy": {
      "acc,none": 0.4407894736842105,
      "acc_stderr,none": 0.04040311062490437,
      "alias": "ogx_mmlux_lv-astronomy"
    },
    "ogx_mmlux_lv-anatomy": {
      "acc,none": 0.34074074074074073,
      "acc_stderr,none": 0.04094376269996793,
      "alias": "ogx_mmlux_lv-anatomy"
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "acc,none": 0.19,
      "acc_stderr,none": 0.039427724440366234,
      "alias": "ogx_mmlux_lv-abstract_algebra"
    },
    "ogx_mmlux_lt-world_religions": {
      "acc,none": 0.5555555555555556,
      "acc_stderr,none": 0.03811079669833531,
      "alias": "ogx_mmlux_lt-world_religions"
    },
    "ogx_mmlux_lt-virology": {
      "acc,none": 0.3855421686746988,
      "acc_stderr,none": 0.037891344246115496,
      "alias": "ogx_mmlux_lt-virology"
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_lt-us_foreign_policy"
    },
    "ogx_mmlux_lt-sociology": {
      "acc,none": 0.6218905472636815,
      "acc_stderr,none": 0.03428867848778657,
      "alias": "ogx_mmlux_lt-sociology"
    },
    "ogx_mmlux_lt-security_studies": {
      "acc,none": 0.5714285714285714,
      "acc_stderr,none": 0.031680911612338825,
      "alias": "ogx_mmlux_lt-security_studies"
    },
    "ogx_mmlux_lt-public_relations": {
      "acc,none": 0.39090909090909093,
      "acc_stderr,none": 0.04673752333670237,
      "alias": "ogx_mmlux_lt-public_relations"
    },
    "ogx_mmlux_lt-professional_psychology": {
      "acc,none": 0.39869281045751637,
      "acc_stderr,none": 0.01980828131744985,
      "alias": "ogx_mmlux_lt-professional_psychology"
    },
    "ogx_mmlux_lt-professional_medicine": {
      "acc,none": 0.36764705882352944,
      "acc_stderr,none": 0.029289413409403192,
      "alias": "ogx_mmlux_lt-professional_medicine"
    },
    "ogx_mmlux_lt-professional_law": {
      "acc,none": 0.3389830508474576,
      "acc_stderr,none": 0.012089941857584477,
      "alias": "ogx_mmlux_lt-professional_law"
    },
    "ogx_mmlux_lt-professional_accounting": {
      "acc,none": 0.3120567375886525,
      "acc_stderr,none": 0.027640120545169927,
      "alias": "ogx_mmlux_lt-professional_accounting"
    },
    "ogx_mmlux_lt-prehistory": {
      "acc,none": 0.4660493827160494,
      "acc_stderr,none": 0.027756535257347666,
      "alias": "ogx_mmlux_lt-prehistory"
    },
    "ogx_mmlux_lt-philosophy": {
      "acc,none": 0.47266881028938906,
      "acc_stderr,none": 0.028355633568328174,
      "alias": "ogx_mmlux_lt-philosophy"
    },
    "ogx_mmlux_lt-nutrition": {
      "acc,none": 0.4869281045751634,
      "acc_stderr,none": 0.028620130800700246,
      "alias": "ogx_mmlux_lt-nutrition"
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "acc,none": 0.2446927374301676,
      "acc_stderr,none": 0.014378169884098433,
      "alias": "ogx_mmlux_lt-moral_scenarios"
    },
    "ogx_mmlux_lt-moral_disputes": {
      "acc,none": 0.476878612716763,
      "acc_stderr,none": 0.026890297881303125,
      "alias": "ogx_mmlux_lt-moral_disputes"
    },
    "ogx_mmlux_lt-miscellaneous": {
      "acc,none": 0.49169859514687103,
      "acc_stderr,none": 0.017877498991072008,
      "alias": "ogx_mmlux_lt-miscellaneous"
    },
    "ogx_mmlux_lt-medical_genetics": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_lt-medical_genetics"
    },
    "ogx_mmlux_lt-marketing": {
      "acc,none": 0.6111111111111112,
      "acc_stderr,none": 0.03193705726200293,
      "alias": "ogx_mmlux_lt-marketing"
    },
    "ogx_mmlux_lt-management": {
      "acc,none": 0.5825242718446602,
      "acc_stderr,none": 0.048828405482122375,
      "alias": "ogx_mmlux_lt-management"
    },
    "ogx_mmlux_lt-machine_learning": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04109974682633932,
      "alias": "ogx_mmlux_lt-machine_learning"
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "acc,none": 0.49079754601226994,
      "acc_stderr,none": 0.039277056007874414,
      "alias": "ogx_mmlux_lt-logical_fallacies"
    },
    "ogx_mmlux_lt-jurisprudence": {
      "acc,none": 0.5277777777777778,
      "acc_stderr,none": 0.04826217294139894,
      "alias": "ogx_mmlux_lt-jurisprudence"
    },
    "ogx_mmlux_lt-international_law": {
      "acc,none": 0.5785123966942148,
      "acc_stderr,none": 0.04507732278775087,
      "alias": "ogx_mmlux_lt-international_law"
    },
    "ogx_mmlux_lt-human_sexuality": {
      "acc,none": 0.5038167938931297,
      "acc_stderr,none": 0.043851623256015534,
      "alias": "ogx_mmlux_lt-human_sexuality"
    },
    "ogx_mmlux_lt-human_aging": {
      "acc,none": 0.4304932735426009,
      "acc_stderr,none": 0.0332319730294294,
      "alias": "ogx_mmlux_lt-human_aging"
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "acc,none": 0.48945147679324896,
      "acc_stderr,none": 0.032539983791662855,
      "alias": "ogx_mmlux_lt-high_school_world_history"
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "acc,none": 0.5147058823529411,
      "acc_stderr,none": 0.03507793834791324,
      "alias": "ogx_mmlux_lt-high_school_us_history"
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "acc,none": 0.2777777777777778,
      "acc_stderr,none": 0.03054674526495318,
      "alias": "ogx_mmlux_lt-high_school_statistics"
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "acc,none": 0.47706422018348627,
      "acc_stderr,none": 0.021414757058175506,
      "alias": "ogx_mmlux_lt-high_school_psychology"
    },
    "ogx_mmlux_lt-high_school_physics": {
      "acc,none": 0.304635761589404,
      "acc_stderr,none": 0.03757949922943342,
      "alias": "ogx_mmlux_lt-high_school_physics"
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "acc,none": 0.3907563025210084,
      "acc_stderr,none": 0.031693802357129965,
      "alias": "ogx_mmlux_lt-high_school_microeconomics"
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "acc,none": 0.32222222222222224,
      "acc_stderr,none": 0.028493465091028597,
      "alias": "ogx_mmlux_lt-high_school_mathematics"
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "acc,none": 0.44871794871794873,
      "acc_stderr,none": 0.02521731518484648,
      "alias": "ogx_mmlux_lt-high_school_macroeconomics"
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "acc,none": 0.5025906735751295,
      "acc_stderr,none": 0.03608390745384486,
      "alias": "ogx_mmlux_lt-high_school_government_and_politics"
    },
    "ogx_mmlux_lt-high_school_geography": {
      "acc,none": 0.5404040404040404,
      "acc_stderr,none": 0.035507024651313425,
      "alias": "ogx_mmlux_lt-high_school_geography"
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "acc,none": 0.5454545454545454,
      "acc_stderr,none": 0.038881769216741004,
      "alias": "ogx_mmlux_lt-high_school_european_history"
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620333,
      "alias": "ogx_mmlux_lt-high_school_computer_science"
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "acc,none": 0.37438423645320196,
      "acc_stderr,none": 0.03405155380561952,
      "alias": "ogx_mmlux_lt-high_school_chemistry"
    },
    "ogx_mmlux_lt-high_school_biology": {
      "acc,none": 0.4612903225806452,
      "acc_stderr,none": 0.028358634859836935,
      "alias": "ogx_mmlux_lt-high_school_biology"
    },
    "ogx_mmlux_lt-global_facts": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.047258156262526045,
      "alias": "ogx_mmlux_lt-global_facts"
    },
    "ogx_mmlux_lt-formal_logic": {
      "acc,none": 0.3492063492063492,
      "acc_stderr,none": 0.04263906892795132,
      "alias": "ogx_mmlux_lt-formal_logic"
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "acc,none": 0.3412698412698413,
      "acc_stderr,none": 0.024419234966819064,
      "alias": "ogx_mmlux_lt-elementary_mathematics"
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "acc,none": 0.503448275862069,
      "acc_stderr,none": 0.04166567577101579,
      "alias": "ogx_mmlux_lt-electrical_engineering"
    },
    "ogx_mmlux_lt-econometrics": {
      "acc,none": 0.2631578947368421,
      "acc_stderr,none": 0.04142439719489361,
      "alias": "ogx_mmlux_lt-econometrics"
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "acc,none": 0.34893617021276596,
      "acc_stderr,none": 0.03115852213135778,
      "alias": "ogx_mmlux_lt-conceptual_physics"
    },
    "ogx_mmlux_lt-computer_security": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_lt-computer_security"
    },
    "ogx_mmlux_lt-college_physics": {
      "acc,none": 0.27450980392156865,
      "acc_stderr,none": 0.04440521906179328,
      "alias": "ogx_mmlux_lt-college_physics"
    },
    "ogx_mmlux_lt-college_medicine": {
      "acc,none": 0.4682080924855491,
      "acc_stderr,none": 0.03804749744364764,
      "alias": "ogx_mmlux_lt-college_medicine"
    },
    "ogx_mmlux_lt-college_mathematics": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_lt-college_mathematics"
    },
    "ogx_mmlux_lt-college_computer_science": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_lt-college_computer_science"
    },
    "ogx_mmlux_lt-college_chemistry": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_lt-college_chemistry"
    },
    "ogx_mmlux_lt-college_biology": {
      "acc,none": 0.3819444444444444,
      "acc_stderr,none": 0.040629907841466674,
      "alias": "ogx_mmlux_lt-college_biology"
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "acc,none": 0.4528301886792453,
      "acc_stderr,none": 0.030635627957961823,
      "alias": "ogx_mmlux_lt-clinical_knowledge"
    },
    "ogx_mmlux_lt-business_ethics": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620333,
      "alias": "ogx_mmlux_lt-business_ethics"
    },
    "ogx_mmlux_lt-astronomy": {
      "acc,none": 0.4276315789473684,
      "acc_stderr,none": 0.040260970832965585,
      "alias": "ogx_mmlux_lt-astronomy"
    },
    "ogx_mmlux_lt-anatomy": {
      "acc,none": 0.35555555555555557,
      "acc_stderr,none": 0.04135176749720386,
      "alias": "ogx_mmlux_lt-anatomy"
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "acc,none": 0.26,
      "acc_stderr,none": 0.04408440022768078,
      "alias": "ogx_mmlux_lt-abstract_algebra"
    },
    "ogx_mmlux_it-world_religions": {
      "acc,none": 0.7719298245614035,
      "acc_stderr,none": 0.03218093795602357,
      "alias": "ogx_mmlux_it-world_religions"
    },
    "ogx_mmlux_it-virology": {
      "acc,none": 0.5060240963855421,
      "acc_stderr,none": 0.03892212195333045,
      "alias": "ogx_mmlux_it-virology"
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "acc,none": 0.76,
      "acc_stderr,none": 0.04292346959909282,
      "alias": "ogx_mmlux_it-us_foreign_policy"
    },
    "ogx_mmlux_it-sociology": {
      "acc,none": 0.746268656716418,
      "acc_stderr,none": 0.030769444967296014,
      "alias": "ogx_mmlux_it-sociology"
    },
    "ogx_mmlux_it-security_studies": {
      "acc,none": 0.710204081632653,
      "acc_stderr,none": 0.029043088683304324,
      "alias": "ogx_mmlux_it-security_studies"
    },
    "ogx_mmlux_it-public_relations": {
      "acc,none": 0.5727272727272728,
      "acc_stderr,none": 0.04738198703545483,
      "alias": "ogx_mmlux_it-public_relations"
    },
    "ogx_mmlux_it-professional_psychology": {
      "acc,none": 0.5212418300653595,
      "acc_stderr,none": 0.020209572388600272,
      "alias": "ogx_mmlux_it-professional_psychology"
    },
    "ogx_mmlux_it-professional_medicine": {
      "acc,none": 0.5588235294117647,
      "acc_stderr,none": 0.030161911930767105,
      "alias": "ogx_mmlux_it-professional_medicine"
    },
    "ogx_mmlux_it-professional_law": {
      "acc,none": 0.41264667535853977,
      "acc_stderr,none": 0.012573836633799023,
      "alias": "ogx_mmlux_it-professional_law"
    },
    "ogx_mmlux_it-professional_accounting": {
      "acc,none": 0.35815602836879434,
      "acc_stderr,none": 0.028602085862759422,
      "alias": "ogx_mmlux_it-professional_accounting"
    },
    "ogx_mmlux_it-prehistory": {
      "acc,none": 0.6666666666666666,
      "acc_stderr,none": 0.02622964917882116,
      "alias": "ogx_mmlux_it-prehistory"
    },
    "ogx_mmlux_it-philosophy": {
      "acc,none": 0.6109324758842444,
      "acc_stderr,none": 0.027690337536485376,
      "alias": "ogx_mmlux_it-philosophy"
    },
    "ogx_mmlux_it-nutrition": {
      "acc,none": 0.6013071895424836,
      "acc_stderr,none": 0.028036092273891776,
      "alias": "ogx_mmlux_it-nutrition"
    },
    "ogx_mmlux_it-moral_scenarios": {
      "acc,none": 0.46033519553072627,
      "acc_stderr,none": 0.016669799592112025,
      "alias": "ogx_mmlux_it-moral_scenarios"
    },
    "ogx_mmlux_it-moral_disputes": {
      "acc,none": 0.630057803468208,
      "acc_stderr,none": 0.025992472029306383,
      "alias": "ogx_mmlux_it-moral_disputes"
    },
    "ogx_mmlux_it-miscellaneous": {
      "acc,none": 0.7279693486590039,
      "acc_stderr,none": 0.015913367447500524,
      "alias": "ogx_mmlux_it-miscellaneous"
    },
    "ogx_mmlux_it-medical_genetics": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_it-medical_genetics"
    },
    "ogx_mmlux_it-marketing": {
      "acc,none": 0.7991452991452992,
      "acc_stderr,none": 0.026246772946890477,
      "alias": "ogx_mmlux_it-marketing"
    },
    "ogx_mmlux_it-management": {
      "acc,none": 0.6990291262135923,
      "acc_stderr,none": 0.04541609446503949,
      "alias": "ogx_mmlux_it-management"
    },
    "ogx_mmlux_it-machine_learning": {
      "acc,none": 0.38392857142857145,
      "acc_stderr,none": 0.04616143075028546,
      "alias": "ogx_mmlux_it-machine_learning"
    },
    "ogx_mmlux_it-logical_fallacies": {
      "acc,none": 0.6073619631901841,
      "acc_stderr,none": 0.03836740907831029,
      "alias": "ogx_mmlux_it-logical_fallacies"
    },
    "ogx_mmlux_it-jurisprudence": {
      "acc,none": 0.6759259259259259,
      "acc_stderr,none": 0.04524596007030048,
      "alias": "ogx_mmlux_it-jurisprudence"
    },
    "ogx_mmlux_it-international_law": {
      "acc,none": 0.7768595041322314,
      "acc_stderr,none": 0.03800754475228733,
      "alias": "ogx_mmlux_it-international_law"
    },
    "ogx_mmlux_it-human_sexuality": {
      "acc,none": 0.6793893129770993,
      "acc_stderr,none": 0.040933292298342784,
      "alias": "ogx_mmlux_it-human_sexuality"
    },
    "ogx_mmlux_it-human_aging": {
      "acc,none": 0.6591928251121076,
      "acc_stderr,none": 0.031811497470553604,
      "alias": "ogx_mmlux_it-human_aging"
    },
    "ogx_mmlux_it-high_school_world_history": {
      "acc,none": 0.7679324894514767,
      "acc_stderr,none": 0.027479744550808517,
      "alias": "ogx_mmlux_it-high_school_world_history"
    },
    "ogx_mmlux_it-high_school_us_history": {
      "acc,none": 0.7598039215686274,
      "acc_stderr,none": 0.02998373305591362,
      "alias": "ogx_mmlux_it-high_school_us_history"
    },
    "ogx_mmlux_it-high_school_statistics": {
      "acc,none": 0.4351851851851852,
      "acc_stderr,none": 0.033812000056435254,
      "alias": "ogx_mmlux_it-high_school_statistics"
    },
    "ogx_mmlux_it-high_school_psychology": {
      "acc,none": 0.7504587155963303,
      "acc_stderr,none": 0.018553897629501624,
      "alias": "ogx_mmlux_it-high_school_psychology"
    },
    "ogx_mmlux_it-high_school_physics": {
      "acc,none": 0.2913907284768212,
      "acc_stderr,none": 0.03710185726119994,
      "alias": "ogx_mmlux_it-high_school_physics"
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "acc,none": 0.5714285714285714,
      "acc_stderr,none": 0.032145368597886394,
      "alias": "ogx_mmlux_it-high_school_microeconomics"
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "acc,none": 0.37037037037037035,
      "acc_stderr,none": 0.029443169323031544,
      "alias": "ogx_mmlux_it-high_school_mathematics"
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "acc,none": 0.6025641025641025,
      "acc_stderr,none": 0.024811920017903836,
      "alias": "ogx_mmlux_it-high_school_macroeconomics"
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "acc,none": 0.7305699481865285,
      "acc_stderr,none": 0.03201867122877794,
      "alias": "ogx_mmlux_it-high_school_government_and_politics"
    },
    "ogx_mmlux_it-high_school_geography": {
      "acc,none": 0.7575757575757576,
      "acc_stderr,none": 0.030532892233932026,
      "alias": "ogx_mmlux_it-high_school_geography"
    },
    "ogx_mmlux_it-high_school_european_history": {
      "acc,none": 0.7333333333333333,
      "acc_stderr,none": 0.03453131801885417,
      "alias": "ogx_mmlux_it-high_school_european_history"
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237101,
      "alias": "ogx_mmlux_it-high_school_computer_science"
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "acc,none": 0.45320197044334976,
      "acc_stderr,none": 0.03502544650845872,
      "alias": "ogx_mmlux_it-high_school_chemistry"
    },
    "ogx_mmlux_it-high_school_biology": {
      "acc,none": 0.7096774193548387,
      "acc_stderr,none": 0.02582210611941589,
      "alias": "ogx_mmlux_it-high_school_biology"
    },
    "ogx_mmlux_it-global_facts": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_it-global_facts"
    },
    "ogx_mmlux_it-formal_logic": {
      "acc,none": 0.42857142857142855,
      "acc_stderr,none": 0.0442626668137991,
      "alias": "ogx_mmlux_it-formal_logic"
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "acc,none": 0.4126984126984127,
      "acc_stderr,none": 0.025355741263055256,
      "alias": "ogx_mmlux_it-elementary_mathematics"
    },
    "ogx_mmlux_it-electrical_engineering": {
      "acc,none": 0.5586206896551724,
      "acc_stderr,none": 0.04137931034482757,
      "alias": "ogx_mmlux_it-electrical_engineering"
    },
    "ogx_mmlux_it-econometrics": {
      "acc,none": 0.37719298245614036,
      "acc_stderr,none": 0.04559522141958215,
      "alias": "ogx_mmlux_it-econometrics"
    },
    "ogx_mmlux_it-conceptual_physics": {
      "acc,none": 0.5234042553191489,
      "acc_stderr,none": 0.032650194750335815,
      "alias": "ogx_mmlux_it-conceptual_physics"
    },
    "ogx_mmlux_it-computer_security": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_it-computer_security"
    },
    "ogx_mmlux_it-college_physics": {
      "acc,none": 0.38235294117647056,
      "acc_stderr,none": 0.04835503696107223,
      "alias": "ogx_mmlux_it-college_physics"
    },
    "ogx_mmlux_it-college_medicine": {
      "acc,none": 0.5895953757225434,
      "acc_stderr,none": 0.03750757044895537,
      "alias": "ogx_mmlux_it-college_medicine"
    },
    "ogx_mmlux_it-college_mathematics": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_it-college_mathematics"
    },
    "ogx_mmlux_it-college_computer_science": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_it-college_computer_science"
    },
    "ogx_mmlux_it-college_chemistry": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_it-college_chemistry"
    },
    "ogx_mmlux_it-college_biology": {
      "acc,none": 0.625,
      "acc_stderr,none": 0.04048439222695598,
      "alias": "ogx_mmlux_it-college_biology"
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.030151134457776292,
      "alias": "ogx_mmlux_it-clinical_knowledge"
    },
    "ogx_mmlux_it-business_ethics": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_it-business_ethics"
    },
    "ogx_mmlux_it-astronomy": {
      "acc,none": 0.6118421052631579,
      "acc_stderr,none": 0.03965842097512744,
      "alias": "ogx_mmlux_it-astronomy"
    },
    "ogx_mmlux_it-anatomy": {
      "acc,none": 0.5259259259259259,
      "acc_stderr,none": 0.043135316967505756,
      "alias": "ogx_mmlux_it-anatomy"
    },
    "ogx_mmlux_it-abstract_algebra": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_it-abstract_algebra"
    },
    "ogx_mmlux_hu-world_religions": {
      "acc,none": 0.6140350877192983,
      "acc_stderr,none": 0.03733756969066164,
      "alias": "ogx_mmlux_hu-world_religions"
    },
    "ogx_mmlux_hu-virology": {
      "acc,none": 0.3674698795180723,
      "acc_stderr,none": 0.03753267402120575,
      "alias": "ogx_mmlux_hu-virology"
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "acc,none": 0.61,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_hu-us_foreign_policy"
    },
    "ogx_mmlux_hu-sociology": {
      "acc,none": 0.5422885572139303,
      "acc_stderr,none": 0.035228658640995975,
      "alias": "ogx_mmlux_hu-sociology"
    },
    "ogx_mmlux_hu-security_studies": {
      "acc,none": 0.5346938775510204,
      "acc_stderr,none": 0.031932070244253145,
      "alias": "ogx_mmlux_hu-security_studies"
    },
    "ogx_mmlux_hu-public_relations": {
      "acc,none": 0.4909090909090909,
      "acc_stderr,none": 0.0478833976870286,
      "alias": "ogx_mmlux_hu-public_relations"
    },
    "ogx_mmlux_hu-professional_psychology": {
      "acc,none": 0.3741830065359477,
      "acc_stderr,none": 0.019576953122088837,
      "alias": "ogx_mmlux_hu-professional_psychology"
    },
    "ogx_mmlux_hu-professional_medicine": {
      "acc,none": 0.40808823529411764,
      "acc_stderr,none": 0.029855261393483924,
      "alias": "ogx_mmlux_hu-professional_medicine"
    },
    "ogx_mmlux_hu-professional_law": {
      "acc,none": 0.29465449804432853,
      "acc_stderr,none": 0.011643576764069546,
      "alias": "ogx_mmlux_hu-professional_law"
    },
    "ogx_mmlux_hu-professional_accounting": {
      "acc,none": 0.2978723404255319,
      "acc_stderr,none": 0.027281608344469414,
      "alias": "ogx_mmlux_hu-professional_accounting"
    },
    "ogx_mmlux_hu-prehistory": {
      "acc,none": 0.4537037037037037,
      "acc_stderr,none": 0.0277012284685426,
      "alias": "ogx_mmlux_hu-prehistory"
    },
    "ogx_mmlux_hu-philosophy": {
      "acc,none": 0.4919614147909968,
      "acc_stderr,none": 0.028394421370984538,
      "alias": "ogx_mmlux_hu-philosophy"
    },
    "ogx_mmlux_hu-nutrition": {
      "acc,none": 0.47058823529411764,
      "acc_stderr,none": 0.0285803410651383,
      "alias": "ogx_mmlux_hu-nutrition"
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "acc,none": 0.26256983240223464,
      "acc_stderr,none": 0.014716824273017761,
      "alias": "ogx_mmlux_hu-moral_scenarios"
    },
    "ogx_mmlux_hu-moral_disputes": {
      "acc,none": 0.47398843930635837,
      "acc_stderr,none": 0.026882643434022895,
      "alias": "ogx_mmlux_hu-moral_disputes"
    },
    "ogx_mmlux_hu-miscellaneous": {
      "acc,none": 0.5057471264367817,
      "acc_stderr,none": 0.017878782326129234,
      "alias": "ogx_mmlux_hu-miscellaneous"
    },
    "ogx_mmlux_hu-medical_genetics": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_hu-medical_genetics"
    },
    "ogx_mmlux_hu-marketing": {
      "acc,none": 0.5726495726495726,
      "acc_stderr,none": 0.032408473935163266,
      "alias": "ogx_mmlux_hu-marketing"
    },
    "ogx_mmlux_hu-management": {
      "acc,none": 0.5436893203883495,
      "acc_stderr,none": 0.049318019942204146,
      "alias": "ogx_mmlux_hu-management"
    },
    "ogx_mmlux_hu-machine_learning": {
      "acc,none": 0.21428571428571427,
      "acc_stderr,none": 0.038946411200447915,
      "alias": "ogx_mmlux_hu-machine_learning"
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "acc,none": 0.4049079754601227,
      "acc_stderr,none": 0.03856672163548913,
      "alias": "ogx_mmlux_hu-logical_fallacies"
    },
    "ogx_mmlux_hu-jurisprudence": {
      "acc,none": 0.49074074074074076,
      "acc_stderr,none": 0.04832853553437055,
      "alias": "ogx_mmlux_hu-jurisprudence"
    },
    "ogx_mmlux_hu-international_law": {
      "acc,none": 0.6198347107438017,
      "acc_stderr,none": 0.04431324501968432,
      "alias": "ogx_mmlux_hu-international_law"
    },
    "ogx_mmlux_hu-human_sexuality": {
      "acc,none": 0.4580152671755725,
      "acc_stderr,none": 0.04369802690578756,
      "alias": "ogx_mmlux_hu-human_sexuality"
    },
    "ogx_mmlux_hu-human_aging": {
      "acc,none": 0.4260089686098655,
      "acc_stderr,none": 0.03318833286217281,
      "alias": "ogx_mmlux_hu-human_aging"
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "acc,none": 0.4767932489451477,
      "acc_stderr,none": 0.032512152011410174,
      "alias": "ogx_mmlux_hu-high_school_world_history"
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "acc,none": 0.5294117647058824,
      "acc_stderr,none": 0.035032352963679916,
      "alias": "ogx_mmlux_hu-high_school_us_history"
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "acc,none": 0.2777777777777778,
      "acc_stderr,none": 0.03054674526495318,
      "alias": "ogx_mmlux_hu-high_school_statistics"
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "acc,none": 0.5064220183486239,
      "acc_stderr,none": 0.021435554820013077,
      "alias": "ogx_mmlux_hu-high_school_psychology"
    },
    "ogx_mmlux_hu-high_school_physics": {
      "acc,none": 0.2582781456953642,
      "acc_stderr,none": 0.035737053147634576,
      "alias": "ogx_mmlux_hu-high_school_physics"
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "acc,none": 0.42857142857142855,
      "acc_stderr,none": 0.032145368597886394,
      "alias": "ogx_mmlux_hu-high_school_microeconomics"
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.027940457136228416,
      "alias": "ogx_mmlux_hu-high_school_mathematics"
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "acc,none": 0.38974358974358975,
      "acc_stderr,none": 0.024726967886647078,
      "alias": "ogx_mmlux_hu-high_school_macroeconomics"
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "acc,none": 0.42487046632124353,
      "acc_stderr,none": 0.035674713352125395,
      "alias": "ogx_mmlux_hu-high_school_government_and_politics"
    },
    "ogx_mmlux_hu-high_school_geography": {
      "acc,none": 0.5656565656565656,
      "acc_stderr,none": 0.03531505879359183,
      "alias": "ogx_mmlux_hu-high_school_geography"
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "acc,none": 0.593939393939394,
      "acc_stderr,none": 0.03834816355401181,
      "alias": "ogx_mmlux_hu-high_school_european_history"
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_hu-high_school_computer_science"
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "acc,none": 0.3891625615763547,
      "acc_stderr,none": 0.034304624161038716,
      "alias": "ogx_mmlux_hu-high_school_chemistry"
    },
    "ogx_mmlux_hu-high_school_biology": {
      "acc,none": 0.45806451612903226,
      "acc_stderr,none": 0.02834378725054062,
      "alias": "ogx_mmlux_hu-high_school_biology"
    },
    "ogx_mmlux_hu-global_facts": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_hu-global_facts"
    },
    "ogx_mmlux_hu-formal_logic": {
      "acc,none": 0.38095238095238093,
      "acc_stderr,none": 0.04343525428949098,
      "alias": "ogx_mmlux_hu-formal_logic"
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "acc,none": 0.3306878306878307,
      "acc_stderr,none": 0.02422996529842507,
      "alias": "ogx_mmlux_hu-elementary_mathematics"
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "acc,none": 0.41379310344827586,
      "acc_stderr,none": 0.04104269211806232,
      "alias": "ogx_mmlux_hu-electrical_engineering"
    },
    "ogx_mmlux_hu-econometrics": {
      "acc,none": 0.2894736842105263,
      "acc_stderr,none": 0.04266339443159394,
      "alias": "ogx_mmlux_hu-econometrics"
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "acc,none": 0.37446808510638296,
      "acc_stderr,none": 0.03163910665367291,
      "alias": "ogx_mmlux_hu-conceptual_physics"
    },
    "ogx_mmlux_hu-computer_security": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_hu-computer_security"
    },
    "ogx_mmlux_hu-college_physics": {
      "acc,none": 0.27450980392156865,
      "acc_stderr,none": 0.044405219061793275,
      "alias": "ogx_mmlux_hu-college_physics"
    },
    "ogx_mmlux_hu-college_medicine": {
      "acc,none": 0.47398843930635837,
      "acc_stderr,none": 0.03807301726504511,
      "alias": "ogx_mmlux_hu-college_medicine"
    },
    "ogx_mmlux_hu-college_mathematics": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.045126085985421276,
      "alias": "ogx_mmlux_hu-college_mathematics"
    },
    "ogx_mmlux_hu-college_computer_science": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.04975698519562428,
      "alias": "ogx_mmlux_hu-college_computer_science"
    },
    "ogx_mmlux_hu-college_chemistry": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_hu-college_chemistry"
    },
    "ogx_mmlux_hu-college_biology": {
      "acc,none": 0.4722222222222222,
      "acc_stderr,none": 0.04174752578923185,
      "alias": "ogx_mmlux_hu-college_biology"
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "acc,none": 0.4528301886792453,
      "acc_stderr,none": 0.03063562795796182,
      "alias": "ogx_mmlux_hu-clinical_knowledge"
    },
    "ogx_mmlux_hu-business_ethics": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_hu-business_ethics"
    },
    "ogx_mmlux_hu-astronomy": {
      "acc,none": 0.4144736842105263,
      "acc_stderr,none": 0.04008973785779206,
      "alias": "ogx_mmlux_hu-astronomy"
    },
    "ogx_mmlux_hu-anatomy": {
      "acc,none": 0.3037037037037037,
      "acc_stderr,none": 0.03972552884785136,
      "alias": "ogx_mmlux_hu-anatomy"
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "acc,none": 0.23,
      "acc_stderr,none": 0.04229525846816506,
      "alias": "ogx_mmlux_hu-abstract_algebra"
    },
    "ogx_mmlux_fr-world_religions": {
      "acc,none": 0.7602339181286549,
      "acc_stderr,none": 0.03274485211946956,
      "alias": "ogx_mmlux_fr-world_religions"
    },
    "ogx_mmlux_fr-virology": {
      "acc,none": 0.5240963855421686,
      "acc_stderr,none": 0.03887971849597264,
      "alias": "ogx_mmlux_fr-virology"
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "acc,none": 0.68,
      "acc_stderr,none": 0.046882617226215034,
      "alias": "ogx_mmlux_fr-us_foreign_policy"
    },
    "ogx_mmlux_fr-sociology": {
      "acc,none": 0.7611940298507462,
      "acc_stderr,none": 0.03014777593540922,
      "alias": "ogx_mmlux_fr-sociology"
    },
    "ogx_mmlux_fr-security_studies": {
      "acc,none": 0.6653061224489796,
      "acc_stderr,none": 0.03020923522624231,
      "alias": "ogx_mmlux_fr-security_studies"
    },
    "ogx_mmlux_fr-public_relations": {
      "acc,none": 0.6181818181818182,
      "acc_stderr,none": 0.04653429807913508,
      "alias": "ogx_mmlux_fr-public_relations"
    },
    "ogx_mmlux_fr-professional_psychology": {
      "acc,none": 0.5555555555555556,
      "acc_stderr,none": 0.02010258389588718,
      "alias": "ogx_mmlux_fr-professional_psychology"
    },
    "ogx_mmlux_fr-professional_medicine": {
      "acc,none": 0.5735294117647058,
      "acc_stderr,none": 0.03004261583271487,
      "alias": "ogx_mmlux_fr-professional_medicine"
    },
    "ogx_mmlux_fr-professional_law": {
      "acc,none": 0.4061277705345502,
      "acc_stderr,none": 0.012543154588412935,
      "alias": "ogx_mmlux_fr-professional_law"
    },
    "ogx_mmlux_fr-professional_accounting": {
      "acc,none": 0.3617021276595745,
      "acc_stderr,none": 0.028663820147199492,
      "alias": "ogx_mmlux_fr-professional_accounting"
    },
    "ogx_mmlux_fr-prehistory": {
      "acc,none": 0.6512345679012346,
      "acc_stderr,none": 0.02651759772446501,
      "alias": "ogx_mmlux_fr-prehistory"
    },
    "ogx_mmlux_fr-philosophy": {
      "acc,none": 0.617363344051447,
      "acc_stderr,none": 0.027604689028582,
      "alias": "ogx_mmlux_fr-philosophy"
    },
    "ogx_mmlux_fr-nutrition": {
      "acc,none": 0.6143790849673203,
      "acc_stderr,none": 0.027870745278290265,
      "alias": "ogx_mmlux_fr-nutrition"
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "acc,none": 0.3888268156424581,
      "acc_stderr,none": 0.01630389953079611,
      "alias": "ogx_mmlux_fr-moral_scenarios"
    },
    "ogx_mmlux_fr-moral_disputes": {
      "acc,none": 0.6271676300578035,
      "acc_stderr,none": 0.02603389061357628,
      "alias": "ogx_mmlux_fr-moral_disputes"
    },
    "ogx_mmlux_fr-miscellaneous": {
      "acc,none": 0.735632183908046,
      "acc_stderr,none": 0.015769984840690518,
      "alias": "ogx_mmlux_fr-miscellaneous"
    },
    "ogx_mmlux_fr-medical_genetics": {
      "acc,none": 0.61,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_fr-medical_genetics"
    },
    "ogx_mmlux_fr-marketing": {
      "acc,none": 0.7948717948717948,
      "acc_stderr,none": 0.026453508054040332,
      "alias": "ogx_mmlux_fr-marketing"
    },
    "ogx_mmlux_fr-management": {
      "acc,none": 0.6990291262135923,
      "acc_stderr,none": 0.04541609446503949,
      "alias": "ogx_mmlux_fr-management"
    },
    "ogx_mmlux_fr-machine_learning": {
      "acc,none": 0.3392857142857143,
      "acc_stderr,none": 0.04493949068613539,
      "alias": "ogx_mmlux_fr-machine_learning"
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "acc,none": 0.6012269938650306,
      "acc_stderr,none": 0.038470214204560246,
      "alias": "ogx_mmlux_fr-logical_fallacies"
    },
    "ogx_mmlux_fr-jurisprudence": {
      "acc,none": 0.6944444444444444,
      "acc_stderr,none": 0.044531975073749834,
      "alias": "ogx_mmlux_fr-jurisprudence"
    },
    "ogx_mmlux_fr-international_law": {
      "acc,none": 0.7107438016528925,
      "acc_stderr,none": 0.041391127276354626,
      "alias": "ogx_mmlux_fr-international_law"
    },
    "ogx_mmlux_fr-human_sexuality": {
      "acc,none": 0.7404580152671756,
      "acc_stderr,none": 0.03844876139785271,
      "alias": "ogx_mmlux_fr-human_sexuality"
    },
    "ogx_mmlux_fr-human_aging": {
      "acc,none": 0.6412556053811659,
      "acc_stderr,none": 0.03219079200419996,
      "alias": "ogx_mmlux_fr-human_aging"
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "acc,none": 0.7510548523206751,
      "acc_stderr,none": 0.028146970599422644,
      "alias": "ogx_mmlux_fr-high_school_world_history"
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "acc,none": 0.7598039215686274,
      "acc_stderr,none": 0.02998373305591362,
      "alias": "ogx_mmlux_fr-high_school_us_history"
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "acc,none": 0.48148148148148145,
      "acc_stderr,none": 0.034076320938540516,
      "alias": "ogx_mmlux_fr-high_school_statistics"
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "acc,none": 0.744954128440367,
      "acc_stderr,none": 0.01868850085653584,
      "alias": "ogx_mmlux_fr-high_school_psychology"
    },
    "ogx_mmlux_fr-high_school_physics": {
      "acc,none": 0.31788079470198677,
      "acc_stderr,none": 0.038020397601079024,
      "alias": "ogx_mmlux_fr-high_school_physics"
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "acc,none": 0.5630252100840336,
      "acc_stderr,none": 0.03221943636566196,
      "alias": "ogx_mmlux_fr-high_school_microeconomics"
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.029723278961476668,
      "alias": "ogx_mmlux_fr-high_school_mathematics"
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "acc,none": 0.5846153846153846,
      "acc_stderr,none": 0.024985354923102356,
      "alias": "ogx_mmlux_fr-high_school_macroeconomics"
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "acc,none": 0.772020725388601,
      "acc_stderr,none": 0.030276909945178274,
      "alias": "ogx_mmlux_fr-high_school_government_and_politics"
    },
    "ogx_mmlux_fr-high_school_geography": {
      "acc,none": 0.7626262626262627,
      "acc_stderr,none": 0.030313710538198896,
      "alias": "ogx_mmlux_fr-high_school_geography"
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "acc,none": 0.7272727272727273,
      "acc_stderr,none": 0.03477691162163659,
      "alias": "ogx_mmlux_fr-high_school_european_history"
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "acc,none": 0.61,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_fr-high_school_computer_science"
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "acc,none": 0.4482758620689655,
      "acc_stderr,none": 0.03499113137676744,
      "alias": "ogx_mmlux_fr-high_school_chemistry"
    },
    "ogx_mmlux_fr-high_school_biology": {
      "acc,none": 0.7032258064516129,
      "acc_stderr,none": 0.02598850079241189,
      "alias": "ogx_mmlux_fr-high_school_biology"
    },
    "ogx_mmlux_fr-global_facts": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_fr-global_facts"
    },
    "ogx_mmlux_fr-formal_logic": {
      "acc,none": 0.4444444444444444,
      "acc_stderr,none": 0.044444444444444495,
      "alias": "ogx_mmlux_fr-formal_logic"
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "acc,none": 0.3835978835978836,
      "acc_stderr,none": 0.025043757318520193,
      "alias": "ogx_mmlux_fr-elementary_mathematics"
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "acc,none": 0.5655172413793104,
      "acc_stderr,none": 0.04130740879555498,
      "alias": "ogx_mmlux_fr-electrical_engineering"
    },
    "ogx_mmlux_fr-econometrics": {
      "acc,none": 0.39473684210526316,
      "acc_stderr,none": 0.04598188057816542,
      "alias": "ogx_mmlux_fr-econometrics"
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "acc,none": 0.48936170212765956,
      "acc_stderr,none": 0.03267862331014063,
      "alias": "ogx_mmlux_fr-conceptual_physics"
    },
    "ogx_mmlux_fr-computer_security": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_fr-computer_security"
    },
    "ogx_mmlux_fr-college_physics": {
      "acc,none": 0.38235294117647056,
      "acc_stderr,none": 0.04835503696107223,
      "alias": "ogx_mmlux_fr-college_physics"
    },
    "ogx_mmlux_fr-college_medicine": {
      "acc,none": 0.6011560693641619,
      "acc_stderr,none": 0.037336266553835096,
      "alias": "ogx_mmlux_fr-college_medicine"
    },
    "ogx_mmlux_fr-college_mathematics": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_fr-college_mathematics"
    },
    "ogx_mmlux_fr-college_computer_science": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_fr-college_computer_science"
    },
    "ogx_mmlux_fr-college_chemistry": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_fr-college_chemistry"
    },
    "ogx_mmlux_fr-college_biology": {
      "acc,none": 0.6180555555555556,
      "acc_stderr,none": 0.040629907841466674,
      "alias": "ogx_mmlux_fr-college_biology"
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "acc,none": 0.5924528301886792,
      "acc_stderr,none": 0.030242233800854498,
      "alias": "ogx_mmlux_fr-clinical_knowledge"
    },
    "ogx_mmlux_fr-business_ethics": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_fr-business_ethics"
    },
    "ogx_mmlux_fr-astronomy": {
      "acc,none": 0.6973684210526315,
      "acc_stderr,none": 0.037385206761196686,
      "alias": "ogx_mmlux_fr-astronomy"
    },
    "ogx_mmlux_fr-anatomy": {
      "acc,none": 0.4962962962962963,
      "acc_stderr,none": 0.04319223625811331,
      "alias": "ogx_mmlux_fr-anatomy"
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542129,
      "alias": "ogx_mmlux_fr-abstract_algebra"
    },
    "ogx_mmlux_fi-world_religions": {
      "acc,none": 0.5847953216374269,
      "acc_stderr,none": 0.03779275945503201,
      "alias": "ogx_mmlux_fi-world_religions"
    },
    "ogx_mmlux_fi-virology": {
      "acc,none": 0.37349397590361444,
      "acc_stderr,none": 0.037658451171688624,
      "alias": "ogx_mmlux_fi-virology"
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "acc,none": 0.55,
      "acc_stderr,none": 0.04999999999999999,
      "alias": "ogx_mmlux_fi-us_foreign_policy"
    },
    "ogx_mmlux_fi-sociology": {
      "acc,none": 0.5621890547263682,
      "acc_stderr,none": 0.0350808011219984,
      "alias": "ogx_mmlux_fi-sociology"
    },
    "ogx_mmlux_fi-security_studies": {
      "acc,none": 0.5551020408163265,
      "acc_stderr,none": 0.031814251181977865,
      "alias": "ogx_mmlux_fi-security_studies"
    },
    "ogx_mmlux_fi-public_relations": {
      "acc,none": 0.4090909090909091,
      "acc_stderr,none": 0.04709306978661896,
      "alias": "ogx_mmlux_fi-public_relations"
    },
    "ogx_mmlux_fi-professional_psychology": {
      "acc,none": 0.3545751633986928,
      "acc_stderr,none": 0.01935336054755369,
      "alias": "ogx_mmlux_fi-professional_psychology"
    },
    "ogx_mmlux_fi-professional_medicine": {
      "acc,none": 0.39338235294117646,
      "acc_stderr,none": 0.029674288281311183,
      "alias": "ogx_mmlux_fi-professional_medicine"
    },
    "ogx_mmlux_fi-professional_law": {
      "acc,none": 0.3194263363754889,
      "acc_stderr,none": 0.011908357176756158,
      "alias": "ogx_mmlux_fi-professional_law"
    },
    "ogx_mmlux_fi-professional_accounting": {
      "acc,none": 0.35815602836879434,
      "acc_stderr,none": 0.028602085862759415,
      "alias": "ogx_mmlux_fi-professional_accounting"
    },
    "ogx_mmlux_fi-prehistory": {
      "acc,none": 0.49382716049382713,
      "acc_stderr,none": 0.027818623962583302,
      "alias": "ogx_mmlux_fi-prehistory"
    },
    "ogx_mmlux_fi-philosophy": {
      "acc,none": 0.41479099678456594,
      "acc_stderr,none": 0.027982680459759563,
      "alias": "ogx_mmlux_fi-philosophy"
    },
    "ogx_mmlux_fi-nutrition": {
      "acc,none": 0.4673202614379085,
      "acc_stderr,none": 0.02856869975222587,
      "alias": "ogx_mmlux_fi-nutrition"
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "acc,none": 0.2905027932960894,
      "acc_stderr,none": 0.015183844307206144,
      "alias": "ogx_mmlux_fi-moral_scenarios"
    },
    "ogx_mmlux_fi-moral_disputes": {
      "acc,none": 0.4624277456647399,
      "acc_stderr,none": 0.026842985519615375,
      "alias": "ogx_mmlux_fi-moral_disputes"
    },
    "ogx_mmlux_fi-miscellaneous": {
      "acc,none": 0.45338441890166026,
      "acc_stderr,none": 0.0178020871358503,
      "alias": "ogx_mmlux_fi-miscellaneous"
    },
    "ogx_mmlux_fi-medical_genetics": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956911,
      "alias": "ogx_mmlux_fi-medical_genetics"
    },
    "ogx_mmlux_fi-marketing": {
      "acc,none": 0.5299145299145299,
      "acc_stderr,none": 0.03269741106812443,
      "alias": "ogx_mmlux_fi-marketing"
    },
    "ogx_mmlux_fi-management": {
      "acc,none": 0.5242718446601942,
      "acc_stderr,none": 0.049449010929737795,
      "alias": "ogx_mmlux_fi-management"
    },
    "ogx_mmlux_fi-machine_learning": {
      "acc,none": 0.24107142857142858,
      "acc_stderr,none": 0.04059867246952687,
      "alias": "ogx_mmlux_fi-machine_learning"
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "acc,none": 0.4049079754601227,
      "acc_stderr,none": 0.03856672163548913,
      "alias": "ogx_mmlux_fi-logical_fallacies"
    },
    "ogx_mmlux_fi-jurisprudence": {
      "acc,none": 0.48148148148148145,
      "acc_stderr,none": 0.04830366024635331,
      "alias": "ogx_mmlux_fi-jurisprudence"
    },
    "ogx_mmlux_fi-international_law": {
      "acc,none": 0.5950413223140496,
      "acc_stderr,none": 0.04481137755942469,
      "alias": "ogx_mmlux_fi-international_law"
    },
    "ogx_mmlux_fi-human_sexuality": {
      "acc,none": 0.4732824427480916,
      "acc_stderr,none": 0.04379024936553894,
      "alias": "ogx_mmlux_fi-human_sexuality"
    },
    "ogx_mmlux_fi-human_aging": {
      "acc,none": 0.3811659192825112,
      "acc_stderr,none": 0.03259625118416827,
      "alias": "ogx_mmlux_fi-human_aging"
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "acc,none": 0.4641350210970464,
      "acc_stderr,none": 0.03246338898055659,
      "alias": "ogx_mmlux_fi-high_school_world_history"
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "acc,none": 0.5049019607843137,
      "acc_stderr,none": 0.035091433756067866,
      "alias": "ogx_mmlux_fi-high_school_us_history"
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "acc,none": 0.3148148148148148,
      "acc_stderr,none": 0.03167468706828978,
      "alias": "ogx_mmlux_fi-high_school_statistics"
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "acc,none": 0.46238532110091746,
      "acc_stderr,none": 0.021376575274397566,
      "alias": "ogx_mmlux_fi-high_school_psychology"
    },
    "ogx_mmlux_fi-high_school_physics": {
      "acc,none": 0.3443708609271523,
      "acc_stderr,none": 0.038796870240733264,
      "alias": "ogx_mmlux_fi-high_school_physics"
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "acc,none": 0.36134453781512604,
      "acc_stderr,none": 0.031204691225150016,
      "alias": "ogx_mmlux_fi-high_school_microeconomics"
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.027940457136228412,
      "alias": "ogx_mmlux_fi-high_school_mathematics"
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "acc,none": 0.3974358974358974,
      "acc_stderr,none": 0.024811920017903836,
      "alias": "ogx_mmlux_fi-high_school_macroeconomics"
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "acc,none": 0.3626943005181347,
      "acc_stderr,none": 0.03469713791704371,
      "alias": "ogx_mmlux_fi-high_school_government_and_politics"
    },
    "ogx_mmlux_fi-high_school_geography": {
      "acc,none": 0.4494949494949495,
      "acc_stderr,none": 0.0354413249194797,
      "alias": "ogx_mmlux_fi-high_school_geography"
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "acc,none": 0.5212121212121212,
      "acc_stderr,none": 0.03900828913737302,
      "alias": "ogx_mmlux_fi-high_school_european_history"
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_fi-high_school_computer_science"
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "acc,none": 0.3448275862068966,
      "acc_stderr,none": 0.03344283744280458,
      "alias": "ogx_mmlux_fi-high_school_chemistry"
    },
    "ogx_mmlux_fi-high_school_biology": {
      "acc,none": 0.4258064516129032,
      "acc_stderr,none": 0.028129112709165904,
      "alias": "ogx_mmlux_fi-high_school_biology"
    },
    "ogx_mmlux_fi-global_facts": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_fi-global_facts"
    },
    "ogx_mmlux_fi-formal_logic": {
      "acc,none": 0.4126984126984127,
      "acc_stderr,none": 0.04403438954768177,
      "alias": "ogx_mmlux_fi-formal_logic"
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "acc,none": 0.3544973544973545,
      "acc_stderr,none": 0.024636830602842,
      "alias": "ogx_mmlux_fi-elementary_mathematics"
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "acc,none": 0.45517241379310347,
      "acc_stderr,none": 0.04149886942192118,
      "alias": "ogx_mmlux_fi-electrical_engineering"
    },
    "ogx_mmlux_fi-econometrics": {
      "acc,none": 0.2719298245614035,
      "acc_stderr,none": 0.041857744240220554,
      "alias": "ogx_mmlux_fi-econometrics"
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "acc,none": 0.34893617021276596,
      "acc_stderr,none": 0.031158522131357794,
      "alias": "ogx_mmlux_fi-conceptual_physics"
    },
    "ogx_mmlux_fi-computer_security": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_fi-computer_security"
    },
    "ogx_mmlux_fi-college_physics": {
      "acc,none": 0.3137254901960784,
      "acc_stderr,none": 0.04617034827006718,
      "alias": "ogx_mmlux_fi-college_physics"
    },
    "ogx_mmlux_fi-college_medicine": {
      "acc,none": 0.4277456647398844,
      "acc_stderr,none": 0.037724468575180255,
      "alias": "ogx_mmlux_fi-college_medicine"
    },
    "ogx_mmlux_fi-college_mathematics": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_fi-college_mathematics"
    },
    "ogx_mmlux_fi-college_computer_science": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_fi-college_computer_science"
    },
    "ogx_mmlux_fi-college_chemistry": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_fi-college_chemistry"
    },
    "ogx_mmlux_fi-college_biology": {
      "acc,none": 0.3055555555555556,
      "acc_stderr,none": 0.03852084696008534,
      "alias": "ogx_mmlux_fi-college_biology"
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "acc,none": 0.45660377358490567,
      "acc_stderr,none": 0.03065674869673943,
      "alias": "ogx_mmlux_fi-clinical_knowledge"
    },
    "ogx_mmlux_fi-business_ethics": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_fi-business_ethics"
    },
    "ogx_mmlux_fi-astronomy": {
      "acc,none": 0.39473684210526316,
      "acc_stderr,none": 0.039777499346220734,
      "alias": "ogx_mmlux_fi-astronomy"
    },
    "ogx_mmlux_fi-anatomy": {
      "acc,none": 0.31851851851851853,
      "acc_stderr,none": 0.040247784019771096,
      "alias": "ogx_mmlux_fi-anatomy"
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "acc,none": 0.21,
      "acc_stderr,none": 0.04093601807403325,
      "alias": "ogx_mmlux_fi-abstract_algebra"
    },
    "ogx_mmlux_et-world_religions": {
      "acc,none": 0.47953216374269003,
      "acc_stderr,none": 0.038316105328219316,
      "alias": "ogx_mmlux_et-world_religions"
    },
    "ogx_mmlux_et-virology": {
      "acc,none": 0.41566265060240964,
      "acc_stderr,none": 0.03836722176598053,
      "alias": "ogx_mmlux_et-virology"
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237101,
      "alias": "ogx_mmlux_et-us_foreign_policy"
    },
    "ogx_mmlux_et-sociology": {
      "acc,none": 0.48756218905472637,
      "acc_stderr,none": 0.0353443984853958,
      "alias": "ogx_mmlux_et-sociology"
    },
    "ogx_mmlux_et-security_studies": {
      "acc,none": 0.5306122448979592,
      "acc_stderr,none": 0.031949171367580624,
      "alias": "ogx_mmlux_et-security_studies"
    },
    "ogx_mmlux_et-public_relations": {
      "acc,none": 0.3181818181818182,
      "acc_stderr,none": 0.044612721759105065,
      "alias": "ogx_mmlux_et-public_relations"
    },
    "ogx_mmlux_et-professional_psychology": {
      "acc,none": 0.32516339869281047,
      "acc_stderr,none": 0.018950886770806315,
      "alias": "ogx_mmlux_et-professional_psychology"
    },
    "ogx_mmlux_et-professional_medicine": {
      "acc,none": 0.29411764705882354,
      "acc_stderr,none": 0.027678468642144703,
      "alias": "ogx_mmlux_et-professional_medicine"
    },
    "ogx_mmlux_et-professional_law": {
      "acc,none": 0.2940026075619296,
      "acc_stderr,none": 0.011636062953698605,
      "alias": "ogx_mmlux_et-professional_law"
    },
    "ogx_mmlux_et-professional_accounting": {
      "acc,none": 0.3404255319148936,
      "acc_stderr,none": 0.02826765748265015,
      "alias": "ogx_mmlux_et-professional_accounting"
    },
    "ogx_mmlux_et-prehistory": {
      "acc,none": 0.42901234567901236,
      "acc_stderr,none": 0.027538925613470863,
      "alias": "ogx_mmlux_et-prehistory"
    },
    "ogx_mmlux_et-philosophy": {
      "acc,none": 0.4115755627009646,
      "acc_stderr,none": 0.02795048149440127,
      "alias": "ogx_mmlux_et-philosophy"
    },
    "ogx_mmlux_et-nutrition": {
      "acc,none": 0.43790849673202614,
      "acc_stderr,none": 0.028408302020332687,
      "alias": "ogx_mmlux_et-nutrition"
    },
    "ogx_mmlux_et-moral_scenarios": {
      "acc,none": 0.23016759776536314,
      "acc_stderr,none": 0.014078339253425817,
      "alias": "ogx_mmlux_et-moral_scenarios"
    },
    "ogx_mmlux_et-moral_disputes": {
      "acc,none": 0.430635838150289,
      "acc_stderr,none": 0.026658800273672387,
      "alias": "ogx_mmlux_et-moral_disputes"
    },
    "ogx_mmlux_et-miscellaneous": {
      "acc,none": 0.4278416347381865,
      "acc_stderr,none": 0.017692787927803728,
      "alias": "ogx_mmlux_et-miscellaneous"
    },
    "ogx_mmlux_et-medical_genetics": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_et-medical_genetics"
    },
    "ogx_mmlux_et-marketing": {
      "acc,none": 0.47863247863247865,
      "acc_stderr,none": 0.032726164476349545,
      "alias": "ogx_mmlux_et-marketing"
    },
    "ogx_mmlux_et-management": {
      "acc,none": 0.5145631067961165,
      "acc_stderr,none": 0.04948637324026637,
      "alias": "ogx_mmlux_et-management"
    },
    "ogx_mmlux_et-machine_learning": {
      "acc,none": 0.26785714285714285,
      "acc_stderr,none": 0.04203277291467762,
      "alias": "ogx_mmlux_et-machine_learning"
    },
    "ogx_mmlux_et-logical_fallacies": {
      "acc,none": 0.3987730061349693,
      "acc_stderr,none": 0.03847021420456023,
      "alias": "ogx_mmlux_et-logical_fallacies"
    },
    "ogx_mmlux_et-jurisprudence": {
      "acc,none": 0.46296296296296297,
      "acc_stderr,none": 0.04820403072760628,
      "alias": "ogx_mmlux_et-jurisprudence"
    },
    "ogx_mmlux_et-international_law": {
      "acc,none": 0.49586776859504134,
      "acc_stderr,none": 0.045641987674327526,
      "alias": "ogx_mmlux_et-international_law"
    },
    "ogx_mmlux_et-human_sexuality": {
      "acc,none": 0.40458015267175573,
      "acc_stderr,none": 0.043046937953806645,
      "alias": "ogx_mmlux_et-human_sexuality"
    },
    "ogx_mmlux_et-human_aging": {
      "acc,none": 0.36771300448430494,
      "acc_stderr,none": 0.03236198350928275,
      "alias": "ogx_mmlux_et-human_aging"
    },
    "ogx_mmlux_et-high_school_world_history": {
      "acc,none": 0.4641350210970464,
      "acc_stderr,none": 0.03246338898055659,
      "alias": "ogx_mmlux_et-high_school_world_history"
    },
    "ogx_mmlux_et-high_school_us_history": {
      "acc,none": 0.45588235294117646,
      "acc_stderr,none": 0.034956245220154746,
      "alias": "ogx_mmlux_et-high_school_us_history"
    },
    "ogx_mmlux_et-high_school_statistics": {
      "acc,none": 0.2962962962962963,
      "acc_stderr,none": 0.03114144782353603,
      "alias": "ogx_mmlux_et-high_school_statistics"
    },
    "ogx_mmlux_et-high_school_psychology": {
      "acc,none": 0.4018348623853211,
      "acc_stderr,none": 0.021020106172997013,
      "alias": "ogx_mmlux_et-high_school_psychology"
    },
    "ogx_mmlux_et-high_school_physics": {
      "acc,none": 0.2251655629139073,
      "acc_stderr,none": 0.03410435282008937,
      "alias": "ogx_mmlux_et-high_school_physics"
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "acc,none": 0.3739495798319328,
      "acc_stderr,none": 0.03142946637883708,
      "alias": "ogx_mmlux_et-high_school_microeconomics"
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "acc,none": 0.26296296296296295,
      "acc_stderr,none": 0.026842057873833706,
      "alias": "ogx_mmlux_et-high_school_mathematics"
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "acc,none": 0.358974358974359,
      "acc_stderr,none": 0.024321738484602368,
      "alias": "ogx_mmlux_et-high_school_macroeconomics"
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "acc,none": 0.35233160621761656,
      "acc_stderr,none": 0.03447478286414358,
      "alias": "ogx_mmlux_et-high_school_government_and_politics"
    },
    "ogx_mmlux_et-high_school_geography": {
      "acc,none": 0.4292929292929293,
      "acc_stderr,none": 0.03526552724601199,
      "alias": "ogx_mmlux_et-high_school_geography"
    },
    "ogx_mmlux_et-high_school_european_history": {
      "acc,none": 0.5636363636363636,
      "acc_stderr,none": 0.03872592983524754,
      "alias": "ogx_mmlux_et-high_school_european_history"
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956911,
      "alias": "ogx_mmlux_et-high_school_computer_science"
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "acc,none": 0.3399014778325123,
      "acc_stderr,none": 0.0333276906841079,
      "alias": "ogx_mmlux_et-high_school_chemistry"
    },
    "ogx_mmlux_et-high_school_biology": {
      "acc,none": 0.4064516129032258,
      "acc_stderr,none": 0.027941727346256308,
      "alias": "ogx_mmlux_et-high_school_biology"
    },
    "ogx_mmlux_et-global_facts": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.046882617226215034,
      "alias": "ogx_mmlux_et-global_facts"
    },
    "ogx_mmlux_et-formal_logic": {
      "acc,none": 0.35714285714285715,
      "acc_stderr,none": 0.04285714285714281,
      "alias": "ogx_mmlux_et-formal_logic"
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "acc,none": 0.3253968253968254,
      "acc_stderr,none": 0.024130158299762602,
      "alias": "ogx_mmlux_et-elementary_mathematics"
    },
    "ogx_mmlux_et-electrical_engineering": {
      "acc,none": 0.4413793103448276,
      "acc_stderr,none": 0.04137931034482758,
      "alias": "ogx_mmlux_et-electrical_engineering"
    },
    "ogx_mmlux_et-econometrics": {
      "acc,none": 0.2719298245614035,
      "acc_stderr,none": 0.04185774424022056,
      "alias": "ogx_mmlux_et-econometrics"
    },
    "ogx_mmlux_et-conceptual_physics": {
      "acc,none": 0.3191489361702128,
      "acc_stderr,none": 0.030472973363380045,
      "alias": "ogx_mmlux_et-conceptual_physics"
    },
    "ogx_mmlux_et-computer_security": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_et-computer_security"
    },
    "ogx_mmlux_et-college_physics": {
      "acc,none": 0.3627450980392157,
      "acc_stderr,none": 0.047840607041056527,
      "alias": "ogx_mmlux_et-college_physics"
    },
    "ogx_mmlux_et-college_medicine": {
      "acc,none": 0.4161849710982659,
      "acc_stderr,none": 0.03758517775404947,
      "alias": "ogx_mmlux_et-college_medicine"
    },
    "ogx_mmlux_et-college_mathematics": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.046882617226215034,
      "alias": "ogx_mmlux_et-college_mathematics"
    },
    "ogx_mmlux_et-college_computer_science": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.04975698519562428,
      "alias": "ogx_mmlux_et-college_computer_science"
    },
    "ogx_mmlux_et-college_chemistry": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_et-college_chemistry"
    },
    "ogx_mmlux_et-college_biology": {
      "acc,none": 0.2638888888888889,
      "acc_stderr,none": 0.03685651095897532,
      "alias": "ogx_mmlux_et-college_biology"
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "acc,none": 0.4641509433962264,
      "acc_stderr,none": 0.030693675018458006,
      "alias": "ogx_mmlux_et-clinical_knowledge"
    },
    "ogx_mmlux_et-business_ethics": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_et-business_ethics"
    },
    "ogx_mmlux_et-astronomy": {
      "acc,none": 0.40131578947368424,
      "acc_stderr,none": 0.039889037033362836,
      "alias": "ogx_mmlux_et-astronomy"
    },
    "ogx_mmlux_et-anatomy": {
      "acc,none": 0.35555555555555557,
      "acc_stderr,none": 0.04135176749720386,
      "alias": "ogx_mmlux_et-anatomy"
    },
    "ogx_mmlux_et-abstract_algebra": {
      "acc,none": 0.23,
      "acc_stderr,none": 0.04229525846816506,
      "alias": "ogx_mmlux_et-abstract_algebra"
    },
    "ogx_mmlux_es-world_religions": {
      "acc,none": 0.7777777777777778,
      "acc_stderr,none": 0.03188578017686397,
      "alias": "ogx_mmlux_es-world_religions"
    },
    "ogx_mmlux_es-virology": {
      "acc,none": 0.5060240963855421,
      "acc_stderr,none": 0.03892212195333045,
      "alias": "ogx_mmlux_es-virology"
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.0440844002276808,
      "alias": "ogx_mmlux_es-us_foreign_policy"
    },
    "ogx_mmlux_es-sociology": {
      "acc,none": 0.7661691542288557,
      "acc_stderr,none": 0.029929415408348384,
      "alias": "ogx_mmlux_es-sociology"
    },
    "ogx_mmlux_es-security_studies": {
      "acc,none": 0.6938775510204082,
      "acc_stderr,none": 0.02950489645459595,
      "alias": "ogx_mmlux_es-security_studies"
    },
    "ogx_mmlux_es-public_relations": {
      "acc,none": 0.5909090909090909,
      "acc_stderr,none": 0.04709306978661895,
      "alias": "ogx_mmlux_es-public_relations"
    },
    "ogx_mmlux_es-professional_psychology": {
      "acc,none": 0.553921568627451,
      "acc_stderr,none": 0.020109864547181368,
      "alias": "ogx_mmlux_es-professional_psychology"
    },
    "ogx_mmlux_es-professional_medicine": {
      "acc,none": 0.5808823529411765,
      "acc_stderr,none": 0.029972807170464622,
      "alias": "ogx_mmlux_es-professional_medicine"
    },
    "ogx_mmlux_es-professional_law": {
      "acc,none": 0.439374185136897,
      "acc_stderr,none": 0.012676014778580214,
      "alias": "ogx_mmlux_es-professional_law"
    },
    "ogx_mmlux_es-professional_accounting": {
      "acc,none": 0.36879432624113473,
      "acc_stderr,none": 0.028782227561347247,
      "alias": "ogx_mmlux_es-professional_accounting"
    },
    "ogx_mmlux_es-prehistory": {
      "acc,none": 0.6759259259259259,
      "acc_stderr,none": 0.026041766202717163,
      "alias": "ogx_mmlux_es-prehistory"
    },
    "ogx_mmlux_es-philosophy": {
      "acc,none": 0.6237942122186495,
      "acc_stderr,none": 0.02751392568354943,
      "alias": "ogx_mmlux_es-philosophy"
    },
    "ogx_mmlux_es-nutrition": {
      "acc,none": 0.6339869281045751,
      "acc_stderr,none": 0.02758281141515962,
      "alias": "ogx_mmlux_es-nutrition"
    },
    "ogx_mmlux_es-moral_scenarios": {
      "acc,none": 0.45251396648044695,
      "acc_stderr,none": 0.016646914804438778,
      "alias": "ogx_mmlux_es-moral_scenarios"
    },
    "ogx_mmlux_es-moral_disputes": {
      "acc,none": 0.6445086705202312,
      "acc_stderr,none": 0.025770292082977254,
      "alias": "ogx_mmlux_es-moral_disputes"
    },
    "ogx_mmlux_es-miscellaneous": {
      "acc,none": 0.7394636015325671,
      "acc_stderr,none": 0.015696008563807096,
      "alias": "ogx_mmlux_es-miscellaneous"
    },
    "ogx_mmlux_es-medical_genetics": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_es-medical_genetics"
    },
    "ogx_mmlux_es-marketing": {
      "acc,none": 0.8034188034188035,
      "acc_stderr,none": 0.02603538609895129,
      "alias": "ogx_mmlux_es-marketing"
    },
    "ogx_mmlux_es-management": {
      "acc,none": 0.7572815533980582,
      "acc_stderr,none": 0.042450224863844956,
      "alias": "ogx_mmlux_es-management"
    },
    "ogx_mmlux_es-machine_learning": {
      "acc,none": 0.4107142857142857,
      "acc_stderr,none": 0.046695106638751926,
      "alias": "ogx_mmlux_es-machine_learning"
    },
    "ogx_mmlux_es-logical_fallacies": {
      "acc,none": 0.6625766871165644,
      "acc_stderr,none": 0.03714908409935574,
      "alias": "ogx_mmlux_es-logical_fallacies"
    },
    "ogx_mmlux_es-jurisprudence": {
      "acc,none": 0.6851851851851852,
      "acc_stderr,none": 0.04489931073591312,
      "alias": "ogx_mmlux_es-jurisprudence"
    },
    "ogx_mmlux_es-international_law": {
      "acc,none": 0.7355371900826446,
      "acc_stderr,none": 0.04026187527591207,
      "alias": "ogx_mmlux_es-international_law"
    },
    "ogx_mmlux_es-human_sexuality": {
      "acc,none": 0.6564885496183206,
      "acc_stderr,none": 0.041649760719448786,
      "alias": "ogx_mmlux_es-human_sexuality"
    },
    "ogx_mmlux_es-human_aging": {
      "acc,none": 0.6771300448430493,
      "acc_stderr,none": 0.03138147637575498,
      "alias": "ogx_mmlux_es-human_aging"
    },
    "ogx_mmlux_es-high_school_world_history": {
      "acc,none": 0.7426160337552743,
      "acc_stderr,none": 0.0284588209914603,
      "alias": "ogx_mmlux_es-high_school_world_history"
    },
    "ogx_mmlux_es-high_school_us_history": {
      "acc,none": 0.7696078431372549,
      "acc_stderr,none": 0.029554292605695053,
      "alias": "ogx_mmlux_es-high_school_us_history"
    },
    "ogx_mmlux_es-high_school_statistics": {
      "acc,none": 0.4398148148148148,
      "acc_stderr,none": 0.03385177976044811,
      "alias": "ogx_mmlux_es-high_school_statistics"
    },
    "ogx_mmlux_es-high_school_psychology": {
      "acc,none": 0.7798165137614679,
      "acc_stderr,none": 0.017765978652327565,
      "alias": "ogx_mmlux_es-high_school_psychology"
    },
    "ogx_mmlux_es-high_school_physics": {
      "acc,none": 0.31788079470198677,
      "acc_stderr,none": 0.038020397601079024,
      "alias": "ogx_mmlux_es-high_school_physics"
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "acc,none": 0.5798319327731093,
      "acc_stderr,none": 0.03206183783236152,
      "alias": "ogx_mmlux_es-high_school_microeconomics"
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "acc,none": 0.37037037037037035,
      "acc_stderr,none": 0.029443169323031544,
      "alias": "ogx_mmlux_es-high_school_mathematics"
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.02483881198803316,
      "alias": "ogx_mmlux_es-high_school_macroeconomics"
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "acc,none": 0.7357512953367875,
      "acc_stderr,none": 0.03182155050916649,
      "alias": "ogx_mmlux_es-high_school_government_and_politics"
    },
    "ogx_mmlux_es-high_school_geography": {
      "acc,none": 0.7626262626262627,
      "acc_stderr,none": 0.030313710538198906,
      "alias": "ogx_mmlux_es-high_school_geography"
    },
    "ogx_mmlux_es-high_school_european_history": {
      "acc,none": 0.7212121212121212,
      "acc_stderr,none": 0.03501438706296781,
      "alias": "ogx_mmlux_es-high_school_european_history"
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "acc,none": 0.55,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_es-high_school_computer_science"
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "acc,none": 0.43349753694581283,
      "acc_stderr,none": 0.034867317274198714,
      "alias": "ogx_mmlux_es-high_school_chemistry"
    },
    "ogx_mmlux_es-high_school_biology": {
      "acc,none": 0.7096774193548387,
      "acc_stderr,none": 0.025822106119415898,
      "alias": "ogx_mmlux_es-high_school_biology"
    },
    "ogx_mmlux_es-global_facts": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_es-global_facts"
    },
    "ogx_mmlux_es-formal_logic": {
      "acc,none": 0.3968253968253968,
      "acc_stderr,none": 0.04375888492727062,
      "alias": "ogx_mmlux_es-formal_logic"
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "acc,none": 0.3941798941798942,
      "acc_stderr,none": 0.025167982333894154,
      "alias": "ogx_mmlux_es-elementary_mathematics"
    },
    "ogx_mmlux_es-electrical_engineering": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.04082482904638628,
      "alias": "ogx_mmlux_es-electrical_engineering"
    },
    "ogx_mmlux_es-econometrics": {
      "acc,none": 0.34210526315789475,
      "acc_stderr,none": 0.04462917535336937,
      "alias": "ogx_mmlux_es-econometrics"
    },
    "ogx_mmlux_es-conceptual_physics": {
      "acc,none": 0.5234042553191489,
      "acc_stderr,none": 0.03265019475033582,
      "alias": "ogx_mmlux_es-conceptual_physics"
    },
    "ogx_mmlux_es-computer_security": {
      "acc,none": 0.67,
      "acc_stderr,none": 0.04725815626252609,
      "alias": "ogx_mmlux_es-computer_security"
    },
    "ogx_mmlux_es-college_physics": {
      "acc,none": 0.35294117647058826,
      "acc_stderr,none": 0.04755129616062947,
      "alias": "ogx_mmlux_es-college_physics"
    },
    "ogx_mmlux_es-college_medicine": {
      "acc,none": 0.5549132947976878,
      "acc_stderr,none": 0.037894017602836484,
      "alias": "ogx_mmlux_es-college_medicine"
    },
    "ogx_mmlux_es-college_mathematics": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_es-college_mathematics"
    },
    "ogx_mmlux_es-college_computer_science": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_es-college_computer_science"
    },
    "ogx_mmlux_es-college_chemistry": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_es-college_chemistry"
    },
    "ogx_mmlux_es-college_biology": {
      "acc,none": 0.5972222222222222,
      "acc_stderr,none": 0.04101405519842425,
      "alias": "ogx_mmlux_es-college_biology"
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "acc,none": 0.5886792452830188,
      "acc_stderr,none": 0.0302850092590098,
      "alias": "ogx_mmlux_es-clinical_knowledge"
    },
    "ogx_mmlux_es-business_ethics": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_es-business_ethics"
    },
    "ogx_mmlux_es-astronomy": {
      "acc,none": 0.6644736842105263,
      "acc_stderr,none": 0.03842498559395269,
      "alias": "ogx_mmlux_es-astronomy"
    },
    "ogx_mmlux_es-anatomy": {
      "acc,none": 0.5407407407407407,
      "acc_stderr,none": 0.04304979692464241,
      "alias": "ogx_mmlux_es-anatomy"
    },
    "ogx_mmlux_es-abstract_algebra": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542129,
      "alias": "ogx_mmlux_es-abstract_algebra"
    },
    "ogx_mmlux_el-world_religions": {
      "acc,none": 0.6842105263157895,
      "acc_stderr,none": 0.03565079670708311,
      "alias": "ogx_mmlux_el-world_religions"
    },
    "ogx_mmlux_el-virology": {
      "acc,none": 0.4939759036144578,
      "acc_stderr,none": 0.03892212195333045,
      "alias": "ogx_mmlux_el-virology"
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_el-us_foreign_policy"
    },
    "ogx_mmlux_el-sociology": {
      "acc,none": 0.7661691542288557,
      "acc_stderr,none": 0.029929415408348384,
      "alias": "ogx_mmlux_el-sociology"
    },
    "ogx_mmlux_el-security_studies": {
      "acc,none": 0.6326530612244898,
      "acc_stderr,none": 0.030862144921087548,
      "alias": "ogx_mmlux_el-security_studies"
    },
    "ogx_mmlux_el-public_relations": {
      "acc,none": 0.5636363636363636,
      "acc_stderr,none": 0.04750185058907296,
      "alias": "ogx_mmlux_el-public_relations"
    },
    "ogx_mmlux_el-professional_psychology": {
      "acc,none": 0.5065359477124183,
      "acc_stderr,none": 0.020226106567657807,
      "alias": "ogx_mmlux_el-professional_psychology"
    },
    "ogx_mmlux_el-professional_medicine": {
      "acc,none": 0.5404411764705882,
      "acc_stderr,none": 0.03027332507734576,
      "alias": "ogx_mmlux_el-professional_medicine"
    },
    "ogx_mmlux_el-professional_law": {
      "acc,none": 0.41395045632333766,
      "acc_stderr,none": 0.012579699631289262,
      "alias": "ogx_mmlux_el-professional_law"
    },
    "ogx_mmlux_el-professional_accounting": {
      "acc,none": 0.39361702127659576,
      "acc_stderr,none": 0.029144544781596157,
      "alias": "ogx_mmlux_el-professional_accounting"
    },
    "ogx_mmlux_el-prehistory": {
      "acc,none": 0.6080246913580247,
      "acc_stderr,none": 0.027163686038271146,
      "alias": "ogx_mmlux_el-prehistory"
    },
    "ogx_mmlux_el-philosophy": {
      "acc,none": 0.6302250803858521,
      "acc_stderr,none": 0.027417996705631,
      "alias": "ogx_mmlux_el-philosophy"
    },
    "ogx_mmlux_el-nutrition": {
      "acc,none": 0.5849673202614379,
      "acc_stderr,none": 0.028213504177824093,
      "alias": "ogx_mmlux_el-nutrition"
    },
    "ogx_mmlux_el-moral_scenarios": {
      "acc,none": 0.4245810055865922,
      "acc_stderr,none": 0.01653117099327889,
      "alias": "ogx_mmlux_el-moral_scenarios"
    },
    "ogx_mmlux_el-moral_disputes": {
      "acc,none": 0.5838150289017341,
      "acc_stderr,none": 0.02653818910470548,
      "alias": "ogx_mmlux_el-moral_disputes"
    },
    "ogx_mmlux_el-miscellaneous": {
      "acc,none": 0.665389527458493,
      "acc_stderr,none": 0.016873468641592157,
      "alias": "ogx_mmlux_el-miscellaneous"
    },
    "ogx_mmlux_el-medical_genetics": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_el-medical_genetics"
    },
    "ogx_mmlux_el-marketing": {
      "acc,none": 0.7649572649572649,
      "acc_stderr,none": 0.027778835904935427,
      "alias": "ogx_mmlux_el-marketing"
    },
    "ogx_mmlux_el-management": {
      "acc,none": 0.7281553398058253,
      "acc_stderr,none": 0.044052680241409216,
      "alias": "ogx_mmlux_el-management"
    },
    "ogx_mmlux_el-machine_learning": {
      "acc,none": 0.3125,
      "acc_stderr,none": 0.043994650575715215,
      "alias": "ogx_mmlux_el-machine_learning"
    },
    "ogx_mmlux_el-logical_fallacies": {
      "acc,none": 0.5214723926380368,
      "acc_stderr,none": 0.03924746876751129,
      "alias": "ogx_mmlux_el-logical_fallacies"
    },
    "ogx_mmlux_el-jurisprudence": {
      "acc,none": 0.6203703703703703,
      "acc_stderr,none": 0.04691521224077742,
      "alias": "ogx_mmlux_el-jurisprudence"
    },
    "ogx_mmlux_el-international_law": {
      "acc,none": 0.7272727272727273,
      "acc_stderr,none": 0.04065578140908705,
      "alias": "ogx_mmlux_el-international_law"
    },
    "ogx_mmlux_el-human_sexuality": {
      "acc,none": 0.6259541984732825,
      "acc_stderr,none": 0.04243869242230524,
      "alias": "ogx_mmlux_el-human_sexuality"
    },
    "ogx_mmlux_el-human_aging": {
      "acc,none": 0.5829596412556054,
      "acc_stderr,none": 0.03309266936071722,
      "alias": "ogx_mmlux_el-human_aging"
    },
    "ogx_mmlux_el-high_school_world_history": {
      "acc,none": 0.7341772151898734,
      "acc_stderr,none": 0.028756799629658332,
      "alias": "ogx_mmlux_el-high_school_world_history"
    },
    "ogx_mmlux_el-high_school_us_history": {
      "acc,none": 0.7156862745098039,
      "acc_stderr,none": 0.031660096793998116,
      "alias": "ogx_mmlux_el-high_school_us_history"
    },
    "ogx_mmlux_el-high_school_statistics": {
      "acc,none": 0.4212962962962963,
      "acc_stderr,none": 0.03367462138896078,
      "alias": "ogx_mmlux_el-high_school_statistics"
    },
    "ogx_mmlux_el-high_school_psychology": {
      "acc,none": 0.689908256880734,
      "acc_stderr,none": 0.019830849684439756,
      "alias": "ogx_mmlux_el-high_school_psychology"
    },
    "ogx_mmlux_el-high_school_physics": {
      "acc,none": 0.33774834437086093,
      "acc_stderr,none": 0.03861557546255169,
      "alias": "ogx_mmlux_el-high_school_physics"
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.032478490123081544,
      "alias": "ogx_mmlux_el-high_school_microeconomics"
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "acc,none": 0.37037037037037035,
      "acc_stderr,none": 0.029443169323031544,
      "alias": "ogx_mmlux_el-high_school_mathematics"
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "acc,none": 0.558974358974359,
      "acc_stderr,none": 0.025174048384000728,
      "alias": "ogx_mmlux_el-high_school_macroeconomics"
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "acc,none": 0.6683937823834197,
      "acc_stderr,none": 0.03397636541089118,
      "alias": "ogx_mmlux_el-high_school_government_and_politics"
    },
    "ogx_mmlux_el-high_school_geography": {
      "acc,none": 0.6919191919191919,
      "acc_stderr,none": 0.03289477330098616,
      "alias": "ogx_mmlux_el-high_school_geography"
    },
    "ogx_mmlux_el-high_school_european_history": {
      "acc,none": 0.7212121212121212,
      "acc_stderr,none": 0.03501438706296781,
      "alias": "ogx_mmlux_el-high_school_european_history"
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "acc,none": 0.55,
      "acc_stderr,none": 0.04999999999999999,
      "alias": "ogx_mmlux_el-high_school_computer_science"
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "acc,none": 0.39408866995073893,
      "acc_stderr,none": 0.034381579670365425,
      "alias": "ogx_mmlux_el-high_school_chemistry"
    },
    "ogx_mmlux_el-high_school_biology": {
      "acc,none": 0.6193548387096774,
      "acc_stderr,none": 0.027621717832907025,
      "alias": "ogx_mmlux_el-high_school_biology"
    },
    "ogx_mmlux_el-global_facts": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_el-global_facts"
    },
    "ogx_mmlux_el-formal_logic": {
      "acc,none": 0.373015873015873,
      "acc_stderr,none": 0.04325506042017086,
      "alias": "ogx_mmlux_el-formal_logic"
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "acc,none": 0.373015873015873,
      "acc_stderr,none": 0.02490699045899257,
      "alias": "ogx_mmlux_el-elementary_mathematics"
    },
    "ogx_mmlux_el-electrical_engineering": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.040824829046386284,
      "alias": "ogx_mmlux_el-electrical_engineering"
    },
    "ogx_mmlux_el-econometrics": {
      "acc,none": 0.42105263157894735,
      "acc_stderr,none": 0.046446020912223177,
      "alias": "ogx_mmlux_el-econometrics"
    },
    "ogx_mmlux_el-conceptual_physics": {
      "acc,none": 0.4723404255319149,
      "acc_stderr,none": 0.03263597118409769,
      "alias": "ogx_mmlux_el-conceptual_physics"
    },
    "ogx_mmlux_el-computer_security": {
      "acc,none": 0.61,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_el-computer_security"
    },
    "ogx_mmlux_el-college_physics": {
      "acc,none": 0.38235294117647056,
      "acc_stderr,none": 0.04835503696107223,
      "alias": "ogx_mmlux_el-college_physics"
    },
    "ogx_mmlux_el-college_medicine": {
      "acc,none": 0.5317919075144508,
      "acc_stderr,none": 0.03804749744364764,
      "alias": "ogx_mmlux_el-college_medicine"
    },
    "ogx_mmlux_el-college_mathematics": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.047258156262526045,
      "alias": "ogx_mmlux_el-college_mathematics"
    },
    "ogx_mmlux_el-college_computer_science": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_el-college_computer_science"
    },
    "ogx_mmlux_el-college_chemistry": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.04923659639173309,
      "alias": "ogx_mmlux_el-college_chemistry"
    },
    "ogx_mmlux_el-college_biology": {
      "acc,none": 0.5763888888888888,
      "acc_stderr,none": 0.041321250197233685,
      "alias": "ogx_mmlux_el-college_biology"
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "acc,none": 0.5584905660377358,
      "acc_stderr,none": 0.03056159042673184,
      "alias": "ogx_mmlux_el-clinical_knowledge"
    },
    "ogx_mmlux_el-business_ethics": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_el-business_ethics"
    },
    "ogx_mmlux_el-astronomy": {
      "acc,none": 0.5657894736842105,
      "acc_stderr,none": 0.040335656678483205,
      "alias": "ogx_mmlux_el-astronomy"
    },
    "ogx_mmlux_el-anatomy": {
      "acc,none": 0.4888888888888889,
      "acc_stderr,none": 0.04318275491977976,
      "alias": "ogx_mmlux_el-anatomy"
    },
    "ogx_mmlux_el-abstract_algebra": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_el-abstract_algebra"
    },
    "ogx_mmlux_de-world_religions": {
      "acc,none": 0.7602339181286549,
      "acc_stderr,none": 0.03274485211946956,
      "alias": "ogx_mmlux_de-world_religions"
    },
    "ogx_mmlux_de-virology": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.03892494720807614,
      "alias": "ogx_mmlux_de-virology"
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_de-us_foreign_policy"
    },
    "ogx_mmlux_de-sociology": {
      "acc,none": 0.7661691542288557,
      "acc_stderr,none": 0.029929415408348384,
      "alias": "ogx_mmlux_de-sociology"
    },
    "ogx_mmlux_de-security_studies": {
      "acc,none": 0.6979591836734694,
      "acc_stderr,none": 0.0293936093198798,
      "alias": "ogx_mmlux_de-security_studies"
    },
    "ogx_mmlux_de-public_relations": {
      "acc,none": 0.5727272727272728,
      "acc_stderr,none": 0.047381987035454834,
      "alias": "ogx_mmlux_de-public_relations"
    },
    "ogx_mmlux_de-professional_psychology": {
      "acc,none": 0.5522875816993464,
      "acc_stderr,none": 0.02011692534742242,
      "alias": "ogx_mmlux_de-professional_psychology"
    },
    "ogx_mmlux_de-professional_medicine": {
      "acc,none": 0.5735294117647058,
      "acc_stderr,none": 0.030042615832714867,
      "alias": "ogx_mmlux_de-professional_medicine"
    },
    "ogx_mmlux_de-professional_law": {
      "acc,none": 0.39895697522816165,
      "acc_stderr,none": 0.01250675765529367,
      "alias": "ogx_mmlux_de-professional_law"
    },
    "ogx_mmlux_de-professional_accounting": {
      "acc,none": 0.3723404255319149,
      "acc_stderr,none": 0.028838921471251455,
      "alias": "ogx_mmlux_de-professional_accounting"
    },
    "ogx_mmlux_de-prehistory": {
      "acc,none": 0.654320987654321,
      "acc_stderr,none": 0.026462487777001872,
      "alias": "ogx_mmlux_de-prehistory"
    },
    "ogx_mmlux_de-philosophy": {
      "acc,none": 0.5819935691318328,
      "acc_stderr,none": 0.028013651891995072,
      "alias": "ogx_mmlux_de-philosophy"
    },
    "ogx_mmlux_de-nutrition": {
      "acc,none": 0.6045751633986928,
      "acc_stderr,none": 0.027996723180631455,
      "alias": "ogx_mmlux_de-nutrition"
    },
    "ogx_mmlux_de-moral_scenarios": {
      "acc,none": 0.48268156424581005,
      "acc_stderr,none": 0.016712467441702517,
      "alias": "ogx_mmlux_de-moral_scenarios"
    },
    "ogx_mmlux_de-moral_disputes": {
      "acc,none": 0.6271676300578035,
      "acc_stderr,none": 0.026033890613576277,
      "alias": "ogx_mmlux_de-moral_disputes"
    },
    "ogx_mmlux_de-miscellaneous": {
      "acc,none": 0.7394636015325671,
      "acc_stderr,none": 0.015696008563807096,
      "alias": "ogx_mmlux_de-miscellaneous"
    },
    "ogx_mmlux_de-medical_genetics": {
      "acc,none": 0.57,
      "acc_stderr,none": 0.04975698519562428,
      "alias": "ogx_mmlux_de-medical_genetics"
    },
    "ogx_mmlux_de-marketing": {
      "acc,none": 0.782051282051282,
      "acc_stderr,none": 0.02704685763071668,
      "alias": "ogx_mmlux_de-marketing"
    },
    "ogx_mmlux_de-management": {
      "acc,none": 0.7475728155339806,
      "acc_stderr,none": 0.04301250399690878,
      "alias": "ogx_mmlux_de-management"
    },
    "ogx_mmlux_de-machine_learning": {
      "acc,none": 0.3482142857142857,
      "acc_stderr,none": 0.045218299028335865,
      "alias": "ogx_mmlux_de-machine_learning"
    },
    "ogx_mmlux_de-logical_fallacies": {
      "acc,none": 0.5705521472392638,
      "acc_stderr,none": 0.03889066619112722,
      "alias": "ogx_mmlux_de-logical_fallacies"
    },
    "ogx_mmlux_de-jurisprudence": {
      "acc,none": 0.6296296296296297,
      "acc_stderr,none": 0.04668408033024931,
      "alias": "ogx_mmlux_de-jurisprudence"
    },
    "ogx_mmlux_de-international_law": {
      "acc,none": 0.768595041322314,
      "acc_stderr,none": 0.03849856098794088,
      "alias": "ogx_mmlux_de-international_law"
    },
    "ogx_mmlux_de-human_sexuality": {
      "acc,none": 0.648854961832061,
      "acc_stderr,none": 0.04186445163013751,
      "alias": "ogx_mmlux_de-human_sexuality"
    },
    "ogx_mmlux_de-human_aging": {
      "acc,none": 0.5919282511210763,
      "acc_stderr,none": 0.03298574607842822,
      "alias": "ogx_mmlux_de-human_aging"
    },
    "ogx_mmlux_de-high_school_world_history": {
      "acc,none": 0.7510548523206751,
      "acc_stderr,none": 0.028146970599422647,
      "alias": "ogx_mmlux_de-high_school_world_history"
    },
    "ogx_mmlux_de-high_school_us_history": {
      "acc,none": 0.803921568627451,
      "acc_stderr,none": 0.027865942286639325,
      "alias": "ogx_mmlux_de-high_school_us_history"
    },
    "ogx_mmlux_de-high_school_statistics": {
      "acc,none": 0.41203703703703703,
      "acc_stderr,none": 0.03356787758160835,
      "alias": "ogx_mmlux_de-high_school_statistics"
    },
    "ogx_mmlux_de-high_school_psychology": {
      "acc,none": 0.7247706422018348,
      "acc_stderr,none": 0.0191490937431552,
      "alias": "ogx_mmlux_de-high_school_psychology"
    },
    "ogx_mmlux_de-high_school_physics": {
      "acc,none": 0.3576158940397351,
      "acc_stderr,none": 0.03913453431177258,
      "alias": "ogx_mmlux_de-high_school_physics"
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "acc,none": 0.592436974789916,
      "acc_stderr,none": 0.031918633744784645,
      "alias": "ogx_mmlux_de-high_school_microeconomics"
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "acc,none": 0.37037037037037035,
      "acc_stderr,none": 0.02944316932303154,
      "alias": "ogx_mmlux_de-high_school_mathematics"
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "acc,none": 0.5538461538461539,
      "acc_stderr,none": 0.02520357177302833,
      "alias": "ogx_mmlux_de-high_school_macroeconomics"
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "acc,none": 0.7512953367875648,
      "acc_stderr,none": 0.03119584087770029,
      "alias": "ogx_mmlux_de-high_school_government_and_politics"
    },
    "ogx_mmlux_de-high_school_geography": {
      "acc,none": 0.7222222222222222,
      "acc_stderr,none": 0.03191178226713547,
      "alias": "ogx_mmlux_de-high_school_geography"
    },
    "ogx_mmlux_de-high_school_european_history": {
      "acc,none": 0.7696969696969697,
      "acc_stderr,none": 0.03287666758603489,
      "alias": "ogx_mmlux_de-high_school_european_history"
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_de-high_school_computer_science"
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "acc,none": 0.4433497536945813,
      "acc_stderr,none": 0.03495334582162934,
      "alias": "ogx_mmlux_de-high_school_chemistry"
    },
    "ogx_mmlux_de-high_school_biology": {
      "acc,none": 0.6774193548387096,
      "acc_stderr,none": 0.026593084516572264,
      "alias": "ogx_mmlux_de-high_school_biology"
    },
    "ogx_mmlux_de-global_facts": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_de-global_facts"
    },
    "ogx_mmlux_de-formal_logic": {
      "acc,none": 0.38095238095238093,
      "acc_stderr,none": 0.043435254289490965,
      "alias": "ogx_mmlux_de-formal_logic"
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "acc,none": 0.43386243386243384,
      "acc_stderr,none": 0.025525034382474884,
      "alias": "ogx_mmlux_de-elementary_mathematics"
    },
    "ogx_mmlux_de-electrical_engineering": {
      "acc,none": 0.5862068965517241,
      "acc_stderr,none": 0.04104269211806232,
      "alias": "ogx_mmlux_de-electrical_engineering"
    },
    "ogx_mmlux_de-econometrics": {
      "acc,none": 0.3684210526315789,
      "acc_stderr,none": 0.04537815354939391,
      "alias": "ogx_mmlux_de-econometrics"
    },
    "ogx_mmlux_de-conceptual_physics": {
      "acc,none": 0.4723404255319149,
      "acc_stderr,none": 0.03263597118409769,
      "alias": "ogx_mmlux_de-conceptual_physics"
    },
    "ogx_mmlux_de-computer_security": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_de-computer_security"
    },
    "ogx_mmlux_de-college_physics": {
      "acc,none": 0.38235294117647056,
      "acc_stderr,none": 0.04835503696107223,
      "alias": "ogx_mmlux_de-college_physics"
    },
    "ogx_mmlux_de-college_medicine": {
      "acc,none": 0.5664739884393064,
      "acc_stderr,none": 0.03778621079092055,
      "alias": "ogx_mmlux_de-college_medicine"
    },
    "ogx_mmlux_de-college_mathematics": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.048523658709390974,
      "alias": "ogx_mmlux_de-college_mathematics"
    },
    "ogx_mmlux_de-college_computer_science": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_de-college_computer_science"
    },
    "ogx_mmlux_de-college_chemistry": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_de-college_chemistry"
    },
    "ogx_mmlux_de-college_biology": {
      "acc,none": 0.5694444444444444,
      "acc_stderr,none": 0.04140685639111503,
      "alias": "ogx_mmlux_de-college_biology"
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "acc,none": 0.6150943396226415,
      "acc_stderr,none": 0.029946498567699948,
      "alias": "ogx_mmlux_de-clinical_knowledge"
    },
    "ogx_mmlux_de-business_ethics": {
      "acc,none": 0.61,
      "acc_stderr,none": 0.04902071300001974,
      "alias": "ogx_mmlux_de-business_ethics"
    },
    "ogx_mmlux_de-astronomy": {
      "acc,none": 0.6052631578947368,
      "acc_stderr,none": 0.039777499346220734,
      "alias": "ogx_mmlux_de-astronomy"
    },
    "ogx_mmlux_de-anatomy": {
      "acc,none": 0.4888888888888889,
      "acc_stderr,none": 0.04318275491977976,
      "alias": "ogx_mmlux_de-anatomy"
    },
    "ogx_mmlux_de-abstract_algebra": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.045126085985421296,
      "alias": "ogx_mmlux_de-abstract_algebra"
    },
    "ogx_mmlux_da-world_religions": {
      "acc,none": 0.6491228070175439,
      "acc_stderr,none": 0.03660298834049161,
      "alias": "ogx_mmlux_da-world_religions"
    },
    "ogx_mmlux_da-virology": {
      "acc,none": 0.4578313253012048,
      "acc_stderr,none": 0.0387862677100236,
      "alias": "ogx_mmlux_da-virology"
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_da-us_foreign_policy"
    },
    "ogx_mmlux_da-sociology": {
      "acc,none": 0.6766169154228856,
      "acc_stderr,none": 0.03307615947979033,
      "alias": "ogx_mmlux_da-sociology"
    },
    "ogx_mmlux_da-security_studies": {
      "acc,none": 0.636734693877551,
      "acc_stderr,none": 0.030789051139030806,
      "alias": "ogx_mmlux_da-security_studies"
    },
    "ogx_mmlux_da-public_relations": {
      "acc,none": 0.4818181818181818,
      "acc_stderr,none": 0.04785964010794916,
      "alias": "ogx_mmlux_da-public_relations"
    },
    "ogx_mmlux_da-professional_psychology": {
      "acc,none": 0.4477124183006536,
      "acc_stderr,none": 0.020116925347422425,
      "alias": "ogx_mmlux_da-professional_psychology"
    },
    "ogx_mmlux_da-professional_medicine": {
      "acc,none": 0.4963235294117647,
      "acc_stderr,none": 0.030372015885428195,
      "alias": "ogx_mmlux_da-professional_medicine"
    },
    "ogx_mmlux_da-professional_law": {
      "acc,none": 0.3663624511082138,
      "acc_stderr,none": 0.012305658346838444,
      "alias": "ogx_mmlux_da-professional_law"
    },
    "ogx_mmlux_da-professional_accounting": {
      "acc,none": 0.3475177304964539,
      "acc_stderr,none": 0.02840662780959095,
      "alias": "ogx_mmlux_da-professional_accounting"
    },
    "ogx_mmlux_da-prehistory": {
      "acc,none": 0.5617283950617284,
      "acc_stderr,none": 0.027607914087400463,
      "alias": "ogx_mmlux_da-prehistory"
    },
    "ogx_mmlux_da-philosophy": {
      "acc,none": 0.5659163987138264,
      "acc_stderr,none": 0.028150232244535597,
      "alias": "ogx_mmlux_da-philosophy"
    },
    "ogx_mmlux_da-nutrition": {
      "acc,none": 0.5163398692810458,
      "acc_stderr,none": 0.028614624752805434,
      "alias": "ogx_mmlux_da-nutrition"
    },
    "ogx_mmlux_da-moral_scenarios": {
      "acc,none": 0.37318435754189944,
      "acc_stderr,none": 0.016175692013381947,
      "alias": "ogx_mmlux_da-moral_scenarios"
    },
    "ogx_mmlux_da-moral_disputes": {
      "acc,none": 0.546242774566474,
      "acc_stderr,none": 0.026803720583206184,
      "alias": "ogx_mmlux_da-moral_disputes"
    },
    "ogx_mmlux_da-miscellaneous": {
      "acc,none": 0.6053639846743295,
      "acc_stderr,none": 0.017478464305911545,
      "alias": "ogx_mmlux_da-miscellaneous"
    },
    "ogx_mmlux_da-medical_genetics": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_da-medical_genetics"
    },
    "ogx_mmlux_da-marketing": {
      "acc,none": 0.7307692307692307,
      "acc_stderr,none": 0.029058588303748845,
      "alias": "ogx_mmlux_da-marketing"
    },
    "ogx_mmlux_da-management": {
      "acc,none": 0.7281553398058253,
      "acc_stderr,none": 0.044052680241409216,
      "alias": "ogx_mmlux_da-management"
    },
    "ogx_mmlux_da-machine_learning": {
      "acc,none": 0.35714285714285715,
      "acc_stderr,none": 0.04547960999764376,
      "alias": "ogx_mmlux_da-machine_learning"
    },
    "ogx_mmlux_da-logical_fallacies": {
      "acc,none": 0.5030674846625767,
      "acc_stderr,none": 0.03928297078179663,
      "alias": "ogx_mmlux_da-logical_fallacies"
    },
    "ogx_mmlux_da-jurisprudence": {
      "acc,none": 0.5648148148148148,
      "acc_stderr,none": 0.04792898170907061,
      "alias": "ogx_mmlux_da-jurisprudence"
    },
    "ogx_mmlux_da-international_law": {
      "acc,none": 0.6528925619834711,
      "acc_stderr,none": 0.04345724570292534,
      "alias": "ogx_mmlux_da-international_law"
    },
    "ogx_mmlux_da-human_sexuality": {
      "acc,none": 0.5877862595419847,
      "acc_stderr,none": 0.04317171194870255,
      "alias": "ogx_mmlux_da-human_sexuality"
    },
    "ogx_mmlux_da-human_aging": {
      "acc,none": 0.5426008968609866,
      "acc_stderr,none": 0.033435777055830646,
      "alias": "ogx_mmlux_da-human_aging"
    },
    "ogx_mmlux_da-high_school_world_history": {
      "acc,none": 0.6540084388185654,
      "acc_stderr,none": 0.03096481058878671,
      "alias": "ogx_mmlux_da-high_school_world_history"
    },
    "ogx_mmlux_da-high_school_us_history": {
      "acc,none": 0.6519607843137255,
      "acc_stderr,none": 0.03343311240488419,
      "alias": "ogx_mmlux_da-high_school_us_history"
    },
    "ogx_mmlux_da-high_school_statistics": {
      "acc,none": 0.375,
      "acc_stderr,none": 0.033016908987210894,
      "alias": "ogx_mmlux_da-high_school_statistics"
    },
    "ogx_mmlux_da-high_school_psychology": {
      "acc,none": 0.6256880733944954,
      "acc_stderr,none": 0.020748959408988313,
      "alias": "ogx_mmlux_da-high_school_psychology"
    },
    "ogx_mmlux_da-high_school_physics": {
      "acc,none": 0.32450331125827814,
      "acc_stderr,none": 0.038227469376587525,
      "alias": "ogx_mmlux_da-high_school_physics"
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "acc,none": 0.49159663865546216,
      "acc_stderr,none": 0.03247390276569669,
      "alias": "ogx_mmlux_da-high_school_microeconomics"
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "acc,none": 0.34814814814814815,
      "acc_stderr,none": 0.029045600290616258,
      "alias": "ogx_mmlux_da-high_school_mathematics"
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "acc,none": 0.4641025641025641,
      "acc_stderr,none": 0.025285585990017838,
      "alias": "ogx_mmlux_da-high_school_macroeconomics"
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "acc,none": 0.5803108808290155,
      "acc_stderr,none": 0.035615873276858834,
      "alias": "ogx_mmlux_da-high_school_government_and_politics"
    },
    "ogx_mmlux_da-high_school_geography": {
      "acc,none": 0.702020202020202,
      "acc_stderr,none": 0.032586303838365555,
      "alias": "ogx_mmlux_da-high_school_geography"
    },
    "ogx_mmlux_da-high_school_european_history": {
      "acc,none": 0.6484848484848484,
      "acc_stderr,none": 0.0372820699868265,
      "alias": "ogx_mmlux_da-high_school_european_history"
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "acc,none": 0.54,
      "acc_stderr,none": 0.05009082659620333,
      "alias": "ogx_mmlux_da-high_school_computer_science"
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "acc,none": 0.4236453201970443,
      "acc_stderr,none": 0.03476725747649037,
      "alias": "ogx_mmlux_da-high_school_chemistry"
    },
    "ogx_mmlux_da-high_school_biology": {
      "acc,none": 0.5709677419354838,
      "acc_stderr,none": 0.028156036538233193,
      "alias": "ogx_mmlux_da-high_school_biology"
    },
    "ogx_mmlux_da-global_facts": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_da-global_facts"
    },
    "ogx_mmlux_da-formal_logic": {
      "acc,none": 0.373015873015873,
      "acc_stderr,none": 0.04325506042017086,
      "alias": "ogx_mmlux_da-formal_logic"
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "acc,none": 0.3439153439153439,
      "acc_stderr,none": 0.02446442662559643,
      "alias": "ogx_mmlux_da-elementary_mathematics"
    },
    "ogx_mmlux_da-electrical_engineering": {
      "acc,none": 0.5172413793103449,
      "acc_stderr,none": 0.04164188720169375,
      "alias": "ogx_mmlux_da-electrical_engineering"
    },
    "ogx_mmlux_da-econometrics": {
      "acc,none": 0.34210526315789475,
      "acc_stderr,none": 0.044629175353369376,
      "alias": "ogx_mmlux_da-econometrics"
    },
    "ogx_mmlux_da-conceptual_physics": {
      "acc,none": 0.44680851063829785,
      "acc_stderr,none": 0.03250053684365839,
      "alias": "ogx_mmlux_da-conceptual_physics"
    },
    "ogx_mmlux_da-computer_security": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_da-computer_security"
    },
    "ogx_mmlux_da-college_physics": {
      "acc,none": 0.29411764705882354,
      "acc_stderr,none": 0.04533838195929775,
      "alias": "ogx_mmlux_da-college_physics"
    },
    "ogx_mmlux_da-college_medicine": {
      "acc,none": 0.5028901734104047,
      "acc_stderr,none": 0.038124005659748335,
      "alias": "ogx_mmlux_da-college_medicine"
    },
    "ogx_mmlux_da-college_mathematics": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.047937248544110196,
      "alias": "ogx_mmlux_da-college_mathematics"
    },
    "ogx_mmlux_da-college_computer_science": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_da-college_computer_science"
    },
    "ogx_mmlux_da-college_chemistry": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_da-college_chemistry"
    },
    "ogx_mmlux_da-college_biology": {
      "acc,none": 0.5555555555555556,
      "acc_stderr,none": 0.041553199555931467,
      "alias": "ogx_mmlux_da-college_biology"
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "acc,none": 0.5245283018867924,
      "acc_stderr,none": 0.030735822206205615,
      "alias": "ogx_mmlux_da-clinical_knowledge"
    },
    "ogx_mmlux_da-business_ethics": {
      "acc,none": 0.53,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_da-business_ethics"
    },
    "ogx_mmlux_da-astronomy": {
      "acc,none": 0.5526315789473685,
      "acc_stderr,none": 0.04046336883978251,
      "alias": "ogx_mmlux_da-astronomy"
    },
    "ogx_mmlux_da-anatomy": {
      "acc,none": 0.4444444444444444,
      "acc_stderr,none": 0.04292596718256981,
      "alias": "ogx_mmlux_da-anatomy"
    },
    "ogx_mmlux_da-abstract_algebra": {
      "acc,none": 0.26,
      "acc_stderr,none": 0.04408440022768078,
      "alias": "ogx_mmlux_da-abstract_algebra"
    },
    "ogx_mmlux_cs-world_religions": {
      "acc,none": 0.7076023391812866,
      "acc_stderr,none": 0.034886477134579215,
      "alias": "ogx_mmlux_cs-world_religions"
    },
    "ogx_mmlux_cs-virology": {
      "acc,none": 0.5542168674698795,
      "acc_stderr,none": 0.03869543323472101,
      "alias": "ogx_mmlux_cs-virology"
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_cs-us_foreign_policy"
    },
    "ogx_mmlux_cs-sociology": {
      "acc,none": 0.7562189054726368,
      "acc_stderr,none": 0.03036049015401466,
      "alias": "ogx_mmlux_cs-sociology"
    },
    "ogx_mmlux_cs-security_studies": {
      "acc,none": 0.6775510204081633,
      "acc_stderr,none": 0.029923100563683906,
      "alias": "ogx_mmlux_cs-security_studies"
    },
    "ogx_mmlux_cs-public_relations": {
      "acc,none": 0.5818181818181818,
      "acc_stderr,none": 0.04724577405731572,
      "alias": "ogx_mmlux_cs-public_relations"
    },
    "ogx_mmlux_cs-professional_psychology": {
      "acc,none": 0.5212418300653595,
      "acc_stderr,none": 0.020209572388600255,
      "alias": "ogx_mmlux_cs-professional_psychology"
    },
    "ogx_mmlux_cs-professional_medicine": {
      "acc,none": 0.5441176470588235,
      "acc_stderr,none": 0.030254372573976705,
      "alias": "ogx_mmlux_cs-professional_medicine"
    },
    "ogx_mmlux_cs-professional_law": {
      "acc,none": 0.40352020860495436,
      "acc_stderr,none": 0.012530241301193186,
      "alias": "ogx_mmlux_cs-professional_law"
    },
    "ogx_mmlux_cs-professional_accounting": {
      "acc,none": 0.34397163120567376,
      "acc_stderr,none": 0.028338017428611334,
      "alias": "ogx_mmlux_cs-professional_accounting"
    },
    "ogx_mmlux_cs-prehistory": {
      "acc,none": 0.6388888888888888,
      "acc_stderr,none": 0.02672586880910079,
      "alias": "ogx_mmlux_cs-prehistory"
    },
    "ogx_mmlux_cs-philosophy": {
      "acc,none": 0.5755627009646302,
      "acc_stderr,none": 0.028071928247946205,
      "alias": "ogx_mmlux_cs-philosophy"
    },
    "ogx_mmlux_cs-nutrition": {
      "acc,none": 0.6143790849673203,
      "acc_stderr,none": 0.02787074527829027,
      "alias": "ogx_mmlux_cs-nutrition"
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.016384638410380816,
      "alias": "ogx_mmlux_cs-moral_scenarios"
    },
    "ogx_mmlux_cs-moral_disputes": {
      "acc,none": 0.5953757225433526,
      "acc_stderr,none": 0.02642481659400985,
      "alias": "ogx_mmlux_cs-moral_disputes"
    },
    "ogx_mmlux_cs-miscellaneous": {
      "acc,none": 0.6845466155810983,
      "acc_stderr,none": 0.016617501738763394,
      "alias": "ogx_mmlux_cs-miscellaneous"
    },
    "ogx_mmlux_cs-medical_genetics": {
      "acc,none": 0.56,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_cs-medical_genetics"
    },
    "ogx_mmlux_cs-marketing": {
      "acc,none": 0.7649572649572649,
      "acc_stderr,none": 0.02777883590493543,
      "alias": "ogx_mmlux_cs-marketing"
    },
    "ogx_mmlux_cs-management": {
      "acc,none": 0.7864077669902912,
      "acc_stderr,none": 0.04058042015646033,
      "alias": "ogx_mmlux_cs-management"
    },
    "ogx_mmlux_cs-machine_learning": {
      "acc,none": 0.2857142857142857,
      "acc_stderr,none": 0.04287858751340456,
      "alias": "ogx_mmlux_cs-machine_learning"
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "acc,none": 0.5828220858895705,
      "acc_stderr,none": 0.03874102859818083,
      "alias": "ogx_mmlux_cs-logical_fallacies"
    },
    "ogx_mmlux_cs-jurisprudence": {
      "acc,none": 0.6481481481481481,
      "acc_stderr,none": 0.04616631111801713,
      "alias": "ogx_mmlux_cs-jurisprudence"
    },
    "ogx_mmlux_cs-international_law": {
      "acc,none": 0.6776859504132231,
      "acc_stderr,none": 0.042664163633521685,
      "alias": "ogx_mmlux_cs-international_law"
    },
    "ogx_mmlux_cs-human_sexuality": {
      "acc,none": 0.6335877862595419,
      "acc_stderr,none": 0.04225875451969638,
      "alias": "ogx_mmlux_cs-human_sexuality"
    },
    "ogx_mmlux_cs-human_aging": {
      "acc,none": 0.6098654708520179,
      "acc_stderr,none": 0.03273766725459157,
      "alias": "ogx_mmlux_cs-human_aging"
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "acc,none": 0.729957805907173,
      "acc_stderr,none": 0.028900721906293426,
      "alias": "ogx_mmlux_cs-high_school_world_history"
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.03039153369274154,
      "alias": "ogx_mmlux_cs-high_school_us_history"
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "acc,none": 0.39814814814814814,
      "acc_stderr,none": 0.03338473403207401,
      "alias": "ogx_mmlux_cs-high_school_statistics"
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "acc,none": 0.6954128440366972,
      "acc_stderr,none": 0.01973229942035404,
      "alias": "ogx_mmlux_cs-high_school_psychology"
    },
    "ogx_mmlux_cs-high_school_physics": {
      "acc,none": 0.33774834437086093,
      "acc_stderr,none": 0.03861557546255169,
      "alias": "ogx_mmlux_cs-high_school_physics"
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "acc,none": 0.5504201680672269,
      "acc_stderr,none": 0.03231293497137707,
      "alias": "ogx_mmlux_cs-high_school_microeconomics"
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "acc,none": 0.32592592592592595,
      "acc_stderr,none": 0.028578348365473072,
      "alias": "ogx_mmlux_cs-high_school_mathematics"
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "acc,none": 0.5538461538461539,
      "acc_stderr,none": 0.02520357177302833,
      "alias": "ogx_mmlux_cs-high_school_macroeconomics"
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "acc,none": 0.7253886010362695,
      "acc_stderr,none": 0.032210245080411544,
      "alias": "ogx_mmlux_cs-high_school_government_and_politics"
    },
    "ogx_mmlux_cs-high_school_geography": {
      "acc,none": 0.696969696969697,
      "acc_stderr,none": 0.03274287914026868,
      "alias": "ogx_mmlux_cs-high_school_geography"
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "acc,none": 0.7212121212121212,
      "acc_stderr,none": 0.03501438706296781,
      "alias": "ogx_mmlux_cs-high_school_european_history"
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_cs-high_school_computer_science"
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "acc,none": 0.42857142857142855,
      "acc_stderr,none": 0.03481904844438804,
      "alias": "ogx_mmlux_cs-high_school_chemistry"
    },
    "ogx_mmlux_cs-high_school_biology": {
      "acc,none": 0.6870967741935484,
      "acc_stderr,none": 0.02637756702864586,
      "alias": "ogx_mmlux_cs-high_school_biology"
    },
    "ogx_mmlux_cs-global_facts": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_cs-global_facts"
    },
    "ogx_mmlux_cs-formal_logic": {
      "acc,none": 0.40476190476190477,
      "acc_stderr,none": 0.04390259265377562,
      "alias": "ogx_mmlux_cs-formal_logic"
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "acc,none": 0.3783068783068783,
      "acc_stderr,none": 0.024976954053155264,
      "alias": "ogx_mmlux_cs-elementary_mathematics"
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "acc,none": 0.5655172413793104,
      "acc_stderr,none": 0.04130740879555497,
      "alias": "ogx_mmlux_cs-electrical_engineering"
    },
    "ogx_mmlux_cs-econometrics": {
      "acc,none": 0.39473684210526316,
      "acc_stderr,none": 0.04598188057816542,
      "alias": "ogx_mmlux_cs-econometrics"
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "acc,none": 0.48936170212765956,
      "acc_stderr,none": 0.03267862331014063,
      "alias": "ogx_mmlux_cs-conceptual_physics"
    },
    "ogx_mmlux_cs-computer_security": {
      "acc,none": 0.64,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_cs-computer_security"
    },
    "ogx_mmlux_cs-college_physics": {
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.04690650298201942,
      "alias": "ogx_mmlux_cs-college_physics"
    },
    "ogx_mmlux_cs-college_medicine": {
      "acc,none": 0.5722543352601156,
      "acc_stderr,none": 0.03772446857518027,
      "alias": "ogx_mmlux_cs-college_medicine"
    },
    "ogx_mmlux_cs-college_mathematics": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_cs-college_mathematics"
    },
    "ogx_mmlux_cs-college_computer_science": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_cs-college_computer_science"
    },
    "ogx_mmlux_cs-college_chemistry": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_cs-college_chemistry"
    },
    "ogx_mmlux_cs-college_biology": {
      "acc,none": 0.5555555555555556,
      "acc_stderr,none": 0.041553199555931467,
      "alias": "ogx_mmlux_cs-college_biology"
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "acc,none": 0.6075471698113207,
      "acc_stderr,none": 0.030052580579557845,
      "alias": "ogx_mmlux_cs-clinical_knowledge"
    },
    "ogx_mmlux_cs-business_ethics": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_cs-business_ethics"
    },
    "ogx_mmlux_cs-astronomy": {
      "acc,none": 0.5986842105263158,
      "acc_stderr,none": 0.039889037033362836,
      "alias": "ogx_mmlux_cs-astronomy"
    },
    "ogx_mmlux_cs-anatomy": {
      "acc,none": 0.48148148148148145,
      "acc_stderr,none": 0.043163785995113245,
      "alias": "ogx_mmlux_cs-anatomy"
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "acc,none": 0.25,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_cs-abstract_algebra"
    },
    "ogx_mmlux_bg-world_religions": {
      "acc,none": 0.6608187134502924,
      "acc_stderr,none": 0.036310534964889056,
      "alias": "ogx_mmlux_bg-world_religions"
    },
    "ogx_mmlux_bg-virology": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.03892494720807614,
      "alias": "ogx_mmlux_bg-virology"
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.04878317312145632,
      "alias": "ogx_mmlux_bg-us_foreign_policy"
    },
    "ogx_mmlux_bg-sociology": {
      "acc,none": 0.6467661691542289,
      "acc_stderr,none": 0.03379790611796777,
      "alias": "ogx_mmlux_bg-sociology"
    },
    "ogx_mmlux_bg-security_studies": {
      "acc,none": 0.6122448979591837,
      "acc_stderr,none": 0.031192230726795656,
      "alias": "ogx_mmlux_bg-security_studies"
    },
    "ogx_mmlux_bg-public_relations": {
      "acc,none": 0.4636363636363636,
      "acc_stderr,none": 0.04776449162396197,
      "alias": "ogx_mmlux_bg-public_relations"
    },
    "ogx_mmlux_bg-professional_psychology": {
      "acc,none": 0.44281045751633985,
      "acc_stderr,none": 0.020095083154577347,
      "alias": "ogx_mmlux_bg-professional_psychology"
    },
    "ogx_mmlux_bg-professional_medicine": {
      "acc,none": 0.47058823529411764,
      "acc_stderr,none": 0.030320243265004137,
      "alias": "ogx_mmlux_bg-professional_medicine"
    },
    "ogx_mmlux_bg-professional_law": {
      "acc,none": 0.34810951760104303,
      "acc_stderr,none": 0.0121667389936982,
      "alias": "ogx_mmlux_bg-professional_law"
    },
    "ogx_mmlux_bg-professional_accounting": {
      "acc,none": 0.3475177304964539,
      "acc_stderr,none": 0.028406627809590954,
      "alias": "ogx_mmlux_bg-professional_accounting"
    },
    "ogx_mmlux_bg-prehistory": {
      "acc,none": 0.4876543209876543,
      "acc_stderr,none": 0.027812262269327252,
      "alias": "ogx_mmlux_bg-prehistory"
    },
    "ogx_mmlux_bg-philosophy": {
      "acc,none": 0.5337620578778135,
      "acc_stderr,none": 0.028333277109562786,
      "alias": "ogx_mmlux_bg-philosophy"
    },
    "ogx_mmlux_bg-nutrition": {
      "acc,none": 0.5294117647058824,
      "acc_stderr,none": 0.02858034106513829,
      "alias": "ogx_mmlux_bg-nutrition"
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "acc,none": 0.2782122905027933,
      "acc_stderr,none": 0.014987325439963553,
      "alias": "ogx_mmlux_bg-moral_scenarios"
    },
    "ogx_mmlux_bg-moral_disputes": {
      "acc,none": 0.546242774566474,
      "acc_stderr,none": 0.02680372058320618,
      "alias": "ogx_mmlux_bg-moral_disputes"
    },
    "ogx_mmlux_bg-miscellaneous": {
      "acc,none": 0.565772669220945,
      "acc_stderr,none": 0.017724589389677785,
      "alias": "ogx_mmlux_bg-miscellaneous"
    },
    "ogx_mmlux_bg-medical_genetics": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_bg-medical_genetics"
    },
    "ogx_mmlux_bg-marketing": {
      "acc,none": 0.6709401709401709,
      "acc_stderr,none": 0.03078232157768817,
      "alias": "ogx_mmlux_bg-marketing"
    },
    "ogx_mmlux_bg-management": {
      "acc,none": 0.5922330097087378,
      "acc_stderr,none": 0.04865777570410769,
      "alias": "ogx_mmlux_bg-management"
    },
    "ogx_mmlux_bg-machine_learning": {
      "acc,none": 0.375,
      "acc_stderr,none": 0.04595091388086298,
      "alias": "ogx_mmlux_bg-machine_learning"
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "acc,none": 0.44785276073619634,
      "acc_stderr,none": 0.03906947479456601,
      "alias": "ogx_mmlux_bg-logical_fallacies"
    },
    "ogx_mmlux_bg-jurisprudence": {
      "acc,none": 0.5277777777777778,
      "acc_stderr,none": 0.048262172941398944,
      "alias": "ogx_mmlux_bg-jurisprudence"
    },
    "ogx_mmlux_bg-international_law": {
      "acc,none": 0.6859504132231405,
      "acc_stderr,none": 0.042369647530410184,
      "alias": "ogx_mmlux_bg-international_law"
    },
    "ogx_mmlux_bg-human_sexuality": {
      "acc,none": 0.549618320610687,
      "acc_stderr,none": 0.04363643698524779,
      "alias": "ogx_mmlux_bg-human_sexuality"
    },
    "ogx_mmlux_bg-human_aging": {
      "acc,none": 0.5067264573991032,
      "acc_stderr,none": 0.03355476596234355,
      "alias": "ogx_mmlux_bg-human_aging"
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "acc,none": 0.6371308016877637,
      "acc_stderr,none": 0.03129920825530213,
      "alias": "ogx_mmlux_bg-high_school_world_history"
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "acc,none": 0.5833333333333334,
      "acc_stderr,none": 0.034602283272391704,
      "alias": "ogx_mmlux_bg-high_school_us_history"
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "acc,none": 0.35185185185185186,
      "acc_stderr,none": 0.03256850570293648,
      "alias": "ogx_mmlux_bg-high_school_statistics"
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "acc,none": 0.6311926605504588,
      "acc_stderr,none": 0.02068622756072956,
      "alias": "ogx_mmlux_bg-high_school_psychology"
    },
    "ogx_mmlux_bg-high_school_physics": {
      "acc,none": 0.3443708609271523,
      "acc_stderr,none": 0.038796870240733264,
      "alias": "ogx_mmlux_bg-high_school_physics"
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "acc,none": 0.453781512605042,
      "acc_stderr,none": 0.03233943468182088,
      "alias": "ogx_mmlux_bg-high_school_microeconomics"
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "acc,none": 0.35555555555555557,
      "acc_stderr,none": 0.029185714949857406,
      "alias": "ogx_mmlux_bg-high_school_mathematics"
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "acc,none": 0.44871794871794873,
      "acc_stderr,none": 0.025217315184846482,
      "alias": "ogx_mmlux_bg-high_school_macroeconomics"
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "acc,none": 0.5595854922279793,
      "acc_stderr,none": 0.03582724530036094,
      "alias": "ogx_mmlux_bg-high_school_government_and_politics"
    },
    "ogx_mmlux_bg-high_school_geography": {
      "acc,none": 0.6111111111111112,
      "acc_stderr,none": 0.0347327959083696,
      "alias": "ogx_mmlux_bg-high_school_geography"
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "acc,none": 0.6727272727272727,
      "acc_stderr,none": 0.03663974994391242,
      "alias": "ogx_mmlux_bg-high_school_european_history"
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620333,
      "alias": "ogx_mmlux_bg-high_school_computer_science"
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "acc,none": 0.39901477832512317,
      "acc_stderr,none": 0.03445487686264715,
      "alias": "ogx_mmlux_bg-high_school_chemistry"
    },
    "ogx_mmlux_bg-high_school_biology": {
      "acc,none": 0.5451612903225806,
      "acc_stderr,none": 0.028327743091561074,
      "alias": "ogx_mmlux_bg-high_school_biology"
    },
    "ogx_mmlux_bg-global_facts": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_bg-global_facts"
    },
    "ogx_mmlux_bg-formal_logic": {
      "acc,none": 0.3968253968253968,
      "acc_stderr,none": 0.04375888492727061,
      "alias": "ogx_mmlux_bg-formal_logic"
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "acc,none": 0.373015873015873,
      "acc_stderr,none": 0.02490699045899257,
      "alias": "ogx_mmlux_bg-elementary_mathematics"
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "acc,none": 0.47586206896551725,
      "acc_stderr,none": 0.041618085035015295,
      "alias": "ogx_mmlux_bg-electrical_engineering"
    },
    "ogx_mmlux_bg-econometrics": {
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.04434600701584925,
      "alias": "ogx_mmlux_bg-econometrics"
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "acc,none": 0.4127659574468085,
      "acc_stderr,none": 0.03218471141400351,
      "alias": "ogx_mmlux_bg-conceptual_physics"
    },
    "ogx_mmlux_bg-computer_security": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.04878317312145633,
      "alias": "ogx_mmlux_bg-computer_security"
    },
    "ogx_mmlux_bg-college_physics": {
      "acc,none": 0.3137254901960784,
      "acc_stderr,none": 0.04617034827006717,
      "alias": "ogx_mmlux_bg-college_physics"
    },
    "ogx_mmlux_bg-college_medicine": {
      "acc,none": 0.5317919075144508,
      "acc_stderr,none": 0.038047497443647646,
      "alias": "ogx_mmlux_bg-college_medicine"
    },
    "ogx_mmlux_bg-college_mathematics": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_bg-college_mathematics"
    },
    "ogx_mmlux_bg-college_computer_science": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_bg-college_computer_science"
    },
    "ogx_mmlux_bg-college_chemistry": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_bg-college_chemistry"
    },
    "ogx_mmlux_bg-college_biology": {
      "acc,none": 0.4513888888888889,
      "acc_stderr,none": 0.04161402398403279,
      "alias": "ogx_mmlux_bg-college_biology"
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "acc,none": 0.4981132075471698,
      "acc_stderr,none": 0.030772653642075657,
      "alias": "ogx_mmlux_bg-clinical_knowledge"
    },
    "ogx_mmlux_bg-business_ethics": {
      "acc,none": 0.54,
      "acc_stderr,none": 0.05009082659620333,
      "alias": "ogx_mmlux_bg-business_ethics"
    },
    "ogx_mmlux_bg-astronomy": {
      "acc,none": 0.4934210526315789,
      "acc_stderr,none": 0.040685900502249704,
      "alias": "ogx_mmlux_bg-astronomy"
    },
    "ogx_mmlux_bg-anatomy": {
      "acc,none": 0.42962962962962964,
      "acc_stderr,none": 0.04276349494376599,
      "alias": "ogx_mmlux_bg-anatomy"
    },
    "ogx_mmlux_bg-abstract_algebra": {
      "acc,none": 0.26,
      "acc_stderr,none": 0.04408440022768078,
      "alias": "ogx_mmlux_bg-abstract_algebra"
    }
  },
  "group_subtasks": {
    "ogx_mmlux_bg-abstract_algebra": [],
    "ogx_mmlux_bg-anatomy": [],
    "ogx_mmlux_bg-astronomy": [],
    "ogx_mmlux_bg-business_ethics": [],
    "ogx_mmlux_bg-clinical_knowledge": [],
    "ogx_mmlux_bg-college_biology": [],
    "ogx_mmlux_bg-college_chemistry": [],
    "ogx_mmlux_bg-college_computer_science": [],
    "ogx_mmlux_bg-college_mathematics": [],
    "ogx_mmlux_bg-college_medicine": [],
    "ogx_mmlux_bg-college_physics": [],
    "ogx_mmlux_bg-computer_security": [],
    "ogx_mmlux_bg-conceptual_physics": [],
    "ogx_mmlux_bg-econometrics": [],
    "ogx_mmlux_bg-electrical_engineering": [],
    "ogx_mmlux_bg-elementary_mathematics": [],
    "ogx_mmlux_bg-formal_logic": [],
    "ogx_mmlux_bg-global_facts": [],
    "ogx_mmlux_bg-high_school_biology": [],
    "ogx_mmlux_bg-high_school_chemistry": [],
    "ogx_mmlux_bg-high_school_computer_science": [],
    "ogx_mmlux_bg-high_school_european_history": [],
    "ogx_mmlux_bg-high_school_geography": [],
    "ogx_mmlux_bg-high_school_government_and_politics": [],
    "ogx_mmlux_bg-high_school_macroeconomics": [],
    "ogx_mmlux_bg-high_school_mathematics": [],
    "ogx_mmlux_bg-high_school_microeconomics": [],
    "ogx_mmlux_bg-high_school_physics": [],
    "ogx_mmlux_bg-high_school_psychology": [],
    "ogx_mmlux_bg-high_school_statistics": [],
    "ogx_mmlux_bg-high_school_us_history": [],
    "ogx_mmlux_bg-high_school_world_history": [],
    "ogx_mmlux_bg-human_aging": [],
    "ogx_mmlux_bg-human_sexuality": [],
    "ogx_mmlux_bg-international_law": [],
    "ogx_mmlux_bg-jurisprudence": [],
    "ogx_mmlux_bg-logical_fallacies": [],
    "ogx_mmlux_bg-machine_learning": [],
    "ogx_mmlux_bg-management": [],
    "ogx_mmlux_bg-marketing": [],
    "ogx_mmlux_bg-medical_genetics": [],
    "ogx_mmlux_bg-miscellaneous": [],
    "ogx_mmlux_bg-moral_disputes": [],
    "ogx_mmlux_bg-moral_scenarios": [],
    "ogx_mmlux_bg-nutrition": [],
    "ogx_mmlux_bg-philosophy": [],
    "ogx_mmlux_bg-prehistory": [],
    "ogx_mmlux_bg-professional_accounting": [],
    "ogx_mmlux_bg-professional_law": [],
    "ogx_mmlux_bg-professional_medicine": [],
    "ogx_mmlux_bg-professional_psychology": [],
    "ogx_mmlux_bg-public_relations": [],
    "ogx_mmlux_bg-security_studies": [],
    "ogx_mmlux_bg-sociology": [],
    "ogx_mmlux_bg-us_foreign_policy": [],
    "ogx_mmlux_bg-virology": [],
    "ogx_mmlux_bg-world_religions": [],
    "ogx_mmlux_cs-abstract_algebra": [],
    "ogx_mmlux_cs-anatomy": [],
    "ogx_mmlux_cs-astronomy": [],
    "ogx_mmlux_cs-business_ethics": [],
    "ogx_mmlux_cs-clinical_knowledge": [],
    "ogx_mmlux_cs-college_biology": [],
    "ogx_mmlux_cs-college_chemistry": [],
    "ogx_mmlux_cs-college_computer_science": [],
    "ogx_mmlux_cs-college_mathematics": [],
    "ogx_mmlux_cs-college_medicine": [],
    "ogx_mmlux_cs-college_physics": [],
    "ogx_mmlux_cs-computer_security": [],
    "ogx_mmlux_cs-conceptual_physics": [],
    "ogx_mmlux_cs-econometrics": [],
    "ogx_mmlux_cs-electrical_engineering": [],
    "ogx_mmlux_cs-elementary_mathematics": [],
    "ogx_mmlux_cs-formal_logic": [],
    "ogx_mmlux_cs-global_facts": [],
    "ogx_mmlux_cs-high_school_biology": [],
    "ogx_mmlux_cs-high_school_chemistry": [],
    "ogx_mmlux_cs-high_school_computer_science": [],
    "ogx_mmlux_cs-high_school_european_history": [],
    "ogx_mmlux_cs-high_school_geography": [],
    "ogx_mmlux_cs-high_school_government_and_politics": [],
    "ogx_mmlux_cs-high_school_macroeconomics": [],
    "ogx_mmlux_cs-high_school_mathematics": [],
    "ogx_mmlux_cs-high_school_microeconomics": [],
    "ogx_mmlux_cs-high_school_physics": [],
    "ogx_mmlux_cs-high_school_psychology": [],
    "ogx_mmlux_cs-high_school_statistics": [],
    "ogx_mmlux_cs-high_school_us_history": [],
    "ogx_mmlux_cs-high_school_world_history": [],
    "ogx_mmlux_cs-human_aging": [],
    "ogx_mmlux_cs-human_sexuality": [],
    "ogx_mmlux_cs-international_law": [],
    "ogx_mmlux_cs-jurisprudence": [],
    "ogx_mmlux_cs-logical_fallacies": [],
    "ogx_mmlux_cs-machine_learning": [],
    "ogx_mmlux_cs-management": [],
    "ogx_mmlux_cs-marketing": [],
    "ogx_mmlux_cs-medical_genetics": [],
    "ogx_mmlux_cs-miscellaneous": [],
    "ogx_mmlux_cs-moral_disputes": [],
    "ogx_mmlux_cs-moral_scenarios": [],
    "ogx_mmlux_cs-nutrition": [],
    "ogx_mmlux_cs-philosophy": [],
    "ogx_mmlux_cs-prehistory": [],
    "ogx_mmlux_cs-professional_accounting": [],
    "ogx_mmlux_cs-professional_law": [],
    "ogx_mmlux_cs-professional_medicine": [],
    "ogx_mmlux_cs-professional_psychology": [],
    "ogx_mmlux_cs-public_relations": [],
    "ogx_mmlux_cs-security_studies": [],
    "ogx_mmlux_cs-sociology": [],
    "ogx_mmlux_cs-us_foreign_policy": [],
    "ogx_mmlux_cs-virology": [],
    "ogx_mmlux_cs-world_religions": [],
    "ogx_mmlux_da-abstract_algebra": [],
    "ogx_mmlux_da-anatomy": [],
    "ogx_mmlux_da-astronomy": [],
    "ogx_mmlux_da-business_ethics": [],
    "ogx_mmlux_da-clinical_knowledge": [],
    "ogx_mmlux_da-college_biology": [],
    "ogx_mmlux_da-college_chemistry": [],
    "ogx_mmlux_da-college_computer_science": [],
    "ogx_mmlux_da-college_mathematics": [],
    "ogx_mmlux_da-college_medicine": [],
    "ogx_mmlux_da-college_physics": [],
    "ogx_mmlux_da-computer_security": [],
    "ogx_mmlux_da-conceptual_physics": [],
    "ogx_mmlux_da-econometrics": [],
    "ogx_mmlux_da-electrical_engineering": [],
    "ogx_mmlux_da-elementary_mathematics": [],
    "ogx_mmlux_da-formal_logic": [],
    "ogx_mmlux_da-global_facts": [],
    "ogx_mmlux_da-high_school_biology": [],
    "ogx_mmlux_da-high_school_chemistry": [],
    "ogx_mmlux_da-high_school_computer_science": [],
    "ogx_mmlux_da-high_school_european_history": [],
    "ogx_mmlux_da-high_school_geography": [],
    "ogx_mmlux_da-high_school_government_and_politics": [],
    "ogx_mmlux_da-high_school_macroeconomics": [],
    "ogx_mmlux_da-high_school_mathematics": [],
    "ogx_mmlux_da-high_school_microeconomics": [],
    "ogx_mmlux_da-high_school_physics": [],
    "ogx_mmlux_da-high_school_psychology": [],
    "ogx_mmlux_da-high_school_statistics": [],
    "ogx_mmlux_da-high_school_us_history": [],
    "ogx_mmlux_da-high_school_world_history": [],
    "ogx_mmlux_da-human_aging": [],
    "ogx_mmlux_da-human_sexuality": [],
    "ogx_mmlux_da-international_law": [],
    "ogx_mmlux_da-jurisprudence": [],
    "ogx_mmlux_da-logical_fallacies": [],
    "ogx_mmlux_da-machine_learning": [],
    "ogx_mmlux_da-management": [],
    "ogx_mmlux_da-marketing": [],
    "ogx_mmlux_da-medical_genetics": [],
    "ogx_mmlux_da-miscellaneous": [],
    "ogx_mmlux_da-moral_disputes": [],
    "ogx_mmlux_da-moral_scenarios": [],
    "ogx_mmlux_da-nutrition": [],
    "ogx_mmlux_da-philosophy": [],
    "ogx_mmlux_da-prehistory": [],
    "ogx_mmlux_da-professional_accounting": [],
    "ogx_mmlux_da-professional_law": [],
    "ogx_mmlux_da-professional_medicine": [],
    "ogx_mmlux_da-professional_psychology": [],
    "ogx_mmlux_da-public_relations": [],
    "ogx_mmlux_da-security_studies": [],
    "ogx_mmlux_da-sociology": [],
    "ogx_mmlux_da-us_foreign_policy": [],
    "ogx_mmlux_da-virology": [],
    "ogx_mmlux_da-world_religions": [],
    "ogx_mmlux_de-abstract_algebra": [],
    "ogx_mmlux_de-anatomy": [],
    "ogx_mmlux_de-astronomy": [],
    "ogx_mmlux_de-business_ethics": [],
    "ogx_mmlux_de-clinical_knowledge": [],
    "ogx_mmlux_de-college_biology": [],
    "ogx_mmlux_de-college_chemistry": [],
    "ogx_mmlux_de-college_computer_science": [],
    "ogx_mmlux_de-college_mathematics": [],
    "ogx_mmlux_de-college_medicine": [],
    "ogx_mmlux_de-college_physics": [],
    "ogx_mmlux_de-computer_security": [],
    "ogx_mmlux_de-conceptual_physics": [],
    "ogx_mmlux_de-econometrics": [],
    "ogx_mmlux_de-electrical_engineering": [],
    "ogx_mmlux_de-elementary_mathematics": [],
    "ogx_mmlux_de-formal_logic": [],
    "ogx_mmlux_de-global_facts": [],
    "ogx_mmlux_de-high_school_biology": [],
    "ogx_mmlux_de-high_school_chemistry": [],
    "ogx_mmlux_de-high_school_computer_science": [],
    "ogx_mmlux_de-high_school_european_history": [],
    "ogx_mmlux_de-high_school_geography": [],
    "ogx_mmlux_de-high_school_government_and_politics": [],
    "ogx_mmlux_de-high_school_macroeconomics": [],
    "ogx_mmlux_de-high_school_mathematics": [],
    "ogx_mmlux_de-high_school_microeconomics": [],
    "ogx_mmlux_de-high_school_physics": [],
    "ogx_mmlux_de-high_school_psychology": [],
    "ogx_mmlux_de-high_school_statistics": [],
    "ogx_mmlux_de-high_school_us_history": [],
    "ogx_mmlux_de-high_school_world_history": [],
    "ogx_mmlux_de-human_aging": [],
    "ogx_mmlux_de-human_sexuality": [],
    "ogx_mmlux_de-international_law": [],
    "ogx_mmlux_de-jurisprudence": [],
    "ogx_mmlux_de-logical_fallacies": [],
    "ogx_mmlux_de-machine_learning": [],
    "ogx_mmlux_de-management": [],
    "ogx_mmlux_de-marketing": [],
    "ogx_mmlux_de-medical_genetics": [],
    "ogx_mmlux_de-miscellaneous": [],
    "ogx_mmlux_de-moral_disputes": [],
    "ogx_mmlux_de-moral_scenarios": [],
    "ogx_mmlux_de-nutrition": [],
    "ogx_mmlux_de-philosophy": [],
    "ogx_mmlux_de-prehistory": [],
    "ogx_mmlux_de-professional_accounting": [],
    "ogx_mmlux_de-professional_law": [],
    "ogx_mmlux_de-professional_medicine": [],
    "ogx_mmlux_de-professional_psychology": [],
    "ogx_mmlux_de-public_relations": [],
    "ogx_mmlux_de-security_studies": [],
    "ogx_mmlux_de-sociology": [],
    "ogx_mmlux_de-us_foreign_policy": [],
    "ogx_mmlux_de-virology": [],
    "ogx_mmlux_de-world_religions": [],
    "ogx_mmlux_el-abstract_algebra": [],
    "ogx_mmlux_el-anatomy": [],
    "ogx_mmlux_el-astronomy": [],
    "ogx_mmlux_el-business_ethics": [],
    "ogx_mmlux_el-clinical_knowledge": [],
    "ogx_mmlux_el-college_biology": [],
    "ogx_mmlux_el-college_chemistry": [],
    "ogx_mmlux_el-college_computer_science": [],
    "ogx_mmlux_el-college_mathematics": [],
    "ogx_mmlux_el-college_medicine": [],
    "ogx_mmlux_el-college_physics": [],
    "ogx_mmlux_el-computer_security": [],
    "ogx_mmlux_el-conceptual_physics": [],
    "ogx_mmlux_el-econometrics": [],
    "ogx_mmlux_el-electrical_engineering": [],
    "ogx_mmlux_el-elementary_mathematics": [],
    "ogx_mmlux_el-formal_logic": [],
    "ogx_mmlux_el-global_facts": [],
    "ogx_mmlux_el-high_school_biology": [],
    "ogx_mmlux_el-high_school_chemistry": [],
    "ogx_mmlux_el-high_school_computer_science": [],
    "ogx_mmlux_el-high_school_european_history": [],
    "ogx_mmlux_el-high_school_geography": [],
    "ogx_mmlux_el-high_school_government_and_politics": [],
    "ogx_mmlux_el-high_school_macroeconomics": [],
    "ogx_mmlux_el-high_school_mathematics": [],
    "ogx_mmlux_el-high_school_microeconomics": [],
    "ogx_mmlux_el-high_school_physics": [],
    "ogx_mmlux_el-high_school_psychology": [],
    "ogx_mmlux_el-high_school_statistics": [],
    "ogx_mmlux_el-high_school_us_history": [],
    "ogx_mmlux_el-high_school_world_history": [],
    "ogx_mmlux_el-human_aging": [],
    "ogx_mmlux_el-human_sexuality": [],
    "ogx_mmlux_el-international_law": [],
    "ogx_mmlux_el-jurisprudence": [],
    "ogx_mmlux_el-logical_fallacies": [],
    "ogx_mmlux_el-machine_learning": [],
    "ogx_mmlux_el-management": [],
    "ogx_mmlux_el-marketing": [],
    "ogx_mmlux_el-medical_genetics": [],
    "ogx_mmlux_el-miscellaneous": [],
    "ogx_mmlux_el-moral_disputes": [],
    "ogx_mmlux_el-moral_scenarios": [],
    "ogx_mmlux_el-nutrition": [],
    "ogx_mmlux_el-philosophy": [],
    "ogx_mmlux_el-prehistory": [],
    "ogx_mmlux_el-professional_accounting": [],
    "ogx_mmlux_el-professional_law": [],
    "ogx_mmlux_el-professional_medicine": [],
    "ogx_mmlux_el-professional_psychology": [],
    "ogx_mmlux_el-public_relations": [],
    "ogx_mmlux_el-security_studies": [],
    "ogx_mmlux_el-sociology": [],
    "ogx_mmlux_el-us_foreign_policy": [],
    "ogx_mmlux_el-virology": [],
    "ogx_mmlux_el-world_religions": [],
    "ogx_mmlux_es-abstract_algebra": [],
    "ogx_mmlux_es-anatomy": [],
    "ogx_mmlux_es-astronomy": [],
    "ogx_mmlux_es-business_ethics": [],
    "ogx_mmlux_es-clinical_knowledge": [],
    "ogx_mmlux_es-college_biology": [],
    "ogx_mmlux_es-college_chemistry": [],
    "ogx_mmlux_es-college_computer_science": [],
    "ogx_mmlux_es-college_mathematics": [],
    "ogx_mmlux_es-college_medicine": [],
    "ogx_mmlux_es-college_physics": [],
    "ogx_mmlux_es-computer_security": [],
    "ogx_mmlux_es-conceptual_physics": [],
    "ogx_mmlux_es-econometrics": [],
    "ogx_mmlux_es-electrical_engineering": [],
    "ogx_mmlux_es-elementary_mathematics": [],
    "ogx_mmlux_es-formal_logic": [],
    "ogx_mmlux_es-global_facts": [],
    "ogx_mmlux_es-high_school_biology": [],
    "ogx_mmlux_es-high_school_chemistry": [],
    "ogx_mmlux_es-high_school_computer_science": [],
    "ogx_mmlux_es-high_school_european_history": [],
    "ogx_mmlux_es-high_school_geography": [],
    "ogx_mmlux_es-high_school_government_and_politics": [],
    "ogx_mmlux_es-high_school_macroeconomics": [],
    "ogx_mmlux_es-high_school_mathematics": [],
    "ogx_mmlux_es-high_school_microeconomics": [],
    "ogx_mmlux_es-high_school_physics": [],
    "ogx_mmlux_es-high_school_psychology": [],
    "ogx_mmlux_es-high_school_statistics": [],
    "ogx_mmlux_es-high_school_us_history": [],
    "ogx_mmlux_es-high_school_world_history": [],
    "ogx_mmlux_es-human_aging": [],
    "ogx_mmlux_es-human_sexuality": [],
    "ogx_mmlux_es-international_law": [],
    "ogx_mmlux_es-jurisprudence": [],
    "ogx_mmlux_es-logical_fallacies": [],
    "ogx_mmlux_es-machine_learning": [],
    "ogx_mmlux_es-management": [],
    "ogx_mmlux_es-marketing": [],
    "ogx_mmlux_es-medical_genetics": [],
    "ogx_mmlux_es-miscellaneous": [],
    "ogx_mmlux_es-moral_disputes": [],
    "ogx_mmlux_es-moral_scenarios": [],
    "ogx_mmlux_es-nutrition": [],
    "ogx_mmlux_es-philosophy": [],
    "ogx_mmlux_es-prehistory": [],
    "ogx_mmlux_es-professional_accounting": [],
    "ogx_mmlux_es-professional_law": [],
    "ogx_mmlux_es-professional_medicine": [],
    "ogx_mmlux_es-professional_psychology": [],
    "ogx_mmlux_es-public_relations": [],
    "ogx_mmlux_es-security_studies": [],
    "ogx_mmlux_es-sociology": [],
    "ogx_mmlux_es-us_foreign_policy": [],
    "ogx_mmlux_es-virology": [],
    "ogx_mmlux_es-world_religions": [],
    "ogx_mmlux_et-abstract_algebra": [],
    "ogx_mmlux_et-anatomy": [],
    "ogx_mmlux_et-astronomy": [],
    "ogx_mmlux_et-business_ethics": [],
    "ogx_mmlux_et-clinical_knowledge": [],
    "ogx_mmlux_et-college_biology": [],
    "ogx_mmlux_et-college_chemistry": [],
    "ogx_mmlux_et-college_computer_science": [],
    "ogx_mmlux_et-college_mathematics": [],
    "ogx_mmlux_et-college_medicine": [],
    "ogx_mmlux_et-college_physics": [],
    "ogx_mmlux_et-computer_security": [],
    "ogx_mmlux_et-conceptual_physics": [],
    "ogx_mmlux_et-econometrics": [],
    "ogx_mmlux_et-electrical_engineering": [],
    "ogx_mmlux_et-elementary_mathematics": [],
    "ogx_mmlux_et-formal_logic": [],
    "ogx_mmlux_et-global_facts": [],
    "ogx_mmlux_et-high_school_biology": [],
    "ogx_mmlux_et-high_school_chemistry": [],
    "ogx_mmlux_et-high_school_computer_science": [],
    "ogx_mmlux_et-high_school_european_history": [],
    "ogx_mmlux_et-high_school_geography": [],
    "ogx_mmlux_et-high_school_government_and_politics": [],
    "ogx_mmlux_et-high_school_macroeconomics": [],
    "ogx_mmlux_et-high_school_mathematics": [],
    "ogx_mmlux_et-high_school_microeconomics": [],
    "ogx_mmlux_et-high_school_physics": [],
    "ogx_mmlux_et-high_school_psychology": [],
    "ogx_mmlux_et-high_school_statistics": [],
    "ogx_mmlux_et-high_school_us_history": [],
    "ogx_mmlux_et-high_school_world_history": [],
    "ogx_mmlux_et-human_aging": [],
    "ogx_mmlux_et-human_sexuality": [],
    "ogx_mmlux_et-international_law": [],
    "ogx_mmlux_et-jurisprudence": [],
    "ogx_mmlux_et-logical_fallacies": [],
    "ogx_mmlux_et-machine_learning": [],
    "ogx_mmlux_et-management": [],
    "ogx_mmlux_et-marketing": [],
    "ogx_mmlux_et-medical_genetics": [],
    "ogx_mmlux_et-miscellaneous": [],
    "ogx_mmlux_et-moral_disputes": [],
    "ogx_mmlux_et-moral_scenarios": [],
    "ogx_mmlux_et-nutrition": [],
    "ogx_mmlux_et-philosophy": [],
    "ogx_mmlux_et-prehistory": [],
    "ogx_mmlux_et-professional_accounting": [],
    "ogx_mmlux_et-professional_law": [],
    "ogx_mmlux_et-professional_medicine": [],
    "ogx_mmlux_et-professional_psychology": [],
    "ogx_mmlux_et-public_relations": [],
    "ogx_mmlux_et-security_studies": [],
    "ogx_mmlux_et-sociology": [],
    "ogx_mmlux_et-us_foreign_policy": [],
    "ogx_mmlux_et-virology": [],
    "ogx_mmlux_et-world_religions": [],
    "ogx_mmlux_fi-abstract_algebra": [],
    "ogx_mmlux_fi-anatomy": [],
    "ogx_mmlux_fi-astronomy": [],
    "ogx_mmlux_fi-business_ethics": [],
    "ogx_mmlux_fi-clinical_knowledge": [],
    "ogx_mmlux_fi-college_biology": [],
    "ogx_mmlux_fi-college_chemistry": [],
    "ogx_mmlux_fi-college_computer_science": [],
    "ogx_mmlux_fi-college_mathematics": [],
    "ogx_mmlux_fi-college_medicine": [],
    "ogx_mmlux_fi-college_physics": [],
    "ogx_mmlux_fi-computer_security": [],
    "ogx_mmlux_fi-conceptual_physics": [],
    "ogx_mmlux_fi-econometrics": [],
    "ogx_mmlux_fi-electrical_engineering": [],
    "ogx_mmlux_fi-elementary_mathematics": [],
    "ogx_mmlux_fi-formal_logic": [],
    "ogx_mmlux_fi-global_facts": [],
    "ogx_mmlux_fi-high_school_biology": [],
    "ogx_mmlux_fi-high_school_chemistry": [],
    "ogx_mmlux_fi-high_school_computer_science": [],
    "ogx_mmlux_fi-high_school_european_history": [],
    "ogx_mmlux_fi-high_school_geography": [],
    "ogx_mmlux_fi-high_school_government_and_politics": [],
    "ogx_mmlux_fi-high_school_macroeconomics": [],
    "ogx_mmlux_fi-high_school_mathematics": [],
    "ogx_mmlux_fi-high_school_microeconomics": [],
    "ogx_mmlux_fi-high_school_physics": [],
    "ogx_mmlux_fi-high_school_psychology": [],
    "ogx_mmlux_fi-high_school_statistics": [],
    "ogx_mmlux_fi-high_school_us_history": [],
    "ogx_mmlux_fi-high_school_world_history": [],
    "ogx_mmlux_fi-human_aging": [],
    "ogx_mmlux_fi-human_sexuality": [],
    "ogx_mmlux_fi-international_law": [],
    "ogx_mmlux_fi-jurisprudence": [],
    "ogx_mmlux_fi-logical_fallacies": [],
    "ogx_mmlux_fi-machine_learning": [],
    "ogx_mmlux_fi-management": [],
    "ogx_mmlux_fi-marketing": [],
    "ogx_mmlux_fi-medical_genetics": [],
    "ogx_mmlux_fi-miscellaneous": [],
    "ogx_mmlux_fi-moral_disputes": [],
    "ogx_mmlux_fi-moral_scenarios": [],
    "ogx_mmlux_fi-nutrition": [],
    "ogx_mmlux_fi-philosophy": [],
    "ogx_mmlux_fi-prehistory": [],
    "ogx_mmlux_fi-professional_accounting": [],
    "ogx_mmlux_fi-professional_law": [],
    "ogx_mmlux_fi-professional_medicine": [],
    "ogx_mmlux_fi-professional_psychology": [],
    "ogx_mmlux_fi-public_relations": [],
    "ogx_mmlux_fi-security_studies": [],
    "ogx_mmlux_fi-sociology": [],
    "ogx_mmlux_fi-us_foreign_policy": [],
    "ogx_mmlux_fi-virology": [],
    "ogx_mmlux_fi-world_religions": [],
    "ogx_mmlux_fr-abstract_algebra": [],
    "ogx_mmlux_fr-anatomy": [],
    "ogx_mmlux_fr-astronomy": [],
    "ogx_mmlux_fr-business_ethics": [],
    "ogx_mmlux_fr-clinical_knowledge": [],
    "ogx_mmlux_fr-college_biology": [],
    "ogx_mmlux_fr-college_chemistry": [],
    "ogx_mmlux_fr-college_computer_science": [],
    "ogx_mmlux_fr-college_mathematics": [],
    "ogx_mmlux_fr-college_medicine": [],
    "ogx_mmlux_fr-college_physics": [],
    "ogx_mmlux_fr-computer_security": [],
    "ogx_mmlux_fr-conceptual_physics": [],
    "ogx_mmlux_fr-econometrics": [],
    "ogx_mmlux_fr-electrical_engineering": [],
    "ogx_mmlux_fr-elementary_mathematics": [],
    "ogx_mmlux_fr-formal_logic": [],
    "ogx_mmlux_fr-global_facts": [],
    "ogx_mmlux_fr-high_school_biology": [],
    "ogx_mmlux_fr-high_school_chemistry": [],
    "ogx_mmlux_fr-high_school_computer_science": [],
    "ogx_mmlux_fr-high_school_european_history": [],
    "ogx_mmlux_fr-high_school_geography": [],
    "ogx_mmlux_fr-high_school_government_and_politics": [],
    "ogx_mmlux_fr-high_school_macroeconomics": [],
    "ogx_mmlux_fr-high_school_mathematics": [],
    "ogx_mmlux_fr-high_school_microeconomics": [],
    "ogx_mmlux_fr-high_school_physics": [],
    "ogx_mmlux_fr-high_school_psychology": [],
    "ogx_mmlux_fr-high_school_statistics": [],
    "ogx_mmlux_fr-high_school_us_history": [],
    "ogx_mmlux_fr-high_school_world_history": [],
    "ogx_mmlux_fr-human_aging": [],
    "ogx_mmlux_fr-human_sexuality": [],
    "ogx_mmlux_fr-international_law": [],
    "ogx_mmlux_fr-jurisprudence": [],
    "ogx_mmlux_fr-logical_fallacies": [],
    "ogx_mmlux_fr-machine_learning": [],
    "ogx_mmlux_fr-management": [],
    "ogx_mmlux_fr-marketing": [],
    "ogx_mmlux_fr-medical_genetics": [],
    "ogx_mmlux_fr-miscellaneous": [],
    "ogx_mmlux_fr-moral_disputes": [],
    "ogx_mmlux_fr-moral_scenarios": [],
    "ogx_mmlux_fr-nutrition": [],
    "ogx_mmlux_fr-philosophy": [],
    "ogx_mmlux_fr-prehistory": [],
    "ogx_mmlux_fr-professional_accounting": [],
    "ogx_mmlux_fr-professional_law": [],
    "ogx_mmlux_fr-professional_medicine": [],
    "ogx_mmlux_fr-professional_psychology": [],
    "ogx_mmlux_fr-public_relations": [],
    "ogx_mmlux_fr-security_studies": [],
    "ogx_mmlux_fr-sociology": [],
    "ogx_mmlux_fr-us_foreign_policy": [],
    "ogx_mmlux_fr-virology": [],
    "ogx_mmlux_fr-world_religions": [],
    "ogx_mmlux_hu-abstract_algebra": [],
    "ogx_mmlux_hu-anatomy": [],
    "ogx_mmlux_hu-astronomy": [],
    "ogx_mmlux_hu-business_ethics": [],
    "ogx_mmlux_hu-clinical_knowledge": [],
    "ogx_mmlux_hu-college_biology": [],
    "ogx_mmlux_hu-college_chemistry": [],
    "ogx_mmlux_hu-college_computer_science": [],
    "ogx_mmlux_hu-college_mathematics": [],
    "ogx_mmlux_hu-college_medicine": [],
    "ogx_mmlux_hu-college_physics": [],
    "ogx_mmlux_hu-computer_security": [],
    "ogx_mmlux_hu-conceptual_physics": [],
    "ogx_mmlux_hu-econometrics": [],
    "ogx_mmlux_hu-electrical_engineering": [],
    "ogx_mmlux_hu-elementary_mathematics": [],
    "ogx_mmlux_hu-formal_logic": [],
    "ogx_mmlux_hu-global_facts": [],
    "ogx_mmlux_hu-high_school_biology": [],
    "ogx_mmlux_hu-high_school_chemistry": [],
    "ogx_mmlux_hu-high_school_computer_science": [],
    "ogx_mmlux_hu-high_school_european_history": [],
    "ogx_mmlux_hu-high_school_geography": [],
    "ogx_mmlux_hu-high_school_government_and_politics": [],
    "ogx_mmlux_hu-high_school_macroeconomics": [],
    "ogx_mmlux_hu-high_school_mathematics": [],
    "ogx_mmlux_hu-high_school_microeconomics": [],
    "ogx_mmlux_hu-high_school_physics": [],
    "ogx_mmlux_hu-high_school_psychology": [],
    "ogx_mmlux_hu-high_school_statistics": [],
    "ogx_mmlux_hu-high_school_us_history": [],
    "ogx_mmlux_hu-high_school_world_history": [],
    "ogx_mmlux_hu-human_aging": [],
    "ogx_mmlux_hu-human_sexuality": [],
    "ogx_mmlux_hu-international_law": [],
    "ogx_mmlux_hu-jurisprudence": [],
    "ogx_mmlux_hu-logical_fallacies": [],
    "ogx_mmlux_hu-machine_learning": [],
    "ogx_mmlux_hu-management": [],
    "ogx_mmlux_hu-marketing": [],
    "ogx_mmlux_hu-medical_genetics": [],
    "ogx_mmlux_hu-miscellaneous": [],
    "ogx_mmlux_hu-moral_disputes": [],
    "ogx_mmlux_hu-moral_scenarios": [],
    "ogx_mmlux_hu-nutrition": [],
    "ogx_mmlux_hu-philosophy": [],
    "ogx_mmlux_hu-prehistory": [],
    "ogx_mmlux_hu-professional_accounting": [],
    "ogx_mmlux_hu-professional_law": [],
    "ogx_mmlux_hu-professional_medicine": [],
    "ogx_mmlux_hu-professional_psychology": [],
    "ogx_mmlux_hu-public_relations": [],
    "ogx_mmlux_hu-security_studies": [],
    "ogx_mmlux_hu-sociology": [],
    "ogx_mmlux_hu-us_foreign_policy": [],
    "ogx_mmlux_hu-virology": [],
    "ogx_mmlux_hu-world_religions": [],
    "ogx_mmlux_it-abstract_algebra": [],
    "ogx_mmlux_it-anatomy": [],
    "ogx_mmlux_it-astronomy": [],
    "ogx_mmlux_it-business_ethics": [],
    "ogx_mmlux_it-clinical_knowledge": [],
    "ogx_mmlux_it-college_biology": [],
    "ogx_mmlux_it-college_chemistry": [],
    "ogx_mmlux_it-college_computer_science": [],
    "ogx_mmlux_it-college_mathematics": [],
    "ogx_mmlux_it-college_medicine": [],
    "ogx_mmlux_it-college_physics": [],
    "ogx_mmlux_it-computer_security": [],
    "ogx_mmlux_it-conceptual_physics": [],
    "ogx_mmlux_it-econometrics": [],
    "ogx_mmlux_it-electrical_engineering": [],
    "ogx_mmlux_it-elementary_mathematics": [],
    "ogx_mmlux_it-formal_logic": [],
    "ogx_mmlux_it-global_facts": [],
    "ogx_mmlux_it-high_school_biology": [],
    "ogx_mmlux_it-high_school_chemistry": [],
    "ogx_mmlux_it-high_school_computer_science": [],
    "ogx_mmlux_it-high_school_european_history": [],
    "ogx_mmlux_it-high_school_geography": [],
    "ogx_mmlux_it-high_school_government_and_politics": [],
    "ogx_mmlux_it-high_school_macroeconomics": [],
    "ogx_mmlux_it-high_school_mathematics": [],
    "ogx_mmlux_it-high_school_microeconomics": [],
    "ogx_mmlux_it-high_school_physics": [],
    "ogx_mmlux_it-high_school_psychology": [],
    "ogx_mmlux_it-high_school_statistics": [],
    "ogx_mmlux_it-high_school_us_history": [],
    "ogx_mmlux_it-high_school_world_history": [],
    "ogx_mmlux_it-human_aging": [],
    "ogx_mmlux_it-human_sexuality": [],
    "ogx_mmlux_it-international_law": [],
    "ogx_mmlux_it-jurisprudence": [],
    "ogx_mmlux_it-logical_fallacies": [],
    "ogx_mmlux_it-machine_learning": [],
    "ogx_mmlux_it-management": [],
    "ogx_mmlux_it-marketing": [],
    "ogx_mmlux_it-medical_genetics": [],
    "ogx_mmlux_it-miscellaneous": [],
    "ogx_mmlux_it-moral_disputes": [],
    "ogx_mmlux_it-moral_scenarios": [],
    "ogx_mmlux_it-nutrition": [],
    "ogx_mmlux_it-philosophy": [],
    "ogx_mmlux_it-prehistory": [],
    "ogx_mmlux_it-professional_accounting": [],
    "ogx_mmlux_it-professional_law": [],
    "ogx_mmlux_it-professional_medicine": [],
    "ogx_mmlux_it-professional_psychology": [],
    "ogx_mmlux_it-public_relations": [],
    "ogx_mmlux_it-security_studies": [],
    "ogx_mmlux_it-sociology": [],
    "ogx_mmlux_it-us_foreign_policy": [],
    "ogx_mmlux_it-virology": [],
    "ogx_mmlux_it-world_religions": [],
    "ogx_mmlux_lt-abstract_algebra": [],
    "ogx_mmlux_lt-anatomy": [],
    "ogx_mmlux_lt-astronomy": [],
    "ogx_mmlux_lt-business_ethics": [],
    "ogx_mmlux_lt-clinical_knowledge": [],
    "ogx_mmlux_lt-college_biology": [],
    "ogx_mmlux_lt-college_chemistry": [],
    "ogx_mmlux_lt-college_computer_science": [],
    "ogx_mmlux_lt-college_mathematics": [],
    "ogx_mmlux_lt-college_medicine": [],
    "ogx_mmlux_lt-college_physics": [],
    "ogx_mmlux_lt-computer_security": [],
    "ogx_mmlux_lt-conceptual_physics": [],
    "ogx_mmlux_lt-econometrics": [],
    "ogx_mmlux_lt-electrical_engineering": [],
    "ogx_mmlux_lt-elementary_mathematics": [],
    "ogx_mmlux_lt-formal_logic": [],
    "ogx_mmlux_lt-global_facts": [],
    "ogx_mmlux_lt-high_school_biology": [],
    "ogx_mmlux_lt-high_school_chemistry": [],
    "ogx_mmlux_lt-high_school_computer_science": [],
    "ogx_mmlux_lt-high_school_european_history": [],
    "ogx_mmlux_lt-high_school_geography": [],
    "ogx_mmlux_lt-high_school_government_and_politics": [],
    "ogx_mmlux_lt-high_school_macroeconomics": [],
    "ogx_mmlux_lt-high_school_mathematics": [],
    "ogx_mmlux_lt-high_school_microeconomics": [],
    "ogx_mmlux_lt-high_school_physics": [],
    "ogx_mmlux_lt-high_school_psychology": [],
    "ogx_mmlux_lt-high_school_statistics": [],
    "ogx_mmlux_lt-high_school_us_history": [],
    "ogx_mmlux_lt-high_school_world_history": [],
    "ogx_mmlux_lt-human_aging": [],
    "ogx_mmlux_lt-human_sexuality": [],
    "ogx_mmlux_lt-international_law": [],
    "ogx_mmlux_lt-jurisprudence": [],
    "ogx_mmlux_lt-logical_fallacies": [],
    "ogx_mmlux_lt-machine_learning": [],
    "ogx_mmlux_lt-management": [],
    "ogx_mmlux_lt-marketing": [],
    "ogx_mmlux_lt-medical_genetics": [],
    "ogx_mmlux_lt-miscellaneous": [],
    "ogx_mmlux_lt-moral_disputes": [],
    "ogx_mmlux_lt-moral_scenarios": [],
    "ogx_mmlux_lt-nutrition": [],
    "ogx_mmlux_lt-philosophy": [],
    "ogx_mmlux_lt-prehistory": [],
    "ogx_mmlux_lt-professional_accounting": [],
    "ogx_mmlux_lt-professional_law": [],
    "ogx_mmlux_lt-professional_medicine": [],
    "ogx_mmlux_lt-professional_psychology": [],
    "ogx_mmlux_lt-public_relations": [],
    "ogx_mmlux_lt-security_studies": [],
    "ogx_mmlux_lt-sociology": [],
    "ogx_mmlux_lt-us_foreign_policy": [],
    "ogx_mmlux_lt-virology": [],
    "ogx_mmlux_lt-world_religions": [],
    "ogx_mmlux_lv-abstract_algebra": [],
    "ogx_mmlux_lv-anatomy": [],
    "ogx_mmlux_lv-astronomy": [],
    "ogx_mmlux_lv-business_ethics": [],
    "ogx_mmlux_lv-clinical_knowledge": [],
    "ogx_mmlux_lv-college_biology": [],
    "ogx_mmlux_lv-college_chemistry": [],
    "ogx_mmlux_lv-college_computer_science": [],
    "ogx_mmlux_lv-college_mathematics": [],
    "ogx_mmlux_lv-college_medicine": [],
    "ogx_mmlux_lv-college_physics": [],
    "ogx_mmlux_lv-computer_security": [],
    "ogx_mmlux_lv-conceptual_physics": [],
    "ogx_mmlux_lv-econometrics": [],
    "ogx_mmlux_lv-electrical_engineering": [],
    "ogx_mmlux_lv-elementary_mathematics": [],
    "ogx_mmlux_lv-formal_logic": [],
    "ogx_mmlux_lv-global_facts": [],
    "ogx_mmlux_lv-high_school_biology": [],
    "ogx_mmlux_lv-high_school_chemistry": [],
    "ogx_mmlux_lv-high_school_computer_science": [],
    "ogx_mmlux_lv-high_school_european_history": [],
    "ogx_mmlux_lv-high_school_geography": [],
    "ogx_mmlux_lv-high_school_government_and_politics": [],
    "ogx_mmlux_lv-high_school_macroeconomics": [],
    "ogx_mmlux_lv-high_school_mathematics": [],
    "ogx_mmlux_lv-high_school_microeconomics": [],
    "ogx_mmlux_lv-high_school_physics": [],
    "ogx_mmlux_lv-high_school_psychology": [],
    "ogx_mmlux_lv-high_school_statistics": [],
    "ogx_mmlux_lv-high_school_us_history": [],
    "ogx_mmlux_lv-high_school_world_history": [],
    "ogx_mmlux_lv-human_aging": [],
    "ogx_mmlux_lv-human_sexuality": [],
    "ogx_mmlux_lv-international_law": [],
    "ogx_mmlux_lv-jurisprudence": [],
    "ogx_mmlux_lv-logical_fallacies": [],
    "ogx_mmlux_lv-machine_learning": [],
    "ogx_mmlux_lv-management": [],
    "ogx_mmlux_lv-marketing": [],
    "ogx_mmlux_lv-medical_genetics": [],
    "ogx_mmlux_lv-miscellaneous": [],
    "ogx_mmlux_lv-moral_disputes": [],
    "ogx_mmlux_lv-moral_scenarios": [],
    "ogx_mmlux_lv-nutrition": [],
    "ogx_mmlux_lv-philosophy": [],
    "ogx_mmlux_lv-prehistory": [],
    "ogx_mmlux_lv-professional_accounting": [],
    "ogx_mmlux_lv-professional_law": [],
    "ogx_mmlux_lv-professional_medicine": [],
    "ogx_mmlux_lv-professional_psychology": [],
    "ogx_mmlux_lv-public_relations": [],
    "ogx_mmlux_lv-security_studies": [],
    "ogx_mmlux_lv-sociology": [],
    "ogx_mmlux_lv-us_foreign_policy": [],
    "ogx_mmlux_lv-virology": [],
    "ogx_mmlux_lv-world_religions": [],
    "ogx_mmlux_nl-abstract_algebra": [],
    "ogx_mmlux_nl-anatomy": [],
    "ogx_mmlux_nl-astronomy": [],
    "ogx_mmlux_nl-business_ethics": [],
    "ogx_mmlux_nl-clinical_knowledge": [],
    "ogx_mmlux_nl-college_biology": [],
    "ogx_mmlux_nl-college_chemistry": [],
    "ogx_mmlux_nl-college_computer_science": [],
    "ogx_mmlux_nl-college_mathematics": [],
    "ogx_mmlux_nl-college_medicine": [],
    "ogx_mmlux_nl-college_physics": [],
    "ogx_mmlux_nl-computer_security": [],
    "ogx_mmlux_nl-conceptual_physics": [],
    "ogx_mmlux_nl-econometrics": [],
    "ogx_mmlux_nl-electrical_engineering": [],
    "ogx_mmlux_nl-elementary_mathematics": [],
    "ogx_mmlux_nl-formal_logic": [],
    "ogx_mmlux_nl-global_facts": [],
    "ogx_mmlux_nl-high_school_biology": [],
    "ogx_mmlux_nl-high_school_chemistry": [],
    "ogx_mmlux_nl-high_school_computer_science": [],
    "ogx_mmlux_nl-high_school_european_history": [],
    "ogx_mmlux_nl-high_school_geography": [],
    "ogx_mmlux_nl-high_school_government_and_politics": [],
    "ogx_mmlux_nl-high_school_macroeconomics": [],
    "ogx_mmlux_nl-high_school_mathematics": [],
    "ogx_mmlux_nl-high_school_microeconomics": [],
    "ogx_mmlux_nl-high_school_physics": [],
    "ogx_mmlux_nl-high_school_psychology": [],
    "ogx_mmlux_nl-high_school_statistics": [],
    "ogx_mmlux_nl-high_school_us_history": [],
    "ogx_mmlux_nl-high_school_world_history": [],
    "ogx_mmlux_nl-human_aging": [],
    "ogx_mmlux_nl-human_sexuality": [],
    "ogx_mmlux_nl-international_law": [],
    "ogx_mmlux_nl-jurisprudence": [],
    "ogx_mmlux_nl-logical_fallacies": [],
    "ogx_mmlux_nl-machine_learning": [],
    "ogx_mmlux_nl-management": [],
    "ogx_mmlux_nl-marketing": [],
    "ogx_mmlux_nl-medical_genetics": [],
    "ogx_mmlux_nl-miscellaneous": [],
    "ogx_mmlux_nl-moral_disputes": [],
    "ogx_mmlux_nl-moral_scenarios": [],
    "ogx_mmlux_nl-nutrition": [],
    "ogx_mmlux_nl-philosophy": [],
    "ogx_mmlux_nl-prehistory": [],
    "ogx_mmlux_nl-professional_accounting": [],
    "ogx_mmlux_nl-professional_law": [],
    "ogx_mmlux_nl-professional_medicine": [],
    "ogx_mmlux_nl-professional_psychology": [],
    "ogx_mmlux_nl-public_relations": [],
    "ogx_mmlux_nl-security_studies": [],
    "ogx_mmlux_nl-sociology": [],
    "ogx_mmlux_nl-us_foreign_policy": [],
    "ogx_mmlux_nl-virology": [],
    "ogx_mmlux_nl-world_religions": [],
    "ogx_mmlux_pl-abstract_algebra": [],
    "ogx_mmlux_pl-anatomy": [],
    "ogx_mmlux_pl-astronomy": [],
    "ogx_mmlux_pl-business_ethics": [],
    "ogx_mmlux_pl-clinical_knowledge": [],
    "ogx_mmlux_pl-college_biology": [],
    "ogx_mmlux_pl-college_chemistry": [],
    "ogx_mmlux_pl-college_computer_science": [],
    "ogx_mmlux_pl-college_mathematics": [],
    "ogx_mmlux_pl-college_medicine": [],
    "ogx_mmlux_pl-college_physics": [],
    "ogx_mmlux_pl-computer_security": [],
    "ogx_mmlux_pl-conceptual_physics": [],
    "ogx_mmlux_pl-econometrics": [],
    "ogx_mmlux_pl-electrical_engineering": [],
    "ogx_mmlux_pl-elementary_mathematics": [],
    "ogx_mmlux_pl-formal_logic": [],
    "ogx_mmlux_pl-global_facts": [],
    "ogx_mmlux_pl-high_school_biology": [],
    "ogx_mmlux_pl-high_school_chemistry": [],
    "ogx_mmlux_pl-high_school_computer_science": [],
    "ogx_mmlux_pl-high_school_european_history": [],
    "ogx_mmlux_pl-high_school_geography": [],
    "ogx_mmlux_pl-high_school_government_and_politics": [],
    "ogx_mmlux_pl-high_school_macroeconomics": [],
    "ogx_mmlux_pl-high_school_mathematics": [],
    "ogx_mmlux_pl-high_school_microeconomics": [],
    "ogx_mmlux_pl-high_school_physics": [],
    "ogx_mmlux_pl-high_school_psychology": [],
    "ogx_mmlux_pl-high_school_statistics": [],
    "ogx_mmlux_pl-high_school_us_history": [],
    "ogx_mmlux_pl-high_school_world_history": [],
    "ogx_mmlux_pl-human_aging": [],
    "ogx_mmlux_pl-human_sexuality": [],
    "ogx_mmlux_pl-international_law": [],
    "ogx_mmlux_pl-jurisprudence": [],
    "ogx_mmlux_pl-logical_fallacies": [],
    "ogx_mmlux_pl-machine_learning": [],
    "ogx_mmlux_pl-management": [],
    "ogx_mmlux_pl-marketing": [],
    "ogx_mmlux_pl-medical_genetics": [],
    "ogx_mmlux_pl-miscellaneous": [],
    "ogx_mmlux_pl-moral_disputes": [],
    "ogx_mmlux_pl-moral_scenarios": [],
    "ogx_mmlux_pl-nutrition": [],
    "ogx_mmlux_pl-philosophy": [],
    "ogx_mmlux_pl-prehistory": [],
    "ogx_mmlux_pl-professional_accounting": [],
    "ogx_mmlux_pl-professional_law": [],
    "ogx_mmlux_pl-professional_medicine": [],
    "ogx_mmlux_pl-professional_psychology": [],
    "ogx_mmlux_pl-public_relations": [],
    "ogx_mmlux_pl-security_studies": [],
    "ogx_mmlux_pl-sociology": [],
    "ogx_mmlux_pl-us_foreign_policy": [],
    "ogx_mmlux_pl-virology": [],
    "ogx_mmlux_pl-world_religions": [],
    "ogx_mmlux_pt-pt-abstract_algebra": [],
    "ogx_mmlux_pt-pt-anatomy": [],
    "ogx_mmlux_pt-pt-astronomy": [],
    "ogx_mmlux_pt-pt-business_ethics": [],
    "ogx_mmlux_pt-pt-clinical_knowledge": [],
    "ogx_mmlux_pt-pt-college_biology": [],
    "ogx_mmlux_pt-pt-college_chemistry": [],
    "ogx_mmlux_pt-pt-college_computer_science": [],
    "ogx_mmlux_pt-pt-college_mathematics": [],
    "ogx_mmlux_pt-pt-college_medicine": [],
    "ogx_mmlux_pt-pt-college_physics": [],
    "ogx_mmlux_pt-pt-computer_security": [],
    "ogx_mmlux_pt-pt-conceptual_physics": [],
    "ogx_mmlux_pt-pt-econometrics": [],
    "ogx_mmlux_pt-pt-electrical_engineering": [],
    "ogx_mmlux_pt-pt-elementary_mathematics": [],
    "ogx_mmlux_pt-pt-formal_logic": [],
    "ogx_mmlux_pt-pt-global_facts": [],
    "ogx_mmlux_pt-pt-high_school_biology": [],
    "ogx_mmlux_pt-pt-high_school_chemistry": [],
    "ogx_mmlux_pt-pt-high_school_computer_science": [],
    "ogx_mmlux_pt-pt-high_school_european_history": [],
    "ogx_mmlux_pt-pt-high_school_geography": [],
    "ogx_mmlux_pt-pt-high_school_government_and_politics": [],
    "ogx_mmlux_pt-pt-high_school_macroeconomics": [],
    "ogx_mmlux_pt-pt-high_school_mathematics": [],
    "ogx_mmlux_pt-pt-high_school_microeconomics": [],
    "ogx_mmlux_pt-pt-high_school_physics": [],
    "ogx_mmlux_pt-pt-high_school_psychology": [],
    "ogx_mmlux_pt-pt-high_school_statistics": [],
    "ogx_mmlux_pt-pt-high_school_us_history": [],
    "ogx_mmlux_pt-pt-high_school_world_history": [],
    "ogx_mmlux_pt-pt-human_aging": [],
    "ogx_mmlux_pt-pt-human_sexuality": [],
    "ogx_mmlux_pt-pt-international_law": [],
    "ogx_mmlux_pt-pt-jurisprudence": [],
    "ogx_mmlux_pt-pt-logical_fallacies": [],
    "ogx_mmlux_pt-pt-machine_learning": [],
    "ogx_mmlux_pt-pt-management": [],
    "ogx_mmlux_pt-pt-marketing": [],
    "ogx_mmlux_pt-pt-medical_genetics": [],
    "ogx_mmlux_pt-pt-miscellaneous": [],
    "ogx_mmlux_pt-pt-moral_disputes": [],
    "ogx_mmlux_pt-pt-moral_scenarios": [],
    "ogx_mmlux_pt-pt-nutrition": [],
    "ogx_mmlux_pt-pt-philosophy": [],
    "ogx_mmlux_pt-pt-prehistory": [],
    "ogx_mmlux_pt-pt-professional_accounting": [],
    "ogx_mmlux_pt-pt-professional_law": [],
    "ogx_mmlux_pt-pt-professional_medicine": [],
    "ogx_mmlux_pt-pt-professional_psychology": [],
    "ogx_mmlux_pt-pt-public_relations": [],
    "ogx_mmlux_pt-pt-security_studies": [],
    "ogx_mmlux_pt-pt-sociology": [],
    "ogx_mmlux_pt-pt-us_foreign_policy": [],
    "ogx_mmlux_pt-pt-virology": [],
    "ogx_mmlux_pt-pt-world_religions": [],
    "ogx_mmlux_ro-abstract_algebra": [],
    "ogx_mmlux_ro-anatomy": [],
    "ogx_mmlux_ro-astronomy": [],
    "ogx_mmlux_ro-business_ethics": [],
    "ogx_mmlux_ro-clinical_knowledge": [],
    "ogx_mmlux_ro-college_biology": [],
    "ogx_mmlux_ro-college_chemistry": [],
    "ogx_mmlux_ro-college_computer_science": [],
    "ogx_mmlux_ro-college_mathematics": [],
    "ogx_mmlux_ro-college_medicine": [],
    "ogx_mmlux_ro-college_physics": [],
    "ogx_mmlux_ro-computer_security": [],
    "ogx_mmlux_ro-conceptual_physics": [],
    "ogx_mmlux_ro-econometrics": [],
    "ogx_mmlux_ro-electrical_engineering": [],
    "ogx_mmlux_ro-elementary_mathematics": [],
    "ogx_mmlux_ro-formal_logic": [],
    "ogx_mmlux_ro-global_facts": [],
    "ogx_mmlux_ro-high_school_biology": [],
    "ogx_mmlux_ro-high_school_chemistry": [],
    "ogx_mmlux_ro-high_school_computer_science": [],
    "ogx_mmlux_ro-high_school_european_history": [],
    "ogx_mmlux_ro-high_school_geography": [],
    "ogx_mmlux_ro-high_school_government_and_politics": [],
    "ogx_mmlux_ro-high_school_macroeconomics": [],
    "ogx_mmlux_ro-high_school_mathematics": [],
    "ogx_mmlux_ro-high_school_microeconomics": [],
    "ogx_mmlux_ro-high_school_physics": [],
    "ogx_mmlux_ro-high_school_psychology": [],
    "ogx_mmlux_ro-high_school_statistics": [],
    "ogx_mmlux_ro-high_school_us_history": [],
    "ogx_mmlux_ro-high_school_world_history": [],
    "ogx_mmlux_ro-human_aging": [],
    "ogx_mmlux_ro-human_sexuality": [],
    "ogx_mmlux_ro-international_law": [],
    "ogx_mmlux_ro-jurisprudence": [],
    "ogx_mmlux_ro-logical_fallacies": [],
    "ogx_mmlux_ro-machine_learning": [],
    "ogx_mmlux_ro-management": [],
    "ogx_mmlux_ro-marketing": [],
    "ogx_mmlux_ro-medical_genetics": [],
    "ogx_mmlux_ro-miscellaneous": [],
    "ogx_mmlux_ro-moral_disputes": [],
    "ogx_mmlux_ro-moral_scenarios": [],
    "ogx_mmlux_ro-nutrition": [],
    "ogx_mmlux_ro-philosophy": [],
    "ogx_mmlux_ro-prehistory": [],
    "ogx_mmlux_ro-professional_accounting": [],
    "ogx_mmlux_ro-professional_law": [],
    "ogx_mmlux_ro-professional_medicine": [],
    "ogx_mmlux_ro-professional_psychology": [],
    "ogx_mmlux_ro-public_relations": [],
    "ogx_mmlux_ro-security_studies": [],
    "ogx_mmlux_ro-sociology": [],
    "ogx_mmlux_ro-us_foreign_policy": [],
    "ogx_mmlux_ro-virology": [],
    "ogx_mmlux_ro-world_religions": [],
    "ogx_mmlux_sk-abstract_algebra": [],
    "ogx_mmlux_sk-anatomy": [],
    "ogx_mmlux_sk-astronomy": [],
    "ogx_mmlux_sk-business_ethics": [],
    "ogx_mmlux_sk-clinical_knowledge": [],
    "ogx_mmlux_sk-college_biology": [],
    "ogx_mmlux_sk-college_chemistry": [],
    "ogx_mmlux_sk-college_computer_science": [],
    "ogx_mmlux_sk-college_mathematics": [],
    "ogx_mmlux_sk-college_medicine": [],
    "ogx_mmlux_sk-college_physics": [],
    "ogx_mmlux_sk-computer_security": [],
    "ogx_mmlux_sk-conceptual_physics": [],
    "ogx_mmlux_sk-econometrics": [],
    "ogx_mmlux_sk-electrical_engineering": [],
    "ogx_mmlux_sk-elementary_mathematics": [],
    "ogx_mmlux_sk-formal_logic": [],
    "ogx_mmlux_sk-global_facts": [],
    "ogx_mmlux_sk-high_school_biology": [],
    "ogx_mmlux_sk-high_school_chemistry": [],
    "ogx_mmlux_sk-high_school_computer_science": [],
    "ogx_mmlux_sk-high_school_european_history": [],
    "ogx_mmlux_sk-high_school_geography": [],
    "ogx_mmlux_sk-high_school_government_and_politics": [],
    "ogx_mmlux_sk-high_school_macroeconomics": [],
    "ogx_mmlux_sk-high_school_mathematics": [],
    "ogx_mmlux_sk-high_school_microeconomics": [],
    "ogx_mmlux_sk-high_school_physics": [],
    "ogx_mmlux_sk-high_school_psychology": [],
    "ogx_mmlux_sk-high_school_statistics": [],
    "ogx_mmlux_sk-high_school_us_history": [],
    "ogx_mmlux_sk-high_school_world_history": [],
    "ogx_mmlux_sk-human_aging": [],
    "ogx_mmlux_sk-human_sexuality": [],
    "ogx_mmlux_sk-international_law": [],
    "ogx_mmlux_sk-jurisprudence": [],
    "ogx_mmlux_sk-logical_fallacies": [],
    "ogx_mmlux_sk-machine_learning": [],
    "ogx_mmlux_sk-management": [],
    "ogx_mmlux_sk-marketing": [],
    "ogx_mmlux_sk-medical_genetics": [],
    "ogx_mmlux_sk-miscellaneous": [],
    "ogx_mmlux_sk-moral_disputes": [],
    "ogx_mmlux_sk-moral_scenarios": [],
    "ogx_mmlux_sk-nutrition": [],
    "ogx_mmlux_sk-philosophy": [],
    "ogx_mmlux_sk-prehistory": [],
    "ogx_mmlux_sk-professional_accounting": [],
    "ogx_mmlux_sk-professional_law": [],
    "ogx_mmlux_sk-professional_medicine": [],
    "ogx_mmlux_sk-professional_psychology": [],
    "ogx_mmlux_sk-public_relations": [],
    "ogx_mmlux_sk-security_studies": [],
    "ogx_mmlux_sk-sociology": [],
    "ogx_mmlux_sk-us_foreign_policy": [],
    "ogx_mmlux_sk-virology": [],
    "ogx_mmlux_sk-world_religions": [],
    "ogx_mmlux_sl-abstract_algebra": [],
    "ogx_mmlux_sl-anatomy": [],
    "ogx_mmlux_sl-astronomy": [],
    "ogx_mmlux_sl-business_ethics": [],
    "ogx_mmlux_sl-clinical_knowledge": [],
    "ogx_mmlux_sl-college_biology": [],
    "ogx_mmlux_sl-college_chemistry": [],
    "ogx_mmlux_sl-college_computer_science": [],
    "ogx_mmlux_sl-college_mathematics": [],
    "ogx_mmlux_sl-college_medicine": [],
    "ogx_mmlux_sl-college_physics": [],
    "ogx_mmlux_sl-computer_security": [],
    "ogx_mmlux_sl-conceptual_physics": [],
    "ogx_mmlux_sl-econometrics": [],
    "ogx_mmlux_sl-electrical_engineering": [],
    "ogx_mmlux_sl-elementary_mathematics": [],
    "ogx_mmlux_sl-formal_logic": [],
    "ogx_mmlux_sl-global_facts": [],
    "ogx_mmlux_sl-high_school_biology": [],
    "ogx_mmlux_sl-high_school_chemistry": [],
    "ogx_mmlux_sl-high_school_computer_science": [],
    "ogx_mmlux_sl-high_school_european_history": [],
    "ogx_mmlux_sl-high_school_geography": [],
    "ogx_mmlux_sl-high_school_government_and_politics": [],
    "ogx_mmlux_sl-high_school_macroeconomics": [],
    "ogx_mmlux_sl-high_school_mathematics": [],
    "ogx_mmlux_sl-high_school_microeconomics": [],
    "ogx_mmlux_sl-high_school_physics": [],
    "ogx_mmlux_sl-high_school_psychology": [],
    "ogx_mmlux_sl-high_school_statistics": [],
    "ogx_mmlux_sl-high_school_us_history": [],
    "ogx_mmlux_sl-high_school_world_history": [],
    "ogx_mmlux_sl-human_aging": [],
    "ogx_mmlux_sl-human_sexuality": [],
    "ogx_mmlux_sl-international_law": [],
    "ogx_mmlux_sl-jurisprudence": [],
    "ogx_mmlux_sl-logical_fallacies": [],
    "ogx_mmlux_sl-machine_learning": [],
    "ogx_mmlux_sl-management": [],
    "ogx_mmlux_sl-marketing": [],
    "ogx_mmlux_sl-medical_genetics": [],
    "ogx_mmlux_sl-miscellaneous": [],
    "ogx_mmlux_sl-moral_disputes": [],
    "ogx_mmlux_sl-moral_scenarios": [],
    "ogx_mmlux_sl-nutrition": [],
    "ogx_mmlux_sl-philosophy": [],
    "ogx_mmlux_sl-prehistory": [],
    "ogx_mmlux_sl-professional_accounting": [],
    "ogx_mmlux_sl-professional_law": [],
    "ogx_mmlux_sl-professional_medicine": [],
    "ogx_mmlux_sl-professional_psychology": [],
    "ogx_mmlux_sl-public_relations": [],
    "ogx_mmlux_sl-security_studies": [],
    "ogx_mmlux_sl-sociology": [],
    "ogx_mmlux_sl-us_foreign_policy": [],
    "ogx_mmlux_sl-virology": [],
    "ogx_mmlux_sl-world_religions": [],
    "ogx_mmlux_sv-abstract_algebra": [],
    "ogx_mmlux_sv-anatomy": [],
    "ogx_mmlux_sv-astronomy": [],
    "ogx_mmlux_sv-business_ethics": [],
    "ogx_mmlux_sv-clinical_knowledge": [],
    "ogx_mmlux_sv-college_biology": [],
    "ogx_mmlux_sv-college_chemistry": [],
    "ogx_mmlux_sv-college_computer_science": [],
    "ogx_mmlux_sv-college_mathematics": [],
    "ogx_mmlux_sv-college_medicine": [],
    "ogx_mmlux_sv-college_physics": [],
    "ogx_mmlux_sv-computer_security": [],
    "ogx_mmlux_sv-conceptual_physics": [],
    "ogx_mmlux_sv-econometrics": [],
    "ogx_mmlux_sv-electrical_engineering": [],
    "ogx_mmlux_sv-elementary_mathematics": [],
    "ogx_mmlux_sv-formal_logic": [],
    "ogx_mmlux_sv-global_facts": [],
    "ogx_mmlux_sv-high_school_biology": [],
    "ogx_mmlux_sv-high_school_chemistry": [],
    "ogx_mmlux_sv-high_school_computer_science": [],
    "ogx_mmlux_sv-high_school_european_history": [],
    "ogx_mmlux_sv-high_school_geography": [],
    "ogx_mmlux_sv-high_school_government_and_politics": [],
    "ogx_mmlux_sv-high_school_macroeconomics": [],
    "ogx_mmlux_sv-high_school_mathematics": [],
    "ogx_mmlux_sv-high_school_microeconomics": [],
    "ogx_mmlux_sv-high_school_physics": [],
    "ogx_mmlux_sv-high_school_psychology": [],
    "ogx_mmlux_sv-high_school_statistics": [],
    "ogx_mmlux_sv-high_school_us_history": [],
    "ogx_mmlux_sv-high_school_world_history": [],
    "ogx_mmlux_sv-human_aging": [],
    "ogx_mmlux_sv-human_sexuality": [],
    "ogx_mmlux_sv-international_law": [],
    "ogx_mmlux_sv-jurisprudence": [],
    "ogx_mmlux_sv-logical_fallacies": [],
    "ogx_mmlux_sv-machine_learning": [],
    "ogx_mmlux_sv-management": [],
    "ogx_mmlux_sv-marketing": [],
    "ogx_mmlux_sv-medical_genetics": [],
    "ogx_mmlux_sv-miscellaneous": [],
    "ogx_mmlux_sv-moral_disputes": [],
    "ogx_mmlux_sv-moral_scenarios": [],
    "ogx_mmlux_sv-nutrition": [],
    "ogx_mmlux_sv-philosophy": [],
    "ogx_mmlux_sv-prehistory": [],
    "ogx_mmlux_sv-professional_accounting": [],
    "ogx_mmlux_sv-professional_law": [],
    "ogx_mmlux_sv-professional_medicine": [],
    "ogx_mmlux_sv-professional_psychology": [],
    "ogx_mmlux_sv-public_relations": [],
    "ogx_mmlux_sv-security_studies": [],
    "ogx_mmlux_sv-sociology": [],
    "ogx_mmlux_sv-us_foreign_policy": [],
    "ogx_mmlux_sv-virology": [],
    "ogx_mmlux_sv-world_religions": []
  },
  "configs": {
    "ogx_mmlux_bg-abstract_algebra": {
      "task": "ogx_mmlux_bg-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-anatomy": {
      "task": "ogx_mmlux_bg-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-astronomy": {
      "task": "ogx_mmlux_bg-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-business_ethics": {
      "task": "ogx_mmlux_bg-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "task": "ogx_mmlux_bg-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_biology": {
      "task": "ogx_mmlux_bg-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_chemistry": {
      "task": "ogx_mmlux_bg-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_computer_science": {
      "task": "ogx_mmlux_bg-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_mathematics": {
      "task": "ogx_mmlux_bg-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_medicine": {
      "task": "ogx_mmlux_bg-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_physics": {
      "task": "ogx_mmlux_bg-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-computer_security": {
      "task": "ogx_mmlux_bg-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "task": "ogx_mmlux_bg-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-econometrics": {
      "task": "ogx_mmlux_bg-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "task": "ogx_mmlux_bg-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "task": "ogx_mmlux_bg-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-formal_logic": {
      "task": "ogx_mmlux_bg-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-global_facts": {
      "task": "ogx_mmlux_bg-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_biology": {
      "task": "ogx_mmlux_bg-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "task": "ogx_mmlux_bg-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "task": "ogx_mmlux_bg-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "task": "ogx_mmlux_bg-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_geography": {
      "task": "ogx_mmlux_bg-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "task": "ogx_mmlux_bg-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "task": "ogx_mmlux_bg-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "task": "ogx_mmlux_bg-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "task": "ogx_mmlux_bg-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_physics": {
      "task": "ogx_mmlux_bg-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "task": "ogx_mmlux_bg-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "task": "ogx_mmlux_bg-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "task": "ogx_mmlux_bg-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "task": "ogx_mmlux_bg-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-human_aging": {
      "task": "ogx_mmlux_bg-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-human_sexuality": {
      "task": "ogx_mmlux_bg-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-international_law": {
      "task": "ogx_mmlux_bg-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-jurisprudence": {
      "task": "ogx_mmlux_bg-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "task": "ogx_mmlux_bg-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-machine_learning": {
      "task": "ogx_mmlux_bg-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-management": {
      "task": "ogx_mmlux_bg-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-marketing": {
      "task": "ogx_mmlux_bg-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-medical_genetics": {
      "task": "ogx_mmlux_bg-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-miscellaneous": {
      "task": "ogx_mmlux_bg-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "      ( )  miscellaneous.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-moral_disputes": {
      "task": "ogx_mmlux_bg-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "task": "ogx_mmlux_bg-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-nutrition": {
      "task": "ogx_mmlux_bg-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "        .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-philosophy": {
      "task": "ogx_mmlux_bg-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "        .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-prehistory": {
      "task": "ogx_mmlux_bg-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_accounting": {
      "task": "ogx_mmlux_bg-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_law": {
      "task": "ogx_mmlux_bg-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "      ,    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_medicine": {
      "task": "ogx_mmlux_bg-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_psychology": {
      "task": "ogx_mmlux_bg-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-public_relations": {
      "task": "ogx_mmlux_bg-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "          .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-security_studies": {
      "task": "ogx_mmlux_bg-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-sociology": {
      "task": "ogx_mmlux_bg-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )  .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "task": "ogx_mmlux_bg-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "      ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-virology": {
      "task": "ogx_mmlux_bg-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-world_religions": {
      "task": "ogx_mmlux_bg-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "     ( )   .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "task": "ogx_mmlux_cs-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o abstraktn algebe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-anatomy": {
      "task": "ogx_mmlux_cs-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o anatomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-astronomy": {
      "task": "ogx_mmlux_cs-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o astronomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-business_ethics": {
      "task": "ogx_mmlux_cs-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o etice podnikn.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "task": "ogx_mmlux_cs-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o klinickch znalostech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_biology": {
      "task": "ogx_mmlux_cs-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o vysokokolsk biologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_chemistry": {
      "task": "ogx_mmlux_cs-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o vysokokolsk chemii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_computer_science": {
      "task": "ogx_mmlux_cs-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o vysokokolsk informatice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_mathematics": {
      "task": "ogx_mmlux_cs-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o vysokokolsk matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_medicine": {
      "task": "ogx_mmlux_cs-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o vysokokolsk medicn.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_physics": {
      "task": "ogx_mmlux_cs-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd z vysokokolsk fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-computer_security": {
      "task": "ogx_mmlux_cs-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o potaov bezpenosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "task": "ogx_mmlux_cs-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd z konceptuln fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-econometrics": {
      "task": "ogx_mmlux_cs-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "task": "ogx_mmlux_cs-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o elektrotechnice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "task": "ogx_mmlux_cs-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o elementrn matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-formal_logic": {
      "task": "ogx_mmlux_cs-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o formln logice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-global_facts": {
      "task": "ogx_mmlux_cs-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o globlnch faktech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_biology": {
      "task": "ogx_mmlux_cs-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk biologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "task": "ogx_mmlux_cs-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk chemii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "task": "ogx_mmlux_cs-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk informatice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "task": "ogx_mmlux_cs-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd z djin Evropy pro stedn koly.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_geography": {
      "task": "ogx_mmlux_cs-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolskm zempisu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "task": "ogx_mmlux_cs-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk vld a politice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "task": "ogx_mmlux_cs-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd z makroekonomie pro stedn koly.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "task": "ogx_mmlux_cs-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "task": "ogx_mmlux_cs-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd z mikroekonomie pro stedn koly.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_physics": {
      "task": "ogx_mmlux_cs-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd ze stedokolsk fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "task": "ogx_mmlux_cs-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk psychologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "task": "ogx_mmlux_cs-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o stedokolsk statistice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "task": "ogx_mmlux_cs-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsledujc otzky s vbrem odpovd se tkaj stedokolsk historie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "task": "ogx_mmlux_cs-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd ze svtovch djin pro stedn koly.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-human_aging": {
      "task": "ogx_mmlux_cs-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o strnut lovka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-human_sexuality": {
      "task": "ogx_mmlux_cs-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o lidsk sexualit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-international_law": {
      "task": "ogx_mmlux_cs-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o mezinrodnm prvu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-jurisprudence": {
      "task": "ogx_mmlux_cs-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o prvu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "task": "ogx_mmlux_cs-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o logickch klamech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-machine_learning": {
      "task": "ogx_mmlux_cs-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o strojovm uen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-management": {
      "task": "ogx_mmlux_cs-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsledujc otzky (s odpovmi) se tkaj managementu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-marketing": {
      "task": "ogx_mmlux_cs-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsledujc otzky (s odpovmi) se tkaj marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-medical_genetics": {
      "task": "ogx_mmlux_cs-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o lkask genetice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-miscellaneous": {
      "task": "ogx_mmlux_cs-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsledujc otzky s vbrem odpovdi se tkaj tmatu miscellaneous.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-moral_disputes": {
      "task": "ogx_mmlux_cs-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsledujc otzky s vbrem odpovd se tkaj morlnch spor.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "task": "ogx_mmlux_cs-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o morlnch scnch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-nutrition": {
      "task": "ogx_mmlux_cs-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o viv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-philosophy": {
      "task": "ogx_mmlux_cs-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-prehistory": {
      "task": "ogx_mmlux_cs-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o pravku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_accounting": {
      "task": "ogx_mmlux_cs-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o odbornm etnictv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_law": {
      "task": "ogx_mmlux_cs-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o profesnm prvu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_medicine": {
      "task": "ogx_mmlux_cs-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o profesionln medicn.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_psychology": {
      "task": "ogx_mmlux_cs-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o odborn psychologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-public_relations": {
      "task": "ogx_mmlux_cs-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o vztazch s veejnost.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-security_studies": {
      "task": "ogx_mmlux_cs-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o bezpenostnch studich.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-sociology": {
      "task": "ogx_mmlux_cs-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o sociologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "task": "ogx_mmlux_cs-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsledujc otzky s vbrem odpovd se tkaj zahranin politiky USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-virology": {
      "task": "ogx_mmlux_cs-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o virologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-world_religions": {
      "task": "ogx_mmlux_cs-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpov:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nsleduj otzky s vbrem odpovd o svtovch nboenstvch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-abstract_algebra": {
      "task": "ogx_mmlux_da-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om abstrakt algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-anatomy": {
      "task": "ogx_mmlux_da-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om anatomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-astronomy": {
      "task": "ogx_mmlux_da-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om astronomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-business_ethics": {
      "task": "ogx_mmlux_da-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om forretningsetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "task": "ogx_mmlux_da-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om klinisk viden.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_biology": {
      "task": "ogx_mmlux_da-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om universitetsbiologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_chemistry": {
      "task": "ogx_mmlux_da-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om kemi p college.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_computer_science": {
      "task": "ogx_mmlux_da-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om computervidenskab p college.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_mathematics": {
      "task": "ogx_mmlux_da-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om universitetsmatematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_medicine": {
      "task": "ogx_mmlux_da-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om universitetsmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_physics": {
      "task": "ogx_mmlux_da-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om universitetsfysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-computer_security": {
      "task": "ogx_mmlux_da-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om computersikkerhed.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-conceptual_physics": {
      "task": "ogx_mmlux_da-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om konceptuel fysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-econometrics": {
      "task": "ogx_mmlux_da-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om konometri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-electrical_engineering": {
      "task": "ogx_mmlux_da-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om elektroteknik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "task": "ogx_mmlux_da-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om elementr matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-formal_logic": {
      "task": "ogx_mmlux_da-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om formel logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-global_facts": {
      "task": "ogx_mmlux_da-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om globale fakta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_biology": {
      "task": "ogx_mmlux_da-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om biologi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "task": "ogx_mmlux_da-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om kemi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "task": "ogx_mmlux_da-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om computervidenskab i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_european_history": {
      "task": "ogx_mmlux_da-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om europisk historie i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_geography": {
      "task": "ogx_mmlux_da-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om geografi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "task": "ogx_mmlux_da-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om regering og politik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "task": "ogx_mmlux_da-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om makrokonomi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "task": "ogx_mmlux_da-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om matematik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "task": "ogx_mmlux_da-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det flgende er multiple choice-sprgsml (med svar) om mikrokonomi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_physics": {
      "task": "ogx_mmlux_da-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om fysik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_psychology": {
      "task": "ogx_mmlux_da-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om psykologi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_statistics": {
      "task": "ogx_mmlux_da-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om statistik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_us_history": {
      "task": "ogx_mmlux_da-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om amerikansk historie i high school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_world_history": {
      "task": "ogx_mmlux_da-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om verdenshistorie i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-human_aging": {
      "task": "ogx_mmlux_da-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om menneskets aldring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-human_sexuality": {
      "task": "ogx_mmlux_da-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om menneskelig seksualitet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-international_law": {
      "task": "ogx_mmlux_da-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om international lov.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-jurisprudence": {
      "task": "ogx_mmlux_da-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om retsvidenskab.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-logical_fallacies": {
      "task": "ogx_mmlux_da-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om logiske fejlslutninger.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-machine_learning": {
      "task": "ogx_mmlux_da-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om maskinlring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-management": {
      "task": "ogx_mmlux_da-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om ledelse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-marketing": {
      "task": "ogx_mmlux_da-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-medical_genetics": {
      "task": "ogx_mmlux_da-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om medicinsk genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-miscellaneous": {
      "task": "ogx_mmlux_da-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-moral_disputes": {
      "task": "ogx_mmlux_da-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om moralske tvister.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-moral_scenarios": {
      "task": "ogx_mmlux_da-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om moralske scenarier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-nutrition": {
      "task": "ogx_mmlux_da-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om ernring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-philosophy": {
      "task": "ogx_mmlux_da-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om filosofi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-prehistory": {
      "task": "ogx_mmlux_da-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det flgende er multiple choice-sprgsml (med svar) om forhistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_accounting": {
      "task": "ogx_mmlux_da-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om professionelt regnskab.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_law": {
      "task": "ogx_mmlux_da-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om erhvervsret.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_medicine": {
      "task": "ogx_mmlux_da-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om professionel medicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_psychology": {
      "task": "ogx_mmlux_da-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om professionel psykologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-public_relations": {
      "task": "ogx_mmlux_da-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-security_studies": {
      "task": "ogx_mmlux_da-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om sikkerhedsstudier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-sociology": {
      "task": "ogx_mmlux_da-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om sociologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "task": "ogx_mmlux_da-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om amerikansk udenrigspolitik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-virology": {
      "task": "ogx_mmlux_da-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Flgende er multiple choice-sprgsml (med svar) om virologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-world_religions": {
      "task": "ogx_mmlux_da-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det flgende er multiple choice-sprgsml (med svar) om verdensreligioner.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-abstract_algebra": {
      "task": "ogx_mmlux_de-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur abstrakten Algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-anatomy": {
      "task": "ogx_mmlux_de-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-astronomy": {
      "task": "ogx_mmlux_de-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-business_ethics": {
      "task": "ogx_mmlux_de-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Unternehmensethik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "task": "ogx_mmlux_de-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu klinischen Kenntnissen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_biology": {
      "task": "ogx_mmlux_de-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Biologie an der Universitt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_chemistry": {
      "task": "ogx_mmlux_de-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Chemie an Hochschulen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_computer_science": {
      "task": "ogx_mmlux_de-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulinformatik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_mathematics": {
      "task": "ogx_mmlux_de-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulmathematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_medicine": {
      "task": "ogx_mmlux_de-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Hochschulmedizin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_physics": {
      "task": "ogx_mmlux_de-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulphysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-computer_security": {
      "task": "ogx_mmlux_de-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Computersicherheit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-conceptual_physics": {
      "task": "ogx_mmlux_de-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur konzeptionellen Physik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-econometrics": {
      "task": "ogx_mmlux_de-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur konometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-electrical_engineering": {
      "task": "ogx_mmlux_de-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Elektrotechnik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "task": "ogx_mmlux_de-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur elementaren Mathematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-formal_logic": {
      "task": "ogx_mmlux_de-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur formalen Logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-global_facts": {
      "task": "ogx_mmlux_de-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu globalen Fakten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_biology": {
      "task": "ogx_mmlux_de-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Biologie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "task": "ogx_mmlux_de-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Chemie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "task": "ogx_mmlux_de-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Informatik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_european_history": {
      "task": "ogx_mmlux_de-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur europischen Geschichte in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_geography": {
      "task": "ogx_mmlux_de-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Geografie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "task": "ogx_mmlux_de-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Regierung und Politik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "task": "ogx_mmlux_de-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Makrokonomie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "task": "ogx_mmlux_de-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Mathematik in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "task": "ogx_mmlux_de-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Mikrokonomie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_physics": {
      "task": "ogx_mmlux_de-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Physik in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_psychology": {
      "task": "ogx_mmlux_de-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Schulpsychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_statistics": {
      "task": "ogx_mmlux_de-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Statistik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_us_history": {
      "task": "ogx_mmlux_de-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Geschichte der USA in der High School.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_world_history": {
      "task": "ogx_mmlux_de-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Weltgeschichte in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-human_aging": {
      "task": "ogx_mmlux_de-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum menschlichen Altern.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-human_sexuality": {
      "task": "ogx_mmlux_de-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur menschlichen Sexualitt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-international_law": {
      "task": "ogx_mmlux_de-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum internationalen Recht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-jurisprudence": {
      "task": "ogx_mmlux_de-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Rechtswissenschaft.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-logical_fallacies": {
      "task": "ogx_mmlux_de-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu logischen Fehlschlssen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-machine_learning": {
      "task": "ogx_mmlux_de-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum maschinellen Lernen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-management": {
      "task": "ogx_mmlux_de-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-marketing": {
      "task": "ogx_mmlux_de-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-medical_genetics": {
      "task": "ogx_mmlux_de-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur medizinischen Genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-miscellaneous": {
      "task": "ogx_mmlux_de-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Verschiedenes.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-moral_disputes": {
      "task": "ogx_mmlux_de-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu moralischen Streitigkeiten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-moral_scenarios": {
      "task": "ogx_mmlux_de-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu moralischen Szenarien.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-nutrition": {
      "task": "ogx_mmlux_de-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Ernhrung.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-philosophy": {
      "task": "ogx_mmlux_de-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Philosophie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-prehistory": {
      "task": "ogx_mmlux_de-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Vorgeschichte.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_accounting": {
      "task": "ogx_mmlux_de-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema professionelle Buchhaltung.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_law": {
      "task": "ogx_mmlux_de-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Berufsrecht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_medicine": {
      "task": "ogx_mmlux_de-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Berufsmedizin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_psychology": {
      "task": "ogx_mmlux_de-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Berufspsychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-public_relations": {
      "task": "ogx_mmlux_de-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema ffentlichkeitsarbeit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-security_studies": {
      "task": "ogx_mmlux_de-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Es folgen Multiple-Choice-Fragen (mit Antworten) zu Sicherheitsstudien.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-sociology": {
      "task": "ogx_mmlux_de-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Soziologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "task": "ogx_mmlux_de-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Auenpolitik der USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-virology": {
      "task": "ogx_mmlux_de-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-world_religions": {
      "task": "ogx_mmlux_de-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu den Weltreligionen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-abstract_algebra": {
      "task": "ogx_mmlux_el-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-anatomy": {
      "task": "ogx_mmlux_el-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-astronomy": {
      "task": "ogx_mmlux_el-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-business_ethics": {
      "task": "ogx_mmlux_el-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "task": "ogx_mmlux_el-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_biology": {
      "task": "ogx_mmlux_el-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_chemistry": {
      "task": "ogx_mmlux_el-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_computer_science": {
      "task": "ogx_mmlux_el-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )        .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_mathematics": {
      "task": "ogx_mmlux_el-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_medicine": {
      "task": "ogx_mmlux_el-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_physics": {
      "task": "ogx_mmlux_el-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-computer_security": {
      "task": "ogx_mmlux_el-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-conceptual_physics": {
      "task": "ogx_mmlux_el-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-econometrics": {
      "task": "ogx_mmlux_el-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-electrical_engineering": {
      "task": "ogx_mmlux_el-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "task": "ogx_mmlux_el-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-formal_logic": {
      "task": "ogx_mmlux_el-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-global_facts": {
      "task": "ogx_mmlux_el-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_biology": {
      "task": "ogx_mmlux_el-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "task": "ogx_mmlux_el-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "task": "ogx_mmlux_el-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )        .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_european_history": {
      "task": "ogx_mmlux_el-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_geography": {
      "task": "ogx_mmlux_el-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "task": "ogx_mmlux_el-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )         .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "task": "ogx_mmlux_el-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "task": "ogx_mmlux_el-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "task": "ogx_mmlux_el-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_physics": {
      "task": "ogx_mmlux_el-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_psychology": {
      "task": "ogx_mmlux_el-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_statistics": {
      "task": "ogx_mmlux_el-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_us_history": {
      "task": "ogx_mmlux_el-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_world_history": {
      "task": "ogx_mmlux_el-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-human_aging": {
      "task": "ogx_mmlux_el-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )      .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-human_sexuality": {
      "task": "ogx_mmlux_el-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-international_law": {
      "task": "ogx_mmlux_el-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-jurisprudence": {
      "task": "ogx_mmlux_el-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-logical_fallacies": {
      "task": "ogx_mmlux_el-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-machine_learning": {
      "task": "ogx_mmlux_el-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-management": {
      "task": "ogx_mmlux_el-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-marketing": {
      "task": "ogx_mmlux_el-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-medical_genetics": {
      "task": "ogx_mmlux_el-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-miscellaneous": {
      "task": "ogx_mmlux_el-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-moral_disputes": {
      "task": "ogx_mmlux_el-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-moral_scenarios": {
      "task": "ogx_mmlux_el-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-nutrition": {
      "task": "ogx_mmlux_el-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-philosophy": {
      "task": "ogx_mmlux_el-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-prehistory": {
      "task": "ogx_mmlux_el-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_accounting": {
      "task": "ogx_mmlux_el-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_law": {
      "task": "ogx_mmlux_el-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_medicine": {
      "task": "ogx_mmlux_el-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_psychology": {
      "task": "ogx_mmlux_el-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-public_relations": {
      "task": "ogx_mmlux_el-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-security_studies": {
      "task": "ogx_mmlux_el-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-sociology": {
      "task": "ogx_mmlux_el-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "task": "ogx_mmlux_el-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )       .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-virology": {
      "task": "ogx_mmlux_el-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )    .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-world_religions": {
      "task": "ogx_mmlux_el-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\n. {{choices[0]}}\n. {{choices[1]}}\n. {{choices[2]}}\n. {{choices[3]}}\n:",
      "doc_to_target": "answer",
      "doc_to_choice": "['', '', '', '']",
      "description": "    ( )     .",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-abstract_algebra": {
      "task": "ogx_mmlux_es-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre lgebra abstracta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-anatomy": {
      "task": "ogx_mmlux_es-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre anatoma.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-astronomy": {
      "task": "ogx_mmlux_es-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre astronoma.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-business_ethics": {
      "task": "ogx_mmlux_es-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre tica empresarial.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "task": "ogx_mmlux_es-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A continuacin se presentan preguntas tipo test (con respuesta) sobre conocimientos clnicos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_biology": {
      "task": "ogx_mmlux_es-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre biologa universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_chemistry": {
      "task": "ogx_mmlux_es-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre qumica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_computer_science": {
      "task": "ogx_mmlux_es-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre informtica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_mathematics": {
      "task": "ogx_mmlux_es-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemticas universitarias.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_medicine": {
      "task": "ogx_mmlux_es-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre medicina universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_physics": {
      "task": "ogx_mmlux_es-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre fsica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-computer_security": {
      "task": "ogx_mmlux_es-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre seguridad informtica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-conceptual_physics": {
      "task": "ogx_mmlux_es-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre fsica conceptual.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-econometrics": {
      "task": "ogx_mmlux_es-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre econometra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-electrical_engineering": {
      "task": "ogx_mmlux_es-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre ingeniera elctrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "task": "ogx_mmlux_es-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemticas elementales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-formal_logic": {
      "task": "ogx_mmlux_es-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre lgica formal.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-global_facts": {
      "task": "ogx_mmlux_es-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre hechos globales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_biology": {
      "task": "ogx_mmlux_es-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre biologa de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "task": "ogx_mmlux_es-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre qumica de bachillerato.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "task": "ogx_mmlux_es-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre informtica en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_european_history": {
      "task": "ogx_mmlux_es-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre historia europea de bachillerato.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_geography": {
      "task": "ogx_mmlux_es-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre geografa de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "task": "ogx_mmlux_es-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre el gobierno y la poltica en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "task": "ogx_mmlux_es-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre macroeconoma en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "task": "ogx_mmlux_es-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemticas de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "task": "ogx_mmlux_es-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre microeconoma en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_physics": {
      "task": "ogx_mmlux_es-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre fsica de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_psychology": {
      "task": "ogx_mmlux_es-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre psicologa en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_statistics": {
      "task": "ogx_mmlux_es-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre estadstica de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_us_history": {
      "task": "ogx_mmlux_es-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre la historia de EE.UU. en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_world_history": {
      "task": "ogx_mmlux_es-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre la historia mundial de la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-human_aging": {
      "task": "ogx_mmlux_es-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre el envejecimiento humano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-human_sexuality": {
      "task": "ogx_mmlux_es-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre la sexualidad humana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-international_law": {
      "task": "ogx_mmlux_es-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre Derecho internacional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-jurisprudence": {
      "task": "ogx_mmlux_es-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre jurisprudencia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-logical_fallacies": {
      "task": "ogx_mmlux_es-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre falacias lgicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-machine_learning": {
      "task": "ogx_mmlux_es-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre aprendizaje automtico.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-management": {
      "task": "ogx_mmlux_es-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre gestin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-marketing": {
      "task": "ogx_mmlux_es-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-medical_genetics": {
      "task": "ogx_mmlux_es-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre gentica mdica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-miscellaneous": {
      "task": "ogx_mmlux_es-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre miscelnea.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-moral_disputes": {
      "task": "ogx_mmlux_es-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre disputas morales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-moral_scenarios": {
      "task": "ogx_mmlux_es-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre escenarios morales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-nutrition": {
      "task": "ogx_mmlux_es-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre nutricin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-philosophy": {
      "task": "ogx_mmlux_es-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre filosofa.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-prehistory": {
      "task": "ogx_mmlux_es-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre la prehistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_accounting": {
      "task": "ogx_mmlux_es-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre contabilidad profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_law": {
      "task": "ogx_mmlux_es-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A continuacin se presentan preguntas tipo test (con respuesta) sobre Derecho profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_medicine": {
      "task": "ogx_mmlux_es-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre medicina profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_psychology": {
      "task": "ogx_mmlux_es-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre psicologa profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-public_relations": {
      "task": "ogx_mmlux_es-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre relaciones pblicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-security_studies": {
      "task": "ogx_mmlux_es-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre estudios de seguridad.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-sociology": {
      "task": "ogx_mmlux_es-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre sociologa.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "task": "ogx_mmlux_es-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre la poltica exterior estadounidense.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-virology": {
      "task": "ogx_mmlux_es-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre virologa.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-world_religions": {
      "task": "ogx_mmlux_es-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opcin mltiple (con respuestas) sobre las religiones del mundo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-abstract_algebra": {
      "task": "ogx_mmlux_et-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) abstraktse algebra kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-anatomy": {
      "task": "ogx_mmlux_et-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) anatoomia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-astronomy": {
      "task": "ogx_mmlux_et-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) astronoomia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-business_ethics": {
      "task": "ogx_mmlux_et-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) rieetika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "task": "ogx_mmlux_et-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kliiniliste teadmiste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_biology": {
      "task": "ogx_mmlux_et-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kolledi bioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_chemistry": {
      "task": "ogx_mmlux_et-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kolledi keemia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_computer_science": {
      "task": "ogx_mmlux_et-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) krgkooli informaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_mathematics": {
      "task": "ogx_mmlux_et-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kolledi matemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_medicine": {
      "task": "ogx_mmlux_et-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kolledi meditsiini kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_physics": {
      "task": "ogx_mmlux_et-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kolledi fsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-computer_security": {
      "task": "ogx_mmlux_et-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) arvutiturbe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-conceptual_physics": {
      "task": "ogx_mmlux_et-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kontseptuaalse fsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-econometrics": {
      "task": "ogx_mmlux_et-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) konomeetria kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-electrical_engineering": {
      "task": "ogx_mmlux_et-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) elektrotehnika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "task": "ogx_mmlux_et-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) elementaarmatemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-formal_logic": {
      "task": "ogx_mmlux_et-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) formaalloogika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-global_facts": {
      "task": "ogx_mmlux_et-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) globaalsete faktide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_biology": {
      "task": "ogx_mmlux_et-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli bioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "task": "ogx_mmlux_et-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli keemia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "task": "ogx_mmlux_et-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli informaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_european_history": {
      "task": "ogx_mmlux_et-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli Euroopa ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_geography": {
      "task": "ogx_mmlux_et-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli geograafia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "task": "ogx_mmlux_et-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli valitsuse ja poliitika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "task": "ogx_mmlux_et-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli makromajanduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "task": "ogx_mmlux_et-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli matemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "task": "ogx_mmlux_et-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli mikrokonoomika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_physics": {
      "task": "ogx_mmlux_et-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkoolifsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_psychology": {
      "task": "ogx_mmlux_et-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkoolipshholoogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_statistics": {
      "task": "ogx_mmlux_et-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli statistika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_us_history": {
      "task": "ogx_mmlux_et-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) meie keskkooli ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_world_history": {
      "task": "ogx_mmlux_et-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) keskkooli maailma ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-human_aging": {
      "task": "ogx_mmlux_et-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) inimese vananemise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-human_sexuality": {
      "task": "ogx_mmlux_et-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) inimese seksuaalsuse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-international_law": {
      "task": "ogx_mmlux_et-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) rahvusvahelise iguse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-jurisprudence": {
      "task": "ogx_mmlux_et-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) igusteaduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-logical_fallacies": {
      "task": "ogx_mmlux_et-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) loogiliste eksituste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-machine_learning": {
      "task": "ogx_mmlux_et-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) masinppe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-management": {
      "task": "ogx_mmlux_et-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) juhtimise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-marketing": {
      "task": "ogx_mmlux_et-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) turunduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-medical_genetics": {
      "task": "ogx_mmlux_et-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) meditsiinigeneetika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-miscellaneous": {
      "task": "ogx_mmlux_et-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) mitmesuguste ksimuste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-moral_disputes": {
      "task": "ogx_mmlux_et-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) moraalsete vaidluste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-moral_scenarios": {
      "task": "ogx_mmlux_et-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) moraalsete stsenaariumide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-nutrition": {
      "task": "ogx_mmlux_et-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) toitumise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-philosophy": {
      "task": "ogx_mmlux_et-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) filosoofia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-prehistory": {
      "task": "ogx_mmlux_et-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) eelajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_accounting": {
      "task": "ogx_mmlux_et-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kutsealase raamatupidamise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_law": {
      "task": "ogx_mmlux_et-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) kutseiguse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_medicine": {
      "task": "ogx_mmlux_et-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) erialase meditsiini kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_psychology": {
      "task": "ogx_mmlux_et-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) erialase pshholoogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-public_relations": {
      "task": "ogx_mmlux_et-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) avalike suhete kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-security_studies": {
      "task": "ogx_mmlux_et-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) julgeolekuppe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-sociology": {
      "task": "ogx_mmlux_et-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) sotsioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "task": "ogx_mmlux_et-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) meie vlispoliitika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-virology": {
      "task": "ogx_mmlux_et-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) viroloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-world_religions": {
      "task": "ogx_mmlux_et-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Jrgnevalt on esitatud valikvastustega ksimused (koos vastustega) maailmareligioonide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "task": "ogx_mmlux_fi-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) abstraktista algebrasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-anatomy": {
      "task": "ogx_mmlux_fi-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) anatomiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-astronomy": {
      "task": "ogx_mmlux_fi-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) thtitieteest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-business_ethics": {
      "task": "ogx_mmlux_fi-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) liike-elmn etiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "task": "ogx_mmlux_fi-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) kliinisest tietmyksest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_biology": {
      "task": "ogx_mmlux_fi-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) yliopistobiologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_chemistry": {
      "task": "ogx_mmlux_fi-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) yliopistokemiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_computer_science": {
      "task": "ogx_mmlux_fi-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) yliopistojen tietotekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_mathematics": {
      "task": "ogx_mmlux_fi-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) yliopistomatematiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_medicine": {
      "task": "ogx_mmlux_fi-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) yliopistolketieteest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_physics": {
      "task": "ogx_mmlux_fi-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) yliopistofysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-computer_security": {
      "task": "ogx_mmlux_fi-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) tietoturvasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "task": "ogx_mmlux_fi-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ksitteellisest fysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-econometrics": {
      "task": "ogx_mmlux_fi-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ekonometriasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "task": "ogx_mmlux_fi-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) shktekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "task": "ogx_mmlux_fi-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) matematiikan alkeista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-formal_logic": {
      "task": "ogx_mmlux_fi-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) muodollisesta logiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-global_facts": {
      "task": "ogx_mmlux_fi-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) globaaleista tosiasioista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_biology": {
      "task": "ogx_mmlux_fi-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion biologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "task": "ogx_mmlux_fi-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion kemiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "task": "ogx_mmlux_fi-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion tietotekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "task": "ogx_mmlux_fi-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion Euroopan historiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_geography": {
      "task": "ogx_mmlux_fi-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion maantiedosta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "task": "ogx_mmlux_fi-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion hallituksesta ja politiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "task": "ogx_mmlux_fi-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion makrotaloudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "task": "ogx_mmlux_fi-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion matematiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "task": "ogx_mmlux_fi-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion mikrotaloustieteest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_physics": {
      "task": "ogx_mmlux_fi-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion fysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "task": "ogx_mmlux_fi-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion psykologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "task": "ogx_mmlux_fi-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion tilastoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "task": "ogx_mmlux_fi-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion historiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "task": "ogx_mmlux_fi-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) lukion maailmanhistoriasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-human_aging": {
      "task": "ogx_mmlux_fi-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ihmisen ikntymisest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-human_sexuality": {
      "task": "ogx_mmlux_fi-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ihmisen seksuaalisuudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-international_law": {
      "task": "ogx_mmlux_fi-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) kansainvlisest oikeudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-jurisprudence": {
      "task": "ogx_mmlux_fi-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) oikeustieteest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "task": "ogx_mmlux_fi-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) loogisista virheist.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-machine_learning": {
      "task": "ogx_mmlux_fi-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) koneoppimisesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-management": {
      "task": "ogx_mmlux_fi-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) johtamisesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-marketing": {
      "task": "ogx_mmlux_fi-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) markkinoinnista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-medical_genetics": {
      "task": "ogx_mmlux_fi-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) lketieteellisest genetiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-miscellaneous": {
      "task": "ogx_mmlux_fi-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) aiheesta sekalaiset.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-moral_disputes": {
      "task": "ogx_mmlux_fi-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) moraalisista kiistoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "task": "ogx_mmlux_fi-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) moraalisista skenaarioista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-nutrition": {
      "task": "ogx_mmlux_fi-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ravitsemuksesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-philosophy": {
      "task": "ogx_mmlux_fi-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) filosofiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-prehistory": {
      "task": "ogx_mmlux_fi-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on esihistoriaa koskevia monivalintakysymyksi (vastauksineen).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_accounting": {
      "task": "ogx_mmlux_fi-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ammattimaisesta kirjanpidosta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_law": {
      "task": "ogx_mmlux_fi-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ammattioikeudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_medicine": {
      "task": "ogx_mmlux_fi-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (ja vastauksia) ammatillisesta lketieteest.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_psychology": {
      "task": "ogx_mmlux_fi-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) ammattipsykologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-public_relations": {
      "task": "ogx_mmlux_fi-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) suhdetoiminnasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-security_studies": {
      "task": "ogx_mmlux_fi-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) turvallisuustutkimuksesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-sociology": {
      "task": "ogx_mmlux_fi-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on sosiologiaa koskevia monivalintakysymyksi (vastauksineen).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "task": "ogx_mmlux_fi-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavat ovat monivalintakysymyksi (vastauksineen) Yhdysvaltojen ulkopolitiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-virology": {
      "task": "ogx_mmlux_fi-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) virologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-world_religions": {
      "task": "ogx_mmlux_fi-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksi (vastauksineen) maailmanuskonnoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "task": "ogx_mmlux_fr-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'algbre abstraite.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-anatomy": {
      "task": "ogx_mmlux_fr-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-astronomy": {
      "task": "ogx_mmlux_fr-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-business_ethics": {
      "task": "ogx_mmlux_fr-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'thique des affaires.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "task": "ogx_mmlux_fr-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les connaissances cliniques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_biology": {
      "task": "ogx_mmlux_fr-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la biologie au collge.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_chemistry": {
      "task": "ogx_mmlux_fr-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la chimie au collge.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_computer_science": {
      "task": "ogx_mmlux_fr-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'informatique au collge.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_mathematics": {
      "task": "ogx_mmlux_fr-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les mathmatiques au collge.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_medicine": {
      "task": "ogx_mmlux_fr-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la mdecine universitaire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_physics": {
      "task": "ogx_mmlux_fr-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la physique au collge.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-computer_security": {
      "task": "ogx_mmlux_fr-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la scurit informatique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "task": "ogx_mmlux_fr-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la physique conceptuelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-econometrics": {
      "task": "ogx_mmlux_fr-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'conomtrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "task": "ogx_mmlux_fr-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le gnie lectrique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "task": "ogx_mmlux_fr-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les mathmatiques lmentaires.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-formal_logic": {
      "task": "ogx_mmlux_fr-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la logique formelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-global_facts": {
      "task": "ogx_mmlux_fr-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les faits mondiaux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_biology": {
      "task": "ogx_mmlux_fr-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la biologie au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "task": "ogx_mmlux_fr-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la chimie au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "task": "ogx_mmlux_fr-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'informatique au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "task": "ogx_mmlux_fr-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'histoire de l'Europe au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_geography": {
      "task": "ogx_mmlux_fr-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la gographie au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "task": "ogx_mmlux_fr-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le gouvernement et la politique au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "task": "ogx_mmlux_fr-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la macroconomie au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "task": "ogx_mmlux_fr-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les mathmatiques au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "task": "ogx_mmlux_fr-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la microconomie au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_physics": {
      "task": "ogx_mmlux_fr-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la physique au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "task": "ogx_mmlux_fr-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la psychologie au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "task": "ogx_mmlux_fr-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les statistiques de l'enseignement secondaire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "task": "ogx_mmlux_fr-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'histoire des tats-Unis au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "task": "ogx_mmlux_fr-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'histoire du monde au lyce.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-human_aging": {
      "task": "ogx_mmlux_fr-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le vieillissement humain.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-human_sexuality": {
      "task": "ogx_mmlux_fr-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la sexualit humaine.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-international_law": {
      "task": "ogx_mmlux_fr-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le droit international.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-jurisprudence": {
      "task": "ogx_mmlux_fr-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la jurisprudence.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "task": "ogx_mmlux_fr-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les sophismes logiques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-machine_learning": {
      "task": "ogx_mmlux_fr-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur l'apprentissage automatique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-management": {
      "task": "ogx_mmlux_fr-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-marketing": {
      "task": "ogx_mmlux_fr-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-medical_genetics": {
      "task": "ogx_mmlux_fr-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la gntique mdicale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-miscellaneous": {
      "task": "ogx_mmlux_fr-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les divers.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-moral_disputes": {
      "task": "ogx_mmlux_fr-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les diffrends moraux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "task": "ogx_mmlux_fr-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur des scnarios moraux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-nutrition": {
      "task": "ogx_mmlux_fr-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la nutrition.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-philosophy": {
      "task": "ogx_mmlux_fr-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la philosophie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-prehistory": {
      "task": "ogx_mmlux_fr-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la prhistoire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_accounting": {
      "task": "ogx_mmlux_fr-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la comptabilit professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_law": {
      "task": "ogx_mmlux_fr-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur le droit professionnel.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_medicine": {
      "task": "ogx_mmlux_fr-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la mdecine professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_psychology": {
      "task": "ogx_mmlux_fr-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la psychologie professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-public_relations": {
      "task": "ogx_mmlux_fr-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les relations publiques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-security_studies": {
      "task": "ogx_mmlux_fr-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur les tudes de scurit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-sociology": {
      "task": "ogx_mmlux_fr-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "task": "ogx_mmlux_fr-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Voici des questions  choix multiples (avec rponses) sur la politique trangre des tats-Unis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-virology": {
      "task": "ogx_mmlux_fr-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions  choix multiples (avec rponses) sur la virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-world_religions": {
      "task": "ogx_mmlux_fr-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Voici des questions  choix multiples (avec rponses) sur les religions du monde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "task": "ogx_mmlux_hu-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) az absztrakt algebrrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-anatomy": {
      "task": "ogx_mmlux_hu-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) az anatmirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-astronomy": {
      "task": "ogx_mmlux_hu-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a csillagszatrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-business_ethics": {
      "task": "ogx_mmlux_hu-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az zleti etikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "task": "ogx_mmlux_hu-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbiakban a klinikai ismeretekkel kapcsolatos feleletvlaszts krdsek (vlaszokkal) kvetkeznek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_biology": {
      "task": "ogx_mmlux_hu-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a fiskolai biolgirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_chemistry": {
      "task": "ogx_mmlux_hu-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a fiskolai kmirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_computer_science": {
      "task": "ogx_mmlux_hu-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a fiskolai informatikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_mathematics": {
      "task": "ogx_mmlux_hu-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a fiskolai matematikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_medicine": {
      "task": "ogx_mmlux_hu-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a fiskolai orvostudomnyrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_physics": {
      "task": "ogx_mmlux_hu-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) az egyetemi fizikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-computer_security": {
      "task": "ogx_mmlux_hu-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a szmtgpes biztonsgrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "task": "ogx_mmlux_hu-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a fogalmi fizikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-econometrics": {
      "task": "ogx_mmlux_hu-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbiakban az konometrival kapcsolatos feleletvlaszts krdsek (vlaszokkal) kvetkeznek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "task": "ogx_mmlux_hu-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a villamosmrnki tudomnyokrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "task": "ogx_mmlux_hu-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az elemi matematikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-formal_logic": {
      "task": "ogx_mmlux_hu-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a formlis logikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-global_facts": {
      "task": "ogx_mmlux_hu-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a globlis tnyekrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_biology": {
      "task": "ogx_mmlux_hu-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai biolgirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "task": "ogx_mmlux_hu-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai kmirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "task": "ogx_mmlux_hu-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai informatikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "task": "ogx_mmlux_hu-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai eurpai trtnelemrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_geography": {
      "task": "ogx_mmlux_hu-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai fldrajzrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "task": "ogx_mmlux_hu-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a kzpiskolai kormnyzatrl s politikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "task": "ogx_mmlux_hu-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai makrokonmirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "task": "ogx_mmlux_hu-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai matematikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "task": "ogx_mmlux_hu-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai mikrokonmirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_physics": {
      "task": "ogx_mmlux_hu-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai fizikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "task": "ogx_mmlux_hu-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a kzpiskolai pszicholgirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "task": "ogx_mmlux_hu-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbiakban a kzpiskolai statisztikval kapcsolatos feleletvlaszts krdsek (vlaszokkal) tallhatk.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "task": "ogx_mmlux_hu-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai trtnelemrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "task": "ogx_mmlux_hu-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a kzpiskolai vilgtrtnelemrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-human_aging": {
      "task": "ogx_mmlux_hu-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az emberi regedssel kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-human_sexuality": {
      "task": "ogx_mmlux_hu-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az emberi szexualitsrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-international_law": {
      "task": "ogx_mmlux_hu-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a nemzetkzi jogrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-jurisprudence": {
      "task": "ogx_mmlux_hu-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a jogtudomnyrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "task": "ogx_mmlux_hu-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbiakban a logikai tvedsekkel kapcsolatos feleletvlaszts krdsek (vlaszokkal) tallhatk.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-machine_learning": {
      "task": "ogx_mmlux_hu-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a gpi tanulsrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-management": {
      "task": "ogx_mmlux_hu-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a menedzsmentrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-marketing": {
      "task": "ogx_mmlux_hu-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a marketingrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-medical_genetics": {
      "task": "ogx_mmlux_hu-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az orvosi genetikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-miscellaneous": {
      "task": "ogx_mmlux_hu-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a klnfle krdsekrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-moral_disputes": {
      "task": "ogx_mmlux_hu-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az erklcsi vitkrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "task": "ogx_mmlux_hu-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbiakban erklcsi forgatknyvekkel kapcsolatos feleletvlaszts krdsek (vlaszokkal) kvetkeznek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-nutrition": {
      "task": "ogx_mmlux_hu-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a tpllkozssal kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-philosophy": {
      "task": "ogx_mmlux_hu-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a filozfirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-prehistory": {
      "task": "ogx_mmlux_hu-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) az strtnetrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_accounting": {
      "task": "ogx_mmlux_hu-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a szakmai szmvitelrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_law": {
      "task": "ogx_mmlux_hu-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a szakmai joggal kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_medicine": {
      "task": "ogx_mmlux_hu-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a hivatsos orvoslsrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_psychology": {
      "task": "ogx_mmlux_hu-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a szakpszicholgirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-public_relations": {
      "task": "ogx_mmlux_hu-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a public relationsrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-security_studies": {
      "task": "ogx_mmlux_hu-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a biztonsgi tanulmnyokrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-sociology": {
      "task": "ogx_mmlux_hu-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a szociolgirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "task": "ogx_mmlux_hu-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) az amerikai klpolitikrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-virology": {
      "task": "ogx_mmlux_hu-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A kvetkez feleletvlaszts krdsek (vlaszokkal) a virolgirl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-world_religions": {
      "task": "ogx_mmlux_hu-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVlasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az albbi feleletvlaszts krdsek (vlaszokkal) a vilgvallsokrl szlnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-abstract_algebra": {
      "task": "ogx_mmlux_it-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'algebra astratta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-anatomy": {
      "task": "ogx_mmlux_it-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'anatomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-astronomy": {
      "task": "ogx_mmlux_it-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'astronomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-business_ethics": {
      "task": "ogx_mmlux_it-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'etica aziendale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "task": "ogx_mmlux_it-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla conoscenza clinica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_biology": {
      "task": "ogx_mmlux_it-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla biologia universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_chemistry": {
      "task": "ogx_mmlux_it-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla chimica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_computer_science": {
      "task": "ogx_mmlux_it-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'informatica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_mathematics": {
      "task": "ogx_mmlux_it-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_medicine": {
      "task": "ogx_mmlux_it-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla medicina universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_physics": {
      "task": "ogx_mmlux_it-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-computer_security": {
      "task": "ogx_mmlux_it-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sicurezza informatica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-conceptual_physics": {
      "task": "ogx_mmlux_it-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica concettuale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-econometrics": {
      "task": "ogx_mmlux_it-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'econometria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-electrical_engineering": {
      "task": "ogx_mmlux_it-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'ingegneria elettrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "task": "ogx_mmlux_it-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica elementare.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-formal_logic": {
      "task": "ogx_mmlux_it-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla logica formale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-global_facts": {
      "task": "ogx_mmlux_it-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sui fatti globali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_biology": {
      "task": "ogx_mmlux_it-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla biologia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "task": "ogx_mmlux_it-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla chimica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "task": "ogx_mmlux_it-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'informatica per le scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_european_history": {
      "task": "ogx_mmlux_it-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia europea delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_geography": {
      "task": "ogx_mmlux_it-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla geografia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "task": "ogx_mmlux_it-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul governo e la politica nelle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "task": "ogx_mmlux_it-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla macroeconomia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "task": "ogx_mmlux_it-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "task": "ogx_mmlux_it-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla microeconomia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_physics": {
      "task": "ogx_mmlux_it-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_psychology": {
      "task": "ogx_mmlux_it-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla psicologia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_statistics": {
      "task": "ogx_mmlux_it-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla statistica della scuola superiore.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_us_history": {
      "task": "ogx_mmlux_it-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia degli Stati Uniti al liceo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_world_history": {
      "task": "ogx_mmlux_it-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia mondiale delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-human_aging": {
      "task": "ogx_mmlux_it-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'invecchiamento umano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-human_sexuality": {
      "task": "ogx_mmlux_it-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sessualit umana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-international_law": {
      "task": "ogx_mmlux_it-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul diritto internazionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-jurisprudence": {
      "task": "ogx_mmlux_it-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla giurisprudenza.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-logical_fallacies": {
      "task": "ogx_mmlux_it-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle fallacie logiche.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-machine_learning": {
      "task": "ogx_mmlux_it-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'apprendimento automatico.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-management": {
      "task": "ogx_mmlux_it-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla gestione.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-marketing": {
      "task": "ogx_mmlux_it-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-medical_genetics": {
      "task": "ogx_mmlux_it-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla genetica medica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-miscellaneous": {
      "task": "ogx_mmlux_it-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) su varie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-moral_disputes": {
      "task": "ogx_mmlux_it-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle controversie morali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-moral_scenarios": {
      "task": "ogx_mmlux_it-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) su scenari morali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-nutrition": {
      "task": "ogx_mmlux_it-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'alimentazione.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-philosophy": {
      "task": "ogx_mmlux_it-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla filosofia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-prehistory": {
      "task": "ogx_mmlux_it-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla preistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_accounting": {
      "task": "ogx_mmlux_it-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla contabilit professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_law": {
      "task": "ogx_mmlux_it-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul diritto professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_medicine": {
      "task": "ogx_mmlux_it-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla medicina professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_psychology": {
      "task": "ogx_mmlux_it-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla psicologia professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-public_relations": {
      "task": "ogx_mmlux_it-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle relazioni pubbliche.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-security_studies": {
      "task": "ogx_mmlux_it-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sugli studi sulla sicurezza.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-sociology": {
      "task": "ogx_mmlux_it-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sociologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "task": "ogx_mmlux_it-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla politica estera degli Stati Uniti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-virology": {
      "task": "ogx_mmlux_it-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla virologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-world_religions": {
      "task": "ogx_mmlux_it-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle religioni del mondo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "task": "ogx_mmlux_lt-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie abstrakij algebr.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-anatomy": {
      "task": "ogx_mmlux_lt-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie anatomij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-astronomy": {
      "task": "ogx_mmlux_lt-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie astronomij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-business_ethics": {
      "task": "ogx_mmlux_lt-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie verslo etik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "task": "ogx_mmlux_lt-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie klinikines inias.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_biology": {
      "task": "ogx_mmlux_lt-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos biologij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_chemistry": {
      "task": "ogx_mmlux_lt-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos chemij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_computer_science": {
      "task": "ogx_mmlux_lt-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos informatik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_mathematics": {
      "task": "ogx_mmlux_lt-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_medicine": {
      "task": "ogx_mmlux_lt-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie koledo medicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_physics": {
      "task": "ogx_mmlux_lt-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos fizik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-computer_security": {
      "task": "ogx_mmlux_lt-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kompiuteri saugum.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "task": "ogx_mmlux_lt-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie konceptualij fizik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-econometrics": {
      "task": "ogx_mmlux_lt-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie ekonometrij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "task": "ogx_mmlux_lt-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie elektrotechnik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "task": "ogx_mmlux_lt-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai su atsakymais apie elementarij matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-formal_logic": {
      "task": "ogx_mmlux_lt-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie formalij logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-global_facts": {
      "task": "ogx_mmlux_lt-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie visuotinius faktus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_biology": {
      "task": "ogx_mmlux_lt-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurins mokyklos biologij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "task": "ogx_mmlux_lt-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie chemij vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "task": "ogx_mmlux_lt-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie informatik vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "task": "ogx_mmlux_lt-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie Europos istorij vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_geography": {
      "task": "ogx_mmlux_lt-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie geografij vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "task": "ogx_mmlux_lt-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vyriausyb ir politik vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "task": "ogx_mmlux_lt-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie makroekonomik vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "task": "ogx_mmlux_lt-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurins mokyklos matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "task": "ogx_mmlux_lt-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mikroekonomik vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_physics": {
      "task": "ogx_mmlux_lt-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie fizik vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "task": "ogx_mmlux_lt-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie psichologij vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "task": "ogx_mmlux_lt-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurins mokyklos statistik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "task": "ogx_mmlux_lt-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie JAV vidurins mokyklos istorij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "task": "ogx_mmlux_lt-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie pasaulio istorij vidurinje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-human_aging": {
      "task": "ogx_mmlux_lt-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mogaus senjim.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-human_sexuality": {
      "task": "ogx_mmlux_lt-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mogaus lytikum.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-international_law": {
      "task": "ogx_mmlux_lt-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie tarptautin teis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-jurisprudence": {
      "task": "ogx_mmlux_lt-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie jurisprudencij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "task": "ogx_mmlux_lt-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie logines klaidas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-machine_learning": {
      "task": "ogx_mmlux_lt-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mainin mokymsi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-management": {
      "task": "ogx_mmlux_lt-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie valdym.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-marketing": {
      "task": "ogx_mmlux_lt-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie rinkodar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-medical_genetics": {
      "task": "ogx_mmlux_lt-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie medicinin genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-miscellaneous": {
      "task": "ogx_mmlux_lt-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vairius dalykus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-moral_disputes": {
      "task": "ogx_mmlux_lt-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie moralinius ginus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "task": "ogx_mmlux_lt-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie moralinius scenarijus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-nutrition": {
      "task": "ogx_mmlux_lt-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mityb.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-philosophy": {
      "task": "ogx_mmlux_lt-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie filosofij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-prehistory": {
      "task": "ogx_mmlux_lt-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie prieistor.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_accounting": {
      "task": "ogx_mmlux_lt-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesin apskait.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_law": {
      "task": "ogx_mmlux_lt-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesin teis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_medicine": {
      "task": "ogx_mmlux_lt-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesin medicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_psychology": {
      "task": "ogx_mmlux_lt-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesin psichologij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-public_relations": {
      "task": "ogx_mmlux_lt-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vieuosius ryius.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-security_studies": {
      "task": "ogx_mmlux_lt-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie saugumo studijas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-sociology": {
      "task": "ogx_mmlux_lt-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie sociologij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "task": "ogx_mmlux_lt-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie JAV usienio politik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-virology": {
      "task": "ogx_mmlux_lt-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie virusologij.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-world_religions": {
      "task": "ogx_mmlux_lt-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie pasaulio religijas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "task": "ogx_mmlux_lv-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par abstrakto algebru.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-anatomy": {
      "task": "ogx_mmlux_lv-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem par anatomiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-astronomy": {
      "task": "ogx_mmlux_lv-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par astronomiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-business_ethics": {
      "task": "ogx_mmlux_lv-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par uzmjdarbbas tiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "task": "ogx_mmlux_lv-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par klniskajm zinanm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_biology": {
      "task": "ogx_mmlux_lv-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par koledas bioloiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_chemistry": {
      "task": "ogx_mmlux_lv-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par koledas miju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_computer_science": {
      "task": "ogx_mmlux_lv-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par datorzintnm koled.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_mathematics": {
      "task": "ogx_mmlux_lv-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par koledas matemtiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_medicine": {
      "task": "ogx_mmlux_lv-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par koledas medicnu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_physics": {
      "task": "ogx_mmlux_lv-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par koledas fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-computer_security": {
      "task": "ogx_mmlux_lv-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par datoru drobu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "task": "ogx_mmlux_lv-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par konceptulo fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-econometrics": {
      "task": "ogx_mmlux_lv-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par ekonometriju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "task": "ogx_mmlux_lv-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par elektrotehniku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "task": "ogx_mmlux_lv-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par elementro matemtiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-formal_logic": {
      "task": "ogx_mmlux_lv-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem par formlo loiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-global_facts": {
      "task": "ogx_mmlux_lv-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par pasaules faktiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_biology": {
      "task": "ogx_mmlux_lv-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas bioloiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "task": "ogx_mmlux_lv-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas miju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "task": "ogx_mmlux_lv-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas informtiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "task": "ogx_mmlux_lv-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas Eiropas vsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_geography": {
      "task": "ogx_mmlux_lv-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas eogrfiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "task": "ogx_mmlux_lv-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par valsts prvaldi un politiku vidusskol.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "task": "ogx_mmlux_lv-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par makroekonomiku vidusskol.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "task": "ogx_mmlux_lv-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas matemtiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "task": "ogx_mmlux_lv-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par mikroekonomiku vidusskol.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_physics": {
      "task": "ogx_mmlux_lv-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "task": "ogx_mmlux_lv-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas psiholoiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "task": "ogx_mmlux_lv-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par vidusskolas statistiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "task": "ogx_mmlux_lv-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par ASV vidusskolas vsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "task": "ogx_mmlux_lv-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par pasaules vsturi vidusskol.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-human_aging": {
      "task": "ogx_mmlux_lv-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par cilvka novecoanu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-human_sexuality": {
      "task": "ogx_mmlux_lv-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par cilvka seksualitti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-international_law": {
      "task": "ogx_mmlux_lv-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par starptautiskajm tiesbm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-jurisprudence": {
      "task": "ogx_mmlux_lv-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmk ir jautjumi ar atbilu variantiem (ar atbildm) par jurisprudenci.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "task": "ogx_mmlux_lv-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par loiskajm kdm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-machine_learning": {
      "task": "ogx_mmlux_lv-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par manmcanos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-management": {
      "task": "ogx_mmlux_lv-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmk ir jautjumi ar atbilu variantiem (ar atbildm) par vadbu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-marketing": {
      "task": "ogx_mmlux_lv-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par mrketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-medical_genetics": {
      "task": "ogx_mmlux_lv-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par medicnas entiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-miscellaneous": {
      "task": "ogx_mmlux_lv-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par dadiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-moral_disputes": {
      "task": "ogx_mmlux_lv-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par morles strdiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "task": "ogx_mmlux_lv-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par morles scenrijiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-nutrition": {
      "task": "ogx_mmlux_lv-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par uzturu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-philosophy": {
      "task": "ogx_mmlux_lv-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par filozofiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-prehistory": {
      "task": "ogx_mmlux_lv-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem (ar atbildm) par aizvsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_accounting": {
      "task": "ogx_mmlux_lv-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par profesionlo grmatvedbu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_law": {
      "task": "ogx_mmlux_lv-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par profesionlajm tiesbm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_medicine": {
      "task": "ogx_mmlux_lv-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par profesionlo medicnu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_psychology": {
      "task": "ogx_mmlux_lv-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par profesionlo psiholoiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-public_relations": {
      "task": "ogx_mmlux_lv-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par sabiedriskajm attiecbm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-security_studies": {
      "task": "ogx_mmlux_lv-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par drobas studijm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-sociology": {
      "task": "ogx_mmlux_lv-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmk ir jautjumi ar atbilu variantiem par socioloiju (ar atbildm).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "task": "ogx_mmlux_lv-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem par ASV rpolitiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-virology": {
      "task": "ogx_mmlux_lv-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir jautjumi ar atbilu variantiem par virusoloiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-world_religions": {
      "task": "ogx_mmlux_lv-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tlk ir iekauti jautjumi ar atbilu variantiem (ar atbildm) par pasaules reliijm.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "task": "ogx_mmlux_nl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over abstracte algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-anatomy": {
      "task": "ogx_mmlux_nl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-astronomy": {
      "task": "ogx_mmlux_nl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-business_ethics": {
      "task": "ogx_mmlux_nl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over bedrijfsethiek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "task": "ogx_mmlux_nl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over klinische kennis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_biology": {
      "task": "ogx_mmlux_nl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over biologie op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_chemistry": {
      "task": "ogx_mmlux_nl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over scheikunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_computer_science": {
      "task": "ogx_mmlux_nl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over informatica op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_mathematics": {
      "task": "ogx_mmlux_nl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wiskunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_medicine": {
      "task": "ogx_mmlux_nl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over geneeskunde aan de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_physics": {
      "task": "ogx_mmlux_nl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over natuurkunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-computer_security": {
      "task": "ogx_mmlux_nl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over computerbeveiliging.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "task": "ogx_mmlux_nl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over conceptuele fysica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-econometrics": {
      "task": "ogx_mmlux_nl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over econometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "task": "ogx_mmlux_nl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over elektrotechniek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "task": "ogx_mmlux_nl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over elementaire wiskunde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-formal_logic": {
      "task": "ogx_mmlux_nl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over formele logica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-global_facts": {
      "task": "ogx_mmlux_nl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over globale feiten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_biology": {
      "task": "ogx_mmlux_nl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over biologie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "task": "ogx_mmlux_nl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over scheikunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "task": "ogx_mmlux_nl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over informatica op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "task": "ogx_mmlux_nl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over Europese geschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_geography": {
      "task": "ogx_mmlux_nl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over aardrijkskunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "task": "ogx_mmlux_nl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over bestuur en politiek op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "task": "ogx_mmlux_nl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over macro-economie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "task": "ogx_mmlux_nl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wiskunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "task": "ogx_mmlux_nl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over micro-economie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_physics": {
      "task": "ogx_mmlux_nl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over natuurkunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "task": "ogx_mmlux_nl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over psychologie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "task": "ogx_mmlux_nl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over statistiek op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "task": "ogx_mmlux_nl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over geschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "task": "ogx_mmlux_nl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wereldgeschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-human_aging": {
      "task": "ogx_mmlux_nl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over menselijke veroudering.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-human_sexuality": {
      "task": "ogx_mmlux_nl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over menselijke seksualiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-international_law": {
      "task": "ogx_mmlux_nl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over internationaal recht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-jurisprudence": {
      "task": "ogx_mmlux_nl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over jurisprudentie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "task": "ogx_mmlux_nl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over logische drogredenen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-machine_learning": {
      "task": "ogx_mmlux_nl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over machinaal leren.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-management": {
      "task": "ogx_mmlux_nl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-marketing": {
      "task": "ogx_mmlux_nl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-medical_genetics": {
      "task": "ogx_mmlux_nl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over medische genetica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-miscellaneous": {
      "task": "ogx_mmlux_nl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over diversen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-moral_disputes": {
      "task": "ogx_mmlux_nl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over morele geschillen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "task": "ogx_mmlux_nl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over morele scenario's.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-nutrition": {
      "task": "ogx_mmlux_nl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over voeding.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-philosophy": {
      "task": "ogx_mmlux_nl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over filosofie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-prehistory": {
      "task": "ogx_mmlux_nl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over de prehistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_accounting": {
      "task": "ogx_mmlux_nl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over professioneel boekhouden.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_law": {
      "task": "ogx_mmlux_nl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over het beroepsrecht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_medicine": {
      "task": "ogx_mmlux_nl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over professionele geneeskunde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_psychology": {
      "task": "ogx_mmlux_nl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over professionele psychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-public_relations": {
      "task": "ogx_mmlux_nl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-security_studies": {
      "task": "ogx_mmlux_nl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over veiligheidsstudies.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-sociology": {
      "task": "ogx_mmlux_nl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "task": "ogx_mmlux_nl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over het buitenlands beleid van de Verenigde Staten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-virology": {
      "task": "ogx_mmlux_nl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-world_religions": {
      "task": "ogx_mmlux_nl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wereldreligies.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "task": "ogx_mmlux_pl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce algebry abstrakcyjnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-anatomy": {
      "task": "ogx_mmlux_pl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce anatomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-astronomy": {
      "task": "ogx_mmlux_pl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce astronomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-business_ethics": {
      "task": "ogx_mmlux_pl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce etyki biznesu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "task": "ogx_mmlux_pl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce wiedzy klinicznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_biology": {
      "task": "ogx_mmlux_pl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce biologii na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_chemistry": {
      "task": "ogx_mmlux_pl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce chemii na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_computer_science": {
      "task": "ogx_mmlux_pl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce informatyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_mathematics": {
      "task": "ogx_mmlux_pl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce matematyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_medicine": {
      "task": "ogx_mmlux_pl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce medycyny uniwersyteckiej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_physics": {
      "task": "ogx_mmlux_pl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce fizyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-computer_security": {
      "task": "ogx_mmlux_pl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce bezpieczestwa komputerowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "task": "ogx_mmlux_pl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce fizyki konceptualnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-econometrics": {
      "task": "ogx_mmlux_pl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "task": "ogx_mmlux_pl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce inynierii elektrycznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "task": "ogx_mmlux_pl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce matematyki elementarnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-formal_logic": {
      "task": "ogx_mmlux_pl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce logiki formalnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-global_facts": {
      "task": "ogx_mmlux_pl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce globalnych faktw.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_biology": {
      "task": "ogx_mmlux_pl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce biologii w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "task": "ogx_mmlux_pl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce chemii w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "task": "ogx_mmlux_pl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce informatyki w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "task": "ogx_mmlux_pl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce historii Europy w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_geography": {
      "task": "ogx_mmlux_pl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce geografii w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "task": "ogx_mmlux_pl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce rzdw i polityki w szkoach rednich.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "task": "ogx_mmlux_pl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce makroekonomii w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "task": "ogx_mmlux_pl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce matematyki w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "task": "ogx_mmlux_pl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce mikroekonomii w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_physics": {
      "task": "ogx_mmlux_pl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce fizyki w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "task": "ogx_mmlux_pl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce psychologii w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "task": "ogx_mmlux_pl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce statystyki w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "task": "ogx_mmlux_pl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce historii Stanw Zjednoczonych w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "task": "ogx_mmlux_pl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce historii wiata w szkole redniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-human_aging": {
      "task": "ogx_mmlux_pl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce starzenia si czowieka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-human_sexuality": {
      "task": "ogx_mmlux_pl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce ludzkiej seksualnoci.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-international_law": {
      "task": "ogx_mmlux_pl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce prawa midzynarodowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-jurisprudence": {
      "task": "ogx_mmlux_pl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce orzecznictwa.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "task": "ogx_mmlux_pl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce bdw logicznych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-machine_learning": {
      "task": "ogx_mmlux_pl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce uczenia maszynowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-management": {
      "task": "ogx_mmlux_pl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce zarzdzania.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-marketing": {
      "task": "ogx_mmlux_pl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-medical_genetics": {
      "task": "ogx_mmlux_pl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce genetyki medycznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-miscellaneous": {
      "task": "ogx_mmlux_pl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce rnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-moral_disputes": {
      "task": "ogx_mmlux_pl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce sporw moralnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "task": "ogx_mmlux_pl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce scenariuszy moralnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-nutrition": {
      "task": "ogx_mmlux_pl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce odywiania.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-philosophy": {
      "task": "ogx_mmlux_pl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-prehistory": {
      "task": "ogx_mmlux_pl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce prehistorii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_accounting": {
      "task": "ogx_mmlux_pl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce profesjonalnej ksigowoci.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_law": {
      "task": "ogx_mmlux_pl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce prawa zawodowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_medicine": {
      "task": "ogx_mmlux_pl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce medycyny profesjonalnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_psychology": {
      "task": "ogx_mmlux_pl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce psychologii zawodowej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-public_relations": {
      "task": "ogx_mmlux_pl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-security_studies": {
      "task": "ogx_mmlux_pl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce studiw nad bezpieczestwem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-sociology": {
      "task": "ogx_mmlux_pl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce socjologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "task": "ogx_mmlux_pl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce polityki zagranicznej Stanw Zjednoczonych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-virology": {
      "task": "ogx_mmlux_pl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce wirusologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-world_religions": {
      "task": "ogx_mmlux_pl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowied:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniej znajduj si pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczce religii wiata.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "task": "ogx_mmlux_pt-pt-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre lgebra abstrata.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "task": "ogx_mmlux_pt-pt-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre anatomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "task": "ogx_mmlux_pt-pt-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre astronomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "task": "ogx_mmlux_pt-pt-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre tica empresarial.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "task": "ogx_mmlux_pt-pt-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre conhecimentos clnicos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "task": "ogx_mmlux_pt-pt-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes so de escolha mltipla (com respostas) sobre biologia universitria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "task": "ogx_mmlux_pt-pt-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes so de escolha mltipla (com respostas) sobre qumica universitria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "task": "ogx_mmlux_pt-pt-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre informtica universitria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "task": "ogx_mmlux_pt-pt-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre matemtica universitria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "task": "ogx_mmlux_pt-pt-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre medicina universitria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "task": "ogx_mmlux_pt-pt-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes so de escolha mltipla (com respostas) sobre fsica universitria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "task": "ogx_mmlux_pt-pt-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre segurana informtica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "task": "ogx_mmlux_pt-pt-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre fsica concetual.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "task": "ogx_mmlux_pt-pt-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre econometria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "task": "ogx_mmlux_pt-pt-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre engenharia elctrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "task": "ogx_mmlux_pt-pt-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre matemtica elementar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "task": "ogx_mmlux_pt-pt-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre lgica formal.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "task": "ogx_mmlux_pt-pt-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre factos globais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "task": "ogx_mmlux_pt-pt-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre biologia do ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "task": "ogx_mmlux_pt-pt-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre qumica no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "task": "ogx_mmlux_pt-pt-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre informtica no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "task": "ogx_mmlux_pt-pt-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre histria europeia no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "task": "ogx_mmlux_pt-pt-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre geografia do ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "task": "ogx_mmlux_pt-pt-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre governo e poltica no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "task": "ogx_mmlux_pt-pt-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre macroeconomia no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "task": "ogx_mmlux_pt-pt-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre matemtica do ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "task": "ogx_mmlux_pt-pt-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre microeconomia no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "task": "ogx_mmlux_pt-pt-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre fsica do ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "task": "ogx_mmlux_pt-pt-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre psicologia no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "task": "ogx_mmlux_pt-pt-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre estatstica no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "task": "ogx_mmlux_pt-pt-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre Histria dos EUA no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "task": "ogx_mmlux_pt-pt-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre histria mundial no ensino secundrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "task": "ogx_mmlux_pt-pt-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre o envelhecimento humano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "task": "ogx_mmlux_pt-pt-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre a sexualidade humana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-international_law": {
      "task": "ogx_mmlux_pt-pt-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre direito internacional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "task": "ogx_mmlux_pt-pt-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre jurisprudncia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "task": "ogx_mmlux_pt-pt-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre falcias lgicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "task": "ogx_mmlux_pt-pt-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre aprendizagem automtica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-management": {
      "task": "ogx_mmlux_pt-pt-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre gesto.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-marketing": {
      "task": "ogx_mmlux_pt-pt-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "task": "ogx_mmlux_pt-pt-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre gentica mdica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "task": "ogx_mmlux_pt-pt-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre miscelnea.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "task": "ogx_mmlux_pt-pt-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre disputas morais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "task": "ogx_mmlux_pt-pt-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre cenrios morais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "task": "ogx_mmlux_pt-pt-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre nutrio.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "task": "ogx_mmlux_pt-pt-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre filosofia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "task": "ogx_mmlux_pt-pt-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre a pr-histria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "task": "ogx_mmlux_pt-pt-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre contabilidade profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "task": "ogx_mmlux_pt-pt-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre direito profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "task": "ogx_mmlux_pt-pt-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre medicina profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "task": "ogx_mmlux_pt-pt-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre psicologia profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "task": "ogx_mmlux_pt-pt-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre relaes pblicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "task": "ogx_mmlux_pt-pt-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre estudos de segurana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-sociology": {
      "task": "ogx_mmlux_pt-pt-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre sociologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "task": "ogx_mmlux_pt-pt-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes so de escolha mltipla (com respostas) sobre a poltica externa dos EUA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-virology": {
      "task": "ogx_mmlux_pt-pt-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre virologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "task": "ogx_mmlux_pt-pt-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha mltipla (com respostas) sobre as religies do mundo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "task": "ogx_mmlux_ro-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre algebra abstract.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-anatomy": {
      "task": "ogx_mmlux_ro-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-astronomy": {
      "task": "ogx_mmlux_ro-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu rspunsuri multiple (cu rspunsuri) despre astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-business_ethics": {
      "task": "ogx_mmlux_ro-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre etica n afaceri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "task": "ogx_mmlux_ro-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre cunotinele clinice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_biology": {
      "task": "ogx_mmlux_ro-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre biologia universitar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_chemistry": {
      "task": "ogx_mmlux_ro-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre chimia universitar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_computer_science": {
      "task": "ogx_mmlux_ro-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre informatic universitar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_mathematics": {
      "task": "ogx_mmlux_ro-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre matematica universitar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_medicine": {
      "task": "ogx_mmlux_ro-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre medicina universitar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_physics": {
      "task": "ogx_mmlux_ro-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre fizica universitar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-computer_security": {
      "task": "ogx_mmlux_ro-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre securitatea calculatoarelor.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "task": "ogx_mmlux_ro-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre fizica conceptual.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-econometrics": {
      "task": "ogx_mmlux_ro-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre econometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "task": "ogx_mmlux_ro-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre inginerie electric.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "task": "ogx_mmlux_ro-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre matematic elementar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-formal_logic": {
      "task": "ogx_mmlux_ro-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre logica formal.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-global_facts": {
      "task": "ogx_mmlux_ro-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre fapte globale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_biology": {
      "task": "ogx_mmlux_ro-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre biologia de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "task": "ogx_mmlux_ro-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre chimia de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "task": "ogx_mmlux_ro-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre informatic la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "task": "ogx_mmlux_ro-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre istoria european la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_geography": {
      "task": "ogx_mmlux_ro-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre geografia liceului.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "task": "ogx_mmlux_ro-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre guvernare i politic n liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "task": "ogx_mmlux_ro-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre macroeconomie la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "task": "ogx_mmlux_ro-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre matematica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "task": "ogx_mmlux_ro-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre microeconomie la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_physics": {
      "task": "ogx_mmlux_ro-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre fizica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "task": "ogx_mmlux_ro-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre psihologia liceului.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "task": "ogx_mmlux_ro-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre statistica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "task": "ogx_mmlux_ro-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre istoria noastr la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "task": "ogx_mmlux_ro-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre istoria universal de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-human_aging": {
      "task": "ogx_mmlux_ro-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre mbtrnirea uman.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-human_sexuality": {
      "task": "ogx_mmlux_ro-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre sexualitatea uman.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-international_law": {
      "task": "ogx_mmlux_ro-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre dreptul internaional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-jurisprudence": {
      "task": "ogx_mmlux_ro-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre jurispruden.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "task": "ogx_mmlux_ro-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre erori logice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-machine_learning": {
      "task": "ogx_mmlux_ro-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre nvarea automat.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-management": {
      "task": "ogx_mmlux_ro-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-marketing": {
      "task": "ogx_mmlux_ro-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-medical_genetics": {
      "task": "ogx_mmlux_ro-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre genetica medical.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-miscellaneous": {
      "task": "ogx_mmlux_ro-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-moral_disputes": {
      "task": "ogx_mmlux_ro-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre disputele morale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "task": "ogx_mmlux_ro-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre scenarii morale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-nutrition": {
      "task": "ogx_mmlux_ro-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre nutriie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-philosophy": {
      "task": "ogx_mmlux_ro-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre filosofie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-prehistory": {
      "task": "ogx_mmlux_ro-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre preistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_accounting": {
      "task": "ogx_mmlux_ro-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre contabilitatea profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_law": {
      "task": "ogx_mmlux_ro-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre dreptul profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_medicine": {
      "task": "ogx_mmlux_ro-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre medicina profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_psychology": {
      "task": "ogx_mmlux_ro-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre psihologia profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-public_relations": {
      "task": "ogx_mmlux_ro-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre relaiile publice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-security_studies": {
      "task": "ogx_mmlux_ro-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre studiile de securitate.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-sociology": {
      "task": "ogx_mmlux_ro-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "task": "ogx_mmlux_ro-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu alegere multipl (cu rspunsuri) despre politica extern a SUA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-virology": {
      "task": "ogx_mmlux_ro-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre virusologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-world_religions": {
      "task": "ogx_mmlux_ro-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Urmtoarele sunt ntrebri cu variante multiple de rspuns (cu rspunsuri) despre religiile lumii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "task": "ogx_mmlux_sk-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o abstraktnej algebre.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-anatomy": {
      "task": "ogx_mmlux_sk-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o anatmii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-astronomy": {
      "task": "ogx_mmlux_sk-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o astronmii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-business_ethics": {
      "task": "ogx_mmlux_sk-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o etike v podnikan.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "task": "ogx_mmlux_sk-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o klinickch znalostiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_biology": {
      "task": "ogx_mmlux_sk-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o vysokokolskej biolgii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_chemistry": {
      "task": "ogx_mmlux_sk-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o vysokokolskej chmii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_computer_science": {
      "task": "ogx_mmlux_sk-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o informatike na vysokej kole.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_mathematics": {
      "task": "ogx_mmlux_sk-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o vysokokolskej matematike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_medicine": {
      "task": "ogx_mmlux_sk-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o vysokokolskej medicne.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_physics": {
      "task": "ogx_mmlux_sk-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o vysokokolskej fyzike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-computer_security": {
      "task": "ogx_mmlux_sk-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o potaovej bezpenosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "task": "ogx_mmlux_sk-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o konceptulnej fyzike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-econometrics": {
      "task": "ogx_mmlux_sk-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "task": "ogx_mmlux_sk-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o elektrotechnike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "task": "ogx_mmlux_sk-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o elementrnej matematike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-formal_logic": {
      "task": "ogx_mmlux_sk-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o formlnej logike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-global_facts": {
      "task": "ogx_mmlux_sk-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o globlnych faktoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_biology": {
      "task": "ogx_mmlux_sk-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o stredokolskej biolgii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "task": "ogx_mmlux_sk-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o stredokolskej chmii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "task": "ogx_mmlux_sk-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o stredokolskej informatike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "task": "ogx_mmlux_sk-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o stredokolskch eurpskych dejinch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_geography": {
      "task": "ogx_mmlux_sk-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o stredokolskom zemepise.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "task": "ogx_mmlux_sk-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky (s odpoveami) sa tkaj vldy a politiky na strednch kolch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "task": "ogx_mmlux_sk-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o stredokolskej makroekonmii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "task": "ogx_mmlux_sk-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky (s odpoveami) sa tkaj stredokolskej matematiky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "task": "ogx_mmlux_sk-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) z mikroekonmie pre stredn koly.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_physics": {
      "task": "ogx_mmlux_sk-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) zo stredokolskej fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "task": "ogx_mmlux_sk-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o stredokolskej psycholgii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "task": "ogx_mmlux_sk-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky (s odpoveami) sa tkaj stredokolskej tatistiky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "task": "ogx_mmlux_sk-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) o stredokolskej histrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "task": "ogx_mmlux_sk-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede (s odpoveami) zo svetovch dejn na strednej kole.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-human_aging": {
      "task": "ogx_mmlux_sk-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o starnut loveka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-human_sexuality": {
      "task": "ogx_mmlux_sk-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o udskej sexualite.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-international_law": {
      "task": "ogx_mmlux_sk-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o medzinrodnom prve.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-jurisprudence": {
      "task": "ogx_mmlux_sk-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky (s odpoveami) sa tkaj prvnej vedy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "task": "ogx_mmlux_sk-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o logickch klamoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-machine_learning": {
      "task": "ogx_mmlux_sk-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o strojovom uen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-management": {
      "task": "ogx_mmlux_sk-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o manamente.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-marketing": {
      "task": "ogx_mmlux_sk-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-medical_genetics": {
      "task": "ogx_mmlux_sk-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o lekrskej genetike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-miscellaneous": {
      "task": "ogx_mmlux_sk-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky s vberom odpovede sa tkaj rzneho.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-moral_disputes": {
      "task": "ogx_mmlux_sk-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o morlnych sporoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "task": "ogx_mmlux_sk-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o morlnych scenroch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-nutrition": {
      "task": "ogx_mmlux_sk-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o vive.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-philosophy": {
      "task": "ogx_mmlux_sk-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-prehistory": {
      "task": "ogx_mmlux_sk-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o prehistrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_accounting": {
      "task": "ogx_mmlux_sk-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o odbornom tovnctve.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_law": {
      "task": "ogx_mmlux_sk-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky (s odpoveami) sa tkaj profesijnho prva.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_medicine": {
      "task": "ogx_mmlux_sk-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky (s odpoveami) sa tkaj profesionlnej medicny.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_psychology": {
      "task": "ogx_mmlux_sk-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o profesionlnej psycholgii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-public_relations": {
      "task": "ogx_mmlux_sk-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o vzahoch s verejnosou.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-security_studies": {
      "task": "ogx_mmlux_sk-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o bezpenostnch tdich.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-sociology": {
      "task": "ogx_mmlux_sk-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o sociolgii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "task": "ogx_mmlux_sk-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujce otzky s vberom odpovede sa tkaj zahraninej politiky USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-virology": {
      "task": "ogx_mmlux_sk-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o virolgii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-world_religions": {
      "task": "ogx_mmlux_sk-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpove:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasleduj otzky s vberom odpovede o svetovch nboenstvch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "task": "ogx_mmlux_sl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o abstraktni algebri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-anatomy": {
      "task": "ogx_mmlux_sl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o anatomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-astronomy": {
      "task": "ogx_mmlux_sl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o astronomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-business_ethics": {
      "task": "ogx_mmlux_sl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o poslovni etiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "task": "ogx_mmlux_sl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o klininem znanju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_biology": {
      "task": "ogx_mmlux_sl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o biologiji na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_chemistry": {
      "task": "ogx_mmlux_sl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o kemiji na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_computer_science": {
      "task": "ogx_mmlux_sl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o raunalnitvu na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_mathematics": {
      "task": "ogx_mmlux_sl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o matematiki na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_medicine": {
      "task": "ogx_mmlux_sl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o univerzitetni medicini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_physics": {
      "task": "ogx_mmlux_sl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o fiziki na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-computer_security": {
      "task": "ogx_mmlux_sl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o raunalniki varnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "task": "ogx_mmlux_sl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o konceptualni fiziki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-econometrics": {
      "task": "ogx_mmlux_sl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o ekonometriji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "task": "ogx_mmlux_sl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o elektrotehniki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "task": "ogx_mmlux_sl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o osnovni matematiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-formal_logic": {
      "task": "ogx_mmlux_sl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o formalni logiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-global_facts": {
      "task": "ogx_mmlux_sl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o globalnih dejstvih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_biology": {
      "task": "ogx_mmlux_sl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o srednjeolski biologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "task": "ogx_mmlux_sl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o kemiji v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "task": "ogx_mmlux_sl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o raunalnitvu v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "task": "ogx_mmlux_sl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o evropski zgodovini v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_geography": {
      "task": "ogx_mmlux_sl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o geografiji v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "task": "ogx_mmlux_sl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o vladi in politiki v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "task": "ogx_mmlux_sl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o srednjeolski makroekonomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "task": "ogx_mmlux_sl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o matematiki v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "task": "ogx_mmlux_sl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o srednjeolski mikroekonomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_physics": {
      "task": "ogx_mmlux_sl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) s podroja srednjeolske fizike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "task": "ogx_mmlux_sl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o srednjeolski psihologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "task": "ogx_mmlux_sl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o srednjeolski statistiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "task": "ogx_mmlux_sl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o srednjeolski zgodovini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "task": "ogx_mmlux_sl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o svetovni zgodovini v srednji oli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-human_aging": {
      "task": "ogx_mmlux_sl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o staranju loveka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-human_sexuality": {
      "task": "ogx_mmlux_sl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o loveki spolnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-international_law": {
      "task": "ogx_mmlux_sl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o mednarodnem pravu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-jurisprudence": {
      "task": "ogx_mmlux_sl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o sodni praksi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "task": "ogx_mmlux_sl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o loginih zmotah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-machine_learning": {
      "task": "ogx_mmlux_sl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o strojnem uenju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-management": {
      "task": "ogx_mmlux_sl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o upravljanju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-marketing": {
      "task": "ogx_mmlux_sl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o trenju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-medical_genetics": {
      "task": "ogx_mmlux_sl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o medicinski genetiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-miscellaneous": {
      "task": "ogx_mmlux_sl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o raznih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-moral_disputes": {
      "task": "ogx_mmlux_sl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o moralnih sporih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "task": "ogx_mmlux_sl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o moralnih scenarijih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-nutrition": {
      "task": "ogx_mmlux_sl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o prehrani.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-philosophy": {
      "task": "ogx_mmlux_sl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o filozofiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-prehistory": {
      "task": "ogx_mmlux_sl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o prazgodovini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_accounting": {
      "task": "ogx_mmlux_sl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o strokovnem raunovodstvu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_law": {
      "task": "ogx_mmlux_sl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o poklicnem pravu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_medicine": {
      "task": "ogx_mmlux_sl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o poklicni medicini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_psychology": {
      "task": "ogx_mmlux_sl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o poklicni psihologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-public_relations": {
      "task": "ogx_mmlux_sl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o odnosih z javnostmi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-security_studies": {
      "task": "ogx_mmlux_sl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o varnostnih tudijah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-sociology": {
      "task": "ogx_mmlux_sl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o sociologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "task": "ogx_mmlux_sl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o zunanji politiki ZDA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-virology": {
      "task": "ogx_mmlux_sl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o virologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-world_religions": {
      "task": "ogx_mmlux_sl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vpraanja (z odgovori) o svetovnih religijah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "task": "ogx_mmlux_sv-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om abstrakt algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-anatomy": {
      "task": "ogx_mmlux_sv-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om anatomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-astronomy": {
      "task": "ogx_mmlux_sv-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om astronomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-business_ethics": {
      "task": "ogx_mmlux_sv-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om affrsetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "task": "ogx_mmlux_sv-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om klinisk kunskap.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_biology": {
      "task": "ogx_mmlux_sv-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om biologi p hgskoleniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_chemistry": {
      "task": "ogx_mmlux_sv-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om kemi p hgskoleniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_computer_science": {
      "task": "ogx_mmlux_sv-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om datavetenskap p hgskoleniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_mathematics": {
      "task": "ogx_mmlux_sv-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om matematik p hgskoleniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_medicine": {
      "task": "ogx_mmlux_sv-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om universitetsmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_physics": {
      "task": "ogx_mmlux_sv-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om hgskolefysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-computer_security": {
      "task": "ogx_mmlux_sv-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om dataskerhet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "task": "ogx_mmlux_sv-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om konceptuell fysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-econometrics": {
      "task": "ogx_mmlux_sv-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om ekonometri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "task": "ogx_mmlux_sv-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om elektroteknik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "task": "ogx_mmlux_sv-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om elementr matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-formal_logic": {
      "task": "ogx_mmlux_sv-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om formell logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-global_facts": {
      "task": "ogx_mmlux_sv-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om globala fakta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_biology": {
      "task": "ogx_mmlux_sv-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om biologi p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "task": "ogx_mmlux_sv-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om kemi p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "task": "ogx_mmlux_sv-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om datavetenskap p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "task": "ogx_mmlux_sv-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om europeisk historia p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_geography": {
      "task": "ogx_mmlux_sv-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om geografi p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "task": "ogx_mmlux_sv-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om regering och politik p gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "task": "ogx_mmlux_sv-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om makroekonomi p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "task": "ogx_mmlux_sv-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om matematik p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "task": "ogx_mmlux_sv-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om mikroekonomi p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_physics": {
      "task": "ogx_mmlux_sv-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om fysik p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "task": "ogx_mmlux_sv-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om psykologi p gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "task": "ogx_mmlux_sv-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om statistik p gymnasieniv.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "task": "ogx_mmlux_sv-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om historia i USA p gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "task": "ogx_mmlux_sv-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om vrldshistoria p gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-human_aging": {
      "task": "ogx_mmlux_sv-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om mnniskans ldrande.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-human_sexuality": {
      "task": "ogx_mmlux_sv-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om mnsklig sexualitet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-international_law": {
      "task": "ogx_mmlux_sv-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om internationell rtt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-jurisprudence": {
      "task": "ogx_mmlux_sv-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om rttsvetenskap.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "task": "ogx_mmlux_sv-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om logiska felslut.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-machine_learning": {
      "task": "ogx_mmlux_sv-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om maskininlrning.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-management": {
      "task": "ogx_mmlux_sv-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-marketing": {
      "task": "ogx_mmlux_sv-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om marknadsfring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-medical_genetics": {
      "task": "ogx_mmlux_sv-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om medicinsk genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-miscellaneous": {
      "task": "ogx_mmlux_sv-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-moral_disputes": {
      "task": "ogx_mmlux_sv-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om moraliska tvister.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "task": "ogx_mmlux_sv-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om moraliska scenarier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-nutrition": {
      "task": "ogx_mmlux_sv-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om nringslra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-philosophy": {
      "task": "ogx_mmlux_sv-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om filosofi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-prehistory": {
      "task": "ogx_mmlux_sv-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om frhistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_accounting": {
      "task": "ogx_mmlux_sv-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om professionell redovisning.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_law": {
      "task": "ogx_mmlux_sv-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om yrkesrtt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_medicine": {
      "task": "ogx_mmlux_sv-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om yrkesmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_psychology": {
      "task": "ogx_mmlux_sv-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om professionell psykologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-public_relations": {
      "task": "ogx_mmlux_sv-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-security_studies": {
      "task": "ogx_mmlux_sv-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om skerhetsstudier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-sociology": {
      "task": "ogx_mmlux_sv-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om sociologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "task": "ogx_mmlux_sv-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om USA:s utrikespolitik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-virology": {
      "task": "ogx_mmlux_sv-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om virologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-world_religions": {
      "task": "ogx_mmlux_sv-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Fljande r flervalsfrgor (med svar) om vrldsreligioner.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    }
  },
  "versions": {
    "ogx_mmlux_bg-abstract_algebra": 0,
    "ogx_mmlux_bg-anatomy": 0,
    "ogx_mmlux_bg-astronomy": 0,
    "ogx_mmlux_bg-business_ethics": 0,
    "ogx_mmlux_bg-clinical_knowledge": 0,
    "ogx_mmlux_bg-college_biology": 0,
    "ogx_mmlux_bg-college_chemistry": 0,
    "ogx_mmlux_bg-college_computer_science": 0,
    "ogx_mmlux_bg-college_mathematics": 0,
    "ogx_mmlux_bg-college_medicine": 0,
    "ogx_mmlux_bg-college_physics": 0,
    "ogx_mmlux_bg-computer_security": 0,
    "ogx_mmlux_bg-conceptual_physics": 0,
    "ogx_mmlux_bg-econometrics": 0,
    "ogx_mmlux_bg-electrical_engineering": 0,
    "ogx_mmlux_bg-elementary_mathematics": 0,
    "ogx_mmlux_bg-formal_logic": 0,
    "ogx_mmlux_bg-global_facts": 0,
    "ogx_mmlux_bg-high_school_biology": 0,
    "ogx_mmlux_bg-high_school_chemistry": 0,
    "ogx_mmlux_bg-high_school_computer_science": 0,
    "ogx_mmlux_bg-high_school_european_history": 0,
    "ogx_mmlux_bg-high_school_geography": 0,
    "ogx_mmlux_bg-high_school_government_and_politics": 0,
    "ogx_mmlux_bg-high_school_macroeconomics": 0,
    "ogx_mmlux_bg-high_school_mathematics": 0,
    "ogx_mmlux_bg-high_school_microeconomics": 0,
    "ogx_mmlux_bg-high_school_physics": 0,
    "ogx_mmlux_bg-high_school_psychology": 0,
    "ogx_mmlux_bg-high_school_statistics": 0,
    "ogx_mmlux_bg-high_school_us_history": 0,
    "ogx_mmlux_bg-high_school_world_history": 0,
    "ogx_mmlux_bg-human_aging": 0,
    "ogx_mmlux_bg-human_sexuality": 0,
    "ogx_mmlux_bg-international_law": 0,
    "ogx_mmlux_bg-jurisprudence": 0,
    "ogx_mmlux_bg-logical_fallacies": 0,
    "ogx_mmlux_bg-machine_learning": 0,
    "ogx_mmlux_bg-management": 0,
    "ogx_mmlux_bg-marketing": 0,
    "ogx_mmlux_bg-medical_genetics": 0,
    "ogx_mmlux_bg-miscellaneous": 0,
    "ogx_mmlux_bg-moral_disputes": 0,
    "ogx_mmlux_bg-moral_scenarios": 0,
    "ogx_mmlux_bg-nutrition": 0,
    "ogx_mmlux_bg-philosophy": 0,
    "ogx_mmlux_bg-prehistory": 0,
    "ogx_mmlux_bg-professional_accounting": 0,
    "ogx_mmlux_bg-professional_law": 0,
    "ogx_mmlux_bg-professional_medicine": 0,
    "ogx_mmlux_bg-professional_psychology": 0,
    "ogx_mmlux_bg-public_relations": 0,
    "ogx_mmlux_bg-security_studies": 0,
    "ogx_mmlux_bg-sociology": 0,
    "ogx_mmlux_bg-us_foreign_policy": 0,
    "ogx_mmlux_bg-virology": 0,
    "ogx_mmlux_bg-world_religions": 0,
    "ogx_mmlux_cs-abstract_algebra": 0,
    "ogx_mmlux_cs-anatomy": 0,
    "ogx_mmlux_cs-astronomy": 0,
    "ogx_mmlux_cs-business_ethics": 0,
    "ogx_mmlux_cs-clinical_knowledge": 0,
    "ogx_mmlux_cs-college_biology": 0,
    "ogx_mmlux_cs-college_chemistry": 0,
    "ogx_mmlux_cs-college_computer_science": 0,
    "ogx_mmlux_cs-college_mathematics": 0,
    "ogx_mmlux_cs-college_medicine": 0,
    "ogx_mmlux_cs-college_physics": 0,
    "ogx_mmlux_cs-computer_security": 0,
    "ogx_mmlux_cs-conceptual_physics": 0,
    "ogx_mmlux_cs-econometrics": 0,
    "ogx_mmlux_cs-electrical_engineering": 0,
    "ogx_mmlux_cs-elementary_mathematics": 0,
    "ogx_mmlux_cs-formal_logic": 0,
    "ogx_mmlux_cs-global_facts": 0,
    "ogx_mmlux_cs-high_school_biology": 0,
    "ogx_mmlux_cs-high_school_chemistry": 0,
    "ogx_mmlux_cs-high_school_computer_science": 0,
    "ogx_mmlux_cs-high_school_european_history": 0,
    "ogx_mmlux_cs-high_school_geography": 0,
    "ogx_mmlux_cs-high_school_government_and_politics": 0,
    "ogx_mmlux_cs-high_school_macroeconomics": 0,
    "ogx_mmlux_cs-high_school_mathematics": 0,
    "ogx_mmlux_cs-high_school_microeconomics": 0,
    "ogx_mmlux_cs-high_school_physics": 0,
    "ogx_mmlux_cs-high_school_psychology": 0,
    "ogx_mmlux_cs-high_school_statistics": 0,
    "ogx_mmlux_cs-high_school_us_history": 0,
    "ogx_mmlux_cs-high_school_world_history": 0,
    "ogx_mmlux_cs-human_aging": 0,
    "ogx_mmlux_cs-human_sexuality": 0,
    "ogx_mmlux_cs-international_law": 0,
    "ogx_mmlux_cs-jurisprudence": 0,
    "ogx_mmlux_cs-logical_fallacies": 0,
    "ogx_mmlux_cs-machine_learning": 0,
    "ogx_mmlux_cs-management": 0,
    "ogx_mmlux_cs-marketing": 0,
    "ogx_mmlux_cs-medical_genetics": 0,
    "ogx_mmlux_cs-miscellaneous": 0,
    "ogx_mmlux_cs-moral_disputes": 0,
    "ogx_mmlux_cs-moral_scenarios": 0,
    "ogx_mmlux_cs-nutrition": 0,
    "ogx_mmlux_cs-philosophy": 0,
    "ogx_mmlux_cs-prehistory": 0,
    "ogx_mmlux_cs-professional_accounting": 0,
    "ogx_mmlux_cs-professional_law": 0,
    "ogx_mmlux_cs-professional_medicine": 0,
    "ogx_mmlux_cs-professional_psychology": 0,
    "ogx_mmlux_cs-public_relations": 0,
    "ogx_mmlux_cs-security_studies": 0,
    "ogx_mmlux_cs-sociology": 0,
    "ogx_mmlux_cs-us_foreign_policy": 0,
    "ogx_mmlux_cs-virology": 0,
    "ogx_mmlux_cs-world_religions": 0,
    "ogx_mmlux_da-abstract_algebra": 0,
    "ogx_mmlux_da-anatomy": 0,
    "ogx_mmlux_da-astronomy": 0,
    "ogx_mmlux_da-business_ethics": 0,
    "ogx_mmlux_da-clinical_knowledge": 0,
    "ogx_mmlux_da-college_biology": 0,
    "ogx_mmlux_da-college_chemistry": 0,
    "ogx_mmlux_da-college_computer_science": 0,
    "ogx_mmlux_da-college_mathematics": 0,
    "ogx_mmlux_da-college_medicine": 0,
    "ogx_mmlux_da-college_physics": 0,
    "ogx_mmlux_da-computer_security": 0,
    "ogx_mmlux_da-conceptual_physics": 0,
    "ogx_mmlux_da-econometrics": 0,
    "ogx_mmlux_da-electrical_engineering": 0,
    "ogx_mmlux_da-elementary_mathematics": 0,
    "ogx_mmlux_da-formal_logic": 0,
    "ogx_mmlux_da-global_facts": 0,
    "ogx_mmlux_da-high_school_biology": 0,
    "ogx_mmlux_da-high_school_chemistry": 0,
    "ogx_mmlux_da-high_school_computer_science": 0,
    "ogx_mmlux_da-high_school_european_history": 0,
    "ogx_mmlux_da-high_school_geography": 0,
    "ogx_mmlux_da-high_school_government_and_politics": 0,
    "ogx_mmlux_da-high_school_macroeconomics": 0,
    "ogx_mmlux_da-high_school_mathematics": 0,
    "ogx_mmlux_da-high_school_microeconomics": 0,
    "ogx_mmlux_da-high_school_physics": 0,
    "ogx_mmlux_da-high_school_psychology": 0,
    "ogx_mmlux_da-high_school_statistics": 0,
    "ogx_mmlux_da-high_school_us_history": 0,
    "ogx_mmlux_da-high_school_world_history": 0,
    "ogx_mmlux_da-human_aging": 0,
    "ogx_mmlux_da-human_sexuality": 0,
    "ogx_mmlux_da-international_law": 0,
    "ogx_mmlux_da-jurisprudence": 0,
    "ogx_mmlux_da-logical_fallacies": 0,
    "ogx_mmlux_da-machine_learning": 0,
    "ogx_mmlux_da-management": 0,
    "ogx_mmlux_da-marketing": 0,
    "ogx_mmlux_da-medical_genetics": 0,
    "ogx_mmlux_da-miscellaneous": 0,
    "ogx_mmlux_da-moral_disputes": 0,
    "ogx_mmlux_da-moral_scenarios": 0,
    "ogx_mmlux_da-nutrition": 0,
    "ogx_mmlux_da-philosophy": 0,
    "ogx_mmlux_da-prehistory": 0,
    "ogx_mmlux_da-professional_accounting": 0,
    "ogx_mmlux_da-professional_law": 0,
    "ogx_mmlux_da-professional_medicine": 0,
    "ogx_mmlux_da-professional_psychology": 0,
    "ogx_mmlux_da-public_relations": 0,
    "ogx_mmlux_da-security_studies": 0,
    "ogx_mmlux_da-sociology": 0,
    "ogx_mmlux_da-us_foreign_policy": 0,
    "ogx_mmlux_da-virology": 0,
    "ogx_mmlux_da-world_religions": 0,
    "ogx_mmlux_de-abstract_algebra": 0,
    "ogx_mmlux_de-anatomy": 0,
    "ogx_mmlux_de-astronomy": 0,
    "ogx_mmlux_de-business_ethics": 0,
    "ogx_mmlux_de-clinical_knowledge": 0,
    "ogx_mmlux_de-college_biology": 0,
    "ogx_mmlux_de-college_chemistry": 0,
    "ogx_mmlux_de-college_computer_science": 0,
    "ogx_mmlux_de-college_mathematics": 0,
    "ogx_mmlux_de-college_medicine": 0,
    "ogx_mmlux_de-college_physics": 0,
    "ogx_mmlux_de-computer_security": 0,
    "ogx_mmlux_de-conceptual_physics": 0,
    "ogx_mmlux_de-econometrics": 0,
    "ogx_mmlux_de-electrical_engineering": 0,
    "ogx_mmlux_de-elementary_mathematics": 0,
    "ogx_mmlux_de-formal_logic": 0,
    "ogx_mmlux_de-global_facts": 0,
    "ogx_mmlux_de-high_school_biology": 0,
    "ogx_mmlux_de-high_school_chemistry": 0,
    "ogx_mmlux_de-high_school_computer_science": 0,
    "ogx_mmlux_de-high_school_european_history": 0,
    "ogx_mmlux_de-high_school_geography": 0,
    "ogx_mmlux_de-high_school_government_and_politics": 0,
    "ogx_mmlux_de-high_school_macroeconomics": 0,
    "ogx_mmlux_de-high_school_mathematics": 0,
    "ogx_mmlux_de-high_school_microeconomics": 0,
    "ogx_mmlux_de-high_school_physics": 0,
    "ogx_mmlux_de-high_school_psychology": 0,
    "ogx_mmlux_de-high_school_statistics": 0,
    "ogx_mmlux_de-high_school_us_history": 0,
    "ogx_mmlux_de-high_school_world_history": 0,
    "ogx_mmlux_de-human_aging": 0,
    "ogx_mmlux_de-human_sexuality": 0,
    "ogx_mmlux_de-international_law": 0,
    "ogx_mmlux_de-jurisprudence": 0,
    "ogx_mmlux_de-logical_fallacies": 0,
    "ogx_mmlux_de-machine_learning": 0,
    "ogx_mmlux_de-management": 0,
    "ogx_mmlux_de-marketing": 0,
    "ogx_mmlux_de-medical_genetics": 0,
    "ogx_mmlux_de-miscellaneous": 0,
    "ogx_mmlux_de-moral_disputes": 0,
    "ogx_mmlux_de-moral_scenarios": 0,
    "ogx_mmlux_de-nutrition": 0,
    "ogx_mmlux_de-philosophy": 0,
    "ogx_mmlux_de-prehistory": 0,
    "ogx_mmlux_de-professional_accounting": 0,
    "ogx_mmlux_de-professional_law": 0,
    "ogx_mmlux_de-professional_medicine": 0,
    "ogx_mmlux_de-professional_psychology": 0,
    "ogx_mmlux_de-public_relations": 0,
    "ogx_mmlux_de-security_studies": 0,
    "ogx_mmlux_de-sociology": 0,
    "ogx_mmlux_de-us_foreign_policy": 0,
    "ogx_mmlux_de-virology": 0,
    "ogx_mmlux_de-world_religions": 0,
    "ogx_mmlux_el-abstract_algebra": 0,
    "ogx_mmlux_el-anatomy": 0,
    "ogx_mmlux_el-astronomy": 0,
    "ogx_mmlux_el-business_ethics": 0,
    "ogx_mmlux_el-clinical_knowledge": 0,
    "ogx_mmlux_el-college_biology": 0,
    "ogx_mmlux_el-college_chemistry": 0,
    "ogx_mmlux_el-college_computer_science": 0,
    "ogx_mmlux_el-college_mathematics": 0,
    "ogx_mmlux_el-college_medicine": 0,
    "ogx_mmlux_el-college_physics": 0,
    "ogx_mmlux_el-computer_security": 0,
    "ogx_mmlux_el-conceptual_physics": 0,
    "ogx_mmlux_el-econometrics": 0,
    "ogx_mmlux_el-electrical_engineering": 0,
    "ogx_mmlux_el-elementary_mathematics": 0,
    "ogx_mmlux_el-formal_logic": 0,
    "ogx_mmlux_el-global_facts": 0,
    "ogx_mmlux_el-high_school_biology": 0,
    "ogx_mmlux_el-high_school_chemistry": 0,
    "ogx_mmlux_el-high_school_computer_science": 0,
    "ogx_mmlux_el-high_school_european_history": 0,
    "ogx_mmlux_el-high_school_geography": 0,
    "ogx_mmlux_el-high_school_government_and_politics": 0,
    "ogx_mmlux_el-high_school_macroeconomics": 0,
    "ogx_mmlux_el-high_school_mathematics": 0,
    "ogx_mmlux_el-high_school_microeconomics": 0,
    "ogx_mmlux_el-high_school_physics": 0,
    "ogx_mmlux_el-high_school_psychology": 0,
    "ogx_mmlux_el-high_school_statistics": 0,
    "ogx_mmlux_el-high_school_us_history": 0,
    "ogx_mmlux_el-high_school_world_history": 0,
    "ogx_mmlux_el-human_aging": 0,
    "ogx_mmlux_el-human_sexuality": 0,
    "ogx_mmlux_el-international_law": 0,
    "ogx_mmlux_el-jurisprudence": 0,
    "ogx_mmlux_el-logical_fallacies": 0,
    "ogx_mmlux_el-machine_learning": 0,
    "ogx_mmlux_el-management": 0,
    "ogx_mmlux_el-marketing": 0,
    "ogx_mmlux_el-medical_genetics": 0,
    "ogx_mmlux_el-miscellaneous": 0,
    "ogx_mmlux_el-moral_disputes": 0,
    "ogx_mmlux_el-moral_scenarios": 0,
    "ogx_mmlux_el-nutrition": 0,
    "ogx_mmlux_el-philosophy": 0,
    "ogx_mmlux_el-prehistory": 0,
    "ogx_mmlux_el-professional_accounting": 0,
    "ogx_mmlux_el-professional_law": 0,
    "ogx_mmlux_el-professional_medicine": 0,
    "ogx_mmlux_el-professional_psychology": 0,
    "ogx_mmlux_el-public_relations": 0,
    "ogx_mmlux_el-security_studies": 0,
    "ogx_mmlux_el-sociology": 0,
    "ogx_mmlux_el-us_foreign_policy": 0,
    "ogx_mmlux_el-virology": 0,
    "ogx_mmlux_el-world_religions": 0,
    "ogx_mmlux_es-abstract_algebra": 0,
    "ogx_mmlux_es-anatomy": 0,
    "ogx_mmlux_es-astronomy": 0,
    "ogx_mmlux_es-business_ethics": 0,
    "ogx_mmlux_es-clinical_knowledge": 0,
    "ogx_mmlux_es-college_biology": 0,
    "ogx_mmlux_es-college_chemistry": 0,
    "ogx_mmlux_es-college_computer_science": 0,
    "ogx_mmlux_es-college_mathematics": 0,
    "ogx_mmlux_es-college_medicine": 0,
    "ogx_mmlux_es-college_physics": 0,
    "ogx_mmlux_es-computer_security": 0,
    "ogx_mmlux_es-conceptual_physics": 0,
    "ogx_mmlux_es-econometrics": 0,
    "ogx_mmlux_es-electrical_engineering": 0,
    "ogx_mmlux_es-elementary_mathematics": 0,
    "ogx_mmlux_es-formal_logic": 0,
    "ogx_mmlux_es-global_facts": 0,
    "ogx_mmlux_es-high_school_biology": 0,
    "ogx_mmlux_es-high_school_chemistry": 0,
    "ogx_mmlux_es-high_school_computer_science": 0,
    "ogx_mmlux_es-high_school_european_history": 0,
    "ogx_mmlux_es-high_school_geography": 0,
    "ogx_mmlux_es-high_school_government_and_politics": 0,
    "ogx_mmlux_es-high_school_macroeconomics": 0,
    "ogx_mmlux_es-high_school_mathematics": 0,
    "ogx_mmlux_es-high_school_microeconomics": 0,
    "ogx_mmlux_es-high_school_physics": 0,
    "ogx_mmlux_es-high_school_psychology": 0,
    "ogx_mmlux_es-high_school_statistics": 0,
    "ogx_mmlux_es-high_school_us_history": 0,
    "ogx_mmlux_es-high_school_world_history": 0,
    "ogx_mmlux_es-human_aging": 0,
    "ogx_mmlux_es-human_sexuality": 0,
    "ogx_mmlux_es-international_law": 0,
    "ogx_mmlux_es-jurisprudence": 0,
    "ogx_mmlux_es-logical_fallacies": 0,
    "ogx_mmlux_es-machine_learning": 0,
    "ogx_mmlux_es-management": 0,
    "ogx_mmlux_es-marketing": 0,
    "ogx_mmlux_es-medical_genetics": 0,
    "ogx_mmlux_es-miscellaneous": 0,
    "ogx_mmlux_es-moral_disputes": 0,
    "ogx_mmlux_es-moral_scenarios": 0,
    "ogx_mmlux_es-nutrition": 0,
    "ogx_mmlux_es-philosophy": 0,
    "ogx_mmlux_es-prehistory": 0,
    "ogx_mmlux_es-professional_accounting": 0,
    "ogx_mmlux_es-professional_law": 0,
    "ogx_mmlux_es-professional_medicine": 0,
    "ogx_mmlux_es-professional_psychology": 0,
    "ogx_mmlux_es-public_relations": 0,
    "ogx_mmlux_es-security_studies": 0,
    "ogx_mmlux_es-sociology": 0,
    "ogx_mmlux_es-us_foreign_policy": 0,
    "ogx_mmlux_es-virology": 0,
    "ogx_mmlux_es-world_religions": 0,
    "ogx_mmlux_et-abstract_algebra": 0,
    "ogx_mmlux_et-anatomy": 0,
    "ogx_mmlux_et-astronomy": 0,
    "ogx_mmlux_et-business_ethics": 0,
    "ogx_mmlux_et-clinical_knowledge": 0,
    "ogx_mmlux_et-college_biology": 0,
    "ogx_mmlux_et-college_chemistry": 0,
    "ogx_mmlux_et-college_computer_science": 0,
    "ogx_mmlux_et-college_mathematics": 0,
    "ogx_mmlux_et-college_medicine": 0,
    "ogx_mmlux_et-college_physics": 0,
    "ogx_mmlux_et-computer_security": 0,
    "ogx_mmlux_et-conceptual_physics": 0,
    "ogx_mmlux_et-econometrics": 0,
    "ogx_mmlux_et-electrical_engineering": 0,
    "ogx_mmlux_et-elementary_mathematics": 0,
    "ogx_mmlux_et-formal_logic": 0,
    "ogx_mmlux_et-global_facts": 0,
    "ogx_mmlux_et-high_school_biology": 0,
    "ogx_mmlux_et-high_school_chemistry": 0,
    "ogx_mmlux_et-high_school_computer_science": 0,
    "ogx_mmlux_et-high_school_european_history": 0,
    "ogx_mmlux_et-high_school_geography": 0,
    "ogx_mmlux_et-high_school_government_and_politics": 0,
    "ogx_mmlux_et-high_school_macroeconomics": 0,
    "ogx_mmlux_et-high_school_mathematics": 0,
    "ogx_mmlux_et-high_school_microeconomics": 0,
    "ogx_mmlux_et-high_school_physics": 0,
    "ogx_mmlux_et-high_school_psychology": 0,
    "ogx_mmlux_et-high_school_statistics": 0,
    "ogx_mmlux_et-high_school_us_history": 0,
    "ogx_mmlux_et-high_school_world_history": 0,
    "ogx_mmlux_et-human_aging": 0,
    "ogx_mmlux_et-human_sexuality": 0,
    "ogx_mmlux_et-international_law": 0,
    "ogx_mmlux_et-jurisprudence": 0,
    "ogx_mmlux_et-logical_fallacies": 0,
    "ogx_mmlux_et-machine_learning": 0,
    "ogx_mmlux_et-management": 0,
    "ogx_mmlux_et-marketing": 0,
    "ogx_mmlux_et-medical_genetics": 0,
    "ogx_mmlux_et-miscellaneous": 0,
    "ogx_mmlux_et-moral_disputes": 0,
    "ogx_mmlux_et-moral_scenarios": 0,
    "ogx_mmlux_et-nutrition": 0,
    "ogx_mmlux_et-philosophy": 0,
    "ogx_mmlux_et-prehistory": 0,
    "ogx_mmlux_et-professional_accounting": 0,
    "ogx_mmlux_et-professional_law": 0,
    "ogx_mmlux_et-professional_medicine": 0,
    "ogx_mmlux_et-professional_psychology": 0,
    "ogx_mmlux_et-public_relations": 0,
    "ogx_mmlux_et-security_studies": 0,
    "ogx_mmlux_et-sociology": 0,
    "ogx_mmlux_et-us_foreign_policy": 0,
    "ogx_mmlux_et-virology": 0,
    "ogx_mmlux_et-world_religions": 0,
    "ogx_mmlux_fi-abstract_algebra": 0,
    "ogx_mmlux_fi-anatomy": 0,
    "ogx_mmlux_fi-astronomy": 0,
    "ogx_mmlux_fi-business_ethics": 0,
    "ogx_mmlux_fi-clinical_knowledge": 0,
    "ogx_mmlux_fi-college_biology": 0,
    "ogx_mmlux_fi-college_chemistry": 0,
    "ogx_mmlux_fi-college_computer_science": 0,
    "ogx_mmlux_fi-college_mathematics": 0,
    "ogx_mmlux_fi-college_medicine": 0,
    "ogx_mmlux_fi-college_physics": 0,
    "ogx_mmlux_fi-computer_security": 0,
    "ogx_mmlux_fi-conceptual_physics": 0,
    "ogx_mmlux_fi-econometrics": 0,
    "ogx_mmlux_fi-electrical_engineering": 0,
    "ogx_mmlux_fi-elementary_mathematics": 0,
    "ogx_mmlux_fi-formal_logic": 0,
    "ogx_mmlux_fi-global_facts": 0,
    "ogx_mmlux_fi-high_school_biology": 0,
    "ogx_mmlux_fi-high_school_chemistry": 0,
    "ogx_mmlux_fi-high_school_computer_science": 0,
    "ogx_mmlux_fi-high_school_european_history": 0,
    "ogx_mmlux_fi-high_school_geography": 0,
    "ogx_mmlux_fi-high_school_government_and_politics": 0,
    "ogx_mmlux_fi-high_school_macroeconomics": 0,
    "ogx_mmlux_fi-high_school_mathematics": 0,
    "ogx_mmlux_fi-high_school_microeconomics": 0,
    "ogx_mmlux_fi-high_school_physics": 0,
    "ogx_mmlux_fi-high_school_psychology": 0,
    "ogx_mmlux_fi-high_school_statistics": 0,
    "ogx_mmlux_fi-high_school_us_history": 0,
    "ogx_mmlux_fi-high_school_world_history": 0,
    "ogx_mmlux_fi-human_aging": 0,
    "ogx_mmlux_fi-human_sexuality": 0,
    "ogx_mmlux_fi-international_law": 0,
    "ogx_mmlux_fi-jurisprudence": 0,
    "ogx_mmlux_fi-logical_fallacies": 0,
    "ogx_mmlux_fi-machine_learning": 0,
    "ogx_mmlux_fi-management": 0,
    "ogx_mmlux_fi-marketing": 0,
    "ogx_mmlux_fi-medical_genetics": 0,
    "ogx_mmlux_fi-miscellaneous": 0,
    "ogx_mmlux_fi-moral_disputes": 0,
    "ogx_mmlux_fi-moral_scenarios": 0,
    "ogx_mmlux_fi-nutrition": 0,
    "ogx_mmlux_fi-philosophy": 0,
    "ogx_mmlux_fi-prehistory": 0,
    "ogx_mmlux_fi-professional_accounting": 0,
    "ogx_mmlux_fi-professional_law": 0,
    "ogx_mmlux_fi-professional_medicine": 0,
    "ogx_mmlux_fi-professional_psychology": 0,
    "ogx_mmlux_fi-public_relations": 0,
    "ogx_mmlux_fi-security_studies": 0,
    "ogx_mmlux_fi-sociology": 0,
    "ogx_mmlux_fi-us_foreign_policy": 0,
    "ogx_mmlux_fi-virology": 0,
    "ogx_mmlux_fi-world_religions": 0,
    "ogx_mmlux_fr-abstract_algebra": 0,
    "ogx_mmlux_fr-anatomy": 0,
    "ogx_mmlux_fr-astronomy": 0,
    "ogx_mmlux_fr-business_ethics": 0,
    "ogx_mmlux_fr-clinical_knowledge": 0,
    "ogx_mmlux_fr-college_biology": 0,
    "ogx_mmlux_fr-college_chemistry": 0,
    "ogx_mmlux_fr-college_computer_science": 0,
    "ogx_mmlux_fr-college_mathematics": 0,
    "ogx_mmlux_fr-college_medicine": 0,
    "ogx_mmlux_fr-college_physics": 0,
    "ogx_mmlux_fr-computer_security": 0,
    "ogx_mmlux_fr-conceptual_physics": 0,
    "ogx_mmlux_fr-econometrics": 0,
    "ogx_mmlux_fr-electrical_engineering": 0,
    "ogx_mmlux_fr-elementary_mathematics": 0,
    "ogx_mmlux_fr-formal_logic": 0,
    "ogx_mmlux_fr-global_facts": 0,
    "ogx_mmlux_fr-high_school_biology": 0,
    "ogx_mmlux_fr-high_school_chemistry": 0,
    "ogx_mmlux_fr-high_school_computer_science": 0,
    "ogx_mmlux_fr-high_school_european_history": 0,
    "ogx_mmlux_fr-high_school_geography": 0,
    "ogx_mmlux_fr-high_school_government_and_politics": 0,
    "ogx_mmlux_fr-high_school_macroeconomics": 0,
    "ogx_mmlux_fr-high_school_mathematics": 0,
    "ogx_mmlux_fr-high_school_microeconomics": 0,
    "ogx_mmlux_fr-high_school_physics": 0,
    "ogx_mmlux_fr-high_school_psychology": 0,
    "ogx_mmlux_fr-high_school_statistics": 0,
    "ogx_mmlux_fr-high_school_us_history": 0,
    "ogx_mmlux_fr-high_school_world_history": 0,
    "ogx_mmlux_fr-human_aging": 0,
    "ogx_mmlux_fr-human_sexuality": 0,
    "ogx_mmlux_fr-international_law": 0,
    "ogx_mmlux_fr-jurisprudence": 0,
    "ogx_mmlux_fr-logical_fallacies": 0,
    "ogx_mmlux_fr-machine_learning": 0,
    "ogx_mmlux_fr-management": 0,
    "ogx_mmlux_fr-marketing": 0,
    "ogx_mmlux_fr-medical_genetics": 0,
    "ogx_mmlux_fr-miscellaneous": 0,
    "ogx_mmlux_fr-moral_disputes": 0,
    "ogx_mmlux_fr-moral_scenarios": 0,
    "ogx_mmlux_fr-nutrition": 0,
    "ogx_mmlux_fr-philosophy": 0,
    "ogx_mmlux_fr-prehistory": 0,
    "ogx_mmlux_fr-professional_accounting": 0,
    "ogx_mmlux_fr-professional_law": 0,
    "ogx_mmlux_fr-professional_medicine": 0,
    "ogx_mmlux_fr-professional_psychology": 0,
    "ogx_mmlux_fr-public_relations": 0,
    "ogx_mmlux_fr-security_studies": 0,
    "ogx_mmlux_fr-sociology": 0,
    "ogx_mmlux_fr-us_foreign_policy": 0,
    "ogx_mmlux_fr-virology": 0,
    "ogx_mmlux_fr-world_religions": 0,
    "ogx_mmlux_hu-abstract_algebra": 0,
    "ogx_mmlux_hu-anatomy": 0,
    "ogx_mmlux_hu-astronomy": 0,
    "ogx_mmlux_hu-business_ethics": 0,
    "ogx_mmlux_hu-clinical_knowledge": 0,
    "ogx_mmlux_hu-college_biology": 0,
    "ogx_mmlux_hu-college_chemistry": 0,
    "ogx_mmlux_hu-college_computer_science": 0,
    "ogx_mmlux_hu-college_mathematics": 0,
    "ogx_mmlux_hu-college_medicine": 0,
    "ogx_mmlux_hu-college_physics": 0,
    "ogx_mmlux_hu-computer_security": 0,
    "ogx_mmlux_hu-conceptual_physics": 0,
    "ogx_mmlux_hu-econometrics": 0,
    "ogx_mmlux_hu-electrical_engineering": 0,
    "ogx_mmlux_hu-elementary_mathematics": 0,
    "ogx_mmlux_hu-formal_logic": 0,
    "ogx_mmlux_hu-global_facts": 0,
    "ogx_mmlux_hu-high_school_biology": 0,
    "ogx_mmlux_hu-high_school_chemistry": 0,
    "ogx_mmlux_hu-high_school_computer_science": 0,
    "ogx_mmlux_hu-high_school_european_history": 0,
    "ogx_mmlux_hu-high_school_geography": 0,
    "ogx_mmlux_hu-high_school_government_and_politics": 0,
    "ogx_mmlux_hu-high_school_macroeconomics": 0,
    "ogx_mmlux_hu-high_school_mathematics": 0,
    "ogx_mmlux_hu-high_school_microeconomics": 0,
    "ogx_mmlux_hu-high_school_physics": 0,
    "ogx_mmlux_hu-high_school_psychology": 0,
    "ogx_mmlux_hu-high_school_statistics": 0,
    "ogx_mmlux_hu-high_school_us_history": 0,
    "ogx_mmlux_hu-high_school_world_history": 0,
    "ogx_mmlux_hu-human_aging": 0,
    "ogx_mmlux_hu-human_sexuality": 0,
    "ogx_mmlux_hu-international_law": 0,
    "ogx_mmlux_hu-jurisprudence": 0,
    "ogx_mmlux_hu-logical_fallacies": 0,
    "ogx_mmlux_hu-machine_learning": 0,
    "ogx_mmlux_hu-management": 0,
    "ogx_mmlux_hu-marketing": 0,
    "ogx_mmlux_hu-medical_genetics": 0,
    "ogx_mmlux_hu-miscellaneous": 0,
    "ogx_mmlux_hu-moral_disputes": 0,
    "ogx_mmlux_hu-moral_scenarios": 0,
    "ogx_mmlux_hu-nutrition": 0,
    "ogx_mmlux_hu-philosophy": 0,
    "ogx_mmlux_hu-prehistory": 0,
    "ogx_mmlux_hu-professional_accounting": 0,
    "ogx_mmlux_hu-professional_law": 0,
    "ogx_mmlux_hu-professional_medicine": 0,
    "ogx_mmlux_hu-professional_psychology": 0,
    "ogx_mmlux_hu-public_relations": 0,
    "ogx_mmlux_hu-security_studies": 0,
    "ogx_mmlux_hu-sociology": 0,
    "ogx_mmlux_hu-us_foreign_policy": 0,
    "ogx_mmlux_hu-virology": 0,
    "ogx_mmlux_hu-world_religions": 0,
    "ogx_mmlux_it-abstract_algebra": 0,
    "ogx_mmlux_it-anatomy": 0,
    "ogx_mmlux_it-astronomy": 0,
    "ogx_mmlux_it-business_ethics": 0,
    "ogx_mmlux_it-clinical_knowledge": 0,
    "ogx_mmlux_it-college_biology": 0,
    "ogx_mmlux_it-college_chemistry": 0,
    "ogx_mmlux_it-college_computer_science": 0,
    "ogx_mmlux_it-college_mathematics": 0,
    "ogx_mmlux_it-college_medicine": 0,
    "ogx_mmlux_it-college_physics": 0,
    "ogx_mmlux_it-computer_security": 0,
    "ogx_mmlux_it-conceptual_physics": 0,
    "ogx_mmlux_it-econometrics": 0,
    "ogx_mmlux_it-electrical_engineering": 0,
    "ogx_mmlux_it-elementary_mathematics": 0,
    "ogx_mmlux_it-formal_logic": 0,
    "ogx_mmlux_it-global_facts": 0,
    "ogx_mmlux_it-high_school_biology": 0,
    "ogx_mmlux_it-high_school_chemistry": 0,
    "ogx_mmlux_it-high_school_computer_science": 0,
    "ogx_mmlux_it-high_school_european_history": 0,
    "ogx_mmlux_it-high_school_geography": 0,
    "ogx_mmlux_it-high_school_government_and_politics": 0,
    "ogx_mmlux_it-high_school_macroeconomics": 0,
    "ogx_mmlux_it-high_school_mathematics": 0,
    "ogx_mmlux_it-high_school_microeconomics": 0,
    "ogx_mmlux_it-high_school_physics": 0,
    "ogx_mmlux_it-high_school_psychology": 0,
    "ogx_mmlux_it-high_school_statistics": 0,
    "ogx_mmlux_it-high_school_us_history": 0,
    "ogx_mmlux_it-high_school_world_history": 0,
    "ogx_mmlux_it-human_aging": 0,
    "ogx_mmlux_it-human_sexuality": 0,
    "ogx_mmlux_it-international_law": 0,
    "ogx_mmlux_it-jurisprudence": 0,
    "ogx_mmlux_it-logical_fallacies": 0,
    "ogx_mmlux_it-machine_learning": 0,
    "ogx_mmlux_it-management": 0,
    "ogx_mmlux_it-marketing": 0,
    "ogx_mmlux_it-medical_genetics": 0,
    "ogx_mmlux_it-miscellaneous": 0,
    "ogx_mmlux_it-moral_disputes": 0,
    "ogx_mmlux_it-moral_scenarios": 0,
    "ogx_mmlux_it-nutrition": 0,
    "ogx_mmlux_it-philosophy": 0,
    "ogx_mmlux_it-prehistory": 0,
    "ogx_mmlux_it-professional_accounting": 0,
    "ogx_mmlux_it-professional_law": 0,
    "ogx_mmlux_it-professional_medicine": 0,
    "ogx_mmlux_it-professional_psychology": 0,
    "ogx_mmlux_it-public_relations": 0,
    "ogx_mmlux_it-security_studies": 0,
    "ogx_mmlux_it-sociology": 0,
    "ogx_mmlux_it-us_foreign_policy": 0,
    "ogx_mmlux_it-virology": 0,
    "ogx_mmlux_it-world_religions": 0,
    "ogx_mmlux_lt-abstract_algebra": 0,
    "ogx_mmlux_lt-anatomy": 0,
    "ogx_mmlux_lt-astronomy": 0,
    "ogx_mmlux_lt-business_ethics": 0,
    "ogx_mmlux_lt-clinical_knowledge": 0,
    "ogx_mmlux_lt-college_biology": 0,
    "ogx_mmlux_lt-college_chemistry": 0,
    "ogx_mmlux_lt-college_computer_science": 0,
    "ogx_mmlux_lt-college_mathematics": 0,
    "ogx_mmlux_lt-college_medicine": 0,
    "ogx_mmlux_lt-college_physics": 0,
    "ogx_mmlux_lt-computer_security": 0,
    "ogx_mmlux_lt-conceptual_physics": 0,
    "ogx_mmlux_lt-econometrics": 0,
    "ogx_mmlux_lt-electrical_engineering": 0,
    "ogx_mmlux_lt-elementary_mathematics": 0,
    "ogx_mmlux_lt-formal_logic": 0,
    "ogx_mmlux_lt-global_facts": 0,
    "ogx_mmlux_lt-high_school_biology": 0,
    "ogx_mmlux_lt-high_school_chemistry": 0,
    "ogx_mmlux_lt-high_school_computer_science": 0,
    "ogx_mmlux_lt-high_school_european_history": 0,
    "ogx_mmlux_lt-high_school_geography": 0,
    "ogx_mmlux_lt-high_school_government_and_politics": 0,
    "ogx_mmlux_lt-high_school_macroeconomics": 0,
    "ogx_mmlux_lt-high_school_mathematics": 0,
    "ogx_mmlux_lt-high_school_microeconomics": 0,
    "ogx_mmlux_lt-high_school_physics": 0,
    "ogx_mmlux_lt-high_school_psychology": 0,
    "ogx_mmlux_lt-high_school_statistics": 0,
    "ogx_mmlux_lt-high_school_us_history": 0,
    "ogx_mmlux_lt-high_school_world_history": 0,
    "ogx_mmlux_lt-human_aging": 0,
    "ogx_mmlux_lt-human_sexuality": 0,
    "ogx_mmlux_lt-international_law": 0,
    "ogx_mmlux_lt-jurisprudence": 0,
    "ogx_mmlux_lt-logical_fallacies": 0,
    "ogx_mmlux_lt-machine_learning": 0,
    "ogx_mmlux_lt-management": 0,
    "ogx_mmlux_lt-marketing": 0,
    "ogx_mmlux_lt-medical_genetics": 0,
    "ogx_mmlux_lt-miscellaneous": 0,
    "ogx_mmlux_lt-moral_disputes": 0,
    "ogx_mmlux_lt-moral_scenarios": 0,
    "ogx_mmlux_lt-nutrition": 0,
    "ogx_mmlux_lt-philosophy": 0,
    "ogx_mmlux_lt-prehistory": 0,
    "ogx_mmlux_lt-professional_accounting": 0,
    "ogx_mmlux_lt-professional_law": 0,
    "ogx_mmlux_lt-professional_medicine": 0,
    "ogx_mmlux_lt-professional_psychology": 0,
    "ogx_mmlux_lt-public_relations": 0,
    "ogx_mmlux_lt-security_studies": 0,
    "ogx_mmlux_lt-sociology": 0,
    "ogx_mmlux_lt-us_foreign_policy": 0,
    "ogx_mmlux_lt-virology": 0,
    "ogx_mmlux_lt-world_religions": 0,
    "ogx_mmlux_lv-abstract_algebra": 0,
    "ogx_mmlux_lv-anatomy": 0,
    "ogx_mmlux_lv-astronomy": 0,
    "ogx_mmlux_lv-business_ethics": 0,
    "ogx_mmlux_lv-clinical_knowledge": 0,
    "ogx_mmlux_lv-college_biology": 0,
    "ogx_mmlux_lv-college_chemistry": 0,
    "ogx_mmlux_lv-college_computer_science": 0,
    "ogx_mmlux_lv-college_mathematics": 0,
    "ogx_mmlux_lv-college_medicine": 0,
    "ogx_mmlux_lv-college_physics": 0,
    "ogx_mmlux_lv-computer_security": 0,
    "ogx_mmlux_lv-conceptual_physics": 0,
    "ogx_mmlux_lv-econometrics": 0,
    "ogx_mmlux_lv-electrical_engineering": 0,
    "ogx_mmlux_lv-elementary_mathematics": 0,
    "ogx_mmlux_lv-formal_logic": 0,
    "ogx_mmlux_lv-global_facts": 0,
    "ogx_mmlux_lv-high_school_biology": 0,
    "ogx_mmlux_lv-high_school_chemistry": 0,
    "ogx_mmlux_lv-high_school_computer_science": 0,
    "ogx_mmlux_lv-high_school_european_history": 0,
    "ogx_mmlux_lv-high_school_geography": 0,
    "ogx_mmlux_lv-high_school_government_and_politics": 0,
    "ogx_mmlux_lv-high_school_macroeconomics": 0,
    "ogx_mmlux_lv-high_school_mathematics": 0,
    "ogx_mmlux_lv-high_school_microeconomics": 0,
    "ogx_mmlux_lv-high_school_physics": 0,
    "ogx_mmlux_lv-high_school_psychology": 0,
    "ogx_mmlux_lv-high_school_statistics": 0,
    "ogx_mmlux_lv-high_school_us_history": 0,
    "ogx_mmlux_lv-high_school_world_history": 0,
    "ogx_mmlux_lv-human_aging": 0,
    "ogx_mmlux_lv-human_sexuality": 0,
    "ogx_mmlux_lv-international_law": 0,
    "ogx_mmlux_lv-jurisprudence": 0,
    "ogx_mmlux_lv-logical_fallacies": 0,
    "ogx_mmlux_lv-machine_learning": 0,
    "ogx_mmlux_lv-management": 0,
    "ogx_mmlux_lv-marketing": 0,
    "ogx_mmlux_lv-medical_genetics": 0,
    "ogx_mmlux_lv-miscellaneous": 0,
    "ogx_mmlux_lv-moral_disputes": 0,
    "ogx_mmlux_lv-moral_scenarios": 0,
    "ogx_mmlux_lv-nutrition": 0,
    "ogx_mmlux_lv-philosophy": 0,
    "ogx_mmlux_lv-prehistory": 0,
    "ogx_mmlux_lv-professional_accounting": 0,
    "ogx_mmlux_lv-professional_law": 0,
    "ogx_mmlux_lv-professional_medicine": 0,
    "ogx_mmlux_lv-professional_psychology": 0,
    "ogx_mmlux_lv-public_relations": 0,
    "ogx_mmlux_lv-security_studies": 0,
    "ogx_mmlux_lv-sociology": 0,
    "ogx_mmlux_lv-us_foreign_policy": 0,
    "ogx_mmlux_lv-virology": 0,
    "ogx_mmlux_lv-world_religions": 0,
    "ogx_mmlux_nl-abstract_algebra": 0,
    "ogx_mmlux_nl-anatomy": 0,
    "ogx_mmlux_nl-astronomy": 0,
    "ogx_mmlux_nl-business_ethics": 0,
    "ogx_mmlux_nl-clinical_knowledge": 0,
    "ogx_mmlux_nl-college_biology": 0,
    "ogx_mmlux_nl-college_chemistry": 0,
    "ogx_mmlux_nl-college_computer_science": 0,
    "ogx_mmlux_nl-college_mathematics": 0,
    "ogx_mmlux_nl-college_medicine": 0,
    "ogx_mmlux_nl-college_physics": 0,
    "ogx_mmlux_nl-computer_security": 0,
    "ogx_mmlux_nl-conceptual_physics": 0,
    "ogx_mmlux_nl-econometrics": 0,
    "ogx_mmlux_nl-electrical_engineering": 0,
    "ogx_mmlux_nl-elementary_mathematics": 0,
    "ogx_mmlux_nl-formal_logic": 0,
    "ogx_mmlux_nl-global_facts": 0,
    "ogx_mmlux_nl-high_school_biology": 0,
    "ogx_mmlux_nl-high_school_chemistry": 0,
    "ogx_mmlux_nl-high_school_computer_science": 0,
    "ogx_mmlux_nl-high_school_european_history": 0,
    "ogx_mmlux_nl-high_school_geography": 0,
    "ogx_mmlux_nl-high_school_government_and_politics": 0,
    "ogx_mmlux_nl-high_school_macroeconomics": 0,
    "ogx_mmlux_nl-high_school_mathematics": 0,
    "ogx_mmlux_nl-high_school_microeconomics": 0,
    "ogx_mmlux_nl-high_school_physics": 0,
    "ogx_mmlux_nl-high_school_psychology": 0,
    "ogx_mmlux_nl-high_school_statistics": 0,
    "ogx_mmlux_nl-high_school_us_history": 0,
    "ogx_mmlux_nl-high_school_world_history": 0,
    "ogx_mmlux_nl-human_aging": 0,
    "ogx_mmlux_nl-human_sexuality": 0,
    "ogx_mmlux_nl-international_law": 0,
    "ogx_mmlux_nl-jurisprudence": 0,
    "ogx_mmlux_nl-logical_fallacies": 0,
    "ogx_mmlux_nl-machine_learning": 0,
    "ogx_mmlux_nl-management": 0,
    "ogx_mmlux_nl-marketing": 0,
    "ogx_mmlux_nl-medical_genetics": 0,
    "ogx_mmlux_nl-miscellaneous": 0,
    "ogx_mmlux_nl-moral_disputes": 0,
    "ogx_mmlux_nl-moral_scenarios": 0,
    "ogx_mmlux_nl-nutrition": 0,
    "ogx_mmlux_nl-philosophy": 0,
    "ogx_mmlux_nl-prehistory": 0,
    "ogx_mmlux_nl-professional_accounting": 0,
    "ogx_mmlux_nl-professional_law": 0,
    "ogx_mmlux_nl-professional_medicine": 0,
    "ogx_mmlux_nl-professional_psychology": 0,
    "ogx_mmlux_nl-public_relations": 0,
    "ogx_mmlux_nl-security_studies": 0,
    "ogx_mmlux_nl-sociology": 0,
    "ogx_mmlux_nl-us_foreign_policy": 0,
    "ogx_mmlux_nl-virology": 0,
    "ogx_mmlux_nl-world_religions": 0,
    "ogx_mmlux_pl-abstract_algebra": 0,
    "ogx_mmlux_pl-anatomy": 0,
    "ogx_mmlux_pl-astronomy": 0,
    "ogx_mmlux_pl-business_ethics": 0,
    "ogx_mmlux_pl-clinical_knowledge": 0,
    "ogx_mmlux_pl-college_biology": 0,
    "ogx_mmlux_pl-college_chemistry": 0,
    "ogx_mmlux_pl-college_computer_science": 0,
    "ogx_mmlux_pl-college_mathematics": 0,
    "ogx_mmlux_pl-college_medicine": 0,
    "ogx_mmlux_pl-college_physics": 0,
    "ogx_mmlux_pl-computer_security": 0,
    "ogx_mmlux_pl-conceptual_physics": 0,
    "ogx_mmlux_pl-econometrics": 0,
    "ogx_mmlux_pl-electrical_engineering": 0,
    "ogx_mmlux_pl-elementary_mathematics": 0,
    "ogx_mmlux_pl-formal_logic": 0,
    "ogx_mmlux_pl-global_facts": 0,
    "ogx_mmlux_pl-high_school_biology": 0,
    "ogx_mmlux_pl-high_school_chemistry": 0,
    "ogx_mmlux_pl-high_school_computer_science": 0,
    "ogx_mmlux_pl-high_school_european_history": 0,
    "ogx_mmlux_pl-high_school_geography": 0,
    "ogx_mmlux_pl-high_school_government_and_politics": 0,
    "ogx_mmlux_pl-high_school_macroeconomics": 0,
    "ogx_mmlux_pl-high_school_mathematics": 0,
    "ogx_mmlux_pl-high_school_microeconomics": 0,
    "ogx_mmlux_pl-high_school_physics": 0,
    "ogx_mmlux_pl-high_school_psychology": 0,
    "ogx_mmlux_pl-high_school_statistics": 0,
    "ogx_mmlux_pl-high_school_us_history": 0,
    "ogx_mmlux_pl-high_school_world_history": 0,
    "ogx_mmlux_pl-human_aging": 0,
    "ogx_mmlux_pl-human_sexuality": 0,
    "ogx_mmlux_pl-international_law": 0,
    "ogx_mmlux_pl-jurisprudence": 0,
    "ogx_mmlux_pl-logical_fallacies": 0,
    "ogx_mmlux_pl-machine_learning": 0,
    "ogx_mmlux_pl-management": 0,
    "ogx_mmlux_pl-marketing": 0,
    "ogx_mmlux_pl-medical_genetics": 0,
    "ogx_mmlux_pl-miscellaneous": 0,
    "ogx_mmlux_pl-moral_disputes": 0,
    "ogx_mmlux_pl-moral_scenarios": 0,
    "ogx_mmlux_pl-nutrition": 0,
    "ogx_mmlux_pl-philosophy": 0,
    "ogx_mmlux_pl-prehistory": 0,
    "ogx_mmlux_pl-professional_accounting": 0,
    "ogx_mmlux_pl-professional_law": 0,
    "ogx_mmlux_pl-professional_medicine": 0,
    "ogx_mmlux_pl-professional_psychology": 0,
    "ogx_mmlux_pl-public_relations": 0,
    "ogx_mmlux_pl-security_studies": 0,
    "ogx_mmlux_pl-sociology": 0,
    "ogx_mmlux_pl-us_foreign_policy": 0,
    "ogx_mmlux_pl-virology": 0,
    "ogx_mmlux_pl-world_religions": 0,
    "ogx_mmlux_pt-pt-abstract_algebra": 0,
    "ogx_mmlux_pt-pt-anatomy": 0,
    "ogx_mmlux_pt-pt-astronomy": 0,
    "ogx_mmlux_pt-pt-business_ethics": 0,
    "ogx_mmlux_pt-pt-clinical_knowledge": 0,
    "ogx_mmlux_pt-pt-college_biology": 0,
    "ogx_mmlux_pt-pt-college_chemistry": 0,
    "ogx_mmlux_pt-pt-college_computer_science": 0,
    "ogx_mmlux_pt-pt-college_mathematics": 0,
    "ogx_mmlux_pt-pt-college_medicine": 0,
    "ogx_mmlux_pt-pt-college_physics": 0,
    "ogx_mmlux_pt-pt-computer_security": 0,
    "ogx_mmlux_pt-pt-conceptual_physics": 0,
    "ogx_mmlux_pt-pt-econometrics": 0,
    "ogx_mmlux_pt-pt-electrical_engineering": 0,
    "ogx_mmlux_pt-pt-elementary_mathematics": 0,
    "ogx_mmlux_pt-pt-formal_logic": 0,
    "ogx_mmlux_pt-pt-global_facts": 0,
    "ogx_mmlux_pt-pt-high_school_biology": 0,
    "ogx_mmlux_pt-pt-high_school_chemistry": 0,
    "ogx_mmlux_pt-pt-high_school_computer_science": 0,
    "ogx_mmlux_pt-pt-high_school_european_history": 0,
    "ogx_mmlux_pt-pt-high_school_geography": 0,
    "ogx_mmlux_pt-pt-high_school_government_and_politics": 0,
    "ogx_mmlux_pt-pt-high_school_macroeconomics": 0,
    "ogx_mmlux_pt-pt-high_school_mathematics": 0,
    "ogx_mmlux_pt-pt-high_school_microeconomics": 0,
    "ogx_mmlux_pt-pt-high_school_physics": 0,
    "ogx_mmlux_pt-pt-high_school_psychology": 0,
    "ogx_mmlux_pt-pt-high_school_statistics": 0,
    "ogx_mmlux_pt-pt-high_school_us_history": 0,
    "ogx_mmlux_pt-pt-high_school_world_history": 0,
    "ogx_mmlux_pt-pt-human_aging": 0,
    "ogx_mmlux_pt-pt-human_sexuality": 0,
    "ogx_mmlux_pt-pt-international_law": 0,
    "ogx_mmlux_pt-pt-jurisprudence": 0,
    "ogx_mmlux_pt-pt-logical_fallacies": 0,
    "ogx_mmlux_pt-pt-machine_learning": 0,
    "ogx_mmlux_pt-pt-management": 0,
    "ogx_mmlux_pt-pt-marketing": 0,
    "ogx_mmlux_pt-pt-medical_genetics": 0,
    "ogx_mmlux_pt-pt-miscellaneous": 0,
    "ogx_mmlux_pt-pt-moral_disputes": 0,
    "ogx_mmlux_pt-pt-moral_scenarios": 0,
    "ogx_mmlux_pt-pt-nutrition": 0,
    "ogx_mmlux_pt-pt-philosophy": 0,
    "ogx_mmlux_pt-pt-prehistory": 0,
    "ogx_mmlux_pt-pt-professional_accounting": 0,
    "ogx_mmlux_pt-pt-professional_law": 0,
    "ogx_mmlux_pt-pt-professional_medicine": 0,
    "ogx_mmlux_pt-pt-professional_psychology": 0,
    "ogx_mmlux_pt-pt-public_relations": 0,
    "ogx_mmlux_pt-pt-security_studies": 0,
    "ogx_mmlux_pt-pt-sociology": 0,
    "ogx_mmlux_pt-pt-us_foreign_policy": 0,
    "ogx_mmlux_pt-pt-virology": 0,
    "ogx_mmlux_pt-pt-world_religions": 0,
    "ogx_mmlux_ro-abstract_algebra": 0,
    "ogx_mmlux_ro-anatomy": 0,
    "ogx_mmlux_ro-astronomy": 0,
    "ogx_mmlux_ro-business_ethics": 0,
    "ogx_mmlux_ro-clinical_knowledge": 0,
    "ogx_mmlux_ro-college_biology": 0,
    "ogx_mmlux_ro-college_chemistry": 0,
    "ogx_mmlux_ro-college_computer_science": 0,
    "ogx_mmlux_ro-college_mathematics": 0,
    "ogx_mmlux_ro-college_medicine": 0,
    "ogx_mmlux_ro-college_physics": 0,
    "ogx_mmlux_ro-computer_security": 0,
    "ogx_mmlux_ro-conceptual_physics": 0,
    "ogx_mmlux_ro-econometrics": 0,
    "ogx_mmlux_ro-electrical_engineering": 0,
    "ogx_mmlux_ro-elementary_mathematics": 0,
    "ogx_mmlux_ro-formal_logic": 0,
    "ogx_mmlux_ro-global_facts": 0,
    "ogx_mmlux_ro-high_school_biology": 0,
    "ogx_mmlux_ro-high_school_chemistry": 0,
    "ogx_mmlux_ro-high_school_computer_science": 0,
    "ogx_mmlux_ro-high_school_european_history": 0,
    "ogx_mmlux_ro-high_school_geography": 0,
    "ogx_mmlux_ro-high_school_government_and_politics": 0,
    "ogx_mmlux_ro-high_school_macroeconomics": 0,
    "ogx_mmlux_ro-high_school_mathematics": 0,
    "ogx_mmlux_ro-high_school_microeconomics": 0,
    "ogx_mmlux_ro-high_school_physics": 0,
    "ogx_mmlux_ro-high_school_psychology": 0,
    "ogx_mmlux_ro-high_school_statistics": 0,
    "ogx_mmlux_ro-high_school_us_history": 0,
    "ogx_mmlux_ro-high_school_world_history": 0,
    "ogx_mmlux_ro-human_aging": 0,
    "ogx_mmlux_ro-human_sexuality": 0,
    "ogx_mmlux_ro-international_law": 0,
    "ogx_mmlux_ro-jurisprudence": 0,
    "ogx_mmlux_ro-logical_fallacies": 0,
    "ogx_mmlux_ro-machine_learning": 0,
    "ogx_mmlux_ro-management": 0,
    "ogx_mmlux_ro-marketing": 0,
    "ogx_mmlux_ro-medical_genetics": 0,
    "ogx_mmlux_ro-miscellaneous": 0,
    "ogx_mmlux_ro-moral_disputes": 0,
    "ogx_mmlux_ro-moral_scenarios": 0,
    "ogx_mmlux_ro-nutrition": 0,
    "ogx_mmlux_ro-philosophy": 0,
    "ogx_mmlux_ro-prehistory": 0,
    "ogx_mmlux_ro-professional_accounting": 0,
    "ogx_mmlux_ro-professional_law": 0,
    "ogx_mmlux_ro-professional_medicine": 0,
    "ogx_mmlux_ro-professional_psychology": 0,
    "ogx_mmlux_ro-public_relations": 0,
    "ogx_mmlux_ro-security_studies": 0,
    "ogx_mmlux_ro-sociology": 0,
    "ogx_mmlux_ro-us_foreign_policy": 0,
    "ogx_mmlux_ro-virology": 0,
    "ogx_mmlux_ro-world_religions": 0,
    "ogx_mmlux_sk-abstract_algebra": 0,
    "ogx_mmlux_sk-anatomy": 0,
    "ogx_mmlux_sk-astronomy": 0,
    "ogx_mmlux_sk-business_ethics": 0,
    "ogx_mmlux_sk-clinical_knowledge": 0,
    "ogx_mmlux_sk-college_biology": 0,
    "ogx_mmlux_sk-college_chemistry": 0,
    "ogx_mmlux_sk-college_computer_science": 0,
    "ogx_mmlux_sk-college_mathematics": 0,
    "ogx_mmlux_sk-college_medicine": 0,
    "ogx_mmlux_sk-college_physics": 0,
    "ogx_mmlux_sk-computer_security": 0,
    "ogx_mmlux_sk-conceptual_physics": 0,
    "ogx_mmlux_sk-econometrics": 0,
    "ogx_mmlux_sk-electrical_engineering": 0,
    "ogx_mmlux_sk-elementary_mathematics": 0,
    "ogx_mmlux_sk-formal_logic": 0,
    "ogx_mmlux_sk-global_facts": 0,
    "ogx_mmlux_sk-high_school_biology": 0,
    "ogx_mmlux_sk-high_school_chemistry": 0,
    "ogx_mmlux_sk-high_school_computer_science": 0,
    "ogx_mmlux_sk-high_school_european_history": 0,
    "ogx_mmlux_sk-high_school_geography": 0,
    "ogx_mmlux_sk-high_school_government_and_politics": 0,
    "ogx_mmlux_sk-high_school_macroeconomics": 0,
    "ogx_mmlux_sk-high_school_mathematics": 0,
    "ogx_mmlux_sk-high_school_microeconomics": 0,
    "ogx_mmlux_sk-high_school_physics": 0,
    "ogx_mmlux_sk-high_school_psychology": 0,
    "ogx_mmlux_sk-high_school_statistics": 0,
    "ogx_mmlux_sk-high_school_us_history": 0,
    "ogx_mmlux_sk-high_school_world_history": 0,
    "ogx_mmlux_sk-human_aging": 0,
    "ogx_mmlux_sk-human_sexuality": 0,
    "ogx_mmlux_sk-international_law": 0,
    "ogx_mmlux_sk-jurisprudence": 0,
    "ogx_mmlux_sk-logical_fallacies": 0,
    "ogx_mmlux_sk-machine_learning": 0,
    "ogx_mmlux_sk-management": 0,
    "ogx_mmlux_sk-marketing": 0,
    "ogx_mmlux_sk-medical_genetics": 0,
    "ogx_mmlux_sk-miscellaneous": 0,
    "ogx_mmlux_sk-moral_disputes": 0,
    "ogx_mmlux_sk-moral_scenarios": 0,
    "ogx_mmlux_sk-nutrition": 0,
    "ogx_mmlux_sk-philosophy": 0,
    "ogx_mmlux_sk-prehistory": 0,
    "ogx_mmlux_sk-professional_accounting": 0,
    "ogx_mmlux_sk-professional_law": 0,
    "ogx_mmlux_sk-professional_medicine": 0,
    "ogx_mmlux_sk-professional_psychology": 0,
    "ogx_mmlux_sk-public_relations": 0,
    "ogx_mmlux_sk-security_studies": 0,
    "ogx_mmlux_sk-sociology": 0,
    "ogx_mmlux_sk-us_foreign_policy": 0,
    "ogx_mmlux_sk-virology": 0,
    "ogx_mmlux_sk-world_religions": 0,
    "ogx_mmlux_sl-abstract_algebra": 0,
    "ogx_mmlux_sl-anatomy": 0,
    "ogx_mmlux_sl-astronomy": 0,
    "ogx_mmlux_sl-business_ethics": 0,
    "ogx_mmlux_sl-clinical_knowledge": 0,
    "ogx_mmlux_sl-college_biology": 0,
    "ogx_mmlux_sl-college_chemistry": 0,
    "ogx_mmlux_sl-college_computer_science": 0,
    "ogx_mmlux_sl-college_mathematics": 0,
    "ogx_mmlux_sl-college_medicine": 0,
    "ogx_mmlux_sl-college_physics": 0,
    "ogx_mmlux_sl-computer_security": 0,
    "ogx_mmlux_sl-conceptual_physics": 0,
    "ogx_mmlux_sl-econometrics": 0,
    "ogx_mmlux_sl-electrical_engineering": 0,
    "ogx_mmlux_sl-elementary_mathematics": 0,
    "ogx_mmlux_sl-formal_logic": 0,
    "ogx_mmlux_sl-global_facts": 0,
    "ogx_mmlux_sl-high_school_biology": 0,
    "ogx_mmlux_sl-high_school_chemistry": 0,
    "ogx_mmlux_sl-high_school_computer_science": 0,
    "ogx_mmlux_sl-high_school_european_history": 0,
    "ogx_mmlux_sl-high_school_geography": 0,
    "ogx_mmlux_sl-high_school_government_and_politics": 0,
    "ogx_mmlux_sl-high_school_macroeconomics": 0,
    "ogx_mmlux_sl-high_school_mathematics": 0,
    "ogx_mmlux_sl-high_school_microeconomics": 0,
    "ogx_mmlux_sl-high_school_physics": 0,
    "ogx_mmlux_sl-high_school_psychology": 0,
    "ogx_mmlux_sl-high_school_statistics": 0,
    "ogx_mmlux_sl-high_school_us_history": 0,
    "ogx_mmlux_sl-high_school_world_history": 0,
    "ogx_mmlux_sl-human_aging": 0,
    "ogx_mmlux_sl-human_sexuality": 0,
    "ogx_mmlux_sl-international_law": 0,
    "ogx_mmlux_sl-jurisprudence": 0,
    "ogx_mmlux_sl-logical_fallacies": 0,
    "ogx_mmlux_sl-machine_learning": 0,
    "ogx_mmlux_sl-management": 0,
    "ogx_mmlux_sl-marketing": 0,
    "ogx_mmlux_sl-medical_genetics": 0,
    "ogx_mmlux_sl-miscellaneous": 0,
    "ogx_mmlux_sl-moral_disputes": 0,
    "ogx_mmlux_sl-moral_scenarios": 0,
    "ogx_mmlux_sl-nutrition": 0,
    "ogx_mmlux_sl-philosophy": 0,
    "ogx_mmlux_sl-prehistory": 0,
    "ogx_mmlux_sl-professional_accounting": 0,
    "ogx_mmlux_sl-professional_law": 0,
    "ogx_mmlux_sl-professional_medicine": 0,
    "ogx_mmlux_sl-professional_psychology": 0,
    "ogx_mmlux_sl-public_relations": 0,
    "ogx_mmlux_sl-security_studies": 0,
    "ogx_mmlux_sl-sociology": 0,
    "ogx_mmlux_sl-us_foreign_policy": 0,
    "ogx_mmlux_sl-virology": 0,
    "ogx_mmlux_sl-world_religions": 0,
    "ogx_mmlux_sv-abstract_algebra": 0,
    "ogx_mmlux_sv-anatomy": 0,
    "ogx_mmlux_sv-astronomy": 0,
    "ogx_mmlux_sv-business_ethics": 0,
    "ogx_mmlux_sv-clinical_knowledge": 0,
    "ogx_mmlux_sv-college_biology": 0,
    "ogx_mmlux_sv-college_chemistry": 0,
    "ogx_mmlux_sv-college_computer_science": 0,
    "ogx_mmlux_sv-college_mathematics": 0,
    "ogx_mmlux_sv-college_medicine": 0,
    "ogx_mmlux_sv-college_physics": 0,
    "ogx_mmlux_sv-computer_security": 0,
    "ogx_mmlux_sv-conceptual_physics": 0,
    "ogx_mmlux_sv-econometrics": 0,
    "ogx_mmlux_sv-electrical_engineering": 0,
    "ogx_mmlux_sv-elementary_mathematics": 0,
    "ogx_mmlux_sv-formal_logic": 0,
    "ogx_mmlux_sv-global_facts": 0,
    "ogx_mmlux_sv-high_school_biology": 0,
    "ogx_mmlux_sv-high_school_chemistry": 0,
    "ogx_mmlux_sv-high_school_computer_science": 0,
    "ogx_mmlux_sv-high_school_european_history": 0,
    "ogx_mmlux_sv-high_school_geography": 0,
    "ogx_mmlux_sv-high_school_government_and_politics": 0,
    "ogx_mmlux_sv-high_school_macroeconomics": 0,
    "ogx_mmlux_sv-high_school_mathematics": 0,
    "ogx_mmlux_sv-high_school_microeconomics": 0,
    "ogx_mmlux_sv-high_school_physics": 0,
    "ogx_mmlux_sv-high_school_psychology": 0,
    "ogx_mmlux_sv-high_school_statistics": 0,
    "ogx_mmlux_sv-high_school_us_history": 0,
    "ogx_mmlux_sv-high_school_world_history": 0,
    "ogx_mmlux_sv-human_aging": 0,
    "ogx_mmlux_sv-human_sexuality": 0,
    "ogx_mmlux_sv-international_law": 0,
    "ogx_mmlux_sv-jurisprudence": 0,
    "ogx_mmlux_sv-logical_fallacies": 0,
    "ogx_mmlux_sv-machine_learning": 0,
    "ogx_mmlux_sv-management": 0,
    "ogx_mmlux_sv-marketing": 0,
    "ogx_mmlux_sv-medical_genetics": 0,
    "ogx_mmlux_sv-miscellaneous": 0,
    "ogx_mmlux_sv-moral_disputes": 0,
    "ogx_mmlux_sv-moral_scenarios": 0,
    "ogx_mmlux_sv-nutrition": 0,
    "ogx_mmlux_sv-philosophy": 0,
    "ogx_mmlux_sv-prehistory": 0,
    "ogx_mmlux_sv-professional_accounting": 0,
    "ogx_mmlux_sv-professional_law": 0,
    "ogx_mmlux_sv-professional_medicine": 0,
    "ogx_mmlux_sv-professional_psychology": 0,
    "ogx_mmlux_sv-public_relations": 0,
    "ogx_mmlux_sv-security_studies": 0,
    "ogx_mmlux_sv-sociology": 0,
    "ogx_mmlux_sv-us_foreign_policy": 0,
    "ogx_mmlux_sv-virology": 0,
    "ogx_mmlux_sv-world_religions": 0
  },
  "n-shot": {
    "ogx_mmlux_bg-abstract_algebra": 5,
    "ogx_mmlux_bg-anatomy": 5,
    "ogx_mmlux_bg-astronomy": 5,
    "ogx_mmlux_bg-business_ethics": 5,
    "ogx_mmlux_bg-clinical_knowledge": 5,
    "ogx_mmlux_bg-college_biology": 5,
    "ogx_mmlux_bg-college_chemistry": 5,
    "ogx_mmlux_bg-college_computer_science": 5,
    "ogx_mmlux_bg-college_mathematics": 5,
    "ogx_mmlux_bg-college_medicine": 5,
    "ogx_mmlux_bg-college_physics": 5,
    "ogx_mmlux_bg-computer_security": 5,
    "ogx_mmlux_bg-conceptual_physics": 5,
    "ogx_mmlux_bg-econometrics": 5,
    "ogx_mmlux_bg-electrical_engineering": 5,
    "ogx_mmlux_bg-elementary_mathematics": 5,
    "ogx_mmlux_bg-formal_logic": 5,
    "ogx_mmlux_bg-global_facts": 5,
    "ogx_mmlux_bg-high_school_biology": 5,
    "ogx_mmlux_bg-high_school_chemistry": 5,
    "ogx_mmlux_bg-high_school_computer_science": 5,
    "ogx_mmlux_bg-high_school_european_history": 5,
    "ogx_mmlux_bg-high_school_geography": 5,
    "ogx_mmlux_bg-high_school_government_and_politics": 5,
    "ogx_mmlux_bg-high_school_macroeconomics": 5,
    "ogx_mmlux_bg-high_school_mathematics": 5,
    "ogx_mmlux_bg-high_school_microeconomics": 5,
    "ogx_mmlux_bg-high_school_physics": 5,
    "ogx_mmlux_bg-high_school_psychology": 5,
    "ogx_mmlux_bg-high_school_statistics": 5,
    "ogx_mmlux_bg-high_school_us_history": 5,
    "ogx_mmlux_bg-high_school_world_history": 5,
    "ogx_mmlux_bg-human_aging": 5,
    "ogx_mmlux_bg-human_sexuality": 5,
    "ogx_mmlux_bg-international_law": 5,
    "ogx_mmlux_bg-jurisprudence": 5,
    "ogx_mmlux_bg-logical_fallacies": 5,
    "ogx_mmlux_bg-machine_learning": 5,
    "ogx_mmlux_bg-management": 5,
    "ogx_mmlux_bg-marketing": 5,
    "ogx_mmlux_bg-medical_genetics": 5,
    "ogx_mmlux_bg-miscellaneous": 5,
    "ogx_mmlux_bg-moral_disputes": 5,
    "ogx_mmlux_bg-moral_scenarios": 5,
    "ogx_mmlux_bg-nutrition": 5,
    "ogx_mmlux_bg-philosophy": 5,
    "ogx_mmlux_bg-prehistory": 5,
    "ogx_mmlux_bg-professional_accounting": 5,
    "ogx_mmlux_bg-professional_law": 5,
    "ogx_mmlux_bg-professional_medicine": 5,
    "ogx_mmlux_bg-professional_psychology": 5,
    "ogx_mmlux_bg-public_relations": 5,
    "ogx_mmlux_bg-security_studies": 5,
    "ogx_mmlux_bg-sociology": 5,
    "ogx_mmlux_bg-us_foreign_policy": 5,
    "ogx_mmlux_bg-virology": 5,
    "ogx_mmlux_bg-world_religions": 5,
    "ogx_mmlux_cs-abstract_algebra": 5,
    "ogx_mmlux_cs-anatomy": 5,
    "ogx_mmlux_cs-astronomy": 5,
    "ogx_mmlux_cs-business_ethics": 5,
    "ogx_mmlux_cs-clinical_knowledge": 5,
    "ogx_mmlux_cs-college_biology": 5,
    "ogx_mmlux_cs-college_chemistry": 5,
    "ogx_mmlux_cs-college_computer_science": 5,
    "ogx_mmlux_cs-college_mathematics": 5,
    "ogx_mmlux_cs-college_medicine": 5,
    "ogx_mmlux_cs-college_physics": 5,
    "ogx_mmlux_cs-computer_security": 5,
    "ogx_mmlux_cs-conceptual_physics": 5,
    "ogx_mmlux_cs-econometrics": 5,
    "ogx_mmlux_cs-electrical_engineering": 5,
    "ogx_mmlux_cs-elementary_mathematics": 5,
    "ogx_mmlux_cs-formal_logic": 5,
    "ogx_mmlux_cs-global_facts": 5,
    "ogx_mmlux_cs-high_school_biology": 5,
    "ogx_mmlux_cs-high_school_chemistry": 5,
    "ogx_mmlux_cs-high_school_computer_science": 5,
    "ogx_mmlux_cs-high_school_european_history": 5,
    "ogx_mmlux_cs-high_school_geography": 5,
    "ogx_mmlux_cs-high_school_government_and_politics": 5,
    "ogx_mmlux_cs-high_school_macroeconomics": 5,
    "ogx_mmlux_cs-high_school_mathematics": 5,
    "ogx_mmlux_cs-high_school_microeconomics": 5,
    "ogx_mmlux_cs-high_school_physics": 5,
    "ogx_mmlux_cs-high_school_psychology": 5,
    "ogx_mmlux_cs-high_school_statistics": 5,
    "ogx_mmlux_cs-high_school_us_history": 5,
    "ogx_mmlux_cs-high_school_world_history": 5,
    "ogx_mmlux_cs-human_aging": 5,
    "ogx_mmlux_cs-human_sexuality": 5,
    "ogx_mmlux_cs-international_law": 5,
    "ogx_mmlux_cs-jurisprudence": 5,
    "ogx_mmlux_cs-logical_fallacies": 5,
    "ogx_mmlux_cs-machine_learning": 5,
    "ogx_mmlux_cs-management": 5,
    "ogx_mmlux_cs-marketing": 5,
    "ogx_mmlux_cs-medical_genetics": 5,
    "ogx_mmlux_cs-miscellaneous": 5,
    "ogx_mmlux_cs-moral_disputes": 5,
    "ogx_mmlux_cs-moral_scenarios": 5,
    "ogx_mmlux_cs-nutrition": 5,
    "ogx_mmlux_cs-philosophy": 5,
    "ogx_mmlux_cs-prehistory": 5,
    "ogx_mmlux_cs-professional_accounting": 5,
    "ogx_mmlux_cs-professional_law": 5,
    "ogx_mmlux_cs-professional_medicine": 5,
    "ogx_mmlux_cs-professional_psychology": 5,
    "ogx_mmlux_cs-public_relations": 5,
    "ogx_mmlux_cs-security_studies": 5,
    "ogx_mmlux_cs-sociology": 5,
    "ogx_mmlux_cs-us_foreign_policy": 5,
    "ogx_mmlux_cs-virology": 5,
    "ogx_mmlux_cs-world_religions": 5,
    "ogx_mmlux_da-abstract_algebra": 5,
    "ogx_mmlux_da-anatomy": 5,
    "ogx_mmlux_da-astronomy": 5,
    "ogx_mmlux_da-business_ethics": 5,
    "ogx_mmlux_da-clinical_knowledge": 5,
    "ogx_mmlux_da-college_biology": 5,
    "ogx_mmlux_da-college_chemistry": 5,
    "ogx_mmlux_da-college_computer_science": 5,
    "ogx_mmlux_da-college_mathematics": 5,
    "ogx_mmlux_da-college_medicine": 5,
    "ogx_mmlux_da-college_physics": 5,
    "ogx_mmlux_da-computer_security": 5,
    "ogx_mmlux_da-conceptual_physics": 5,
    "ogx_mmlux_da-econometrics": 5,
    "ogx_mmlux_da-electrical_engineering": 5,
    "ogx_mmlux_da-elementary_mathematics": 5,
    "ogx_mmlux_da-formal_logic": 5,
    "ogx_mmlux_da-global_facts": 5,
    "ogx_mmlux_da-high_school_biology": 5,
    "ogx_mmlux_da-high_school_chemistry": 5,
    "ogx_mmlux_da-high_school_computer_science": 5,
    "ogx_mmlux_da-high_school_european_history": 5,
    "ogx_mmlux_da-high_school_geography": 5,
    "ogx_mmlux_da-high_school_government_and_politics": 5,
    "ogx_mmlux_da-high_school_macroeconomics": 5,
    "ogx_mmlux_da-high_school_mathematics": 5,
    "ogx_mmlux_da-high_school_microeconomics": 5,
    "ogx_mmlux_da-high_school_physics": 5,
    "ogx_mmlux_da-high_school_psychology": 5,
    "ogx_mmlux_da-high_school_statistics": 5,
    "ogx_mmlux_da-high_school_us_history": 5,
    "ogx_mmlux_da-high_school_world_history": 5,
    "ogx_mmlux_da-human_aging": 5,
    "ogx_mmlux_da-human_sexuality": 5,
    "ogx_mmlux_da-international_law": 5,
    "ogx_mmlux_da-jurisprudence": 5,
    "ogx_mmlux_da-logical_fallacies": 5,
    "ogx_mmlux_da-machine_learning": 5,
    "ogx_mmlux_da-management": 5,
    "ogx_mmlux_da-marketing": 5,
    "ogx_mmlux_da-medical_genetics": 5,
    "ogx_mmlux_da-miscellaneous": 5,
    "ogx_mmlux_da-moral_disputes": 5,
    "ogx_mmlux_da-moral_scenarios": 5,
    "ogx_mmlux_da-nutrition": 5,
    "ogx_mmlux_da-philosophy": 5,
    "ogx_mmlux_da-prehistory": 5,
    "ogx_mmlux_da-professional_accounting": 5,
    "ogx_mmlux_da-professional_law": 5,
    "ogx_mmlux_da-professional_medicine": 5,
    "ogx_mmlux_da-professional_psychology": 5,
    "ogx_mmlux_da-public_relations": 5,
    "ogx_mmlux_da-security_studies": 5,
    "ogx_mmlux_da-sociology": 5,
    "ogx_mmlux_da-us_foreign_policy": 5,
    "ogx_mmlux_da-virology": 5,
    "ogx_mmlux_da-world_religions": 5,
    "ogx_mmlux_de-abstract_algebra": 5,
    "ogx_mmlux_de-anatomy": 5,
    "ogx_mmlux_de-astronomy": 5,
    "ogx_mmlux_de-business_ethics": 5,
    "ogx_mmlux_de-clinical_knowledge": 5,
    "ogx_mmlux_de-college_biology": 5,
    "ogx_mmlux_de-college_chemistry": 5,
    "ogx_mmlux_de-college_computer_science": 5,
    "ogx_mmlux_de-college_mathematics": 5,
    "ogx_mmlux_de-college_medicine": 5,
    "ogx_mmlux_de-college_physics": 5,
    "ogx_mmlux_de-computer_security": 5,
    "ogx_mmlux_de-conceptual_physics": 5,
    "ogx_mmlux_de-econometrics": 5,
    "ogx_mmlux_de-electrical_engineering": 5,
    "ogx_mmlux_de-elementary_mathematics": 5,
    "ogx_mmlux_de-formal_logic": 5,
    "ogx_mmlux_de-global_facts": 5,
    "ogx_mmlux_de-high_school_biology": 5,
    "ogx_mmlux_de-high_school_chemistry": 5,
    "ogx_mmlux_de-high_school_computer_science": 5,
    "ogx_mmlux_de-high_school_european_history": 5,
    "ogx_mmlux_de-high_school_geography": 5,
    "ogx_mmlux_de-high_school_government_and_politics": 5,
    "ogx_mmlux_de-high_school_macroeconomics": 5,
    "ogx_mmlux_de-high_school_mathematics": 5,
    "ogx_mmlux_de-high_school_microeconomics": 5,
    "ogx_mmlux_de-high_school_physics": 5,
    "ogx_mmlux_de-high_school_psychology": 5,
    "ogx_mmlux_de-high_school_statistics": 5,
    "ogx_mmlux_de-high_school_us_history": 5,
    "ogx_mmlux_de-high_school_world_history": 5,
    "ogx_mmlux_de-human_aging": 5,
    "ogx_mmlux_de-human_sexuality": 5,
    "ogx_mmlux_de-international_law": 5,
    "ogx_mmlux_de-jurisprudence": 5,
    "ogx_mmlux_de-logical_fallacies": 5,
    "ogx_mmlux_de-machine_learning": 5,
    "ogx_mmlux_de-management": 5,
    "ogx_mmlux_de-marketing": 5,
    "ogx_mmlux_de-medical_genetics": 5,
    "ogx_mmlux_de-miscellaneous": 5,
    "ogx_mmlux_de-moral_disputes": 5,
    "ogx_mmlux_de-moral_scenarios": 5,
    "ogx_mmlux_de-nutrition": 5,
    "ogx_mmlux_de-philosophy": 5,
    "ogx_mmlux_de-prehistory": 5,
    "ogx_mmlux_de-professional_accounting": 5,
    "ogx_mmlux_de-professional_law": 5,
    "ogx_mmlux_de-professional_medicine": 5,
    "ogx_mmlux_de-professional_psychology": 5,
    "ogx_mmlux_de-public_relations": 5,
    "ogx_mmlux_de-security_studies": 5,
    "ogx_mmlux_de-sociology": 5,
    "ogx_mmlux_de-us_foreign_policy": 5,
    "ogx_mmlux_de-virology": 5,
    "ogx_mmlux_de-world_religions": 5,
    "ogx_mmlux_el-abstract_algebra": 5,
    "ogx_mmlux_el-anatomy": 5,
    "ogx_mmlux_el-astronomy": 5,
    "ogx_mmlux_el-business_ethics": 5,
    "ogx_mmlux_el-clinical_knowledge": 5,
    "ogx_mmlux_el-college_biology": 5,
    "ogx_mmlux_el-college_chemistry": 5,
    "ogx_mmlux_el-college_computer_science": 5,
    "ogx_mmlux_el-college_mathematics": 5,
    "ogx_mmlux_el-college_medicine": 5,
    "ogx_mmlux_el-college_physics": 5,
    "ogx_mmlux_el-computer_security": 5,
    "ogx_mmlux_el-conceptual_physics": 5,
    "ogx_mmlux_el-econometrics": 5,
    "ogx_mmlux_el-electrical_engineering": 5,
    "ogx_mmlux_el-elementary_mathematics": 5,
    "ogx_mmlux_el-formal_logic": 5,
    "ogx_mmlux_el-global_facts": 5,
    "ogx_mmlux_el-high_school_biology": 5,
    "ogx_mmlux_el-high_school_chemistry": 5,
    "ogx_mmlux_el-high_school_computer_science": 5,
    "ogx_mmlux_el-high_school_european_history": 5,
    "ogx_mmlux_el-high_school_geography": 5,
    "ogx_mmlux_el-high_school_government_and_politics": 5,
    "ogx_mmlux_el-high_school_macroeconomics": 5,
    "ogx_mmlux_el-high_school_mathematics": 5,
    "ogx_mmlux_el-high_school_microeconomics": 5,
    "ogx_mmlux_el-high_school_physics": 5,
    "ogx_mmlux_el-high_school_psychology": 5,
    "ogx_mmlux_el-high_school_statistics": 5,
    "ogx_mmlux_el-high_school_us_history": 5,
    "ogx_mmlux_el-high_school_world_history": 5,
    "ogx_mmlux_el-human_aging": 5,
    "ogx_mmlux_el-human_sexuality": 5,
    "ogx_mmlux_el-international_law": 5,
    "ogx_mmlux_el-jurisprudence": 5,
    "ogx_mmlux_el-logical_fallacies": 5,
    "ogx_mmlux_el-machine_learning": 5,
    "ogx_mmlux_el-management": 5,
    "ogx_mmlux_el-marketing": 5,
    "ogx_mmlux_el-medical_genetics": 5,
    "ogx_mmlux_el-miscellaneous": 5,
    "ogx_mmlux_el-moral_disputes": 5,
    "ogx_mmlux_el-moral_scenarios": 5,
    "ogx_mmlux_el-nutrition": 5,
    "ogx_mmlux_el-philosophy": 5,
    "ogx_mmlux_el-prehistory": 5,
    "ogx_mmlux_el-professional_accounting": 5,
    "ogx_mmlux_el-professional_law": 5,
    "ogx_mmlux_el-professional_medicine": 5,
    "ogx_mmlux_el-professional_psychology": 5,
    "ogx_mmlux_el-public_relations": 5,
    "ogx_mmlux_el-security_studies": 5,
    "ogx_mmlux_el-sociology": 5,
    "ogx_mmlux_el-us_foreign_policy": 5,
    "ogx_mmlux_el-virology": 5,
    "ogx_mmlux_el-world_religions": 5,
    "ogx_mmlux_es-abstract_algebra": 5,
    "ogx_mmlux_es-anatomy": 5,
    "ogx_mmlux_es-astronomy": 5,
    "ogx_mmlux_es-business_ethics": 5,
    "ogx_mmlux_es-clinical_knowledge": 5,
    "ogx_mmlux_es-college_biology": 5,
    "ogx_mmlux_es-college_chemistry": 5,
    "ogx_mmlux_es-college_computer_science": 5,
    "ogx_mmlux_es-college_mathematics": 5,
    "ogx_mmlux_es-college_medicine": 5,
    "ogx_mmlux_es-college_physics": 5,
    "ogx_mmlux_es-computer_security": 5,
    "ogx_mmlux_es-conceptual_physics": 5,
    "ogx_mmlux_es-econometrics": 5,
    "ogx_mmlux_es-electrical_engineering": 5,
    "ogx_mmlux_es-elementary_mathematics": 5,
    "ogx_mmlux_es-formal_logic": 5,
    "ogx_mmlux_es-global_facts": 5,
    "ogx_mmlux_es-high_school_biology": 5,
    "ogx_mmlux_es-high_school_chemistry": 5,
    "ogx_mmlux_es-high_school_computer_science": 5,
    "ogx_mmlux_es-high_school_european_history": 5,
    "ogx_mmlux_es-high_school_geography": 5,
    "ogx_mmlux_es-high_school_government_and_politics": 5,
    "ogx_mmlux_es-high_school_macroeconomics": 5,
    "ogx_mmlux_es-high_school_mathematics": 5,
    "ogx_mmlux_es-high_school_microeconomics": 5,
    "ogx_mmlux_es-high_school_physics": 5,
    "ogx_mmlux_es-high_school_psychology": 5,
    "ogx_mmlux_es-high_school_statistics": 5,
    "ogx_mmlux_es-high_school_us_history": 5,
    "ogx_mmlux_es-high_school_world_history": 5,
    "ogx_mmlux_es-human_aging": 5,
    "ogx_mmlux_es-human_sexuality": 5,
    "ogx_mmlux_es-international_law": 5,
    "ogx_mmlux_es-jurisprudence": 5,
    "ogx_mmlux_es-logical_fallacies": 5,
    "ogx_mmlux_es-machine_learning": 5,
    "ogx_mmlux_es-management": 5,
    "ogx_mmlux_es-marketing": 5,
    "ogx_mmlux_es-medical_genetics": 5,
    "ogx_mmlux_es-miscellaneous": 5,
    "ogx_mmlux_es-moral_disputes": 5,
    "ogx_mmlux_es-moral_scenarios": 5,
    "ogx_mmlux_es-nutrition": 5,
    "ogx_mmlux_es-philosophy": 5,
    "ogx_mmlux_es-prehistory": 5,
    "ogx_mmlux_es-professional_accounting": 5,
    "ogx_mmlux_es-professional_law": 5,
    "ogx_mmlux_es-professional_medicine": 5,
    "ogx_mmlux_es-professional_psychology": 5,
    "ogx_mmlux_es-public_relations": 5,
    "ogx_mmlux_es-security_studies": 5,
    "ogx_mmlux_es-sociology": 5,
    "ogx_mmlux_es-us_foreign_policy": 5,
    "ogx_mmlux_es-virology": 5,
    "ogx_mmlux_es-world_religions": 5,
    "ogx_mmlux_et-abstract_algebra": 5,
    "ogx_mmlux_et-anatomy": 5,
    "ogx_mmlux_et-astronomy": 5,
    "ogx_mmlux_et-business_ethics": 5,
    "ogx_mmlux_et-clinical_knowledge": 5,
    "ogx_mmlux_et-college_biology": 5,
    "ogx_mmlux_et-college_chemistry": 5,
    "ogx_mmlux_et-college_computer_science": 5,
    "ogx_mmlux_et-college_mathematics": 5,
    "ogx_mmlux_et-college_medicine": 5,
    "ogx_mmlux_et-college_physics": 5,
    "ogx_mmlux_et-computer_security": 5,
    "ogx_mmlux_et-conceptual_physics": 5,
    "ogx_mmlux_et-econometrics": 5,
    "ogx_mmlux_et-electrical_engineering": 5,
    "ogx_mmlux_et-elementary_mathematics": 5,
    "ogx_mmlux_et-formal_logic": 5,
    "ogx_mmlux_et-global_facts": 5,
    "ogx_mmlux_et-high_school_biology": 5,
    "ogx_mmlux_et-high_school_chemistry": 5,
    "ogx_mmlux_et-high_school_computer_science": 5,
    "ogx_mmlux_et-high_school_european_history": 5,
    "ogx_mmlux_et-high_school_geography": 5,
    "ogx_mmlux_et-high_school_government_and_politics": 5,
    "ogx_mmlux_et-high_school_macroeconomics": 5,
    "ogx_mmlux_et-high_school_mathematics": 5,
    "ogx_mmlux_et-high_school_microeconomics": 5,
    "ogx_mmlux_et-high_school_physics": 5,
    "ogx_mmlux_et-high_school_psychology": 5,
    "ogx_mmlux_et-high_school_statistics": 5,
    "ogx_mmlux_et-high_school_us_history": 5,
    "ogx_mmlux_et-high_school_world_history": 5,
    "ogx_mmlux_et-human_aging": 5,
    "ogx_mmlux_et-human_sexuality": 5,
    "ogx_mmlux_et-international_law": 5,
    "ogx_mmlux_et-jurisprudence": 5,
    "ogx_mmlux_et-logical_fallacies": 5,
    "ogx_mmlux_et-machine_learning": 5,
    "ogx_mmlux_et-management": 5,
    "ogx_mmlux_et-marketing": 5,
    "ogx_mmlux_et-medical_genetics": 5,
    "ogx_mmlux_et-miscellaneous": 5,
    "ogx_mmlux_et-moral_disputes": 5,
    "ogx_mmlux_et-moral_scenarios": 5,
    "ogx_mmlux_et-nutrition": 5,
    "ogx_mmlux_et-philosophy": 5,
    "ogx_mmlux_et-prehistory": 5,
    "ogx_mmlux_et-professional_accounting": 5,
    "ogx_mmlux_et-professional_law": 5,
    "ogx_mmlux_et-professional_medicine": 5,
    "ogx_mmlux_et-professional_psychology": 5,
    "ogx_mmlux_et-public_relations": 5,
    "ogx_mmlux_et-security_studies": 5,
    "ogx_mmlux_et-sociology": 5,
    "ogx_mmlux_et-us_foreign_policy": 5,
    "ogx_mmlux_et-virology": 5,
    "ogx_mmlux_et-world_religions": 5,
    "ogx_mmlux_fi-abstract_algebra": 5,
    "ogx_mmlux_fi-anatomy": 5,
    "ogx_mmlux_fi-astronomy": 5,
    "ogx_mmlux_fi-business_ethics": 5,
    "ogx_mmlux_fi-clinical_knowledge": 5,
    "ogx_mmlux_fi-college_biology": 5,
    "ogx_mmlux_fi-college_chemistry": 5,
    "ogx_mmlux_fi-college_computer_science": 5,
    "ogx_mmlux_fi-college_mathematics": 5,
    "ogx_mmlux_fi-college_medicine": 5,
    "ogx_mmlux_fi-college_physics": 5,
    "ogx_mmlux_fi-computer_security": 5,
    "ogx_mmlux_fi-conceptual_physics": 5,
    "ogx_mmlux_fi-econometrics": 5,
    "ogx_mmlux_fi-electrical_engineering": 5,
    "ogx_mmlux_fi-elementary_mathematics": 5,
    "ogx_mmlux_fi-formal_logic": 5,
    "ogx_mmlux_fi-global_facts": 5,
    "ogx_mmlux_fi-high_school_biology": 5,
    "ogx_mmlux_fi-high_school_chemistry": 5,
    "ogx_mmlux_fi-high_school_computer_science": 5,
    "ogx_mmlux_fi-high_school_european_history": 5,
    "ogx_mmlux_fi-high_school_geography": 5,
    "ogx_mmlux_fi-high_school_government_and_politics": 5,
    "ogx_mmlux_fi-high_school_macroeconomics": 5,
    "ogx_mmlux_fi-high_school_mathematics": 5,
    "ogx_mmlux_fi-high_school_microeconomics": 5,
    "ogx_mmlux_fi-high_school_physics": 5,
    "ogx_mmlux_fi-high_school_psychology": 5,
    "ogx_mmlux_fi-high_school_statistics": 5,
    "ogx_mmlux_fi-high_school_us_history": 5,
    "ogx_mmlux_fi-high_school_world_history": 5,
    "ogx_mmlux_fi-human_aging": 5,
    "ogx_mmlux_fi-human_sexuality": 5,
    "ogx_mmlux_fi-international_law": 5,
    "ogx_mmlux_fi-jurisprudence": 5,
    "ogx_mmlux_fi-logical_fallacies": 5,
    "ogx_mmlux_fi-machine_learning": 5,
    "ogx_mmlux_fi-management": 5,
    "ogx_mmlux_fi-marketing": 5,
    "ogx_mmlux_fi-medical_genetics": 5,
    "ogx_mmlux_fi-miscellaneous": 5,
    "ogx_mmlux_fi-moral_disputes": 5,
    "ogx_mmlux_fi-moral_scenarios": 5,
    "ogx_mmlux_fi-nutrition": 5,
    "ogx_mmlux_fi-philosophy": 5,
    "ogx_mmlux_fi-prehistory": 5,
    "ogx_mmlux_fi-professional_accounting": 5,
    "ogx_mmlux_fi-professional_law": 5,
    "ogx_mmlux_fi-professional_medicine": 5,
    "ogx_mmlux_fi-professional_psychology": 5,
    "ogx_mmlux_fi-public_relations": 5,
    "ogx_mmlux_fi-security_studies": 5,
    "ogx_mmlux_fi-sociology": 5,
    "ogx_mmlux_fi-us_foreign_policy": 5,
    "ogx_mmlux_fi-virology": 5,
    "ogx_mmlux_fi-world_religions": 5,
    "ogx_mmlux_fr-abstract_algebra": 5,
    "ogx_mmlux_fr-anatomy": 5,
    "ogx_mmlux_fr-astronomy": 5,
    "ogx_mmlux_fr-business_ethics": 5,
    "ogx_mmlux_fr-clinical_knowledge": 5,
    "ogx_mmlux_fr-college_biology": 5,
    "ogx_mmlux_fr-college_chemistry": 5,
    "ogx_mmlux_fr-college_computer_science": 5,
    "ogx_mmlux_fr-college_mathematics": 5,
    "ogx_mmlux_fr-college_medicine": 5,
    "ogx_mmlux_fr-college_physics": 5,
    "ogx_mmlux_fr-computer_security": 5,
    "ogx_mmlux_fr-conceptual_physics": 5,
    "ogx_mmlux_fr-econometrics": 5,
    "ogx_mmlux_fr-electrical_engineering": 5,
    "ogx_mmlux_fr-elementary_mathematics": 5,
    "ogx_mmlux_fr-formal_logic": 5,
    "ogx_mmlux_fr-global_facts": 5,
    "ogx_mmlux_fr-high_school_biology": 5,
    "ogx_mmlux_fr-high_school_chemistry": 5,
    "ogx_mmlux_fr-high_school_computer_science": 5,
    "ogx_mmlux_fr-high_school_european_history": 5,
    "ogx_mmlux_fr-high_school_geography": 5,
    "ogx_mmlux_fr-high_school_government_and_politics": 5,
    "ogx_mmlux_fr-high_school_macroeconomics": 5,
    "ogx_mmlux_fr-high_school_mathematics": 5,
    "ogx_mmlux_fr-high_school_microeconomics": 5,
    "ogx_mmlux_fr-high_school_physics": 5,
    "ogx_mmlux_fr-high_school_psychology": 5,
    "ogx_mmlux_fr-high_school_statistics": 5,
    "ogx_mmlux_fr-high_school_us_history": 5,
    "ogx_mmlux_fr-high_school_world_history": 5,
    "ogx_mmlux_fr-human_aging": 5,
    "ogx_mmlux_fr-human_sexuality": 5,
    "ogx_mmlux_fr-international_law": 5,
    "ogx_mmlux_fr-jurisprudence": 5,
    "ogx_mmlux_fr-logical_fallacies": 5,
    "ogx_mmlux_fr-machine_learning": 5,
    "ogx_mmlux_fr-management": 5,
    "ogx_mmlux_fr-marketing": 5,
    "ogx_mmlux_fr-medical_genetics": 5,
    "ogx_mmlux_fr-miscellaneous": 5,
    "ogx_mmlux_fr-moral_disputes": 5,
    "ogx_mmlux_fr-moral_scenarios": 5,
    "ogx_mmlux_fr-nutrition": 5,
    "ogx_mmlux_fr-philosophy": 5,
    "ogx_mmlux_fr-prehistory": 5,
    "ogx_mmlux_fr-professional_accounting": 5,
    "ogx_mmlux_fr-professional_law": 5,
    "ogx_mmlux_fr-professional_medicine": 5,
    "ogx_mmlux_fr-professional_psychology": 5,
    "ogx_mmlux_fr-public_relations": 5,
    "ogx_mmlux_fr-security_studies": 5,
    "ogx_mmlux_fr-sociology": 5,
    "ogx_mmlux_fr-us_foreign_policy": 5,
    "ogx_mmlux_fr-virology": 5,
    "ogx_mmlux_fr-world_religions": 5,
    "ogx_mmlux_hu-abstract_algebra": 5,
    "ogx_mmlux_hu-anatomy": 5,
    "ogx_mmlux_hu-astronomy": 5,
    "ogx_mmlux_hu-business_ethics": 5,
    "ogx_mmlux_hu-clinical_knowledge": 5,
    "ogx_mmlux_hu-college_biology": 5,
    "ogx_mmlux_hu-college_chemistry": 5,
    "ogx_mmlux_hu-college_computer_science": 5,
    "ogx_mmlux_hu-college_mathematics": 5,
    "ogx_mmlux_hu-college_medicine": 5,
    "ogx_mmlux_hu-college_physics": 5,
    "ogx_mmlux_hu-computer_security": 5,
    "ogx_mmlux_hu-conceptual_physics": 5,
    "ogx_mmlux_hu-econometrics": 5,
    "ogx_mmlux_hu-electrical_engineering": 5,
    "ogx_mmlux_hu-elementary_mathematics": 5,
    "ogx_mmlux_hu-formal_logic": 5,
    "ogx_mmlux_hu-global_facts": 5,
    "ogx_mmlux_hu-high_school_biology": 5,
    "ogx_mmlux_hu-high_school_chemistry": 5,
    "ogx_mmlux_hu-high_school_computer_science": 5,
    "ogx_mmlux_hu-high_school_european_history": 5,
    "ogx_mmlux_hu-high_school_geography": 5,
    "ogx_mmlux_hu-high_school_government_and_politics": 5,
    "ogx_mmlux_hu-high_school_macroeconomics": 5,
    "ogx_mmlux_hu-high_school_mathematics": 5,
    "ogx_mmlux_hu-high_school_microeconomics": 5,
    "ogx_mmlux_hu-high_school_physics": 5,
    "ogx_mmlux_hu-high_school_psychology": 5,
    "ogx_mmlux_hu-high_school_statistics": 5,
    "ogx_mmlux_hu-high_school_us_history": 5,
    "ogx_mmlux_hu-high_school_world_history": 5,
    "ogx_mmlux_hu-human_aging": 5,
    "ogx_mmlux_hu-human_sexuality": 5,
    "ogx_mmlux_hu-international_law": 5,
    "ogx_mmlux_hu-jurisprudence": 5,
    "ogx_mmlux_hu-logical_fallacies": 5,
    "ogx_mmlux_hu-machine_learning": 5,
    "ogx_mmlux_hu-management": 5,
    "ogx_mmlux_hu-marketing": 5,
    "ogx_mmlux_hu-medical_genetics": 5,
    "ogx_mmlux_hu-miscellaneous": 5,
    "ogx_mmlux_hu-moral_disputes": 5,
    "ogx_mmlux_hu-moral_scenarios": 5,
    "ogx_mmlux_hu-nutrition": 5,
    "ogx_mmlux_hu-philosophy": 5,
    "ogx_mmlux_hu-prehistory": 5,
    "ogx_mmlux_hu-professional_accounting": 5,
    "ogx_mmlux_hu-professional_law": 5,
    "ogx_mmlux_hu-professional_medicine": 5,
    "ogx_mmlux_hu-professional_psychology": 5,
    "ogx_mmlux_hu-public_relations": 5,
    "ogx_mmlux_hu-security_studies": 5,
    "ogx_mmlux_hu-sociology": 5,
    "ogx_mmlux_hu-us_foreign_policy": 5,
    "ogx_mmlux_hu-virology": 5,
    "ogx_mmlux_hu-world_religions": 5,
    "ogx_mmlux_it-abstract_algebra": 5,
    "ogx_mmlux_it-anatomy": 5,
    "ogx_mmlux_it-astronomy": 5,
    "ogx_mmlux_it-business_ethics": 5,
    "ogx_mmlux_it-clinical_knowledge": 5,
    "ogx_mmlux_it-college_biology": 5,
    "ogx_mmlux_it-college_chemistry": 5,
    "ogx_mmlux_it-college_computer_science": 5,
    "ogx_mmlux_it-college_mathematics": 5,
    "ogx_mmlux_it-college_medicine": 5,
    "ogx_mmlux_it-college_physics": 5,
    "ogx_mmlux_it-computer_security": 5,
    "ogx_mmlux_it-conceptual_physics": 5,
    "ogx_mmlux_it-econometrics": 5,
    "ogx_mmlux_it-electrical_engineering": 5,
    "ogx_mmlux_it-elementary_mathematics": 5,
    "ogx_mmlux_it-formal_logic": 5,
    "ogx_mmlux_it-global_facts": 5,
    "ogx_mmlux_it-high_school_biology": 5,
    "ogx_mmlux_it-high_school_chemistry": 5,
    "ogx_mmlux_it-high_school_computer_science": 5,
    "ogx_mmlux_it-high_school_european_history": 5,
    "ogx_mmlux_it-high_school_geography": 5,
    "ogx_mmlux_it-high_school_government_and_politics": 5,
    "ogx_mmlux_it-high_school_macroeconomics": 5,
    "ogx_mmlux_it-high_school_mathematics": 5,
    "ogx_mmlux_it-high_school_microeconomics": 5,
    "ogx_mmlux_it-high_school_physics": 5,
    "ogx_mmlux_it-high_school_psychology": 5,
    "ogx_mmlux_it-high_school_statistics": 5,
    "ogx_mmlux_it-high_school_us_history": 5,
    "ogx_mmlux_it-high_school_world_history": 5,
    "ogx_mmlux_it-human_aging": 5,
    "ogx_mmlux_it-human_sexuality": 5,
    "ogx_mmlux_it-international_law": 5,
    "ogx_mmlux_it-jurisprudence": 5,
    "ogx_mmlux_it-logical_fallacies": 5,
    "ogx_mmlux_it-machine_learning": 5,
    "ogx_mmlux_it-management": 5,
    "ogx_mmlux_it-marketing": 5,
    "ogx_mmlux_it-medical_genetics": 5,
    "ogx_mmlux_it-miscellaneous": 5,
    "ogx_mmlux_it-moral_disputes": 5,
    "ogx_mmlux_it-moral_scenarios": 5,
    "ogx_mmlux_it-nutrition": 5,
    "ogx_mmlux_it-philosophy": 5,
    "ogx_mmlux_it-prehistory": 5,
    "ogx_mmlux_it-professional_accounting": 5,
    "ogx_mmlux_it-professional_law": 5,
    "ogx_mmlux_it-professional_medicine": 5,
    "ogx_mmlux_it-professional_psychology": 5,
    "ogx_mmlux_it-public_relations": 5,
    "ogx_mmlux_it-security_studies": 5,
    "ogx_mmlux_it-sociology": 5,
    "ogx_mmlux_it-us_foreign_policy": 5,
    "ogx_mmlux_it-virology": 5,
    "ogx_mmlux_it-world_religions": 5,
    "ogx_mmlux_lt-abstract_algebra": 5,
    "ogx_mmlux_lt-anatomy": 5,
    "ogx_mmlux_lt-astronomy": 5,
    "ogx_mmlux_lt-business_ethics": 5,
    "ogx_mmlux_lt-clinical_knowledge": 5,
    "ogx_mmlux_lt-college_biology": 5,
    "ogx_mmlux_lt-college_chemistry": 5,
    "ogx_mmlux_lt-college_computer_science": 5,
    "ogx_mmlux_lt-college_mathematics": 5,
    "ogx_mmlux_lt-college_medicine": 5,
    "ogx_mmlux_lt-college_physics": 5,
    "ogx_mmlux_lt-computer_security": 5,
    "ogx_mmlux_lt-conceptual_physics": 5,
    "ogx_mmlux_lt-econometrics": 5,
    "ogx_mmlux_lt-electrical_engineering": 5,
    "ogx_mmlux_lt-elementary_mathematics": 5,
    "ogx_mmlux_lt-formal_logic": 5,
    "ogx_mmlux_lt-global_facts": 5,
    "ogx_mmlux_lt-high_school_biology": 5,
    "ogx_mmlux_lt-high_school_chemistry": 5,
    "ogx_mmlux_lt-high_school_computer_science": 5,
    "ogx_mmlux_lt-high_school_european_history": 5,
    "ogx_mmlux_lt-high_school_geography": 5,
    "ogx_mmlux_lt-high_school_government_and_politics": 5,
    "ogx_mmlux_lt-high_school_macroeconomics": 5,
    "ogx_mmlux_lt-high_school_mathematics": 5,
    "ogx_mmlux_lt-high_school_microeconomics": 5,
    "ogx_mmlux_lt-high_school_physics": 5,
    "ogx_mmlux_lt-high_school_psychology": 5,
    "ogx_mmlux_lt-high_school_statistics": 5,
    "ogx_mmlux_lt-high_school_us_history": 5,
    "ogx_mmlux_lt-high_school_world_history": 5,
    "ogx_mmlux_lt-human_aging": 5,
    "ogx_mmlux_lt-human_sexuality": 5,
    "ogx_mmlux_lt-international_law": 5,
    "ogx_mmlux_lt-jurisprudence": 5,
    "ogx_mmlux_lt-logical_fallacies": 5,
    "ogx_mmlux_lt-machine_learning": 5,
    "ogx_mmlux_lt-management": 5,
    "ogx_mmlux_lt-marketing": 5,
    "ogx_mmlux_lt-medical_genetics": 5,
    "ogx_mmlux_lt-miscellaneous": 5,
    "ogx_mmlux_lt-moral_disputes": 5,
    "ogx_mmlux_lt-moral_scenarios": 5,
    "ogx_mmlux_lt-nutrition": 5,
    "ogx_mmlux_lt-philosophy": 5,
    "ogx_mmlux_lt-prehistory": 5,
    "ogx_mmlux_lt-professional_accounting": 5,
    "ogx_mmlux_lt-professional_law": 5,
    "ogx_mmlux_lt-professional_medicine": 5,
    "ogx_mmlux_lt-professional_psychology": 5,
    "ogx_mmlux_lt-public_relations": 5,
    "ogx_mmlux_lt-security_studies": 5,
    "ogx_mmlux_lt-sociology": 5,
    "ogx_mmlux_lt-us_foreign_policy": 5,
    "ogx_mmlux_lt-virology": 5,
    "ogx_mmlux_lt-world_religions": 5,
    "ogx_mmlux_lv-abstract_algebra": 5,
    "ogx_mmlux_lv-anatomy": 5,
    "ogx_mmlux_lv-astronomy": 5,
    "ogx_mmlux_lv-business_ethics": 5,
    "ogx_mmlux_lv-clinical_knowledge": 5,
    "ogx_mmlux_lv-college_biology": 5,
    "ogx_mmlux_lv-college_chemistry": 5,
    "ogx_mmlux_lv-college_computer_science": 5,
    "ogx_mmlux_lv-college_mathematics": 5,
    "ogx_mmlux_lv-college_medicine": 5,
    "ogx_mmlux_lv-college_physics": 5,
    "ogx_mmlux_lv-computer_security": 5,
    "ogx_mmlux_lv-conceptual_physics": 5,
    "ogx_mmlux_lv-econometrics": 5,
    "ogx_mmlux_lv-electrical_engineering": 5,
    "ogx_mmlux_lv-elementary_mathematics": 5,
    "ogx_mmlux_lv-formal_logic": 5,
    "ogx_mmlux_lv-global_facts": 5,
    "ogx_mmlux_lv-high_school_biology": 5,
    "ogx_mmlux_lv-high_school_chemistry": 5,
    "ogx_mmlux_lv-high_school_computer_science": 5,
    "ogx_mmlux_lv-high_school_european_history": 5,
    "ogx_mmlux_lv-high_school_geography": 5,
    "ogx_mmlux_lv-high_school_government_and_politics": 5,
    "ogx_mmlux_lv-high_school_macroeconomics": 5,
    "ogx_mmlux_lv-high_school_mathematics": 5,
    "ogx_mmlux_lv-high_school_microeconomics": 5,
    "ogx_mmlux_lv-high_school_physics": 5,
    "ogx_mmlux_lv-high_school_psychology": 5,
    "ogx_mmlux_lv-high_school_statistics": 5,
    "ogx_mmlux_lv-high_school_us_history": 5,
    "ogx_mmlux_lv-high_school_world_history": 5,
    "ogx_mmlux_lv-human_aging": 5,
    "ogx_mmlux_lv-human_sexuality": 5,
    "ogx_mmlux_lv-international_law": 5,
    "ogx_mmlux_lv-jurisprudence": 5,
    "ogx_mmlux_lv-logical_fallacies": 5,
    "ogx_mmlux_lv-machine_learning": 5,
    "ogx_mmlux_lv-management": 5,
    "ogx_mmlux_lv-marketing": 5,
    "ogx_mmlux_lv-medical_genetics": 5,
    "ogx_mmlux_lv-miscellaneous": 5,
    "ogx_mmlux_lv-moral_disputes": 5,
    "ogx_mmlux_lv-moral_scenarios": 5,
    "ogx_mmlux_lv-nutrition": 5,
    "ogx_mmlux_lv-philosophy": 5,
    "ogx_mmlux_lv-prehistory": 5,
    "ogx_mmlux_lv-professional_accounting": 5,
    "ogx_mmlux_lv-professional_law": 5,
    "ogx_mmlux_lv-professional_medicine": 5,
    "ogx_mmlux_lv-professional_psychology": 5,
    "ogx_mmlux_lv-public_relations": 5,
    "ogx_mmlux_lv-security_studies": 5,
    "ogx_mmlux_lv-sociology": 5,
    "ogx_mmlux_lv-us_foreign_policy": 5,
    "ogx_mmlux_lv-virology": 5,
    "ogx_mmlux_lv-world_religions": 5,
    "ogx_mmlux_nl-abstract_algebra": 5,
    "ogx_mmlux_nl-anatomy": 5,
    "ogx_mmlux_nl-astronomy": 5,
    "ogx_mmlux_nl-business_ethics": 5,
    "ogx_mmlux_nl-clinical_knowledge": 5,
    "ogx_mmlux_nl-college_biology": 5,
    "ogx_mmlux_nl-college_chemistry": 5,
    "ogx_mmlux_nl-college_computer_science": 5,
    "ogx_mmlux_nl-college_mathematics": 5,
    "ogx_mmlux_nl-college_medicine": 5,
    "ogx_mmlux_nl-college_physics": 5,
    "ogx_mmlux_nl-computer_security": 5,
    "ogx_mmlux_nl-conceptual_physics": 5,
    "ogx_mmlux_nl-econometrics": 5,
    "ogx_mmlux_nl-electrical_engineering": 5,
    "ogx_mmlux_nl-elementary_mathematics": 5,
    "ogx_mmlux_nl-formal_logic": 5,
    "ogx_mmlux_nl-global_facts": 5,
    "ogx_mmlux_nl-high_school_biology": 5,
    "ogx_mmlux_nl-high_school_chemistry": 5,
    "ogx_mmlux_nl-high_school_computer_science": 5,
    "ogx_mmlux_nl-high_school_european_history": 5,
    "ogx_mmlux_nl-high_school_geography": 5,
    "ogx_mmlux_nl-high_school_government_and_politics": 5,
    "ogx_mmlux_nl-high_school_macroeconomics": 5,
    "ogx_mmlux_nl-high_school_mathematics": 5,
    "ogx_mmlux_nl-high_school_microeconomics": 5,
    "ogx_mmlux_nl-high_school_physics": 5,
    "ogx_mmlux_nl-high_school_psychology": 5,
    "ogx_mmlux_nl-high_school_statistics": 5,
    "ogx_mmlux_nl-high_school_us_history": 5,
    "ogx_mmlux_nl-high_school_world_history": 5,
    "ogx_mmlux_nl-human_aging": 5,
    "ogx_mmlux_nl-human_sexuality": 5,
    "ogx_mmlux_nl-international_law": 5,
    "ogx_mmlux_nl-jurisprudence": 5,
    "ogx_mmlux_nl-logical_fallacies": 5,
    "ogx_mmlux_nl-machine_learning": 5,
    "ogx_mmlux_nl-management": 5,
    "ogx_mmlux_nl-marketing": 5,
    "ogx_mmlux_nl-medical_genetics": 5,
    "ogx_mmlux_nl-miscellaneous": 5,
    "ogx_mmlux_nl-moral_disputes": 5,
    "ogx_mmlux_nl-moral_scenarios": 5,
    "ogx_mmlux_nl-nutrition": 5,
    "ogx_mmlux_nl-philosophy": 5,
    "ogx_mmlux_nl-prehistory": 5,
    "ogx_mmlux_nl-professional_accounting": 5,
    "ogx_mmlux_nl-professional_law": 5,
    "ogx_mmlux_nl-professional_medicine": 5,
    "ogx_mmlux_nl-professional_psychology": 5,
    "ogx_mmlux_nl-public_relations": 5,
    "ogx_mmlux_nl-security_studies": 5,
    "ogx_mmlux_nl-sociology": 5,
    "ogx_mmlux_nl-us_foreign_policy": 5,
    "ogx_mmlux_nl-virology": 5,
    "ogx_mmlux_nl-world_religions": 5,
    "ogx_mmlux_pl-abstract_algebra": 5,
    "ogx_mmlux_pl-anatomy": 5,
    "ogx_mmlux_pl-astronomy": 5,
    "ogx_mmlux_pl-business_ethics": 5,
    "ogx_mmlux_pl-clinical_knowledge": 5,
    "ogx_mmlux_pl-college_biology": 5,
    "ogx_mmlux_pl-college_chemistry": 5,
    "ogx_mmlux_pl-college_computer_science": 5,
    "ogx_mmlux_pl-college_mathematics": 5,
    "ogx_mmlux_pl-college_medicine": 5,
    "ogx_mmlux_pl-college_physics": 5,
    "ogx_mmlux_pl-computer_security": 5,
    "ogx_mmlux_pl-conceptual_physics": 5,
    "ogx_mmlux_pl-econometrics": 5,
    "ogx_mmlux_pl-electrical_engineering": 5,
    "ogx_mmlux_pl-elementary_mathematics": 5,
    "ogx_mmlux_pl-formal_logic": 5,
    "ogx_mmlux_pl-global_facts": 5,
    "ogx_mmlux_pl-high_school_biology": 5,
    "ogx_mmlux_pl-high_school_chemistry": 5,
    "ogx_mmlux_pl-high_school_computer_science": 5,
    "ogx_mmlux_pl-high_school_european_history": 5,
    "ogx_mmlux_pl-high_school_geography": 5,
    "ogx_mmlux_pl-high_school_government_and_politics": 5,
    "ogx_mmlux_pl-high_school_macroeconomics": 5,
    "ogx_mmlux_pl-high_school_mathematics": 5,
    "ogx_mmlux_pl-high_school_microeconomics": 5,
    "ogx_mmlux_pl-high_school_physics": 5,
    "ogx_mmlux_pl-high_school_psychology": 5,
    "ogx_mmlux_pl-high_school_statistics": 5,
    "ogx_mmlux_pl-high_school_us_history": 5,
    "ogx_mmlux_pl-high_school_world_history": 5,
    "ogx_mmlux_pl-human_aging": 5,
    "ogx_mmlux_pl-human_sexuality": 5,
    "ogx_mmlux_pl-international_law": 5,
    "ogx_mmlux_pl-jurisprudence": 5,
    "ogx_mmlux_pl-logical_fallacies": 5,
    "ogx_mmlux_pl-machine_learning": 5,
    "ogx_mmlux_pl-management": 5,
    "ogx_mmlux_pl-marketing": 5,
    "ogx_mmlux_pl-medical_genetics": 5,
    "ogx_mmlux_pl-miscellaneous": 5,
    "ogx_mmlux_pl-moral_disputes": 5,
    "ogx_mmlux_pl-moral_scenarios": 5,
    "ogx_mmlux_pl-nutrition": 5,
    "ogx_mmlux_pl-philosophy": 5,
    "ogx_mmlux_pl-prehistory": 5,
    "ogx_mmlux_pl-professional_accounting": 5,
    "ogx_mmlux_pl-professional_law": 5,
    "ogx_mmlux_pl-professional_medicine": 5,
    "ogx_mmlux_pl-professional_psychology": 5,
    "ogx_mmlux_pl-public_relations": 5,
    "ogx_mmlux_pl-security_studies": 5,
    "ogx_mmlux_pl-sociology": 5,
    "ogx_mmlux_pl-us_foreign_policy": 5,
    "ogx_mmlux_pl-virology": 5,
    "ogx_mmlux_pl-world_religions": 5,
    "ogx_mmlux_pt-pt-abstract_algebra": 5,
    "ogx_mmlux_pt-pt-anatomy": 5,
    "ogx_mmlux_pt-pt-astronomy": 5,
    "ogx_mmlux_pt-pt-business_ethics": 5,
    "ogx_mmlux_pt-pt-clinical_knowledge": 5,
    "ogx_mmlux_pt-pt-college_biology": 5,
    "ogx_mmlux_pt-pt-college_chemistry": 5,
    "ogx_mmlux_pt-pt-college_computer_science": 5,
    "ogx_mmlux_pt-pt-college_mathematics": 5,
    "ogx_mmlux_pt-pt-college_medicine": 5,
    "ogx_mmlux_pt-pt-college_physics": 5,
    "ogx_mmlux_pt-pt-computer_security": 5,
    "ogx_mmlux_pt-pt-conceptual_physics": 5,
    "ogx_mmlux_pt-pt-econometrics": 5,
    "ogx_mmlux_pt-pt-electrical_engineering": 5,
    "ogx_mmlux_pt-pt-elementary_mathematics": 5,
    "ogx_mmlux_pt-pt-formal_logic": 5,
    "ogx_mmlux_pt-pt-global_facts": 5,
    "ogx_mmlux_pt-pt-high_school_biology": 5,
    "ogx_mmlux_pt-pt-high_school_chemistry": 5,
    "ogx_mmlux_pt-pt-high_school_computer_science": 5,
    "ogx_mmlux_pt-pt-high_school_european_history": 5,
    "ogx_mmlux_pt-pt-high_school_geography": 5,
    "ogx_mmlux_pt-pt-high_school_government_and_politics": 5,
    "ogx_mmlux_pt-pt-high_school_macroeconomics": 5,
    "ogx_mmlux_pt-pt-high_school_mathematics": 5,
    "ogx_mmlux_pt-pt-high_school_microeconomics": 5,
    "ogx_mmlux_pt-pt-high_school_physics": 5,
    "ogx_mmlux_pt-pt-high_school_psychology": 5,
    "ogx_mmlux_pt-pt-high_school_statistics": 5,
    "ogx_mmlux_pt-pt-high_school_us_history": 5,
    "ogx_mmlux_pt-pt-high_school_world_history": 5,
    "ogx_mmlux_pt-pt-human_aging": 5,
    "ogx_mmlux_pt-pt-human_sexuality": 5,
    "ogx_mmlux_pt-pt-international_law": 5,
    "ogx_mmlux_pt-pt-jurisprudence": 5,
    "ogx_mmlux_pt-pt-logical_fallacies": 5,
    "ogx_mmlux_pt-pt-machine_learning": 5,
    "ogx_mmlux_pt-pt-management": 5,
    "ogx_mmlux_pt-pt-marketing": 5,
    "ogx_mmlux_pt-pt-medical_genetics": 5,
    "ogx_mmlux_pt-pt-miscellaneous": 5,
    "ogx_mmlux_pt-pt-moral_disputes": 5,
    "ogx_mmlux_pt-pt-moral_scenarios": 5,
    "ogx_mmlux_pt-pt-nutrition": 5,
    "ogx_mmlux_pt-pt-philosophy": 5,
    "ogx_mmlux_pt-pt-prehistory": 5,
    "ogx_mmlux_pt-pt-professional_accounting": 5,
    "ogx_mmlux_pt-pt-professional_law": 5,
    "ogx_mmlux_pt-pt-professional_medicine": 5,
    "ogx_mmlux_pt-pt-professional_psychology": 5,
    "ogx_mmlux_pt-pt-public_relations": 5,
    "ogx_mmlux_pt-pt-security_studies": 5,
    "ogx_mmlux_pt-pt-sociology": 5,
    "ogx_mmlux_pt-pt-us_foreign_policy": 5,
    "ogx_mmlux_pt-pt-virology": 5,
    "ogx_mmlux_pt-pt-world_religions": 5,
    "ogx_mmlux_ro-abstract_algebra": 5,
    "ogx_mmlux_ro-anatomy": 5,
    "ogx_mmlux_ro-astronomy": 5,
    "ogx_mmlux_ro-business_ethics": 5,
    "ogx_mmlux_ro-clinical_knowledge": 5,
    "ogx_mmlux_ro-college_biology": 5,
    "ogx_mmlux_ro-college_chemistry": 5,
    "ogx_mmlux_ro-college_computer_science": 5,
    "ogx_mmlux_ro-college_mathematics": 5,
    "ogx_mmlux_ro-college_medicine": 5,
    "ogx_mmlux_ro-college_physics": 5,
    "ogx_mmlux_ro-computer_security": 5,
    "ogx_mmlux_ro-conceptual_physics": 5,
    "ogx_mmlux_ro-econometrics": 5,
    "ogx_mmlux_ro-electrical_engineering": 5,
    "ogx_mmlux_ro-elementary_mathematics": 5,
    "ogx_mmlux_ro-formal_logic": 5,
    "ogx_mmlux_ro-global_facts": 5,
    "ogx_mmlux_ro-high_school_biology": 5,
    "ogx_mmlux_ro-high_school_chemistry": 5,
    "ogx_mmlux_ro-high_school_computer_science": 5,
    "ogx_mmlux_ro-high_school_european_history": 5,
    "ogx_mmlux_ro-high_school_geography": 5,
    "ogx_mmlux_ro-high_school_government_and_politics": 5,
    "ogx_mmlux_ro-high_school_macroeconomics": 5,
    "ogx_mmlux_ro-high_school_mathematics": 5,
    "ogx_mmlux_ro-high_school_microeconomics": 5,
    "ogx_mmlux_ro-high_school_physics": 5,
    "ogx_mmlux_ro-high_school_psychology": 5,
    "ogx_mmlux_ro-high_school_statistics": 5,
    "ogx_mmlux_ro-high_school_us_history": 5,
    "ogx_mmlux_ro-high_school_world_history": 5,
    "ogx_mmlux_ro-human_aging": 5,
    "ogx_mmlux_ro-human_sexuality": 5,
    "ogx_mmlux_ro-international_law": 5,
    "ogx_mmlux_ro-jurisprudence": 5,
    "ogx_mmlux_ro-logical_fallacies": 5,
    "ogx_mmlux_ro-machine_learning": 5,
    "ogx_mmlux_ro-management": 5,
    "ogx_mmlux_ro-marketing": 5,
    "ogx_mmlux_ro-medical_genetics": 5,
    "ogx_mmlux_ro-miscellaneous": 5,
    "ogx_mmlux_ro-moral_disputes": 5,
    "ogx_mmlux_ro-moral_scenarios": 5,
    "ogx_mmlux_ro-nutrition": 5,
    "ogx_mmlux_ro-philosophy": 5,
    "ogx_mmlux_ro-prehistory": 5,
    "ogx_mmlux_ro-professional_accounting": 5,
    "ogx_mmlux_ro-professional_law": 5,
    "ogx_mmlux_ro-professional_medicine": 5,
    "ogx_mmlux_ro-professional_psychology": 5,
    "ogx_mmlux_ro-public_relations": 5,
    "ogx_mmlux_ro-security_studies": 5,
    "ogx_mmlux_ro-sociology": 5,
    "ogx_mmlux_ro-us_foreign_policy": 5,
    "ogx_mmlux_ro-virology": 5,
    "ogx_mmlux_ro-world_religions": 5,
    "ogx_mmlux_sk-abstract_algebra": 5,
    "ogx_mmlux_sk-anatomy": 5,
    "ogx_mmlux_sk-astronomy": 5,
    "ogx_mmlux_sk-business_ethics": 5,
    "ogx_mmlux_sk-clinical_knowledge": 5,
    "ogx_mmlux_sk-college_biology": 5,
    "ogx_mmlux_sk-college_chemistry": 5,
    "ogx_mmlux_sk-college_computer_science": 5,
    "ogx_mmlux_sk-college_mathematics": 5,
    "ogx_mmlux_sk-college_medicine": 5,
    "ogx_mmlux_sk-college_physics": 5,
    "ogx_mmlux_sk-computer_security": 5,
    "ogx_mmlux_sk-conceptual_physics": 5,
    "ogx_mmlux_sk-econometrics": 5,
    "ogx_mmlux_sk-electrical_engineering": 5,
    "ogx_mmlux_sk-elementary_mathematics": 5,
    "ogx_mmlux_sk-formal_logic": 5,
    "ogx_mmlux_sk-global_facts": 5,
    "ogx_mmlux_sk-high_school_biology": 5,
    "ogx_mmlux_sk-high_school_chemistry": 5,
    "ogx_mmlux_sk-high_school_computer_science": 5,
    "ogx_mmlux_sk-high_school_european_history": 5,
    "ogx_mmlux_sk-high_school_geography": 5,
    "ogx_mmlux_sk-high_school_government_and_politics": 5,
    "ogx_mmlux_sk-high_school_macroeconomics": 5,
    "ogx_mmlux_sk-high_school_mathematics": 5,
    "ogx_mmlux_sk-high_school_microeconomics": 5,
    "ogx_mmlux_sk-high_school_physics": 5,
    "ogx_mmlux_sk-high_school_psychology": 5,
    "ogx_mmlux_sk-high_school_statistics": 5,
    "ogx_mmlux_sk-high_school_us_history": 5,
    "ogx_mmlux_sk-high_school_world_history": 5,
    "ogx_mmlux_sk-human_aging": 5,
    "ogx_mmlux_sk-human_sexuality": 5,
    "ogx_mmlux_sk-international_law": 5,
    "ogx_mmlux_sk-jurisprudence": 5,
    "ogx_mmlux_sk-logical_fallacies": 5,
    "ogx_mmlux_sk-machine_learning": 5,
    "ogx_mmlux_sk-management": 5,
    "ogx_mmlux_sk-marketing": 5,
    "ogx_mmlux_sk-medical_genetics": 5,
    "ogx_mmlux_sk-miscellaneous": 5,
    "ogx_mmlux_sk-moral_disputes": 5,
    "ogx_mmlux_sk-moral_scenarios": 5,
    "ogx_mmlux_sk-nutrition": 5,
    "ogx_mmlux_sk-philosophy": 5,
    "ogx_mmlux_sk-prehistory": 5,
    "ogx_mmlux_sk-professional_accounting": 5,
    "ogx_mmlux_sk-professional_law": 5,
    "ogx_mmlux_sk-professional_medicine": 5,
    "ogx_mmlux_sk-professional_psychology": 5,
    "ogx_mmlux_sk-public_relations": 5,
    "ogx_mmlux_sk-security_studies": 5,
    "ogx_mmlux_sk-sociology": 5,
    "ogx_mmlux_sk-us_foreign_policy": 5,
    "ogx_mmlux_sk-virology": 5,
    "ogx_mmlux_sk-world_religions": 5,
    "ogx_mmlux_sl-abstract_algebra": 5,
    "ogx_mmlux_sl-anatomy": 5,
    "ogx_mmlux_sl-astronomy": 5,
    "ogx_mmlux_sl-business_ethics": 5,
    "ogx_mmlux_sl-clinical_knowledge": 5,
    "ogx_mmlux_sl-college_biology": 5,
    "ogx_mmlux_sl-college_chemistry": 5,
    "ogx_mmlux_sl-college_computer_science": 5,
    "ogx_mmlux_sl-college_mathematics": 5,
    "ogx_mmlux_sl-college_medicine": 5,
    "ogx_mmlux_sl-college_physics": 5,
    "ogx_mmlux_sl-computer_security": 5,
    "ogx_mmlux_sl-conceptual_physics": 5,
    "ogx_mmlux_sl-econometrics": 5,
    "ogx_mmlux_sl-electrical_engineering": 5,
    "ogx_mmlux_sl-elementary_mathematics": 5,
    "ogx_mmlux_sl-formal_logic": 5,
    "ogx_mmlux_sl-global_facts": 5,
    "ogx_mmlux_sl-high_school_biology": 5,
    "ogx_mmlux_sl-high_school_chemistry": 5,
    "ogx_mmlux_sl-high_school_computer_science": 5,
    "ogx_mmlux_sl-high_school_european_history": 5,
    "ogx_mmlux_sl-high_school_geography": 5,
    "ogx_mmlux_sl-high_school_government_and_politics": 5,
    "ogx_mmlux_sl-high_school_macroeconomics": 5,
    "ogx_mmlux_sl-high_school_mathematics": 5,
    "ogx_mmlux_sl-high_school_microeconomics": 5,
    "ogx_mmlux_sl-high_school_physics": 5,
    "ogx_mmlux_sl-high_school_psychology": 5,
    "ogx_mmlux_sl-high_school_statistics": 5,
    "ogx_mmlux_sl-high_school_us_history": 5,
    "ogx_mmlux_sl-high_school_world_history": 5,
    "ogx_mmlux_sl-human_aging": 5,
    "ogx_mmlux_sl-human_sexuality": 5,
    "ogx_mmlux_sl-international_law": 5,
    "ogx_mmlux_sl-jurisprudence": 5,
    "ogx_mmlux_sl-logical_fallacies": 5,
    "ogx_mmlux_sl-machine_learning": 5,
    "ogx_mmlux_sl-management": 5,
    "ogx_mmlux_sl-marketing": 5,
    "ogx_mmlux_sl-medical_genetics": 5,
    "ogx_mmlux_sl-miscellaneous": 5,
    "ogx_mmlux_sl-moral_disputes": 5,
    "ogx_mmlux_sl-moral_scenarios": 5,
    "ogx_mmlux_sl-nutrition": 5,
    "ogx_mmlux_sl-philosophy": 5,
    "ogx_mmlux_sl-prehistory": 5,
    "ogx_mmlux_sl-professional_accounting": 5,
    "ogx_mmlux_sl-professional_law": 5,
    "ogx_mmlux_sl-professional_medicine": 5,
    "ogx_mmlux_sl-professional_psychology": 5,
    "ogx_mmlux_sl-public_relations": 5,
    "ogx_mmlux_sl-security_studies": 5,
    "ogx_mmlux_sl-sociology": 5,
    "ogx_mmlux_sl-us_foreign_policy": 5,
    "ogx_mmlux_sl-virology": 5,
    "ogx_mmlux_sl-world_religions": 5,
    "ogx_mmlux_sv-abstract_algebra": 5,
    "ogx_mmlux_sv-anatomy": 5,
    "ogx_mmlux_sv-astronomy": 5,
    "ogx_mmlux_sv-business_ethics": 5,
    "ogx_mmlux_sv-clinical_knowledge": 5,
    "ogx_mmlux_sv-college_biology": 5,
    "ogx_mmlux_sv-college_chemistry": 5,
    "ogx_mmlux_sv-college_computer_science": 5,
    "ogx_mmlux_sv-college_mathematics": 5,
    "ogx_mmlux_sv-college_medicine": 5,
    "ogx_mmlux_sv-college_physics": 5,
    "ogx_mmlux_sv-computer_security": 5,
    "ogx_mmlux_sv-conceptual_physics": 5,
    "ogx_mmlux_sv-econometrics": 5,
    "ogx_mmlux_sv-electrical_engineering": 5,
    "ogx_mmlux_sv-elementary_mathematics": 5,
    "ogx_mmlux_sv-formal_logic": 5,
    "ogx_mmlux_sv-global_facts": 5,
    "ogx_mmlux_sv-high_school_biology": 5,
    "ogx_mmlux_sv-high_school_chemistry": 5,
    "ogx_mmlux_sv-high_school_computer_science": 5,
    "ogx_mmlux_sv-high_school_european_history": 5,
    "ogx_mmlux_sv-high_school_geography": 5,
    "ogx_mmlux_sv-high_school_government_and_politics": 5,
    "ogx_mmlux_sv-high_school_macroeconomics": 5,
    "ogx_mmlux_sv-high_school_mathematics": 5,
    "ogx_mmlux_sv-high_school_microeconomics": 5,
    "ogx_mmlux_sv-high_school_physics": 5,
    "ogx_mmlux_sv-high_school_psychology": 5,
    "ogx_mmlux_sv-high_school_statistics": 5,
    "ogx_mmlux_sv-high_school_us_history": 5,
    "ogx_mmlux_sv-high_school_world_history": 5,
    "ogx_mmlux_sv-human_aging": 5,
    "ogx_mmlux_sv-human_sexuality": 5,
    "ogx_mmlux_sv-international_law": 5,
    "ogx_mmlux_sv-jurisprudence": 5,
    "ogx_mmlux_sv-logical_fallacies": 5,
    "ogx_mmlux_sv-machine_learning": 5,
    "ogx_mmlux_sv-management": 5,
    "ogx_mmlux_sv-marketing": 5,
    "ogx_mmlux_sv-medical_genetics": 5,
    "ogx_mmlux_sv-miscellaneous": 5,
    "ogx_mmlux_sv-moral_disputes": 5,
    "ogx_mmlux_sv-moral_scenarios": 5,
    "ogx_mmlux_sv-nutrition": 5,
    "ogx_mmlux_sv-philosophy": 5,
    "ogx_mmlux_sv-prehistory": 5,
    "ogx_mmlux_sv-professional_accounting": 5,
    "ogx_mmlux_sv-professional_law": 5,
    "ogx_mmlux_sv-professional_medicine": 5,
    "ogx_mmlux_sv-professional_psychology": 5,
    "ogx_mmlux_sv-public_relations": 5,
    "ogx_mmlux_sv-security_studies": 5,
    "ogx_mmlux_sv-sociology": 5,
    "ogx_mmlux_sv-us_foreign_policy": 5,
    "ogx_mmlux_sv-virology": 5,
    "ogx_mmlux_sv-world_religions": 5
  },
  "higher_is_better": {
    "ogx_mmlux_bg-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_bg-anatomy": {
      "acc": true
    },
    "ogx_mmlux_bg-astronomy": {
      "acc": true
    },
    "ogx_mmlux_bg-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_bg-college_biology": {
      "acc": true
    },
    "ogx_mmlux_bg-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_bg-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_bg-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_bg-college_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-computer_security": {
      "acc": true
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-econometrics": {
      "acc": true
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_bg-global_facts": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_bg-human_aging": {
      "acc": true
    },
    "ogx_mmlux_bg-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_bg-international_law": {
      "acc": true
    },
    "ogx_mmlux_bg-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_bg-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_bg-management": {
      "acc": true
    },
    "ogx_mmlux_bg-marketing": {
      "acc": true
    },
    "ogx_mmlux_bg-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_bg-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_bg-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_bg-nutrition": {
      "acc": true
    },
    "ogx_mmlux_bg-philosophy": {
      "acc": true
    },
    "ogx_mmlux_bg-prehistory": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_law": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_bg-public_relations": {
      "acc": true
    },
    "ogx_mmlux_bg-security_studies": {
      "acc": true
    },
    "ogx_mmlux_bg-sociology": {
      "acc": true
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_bg-virology": {
      "acc": true
    },
    "ogx_mmlux_bg-world_religions": {
      "acc": true
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_cs-anatomy": {
      "acc": true
    },
    "ogx_mmlux_cs-astronomy": {
      "acc": true
    },
    "ogx_mmlux_cs-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_cs-college_biology": {
      "acc": true
    },
    "ogx_mmlux_cs-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_cs-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_cs-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_cs-college_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-computer_security": {
      "acc": true
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-econometrics": {
      "acc": true
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_cs-global_facts": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_cs-human_aging": {
      "acc": true
    },
    "ogx_mmlux_cs-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_cs-international_law": {
      "acc": true
    },
    "ogx_mmlux_cs-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_cs-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_cs-management": {
      "acc": true
    },
    "ogx_mmlux_cs-marketing": {
      "acc": true
    },
    "ogx_mmlux_cs-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_cs-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_cs-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_cs-nutrition": {
      "acc": true
    },
    "ogx_mmlux_cs-philosophy": {
      "acc": true
    },
    "ogx_mmlux_cs-prehistory": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_law": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_cs-public_relations": {
      "acc": true
    },
    "ogx_mmlux_cs-security_studies": {
      "acc": true
    },
    "ogx_mmlux_cs-sociology": {
      "acc": true
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_cs-virology": {
      "acc": true
    },
    "ogx_mmlux_cs-world_religions": {
      "acc": true
    },
    "ogx_mmlux_da-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_da-anatomy": {
      "acc": true
    },
    "ogx_mmlux_da-astronomy": {
      "acc": true
    },
    "ogx_mmlux_da-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_da-college_biology": {
      "acc": true
    },
    "ogx_mmlux_da-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_da-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_da-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_da-college_physics": {
      "acc": true
    },
    "ogx_mmlux_da-computer_security": {
      "acc": true
    },
    "ogx_mmlux_da-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_da-econometrics": {
      "acc": true
    },
    "ogx_mmlux_da-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_da-global_facts": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_da-human_aging": {
      "acc": true
    },
    "ogx_mmlux_da-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_da-international_law": {
      "acc": true
    },
    "ogx_mmlux_da-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_da-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_da-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_da-management": {
      "acc": true
    },
    "ogx_mmlux_da-marketing": {
      "acc": true
    },
    "ogx_mmlux_da-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_da-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_da-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_da-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_da-nutrition": {
      "acc": true
    },
    "ogx_mmlux_da-philosophy": {
      "acc": true
    },
    "ogx_mmlux_da-prehistory": {
      "acc": true
    },
    "ogx_mmlux_da-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_da-professional_law": {
      "acc": true
    },
    "ogx_mmlux_da-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_da-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_da-public_relations": {
      "acc": true
    },
    "ogx_mmlux_da-security_studies": {
      "acc": true
    },
    "ogx_mmlux_da-sociology": {
      "acc": true
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_da-virology": {
      "acc": true
    },
    "ogx_mmlux_da-world_religions": {
      "acc": true
    },
    "ogx_mmlux_de-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_de-anatomy": {
      "acc": true
    },
    "ogx_mmlux_de-astronomy": {
      "acc": true
    },
    "ogx_mmlux_de-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_de-college_biology": {
      "acc": true
    },
    "ogx_mmlux_de-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_de-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_de-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_de-college_physics": {
      "acc": true
    },
    "ogx_mmlux_de-computer_security": {
      "acc": true
    },
    "ogx_mmlux_de-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_de-econometrics": {
      "acc": true
    },
    "ogx_mmlux_de-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_de-global_facts": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_de-human_aging": {
      "acc": true
    },
    "ogx_mmlux_de-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_de-international_law": {
      "acc": true
    },
    "ogx_mmlux_de-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_de-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_de-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_de-management": {
      "acc": true
    },
    "ogx_mmlux_de-marketing": {
      "acc": true
    },
    "ogx_mmlux_de-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_de-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_de-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_de-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_de-nutrition": {
      "acc": true
    },
    "ogx_mmlux_de-philosophy": {
      "acc": true
    },
    "ogx_mmlux_de-prehistory": {
      "acc": true
    },
    "ogx_mmlux_de-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_de-professional_law": {
      "acc": true
    },
    "ogx_mmlux_de-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_de-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_de-public_relations": {
      "acc": true
    },
    "ogx_mmlux_de-security_studies": {
      "acc": true
    },
    "ogx_mmlux_de-sociology": {
      "acc": true
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_de-virology": {
      "acc": true
    },
    "ogx_mmlux_de-world_religions": {
      "acc": true
    },
    "ogx_mmlux_el-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_el-anatomy": {
      "acc": true
    },
    "ogx_mmlux_el-astronomy": {
      "acc": true
    },
    "ogx_mmlux_el-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_el-college_biology": {
      "acc": true
    },
    "ogx_mmlux_el-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_el-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_el-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_el-college_physics": {
      "acc": true
    },
    "ogx_mmlux_el-computer_security": {
      "acc": true
    },
    "ogx_mmlux_el-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_el-econometrics": {
      "acc": true
    },
    "ogx_mmlux_el-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_el-global_facts": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_el-human_aging": {
      "acc": true
    },
    "ogx_mmlux_el-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_el-international_law": {
      "acc": true
    },
    "ogx_mmlux_el-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_el-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_el-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_el-management": {
      "acc": true
    },
    "ogx_mmlux_el-marketing": {
      "acc": true
    },
    "ogx_mmlux_el-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_el-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_el-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_el-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_el-nutrition": {
      "acc": true
    },
    "ogx_mmlux_el-philosophy": {
      "acc": true
    },
    "ogx_mmlux_el-prehistory": {
      "acc": true
    },
    "ogx_mmlux_el-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_el-professional_law": {
      "acc": true
    },
    "ogx_mmlux_el-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_el-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_el-public_relations": {
      "acc": true
    },
    "ogx_mmlux_el-security_studies": {
      "acc": true
    },
    "ogx_mmlux_el-sociology": {
      "acc": true
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_el-virology": {
      "acc": true
    },
    "ogx_mmlux_el-world_religions": {
      "acc": true
    },
    "ogx_mmlux_es-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_es-anatomy": {
      "acc": true
    },
    "ogx_mmlux_es-astronomy": {
      "acc": true
    },
    "ogx_mmlux_es-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_es-college_biology": {
      "acc": true
    },
    "ogx_mmlux_es-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_es-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_es-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_es-college_physics": {
      "acc": true
    },
    "ogx_mmlux_es-computer_security": {
      "acc": true
    },
    "ogx_mmlux_es-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_es-econometrics": {
      "acc": true
    },
    "ogx_mmlux_es-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_es-global_facts": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_es-human_aging": {
      "acc": true
    },
    "ogx_mmlux_es-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_es-international_law": {
      "acc": true
    },
    "ogx_mmlux_es-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_es-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_es-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_es-management": {
      "acc": true
    },
    "ogx_mmlux_es-marketing": {
      "acc": true
    },
    "ogx_mmlux_es-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_es-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_es-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_es-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_es-nutrition": {
      "acc": true
    },
    "ogx_mmlux_es-philosophy": {
      "acc": true
    },
    "ogx_mmlux_es-prehistory": {
      "acc": true
    },
    "ogx_mmlux_es-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_es-professional_law": {
      "acc": true
    },
    "ogx_mmlux_es-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_es-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_es-public_relations": {
      "acc": true
    },
    "ogx_mmlux_es-security_studies": {
      "acc": true
    },
    "ogx_mmlux_es-sociology": {
      "acc": true
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_es-virology": {
      "acc": true
    },
    "ogx_mmlux_es-world_religions": {
      "acc": true
    },
    "ogx_mmlux_et-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_et-anatomy": {
      "acc": true
    },
    "ogx_mmlux_et-astronomy": {
      "acc": true
    },
    "ogx_mmlux_et-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_et-college_biology": {
      "acc": true
    },
    "ogx_mmlux_et-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_et-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_et-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_et-college_physics": {
      "acc": true
    },
    "ogx_mmlux_et-computer_security": {
      "acc": true
    },
    "ogx_mmlux_et-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_et-econometrics": {
      "acc": true
    },
    "ogx_mmlux_et-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_et-global_facts": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_et-human_aging": {
      "acc": true
    },
    "ogx_mmlux_et-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_et-international_law": {
      "acc": true
    },
    "ogx_mmlux_et-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_et-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_et-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_et-management": {
      "acc": true
    },
    "ogx_mmlux_et-marketing": {
      "acc": true
    },
    "ogx_mmlux_et-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_et-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_et-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_et-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_et-nutrition": {
      "acc": true
    },
    "ogx_mmlux_et-philosophy": {
      "acc": true
    },
    "ogx_mmlux_et-prehistory": {
      "acc": true
    },
    "ogx_mmlux_et-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_et-professional_law": {
      "acc": true
    },
    "ogx_mmlux_et-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_et-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_et-public_relations": {
      "acc": true
    },
    "ogx_mmlux_et-security_studies": {
      "acc": true
    },
    "ogx_mmlux_et-sociology": {
      "acc": true
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_et-virology": {
      "acc": true
    },
    "ogx_mmlux_et-world_religions": {
      "acc": true
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_fi-anatomy": {
      "acc": true
    },
    "ogx_mmlux_fi-astronomy": {
      "acc": true
    },
    "ogx_mmlux_fi-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_fi-college_biology": {
      "acc": true
    },
    "ogx_mmlux_fi-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fi-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fi-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_fi-college_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-computer_security": {
      "acc": true
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-econometrics": {
      "acc": true
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_fi-global_facts": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_fi-human_aging": {
      "acc": true
    },
    "ogx_mmlux_fi-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_fi-international_law": {
      "acc": true
    },
    "ogx_mmlux_fi-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_fi-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_fi-management": {
      "acc": true
    },
    "ogx_mmlux_fi-marketing": {
      "acc": true
    },
    "ogx_mmlux_fi-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_fi-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_fi-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_fi-nutrition": {
      "acc": true
    },
    "ogx_mmlux_fi-philosophy": {
      "acc": true
    },
    "ogx_mmlux_fi-prehistory": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_law": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_fi-public_relations": {
      "acc": true
    },
    "ogx_mmlux_fi-security_studies": {
      "acc": true
    },
    "ogx_mmlux_fi-sociology": {
      "acc": true
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_fi-virology": {
      "acc": true
    },
    "ogx_mmlux_fi-world_religions": {
      "acc": true
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_fr-anatomy": {
      "acc": true
    },
    "ogx_mmlux_fr-astronomy": {
      "acc": true
    },
    "ogx_mmlux_fr-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_fr-college_biology": {
      "acc": true
    },
    "ogx_mmlux_fr-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fr-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fr-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_fr-college_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-computer_security": {
      "acc": true
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-econometrics": {
      "acc": true
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_fr-global_facts": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_fr-human_aging": {
      "acc": true
    },
    "ogx_mmlux_fr-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_fr-international_law": {
      "acc": true
    },
    "ogx_mmlux_fr-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_fr-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_fr-management": {
      "acc": true
    },
    "ogx_mmlux_fr-marketing": {
      "acc": true
    },
    "ogx_mmlux_fr-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_fr-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_fr-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_fr-nutrition": {
      "acc": true
    },
    "ogx_mmlux_fr-philosophy": {
      "acc": true
    },
    "ogx_mmlux_fr-prehistory": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_law": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_fr-public_relations": {
      "acc": true
    },
    "ogx_mmlux_fr-security_studies": {
      "acc": true
    },
    "ogx_mmlux_fr-sociology": {
      "acc": true
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_fr-virology": {
      "acc": true
    },
    "ogx_mmlux_fr-world_religions": {
      "acc": true
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_hu-anatomy": {
      "acc": true
    },
    "ogx_mmlux_hu-astronomy": {
      "acc": true
    },
    "ogx_mmlux_hu-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_hu-college_biology": {
      "acc": true
    },
    "ogx_mmlux_hu-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_hu-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_hu-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_hu-college_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-computer_security": {
      "acc": true
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-econometrics": {
      "acc": true
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_hu-global_facts": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_hu-human_aging": {
      "acc": true
    },
    "ogx_mmlux_hu-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_hu-international_law": {
      "acc": true
    },
    "ogx_mmlux_hu-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_hu-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_hu-management": {
      "acc": true
    },
    "ogx_mmlux_hu-marketing": {
      "acc": true
    },
    "ogx_mmlux_hu-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_hu-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_hu-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_hu-nutrition": {
      "acc": true
    },
    "ogx_mmlux_hu-philosophy": {
      "acc": true
    },
    "ogx_mmlux_hu-prehistory": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_law": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_hu-public_relations": {
      "acc": true
    },
    "ogx_mmlux_hu-security_studies": {
      "acc": true
    },
    "ogx_mmlux_hu-sociology": {
      "acc": true
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_hu-virology": {
      "acc": true
    },
    "ogx_mmlux_hu-world_religions": {
      "acc": true
    },
    "ogx_mmlux_it-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_it-anatomy": {
      "acc": true
    },
    "ogx_mmlux_it-astronomy": {
      "acc": true
    },
    "ogx_mmlux_it-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_it-college_biology": {
      "acc": true
    },
    "ogx_mmlux_it-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_it-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_it-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_it-college_physics": {
      "acc": true
    },
    "ogx_mmlux_it-computer_security": {
      "acc": true
    },
    "ogx_mmlux_it-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_it-econometrics": {
      "acc": true
    },
    "ogx_mmlux_it-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_it-global_facts": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_it-human_aging": {
      "acc": true
    },
    "ogx_mmlux_it-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_it-international_law": {
      "acc": true
    },
    "ogx_mmlux_it-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_it-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_it-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_it-management": {
      "acc": true
    },
    "ogx_mmlux_it-marketing": {
      "acc": true
    },
    "ogx_mmlux_it-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_it-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_it-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_it-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_it-nutrition": {
      "acc": true
    },
    "ogx_mmlux_it-philosophy": {
      "acc": true
    },
    "ogx_mmlux_it-prehistory": {
      "acc": true
    },
    "ogx_mmlux_it-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_it-professional_law": {
      "acc": true
    },
    "ogx_mmlux_it-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_it-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_it-public_relations": {
      "acc": true
    },
    "ogx_mmlux_it-security_studies": {
      "acc": true
    },
    "ogx_mmlux_it-sociology": {
      "acc": true
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_it-virology": {
      "acc": true
    },
    "ogx_mmlux_it-world_religions": {
      "acc": true
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_lt-anatomy": {
      "acc": true
    },
    "ogx_mmlux_lt-astronomy": {
      "acc": true
    },
    "ogx_mmlux_lt-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_lt-college_biology": {
      "acc": true
    },
    "ogx_mmlux_lt-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lt-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lt-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_lt-college_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-computer_security": {
      "acc": true
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-econometrics": {
      "acc": true
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_lt-global_facts": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_lt-human_aging": {
      "acc": true
    },
    "ogx_mmlux_lt-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_lt-international_law": {
      "acc": true
    },
    "ogx_mmlux_lt-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_lt-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_lt-management": {
      "acc": true
    },
    "ogx_mmlux_lt-marketing": {
      "acc": true
    },
    "ogx_mmlux_lt-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_lt-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_lt-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_lt-nutrition": {
      "acc": true
    },
    "ogx_mmlux_lt-philosophy": {
      "acc": true
    },
    "ogx_mmlux_lt-prehistory": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_law": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_lt-public_relations": {
      "acc": true
    },
    "ogx_mmlux_lt-security_studies": {
      "acc": true
    },
    "ogx_mmlux_lt-sociology": {
      "acc": true
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_lt-virology": {
      "acc": true
    },
    "ogx_mmlux_lt-world_religions": {
      "acc": true
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_lv-anatomy": {
      "acc": true
    },
    "ogx_mmlux_lv-astronomy": {
      "acc": true
    },
    "ogx_mmlux_lv-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_lv-college_biology": {
      "acc": true
    },
    "ogx_mmlux_lv-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lv-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lv-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_lv-college_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-computer_security": {
      "acc": true
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-econometrics": {
      "acc": true
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_lv-global_facts": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_lv-human_aging": {
      "acc": true
    },
    "ogx_mmlux_lv-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_lv-international_law": {
      "acc": true
    },
    "ogx_mmlux_lv-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_lv-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_lv-management": {
      "acc": true
    },
    "ogx_mmlux_lv-marketing": {
      "acc": true
    },
    "ogx_mmlux_lv-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_lv-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_lv-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_lv-nutrition": {
      "acc": true
    },
    "ogx_mmlux_lv-philosophy": {
      "acc": true
    },
    "ogx_mmlux_lv-prehistory": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_law": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_lv-public_relations": {
      "acc": true
    },
    "ogx_mmlux_lv-security_studies": {
      "acc": true
    },
    "ogx_mmlux_lv-sociology": {
      "acc": true
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_lv-virology": {
      "acc": true
    },
    "ogx_mmlux_lv-world_religions": {
      "acc": true
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_nl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_nl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_nl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_nl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_nl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_nl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_nl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_nl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_nl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_nl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_nl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_nl-international_law": {
      "acc": true
    },
    "ogx_mmlux_nl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_nl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_nl-management": {
      "acc": true
    },
    "ogx_mmlux_nl-marketing": {
      "acc": true
    },
    "ogx_mmlux_nl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_nl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_nl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_nl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_nl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_nl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_nl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_nl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_nl-sociology": {
      "acc": true
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_nl-virology": {
      "acc": true
    },
    "ogx_mmlux_nl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_pl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_pl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_pl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_pl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_pl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_pl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_pl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_pl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_pl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_pl-international_law": {
      "acc": true
    },
    "ogx_mmlux_pl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_pl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_pl-management": {
      "acc": true
    },
    "ogx_mmlux_pl-marketing": {
      "acc": true
    },
    "ogx_mmlux_pl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_pl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_pl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_pl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_pl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_pl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_pl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_pl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_pl-sociology": {
      "acc": true
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_pl-virology": {
      "acc": true
    },
    "ogx_mmlux_pl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-international_law": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-management": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-marketing": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-sociology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-virology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "acc": true
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_ro-anatomy": {
      "acc": true
    },
    "ogx_mmlux_ro-astronomy": {
      "acc": true
    },
    "ogx_mmlux_ro-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_ro-college_biology": {
      "acc": true
    },
    "ogx_mmlux_ro-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_ro-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_ro-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_ro-college_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-computer_security": {
      "acc": true
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-econometrics": {
      "acc": true
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_ro-global_facts": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_ro-human_aging": {
      "acc": true
    },
    "ogx_mmlux_ro-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_ro-international_law": {
      "acc": true
    },
    "ogx_mmlux_ro-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_ro-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_ro-management": {
      "acc": true
    },
    "ogx_mmlux_ro-marketing": {
      "acc": true
    },
    "ogx_mmlux_ro-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_ro-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_ro-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_ro-nutrition": {
      "acc": true
    },
    "ogx_mmlux_ro-philosophy": {
      "acc": true
    },
    "ogx_mmlux_ro-prehistory": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_law": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_ro-public_relations": {
      "acc": true
    },
    "ogx_mmlux_ro-security_studies": {
      "acc": true
    },
    "ogx_mmlux_ro-sociology": {
      "acc": true
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_ro-virology": {
      "acc": true
    },
    "ogx_mmlux_ro-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sk-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sk-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sk-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sk-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sk-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sk-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sk-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sk-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sk-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sk-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sk-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sk-international_law": {
      "acc": true
    },
    "ogx_mmlux_sk-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sk-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sk-management": {
      "acc": true
    },
    "ogx_mmlux_sk-marketing": {
      "acc": true
    },
    "ogx_mmlux_sk-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sk-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sk-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sk-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sk-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sk-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sk-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sk-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sk-sociology": {
      "acc": true
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sk-virology": {
      "acc": true
    },
    "ogx_mmlux_sk-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sl-international_law": {
      "acc": true
    },
    "ogx_mmlux_sl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sl-management": {
      "acc": true
    },
    "ogx_mmlux_sl-marketing": {
      "acc": true
    },
    "ogx_mmlux_sl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sl-sociology": {
      "acc": true
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sl-virology": {
      "acc": true
    },
    "ogx_mmlux_sl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sv-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sv-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sv-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sv-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sv-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sv-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sv-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sv-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sv-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sv-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sv-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sv-international_law": {
      "acc": true
    },
    "ogx_mmlux_sv-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sv-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sv-management": {
      "acc": true
    },
    "ogx_mmlux_sv-marketing": {
      "acc": true
    },
    "ogx_mmlux_sv-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sv-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sv-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sv-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sv-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sv-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sv-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sv-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sv-sociology": {
      "acc": true
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sv-virology": {
      "acc": true
    },
    "ogx_mmlux_sv-world_religions": {
      "acc": true
    }
  },
  "n-samples": {
    "ogx_mmlux_sv-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sv-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sv-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sv-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sv-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sv-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sv-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sv-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sv-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sv-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sv-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sv-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sv-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sv-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sv-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sv-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sv-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sv-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sv-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sv-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sv-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sv-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sv-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sv-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sv-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sv-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sv-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sv-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sv-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sv-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sk-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sk-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sk-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sk-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sk-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sk-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sk-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sk-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sk-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sk-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sk-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sk-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sk-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sk-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sk-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sk-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sk-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sk-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sk-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sk-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sk-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sk-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sk-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sk-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sk-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sk-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sk-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sk-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sk-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_ro-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_ro-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_ro-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_ro-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_ro-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_ro-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_ro-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_ro-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_ro-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_ro-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_ro-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_ro-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_ro-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_ro-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_ro-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_ro-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_ro-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_ro-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_ro-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_ro-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_ro-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_ro-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_ro-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_ro-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_ro-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_ro-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_ro-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_ro-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_ro-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_pt-pt-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_pt-pt-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_pt-pt-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_pl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_pl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_pl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_pl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_pl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_pl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_pl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_pl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_pl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_pl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_pl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_pl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_pl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_pl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_pl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_pl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_pl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_pl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_pl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_pl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_pl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_pl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_pl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_pl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_pl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_pl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_pl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_pl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_pl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_nl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_nl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_nl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_nl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_nl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_nl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_nl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_nl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_nl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_nl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_nl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_nl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_nl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_nl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_nl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_nl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_nl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_nl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_nl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_nl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_nl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_nl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_nl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_nl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_nl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_nl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_nl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_nl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_nl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_lv-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_lv-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_lv-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_lv-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_lv-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_lv-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_lv-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_lv-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_lv-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_lv-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_lv-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_lv-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_lv-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_lv-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_lv-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_lv-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_lv-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_lv-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_lv-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_lv-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_lv-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_lv-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_lv-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_lv-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_lv-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_lv-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_lv-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_lv-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_lv-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_lt-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_lt-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_lt-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_lt-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_lt-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_lt-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_lt-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_lt-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_lt-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_lt-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_lt-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_lt-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_lt-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_lt-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_lt-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_lt-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_lt-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_lt-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_lt-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_lt-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_lt-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_lt-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_lt-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_lt-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_lt-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_lt-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_lt-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_lt-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_lt-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_it-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_it-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_it-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_it-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_it-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_it-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_it-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_it-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_it-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_it-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_it-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_it-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_it-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_it-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_it-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_it-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_it-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_it-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_it-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_it-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_it-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_it-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_it-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_it-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_it-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_it-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_it-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_it-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_it-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_it-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_it-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_it-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_it-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_it-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_it-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_it-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_it-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_it-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_it-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_hu-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_hu-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_hu-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_hu-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_hu-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_hu-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_hu-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_hu-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_hu-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_hu-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_hu-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_hu-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_hu-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_hu-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_hu-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_hu-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_hu-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_hu-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_hu-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_hu-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_hu-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_hu-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_hu-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_hu-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_hu-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_hu-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_hu-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_hu-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_hu-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_fr-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_fr-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_fr-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_fr-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_fr-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_fr-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_fr-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_fr-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_fr-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_fr-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_fr-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_fr-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_fr-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_fr-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_fr-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_fr-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_fr-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_fr-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_fr-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_fr-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_fr-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_fr-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_fr-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_fr-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_fr-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_fr-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_fr-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_fr-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_fr-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_fi-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_fi-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_fi-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_fi-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_fi-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_fi-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_fi-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_fi-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_fi-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_fi-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_fi-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_fi-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_fi-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_fi-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_fi-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_fi-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_fi-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_fi-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_fi-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_fi-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_fi-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_fi-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_fi-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_fi-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_fi-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_fi-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_fi-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_fi-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_fi-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_et-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_et-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_et-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_et-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_et-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_et-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_et-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_et-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_et-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_et-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_et-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_et-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_et-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_et-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_et-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_et-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_et-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_et-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_et-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_et-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_et-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_et-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_et-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_et-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_et-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_et-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_et-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_et-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_et-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_et-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_et-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_et-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_et-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_et-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_et-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_et-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_et-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_et-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_et-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_es-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_es-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_es-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_es-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_es-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_es-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_es-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_es-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_es-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_es-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_es-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_es-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_es-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_es-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_es-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_es-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_es-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_es-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_es-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_es-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_es-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_es-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_es-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_es-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_es-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_es-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_es-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_es-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_es-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_es-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_es-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_es-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_es-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_es-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_es-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_es-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_es-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_es-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_es-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_el-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_el-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_el-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_el-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_el-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_el-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_el-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_el-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_el-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_el-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_el-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_el-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_el-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_el-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_el-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_el-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_el-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_el-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_el-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_el-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_el-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_el-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_el-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_el-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_el-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_el-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_el-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_el-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_el-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_el-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_el-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_el-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_el-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_el-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_el-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_el-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_el-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_el-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_el-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_de-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_de-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_de-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_de-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_de-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_de-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_de-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_de-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_de-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_de-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_de-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_de-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_de-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_de-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_de-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_de-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_de-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_de-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_de-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_de-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_de-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_de-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_de-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_de-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_de-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_de-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_de-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_de-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_de-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_de-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_de-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_de-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_de-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_de-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_de-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_de-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_de-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_de-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_de-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_da-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_da-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_da-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_da-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_da-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_da-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_da-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_da-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_da-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_da-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_da-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_da-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_da-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_da-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_da-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_da-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_da-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_da-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_da-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_da-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_da-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_da-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_da-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_da-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_da-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_da-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_da-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_da-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_da-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_da-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_da-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_da-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_da-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_da-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_da-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_da-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_da-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_da-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_da-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_cs-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_cs-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_cs-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_cs-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_cs-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_cs-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_cs-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_cs-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_cs-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_cs-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_cs-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_cs-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_cs-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_cs-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_cs-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_cs-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_cs-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_cs-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_cs-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_cs-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_cs-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_cs-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_cs-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_cs-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_cs-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_cs-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_cs-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_cs-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_cs-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_bg-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_bg-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_bg-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_bg-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_bg-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_bg-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_bg-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_bg-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_bg-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_bg-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_bg-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_bg-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_bg-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_bg-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_bg-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_bg-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_bg-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_bg-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_bg-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_bg-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_bg-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_bg-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_bg-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_bg-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_bg-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_bg-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_bg-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_bg-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_bg-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_bg-abstract_algebra": {
      "original": 100,
      "effective": 100
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=CohereForAI/aya-expanse-8b,dtype=bfloat16,trust_remote_code=True,nccl_timeout=3600,trust_remote_code=True",
    "model_num_parameters": 8028033024,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "d10159f8405826732641ce11c6892459d447d48c",
    "batch_size": "auto",
    "batch_sizes": [
      4
    ],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "43468b99",
  "date": 1740785171.857487,
  "pretty_env_info": "PyTorch version: 2.5.1\nIs debug build: False\nCUDA used to build PyTorch: 12.1\nROCM used to build PyTorch: N/A\n\nOS: Red Hat Enterprise Linux release 8.10 (Ootpa) (x86_64)\nGCC version: (GCC) 8.5.0 20210514 (Red Hat 8.5.0-23)\nClang version: Could not collect\nCMake version: version 3.26.5\nLibc version: glibc-2.28\n\nPython version: 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0] (64-bit runtime)\nPython platform: Linux-4.18.0-553.el8_10.x86_64-x86_64-with-glibc2.28\nIs CUDA available: True\nCUDA runtime version: 12.1.105\nCUDA_MODULE_LOADING set to: LAZY\nGPU models and configuration: \nGPU 0: NVIDIA A100-SXM4-80GB\nGPU 1: NVIDIA A100-SXM4-80GB\n\nNvidia driver version: 560.35.05\ncuDNN version: Could not collect\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nArchitecture:        x86_64\nCPU op-mode(s):      32-bit, 64-bit\nByte Order:          Little Endian\nCPU(s):              144\nOn-line CPU(s) list: 0-143\nThread(s) per core:  2\nCore(s) per socket:  36\nSocket(s):           2\nNUMA node(s):        2\nVendor ID:           GenuineIntel\nCPU family:          6\nModel:               106\nModel name:          Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz\nStepping:            6\nCPU MHz:             2400.000\nBogoMIPS:            4800.00\nVirtualization:      VT-x\nL1d cache:           48K\nL1i cache:           32K\nL2 cache:            1280K\nL3 cache:            55296K\nNUMA node0 CPU(s):   0-35,72-107\nNUMA node1 CPU(s):   36-71,108-143\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 invpcid_single intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb intel_pt avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local split_lock_detect wbnoinvd dtherm ida arat pln pts hwp_epp avx512vbmi umip pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq rdpid fsrm md_clear pconfig flush_l1d arch_capabilities\n\nVersions of relevant libraries:\n[pip3] numpy==2.0.1\n[pip3] torch==2.5.1\n[pip3] torchaudio==2.5.1\n[pip3] torchvision==0.20.1\n[pip3] triton==3.1.0\n[conda] blas                      1.0                         mkl  \n[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch\n[conda] libjpeg-turbo             2.0.0                h9bf148f_0    pytorch\n[conda] mkl                       2023.1.0         h213fc3f_46344  \n[conda] mkl-service               2.4.0           py310h5eee18b_1  \n[conda] mkl_fft                   1.3.11          py310h5eee18b_0  \n[conda] mkl_random                1.2.8           py310h1128e8f_0  \n[conda] numpy                     2.0.1           py310h5f9d8c6_1  \n[conda] numpy-base                2.0.1           py310hb5e798b_1  \n[conda] pytorch                   2.5.1           py3.10_cuda12.1_cudnn9.1.0_0    pytorch\n[conda] pytorch-cuda              12.1                 ha16c6d3_6    pytorch\n[conda] pytorch-mutex             1.0                        cuda    pytorch\n[conda] torchaudio                2.5.1               py310_cu121    pytorch\n[conda] torchtriton               3.1.0                     py310    pytorch\n[conda] torchvision               0.20.1              py310_cu121    pytorch",
  "transformers_version": "4.49.0",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<PAD>",
    0
  ],
  "tokenizer_eos_token": [
    "<|END_OF_TURN_TOKEN|>",
    255001
  ],
  "tokenizer_bos_token": [
    "<BOS_TOKEN>",
    5
  ],
  "eot_token_id": 255001,
  "max_length": 8192,
  "task_hashes": {},
  "model_source": "hf",
  "model_name": "CohereForAI/aya-expanse-8b",
  "model_name_sanitized": "CohereForAI__aya-expanse-8b",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": true,
  "chat_template": "{{ bos_token }}{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% elif false == true %}{% set loop_messages = messages %}{% set system_message = 'You are Aya, a brilliant, sophisticated, multilingual AI-assistant trained to assist human users by providing thorough responses. You are able to interact and respond to questions in 23 languages and you are powered by a multilingual model built by Cohere For AI.' %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% if system_message != false %}{{ '<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>' + system_message + '<|END_OF_TURN_TOKEN|>' }}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<|START_OF_TURN_TOKEN|><|USER_TOKEN|>' + content.strip() + '<|END_OF_TURN_TOKEN|>' }}{% elif message['role'] == 'assistant' %}{{ '<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>'  + content.strip() + '<|END_OF_TURN_TOKEN|>' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>' }}{% endif %}",
  "chat_template_sha": "90c33aee14aa2a226127516d48ee9184c9b90745d4a04c484621ec2e82fb712c",
  "start_time": 15592.937198153,
  "end_time": 34620.765291483,
  "total_evaluation_time_seconds": "19027.828093330005"
}