{
  "results": {
    "ogx_mmlux_sv-world_religions": {
      "acc,none": 0.7192982456140351,
      "acc_stderr,none": 0.034462962170884265,
      "alias": "ogx_mmlux_sv-world_religions"
    },
    "ogx_mmlux_sv-virology": {
      "acc,none": 0.5120481927710844,
      "acc_stderr,none": 0.03891364495835816,
      "alias": "ogx_mmlux_sv-virology"
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "acc,none": 0.83,
      "acc_stderr,none": 0.03775251680686371,
      "alias": "ogx_mmlux_sv-us_foreign_policy"
    },
    "ogx_mmlux_sv-sociology": {
      "acc,none": 0.7661691542288557,
      "acc_stderr,none": 0.029929415408348384,
      "alias": "ogx_mmlux_sv-sociology"
    },
    "ogx_mmlux_sv-security_studies": {
      "acc,none": 0.636734693877551,
      "acc_stderr,none": 0.030789051139030806,
      "alias": "ogx_mmlux_sv-security_studies"
    },
    "ogx_mmlux_sv-public_relations": {
      "acc,none": 0.5909090909090909,
      "acc_stderr,none": 0.04709306978661896,
      "alias": "ogx_mmlux_sv-public_relations"
    },
    "ogx_mmlux_sv-professional_psychology": {
      "acc,none": 0.5555555555555556,
      "acc_stderr,none": 0.02010258389588718,
      "alias": "ogx_mmlux_sv-professional_psychology"
    },
    "ogx_mmlux_sv-professional_medicine": {
      "acc,none": 0.5404411764705882,
      "acc_stderr,none": 0.03027332507734575,
      "alias": "ogx_mmlux_sv-professional_medicine"
    },
    "ogx_mmlux_sv-professional_law": {
      "acc,none": 0.39895697522816165,
      "acc_stderr,none": 0.01250675765529367,
      "alias": "ogx_mmlux_sv-professional_law"
    },
    "ogx_mmlux_sv-professional_accounting": {
      "acc,none": 0.43617021276595747,
      "acc_stderr,none": 0.02958345203628407,
      "alias": "ogx_mmlux_sv-professional_accounting"
    },
    "ogx_mmlux_sv-prehistory": {
      "acc,none": 0.6327160493827161,
      "acc_stderr,none": 0.02682280175950789,
      "alias": "ogx_mmlux_sv-prehistory"
    },
    "ogx_mmlux_sv-philosophy": {
      "acc,none": 0.6430868167202572,
      "acc_stderr,none": 0.027210420375934023,
      "alias": "ogx_mmlux_sv-philosophy"
    },
    "ogx_mmlux_sv-nutrition": {
      "acc,none": 0.6797385620915033,
      "acc_stderr,none": 0.026716118380156847,
      "alias": "ogx_mmlux_sv-nutrition"
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "acc,none": 0.35977653631284917,
      "acc_stderr,none": 0.01605141976031027,
      "alias": "ogx_mmlux_sv-moral_scenarios"
    },
    "ogx_mmlux_sv-moral_disputes": {
      "acc,none": 0.6329479768786127,
      "acc_stderr,none": 0.02595005433765408,
      "alias": "ogx_mmlux_sv-moral_disputes"
    },
    "ogx_mmlux_sv-miscellaneous": {
      "acc,none": 0.7075351213282248,
      "acc_stderr,none": 0.016267000684598652,
      "alias": "ogx_mmlux_sv-miscellaneous"
    },
    "ogx_mmlux_sv-medical_genetics": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.04461960433384741,
      "alias": "ogx_mmlux_sv-medical_genetics"
    },
    "ogx_mmlux_sv-marketing": {
      "acc,none": 0.7393162393162394,
      "acc_stderr,none": 0.02876034895652341,
      "alias": "ogx_mmlux_sv-marketing"
    },
    "ogx_mmlux_sv-management": {
      "acc,none": 0.7864077669902912,
      "acc_stderr,none": 0.04058042015646034,
      "alias": "ogx_mmlux_sv-management"
    },
    "ogx_mmlux_sv-machine_learning": {
      "acc,none": 0.4732142857142857,
      "acc_stderr,none": 0.047389751192741546,
      "alias": "ogx_mmlux_sv-machine_learning"
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "acc,none": 0.6319018404907976,
      "acc_stderr,none": 0.03789213935838395,
      "alias": "ogx_mmlux_sv-logical_fallacies"
    },
    "ogx_mmlux_sv-jurisprudence": {
      "acc,none": 0.6759259259259259,
      "acc_stderr,none": 0.045245960070300496,
      "alias": "ogx_mmlux_sv-jurisprudence"
    },
    "ogx_mmlux_sv-international_law": {
      "acc,none": 0.7603305785123967,
      "acc_stderr,none": 0.038968789850704164,
      "alias": "ogx_mmlux_sv-international_law"
    },
    "ogx_mmlux_sv-human_sexuality": {
      "acc,none": 0.7175572519083969,
      "acc_stderr,none": 0.03948406125768361,
      "alias": "ogx_mmlux_sv-human_sexuality"
    },
    "ogx_mmlux_sv-human_aging": {
      "acc,none": 0.6322869955156951,
      "acc_stderr,none": 0.03236198350928276,
      "alias": "ogx_mmlux_sv-human_aging"
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "acc,none": 0.7510548523206751,
      "acc_stderr,none": 0.028146970599422644,
      "alias": "ogx_mmlux_sv-high_school_world_history"
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "acc,none": 0.7156862745098039,
      "acc_stderr,none": 0.0316600967939981,
      "alias": "ogx_mmlux_sv-high_school_us_history"
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "acc,none": 0.4722222222222222,
      "acc_stderr,none": 0.0340470532865388,
      "alias": "ogx_mmlux_sv-high_school_statistics"
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "acc,none": 0.7211009174311926,
      "acc_stderr,none": 0.01922746887646352,
      "alias": "ogx_mmlux_sv-high_school_psychology"
    },
    "ogx_mmlux_sv-high_school_physics": {
      "acc,none": 0.41721854304635764,
      "acc_stderr,none": 0.040261414976346104,
      "alias": "ogx_mmlux_sv-high_school_physics"
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "acc,none": 0.5840336134453782,
      "acc_stderr,none": 0.03201650100739611,
      "alias": "ogx_mmlux_sv-high_school_microeconomics"
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "acc,none": 0.3962962962962963,
      "acc_stderr,none": 0.029822619458534,
      "alias": "ogx_mmlux_sv-high_school_mathematics"
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "acc,none": 0.49743589743589745,
      "acc_stderr,none": 0.025350672979412188,
      "alias": "ogx_mmlux_sv-high_school_macroeconomics"
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "acc,none": 0.6839378238341969,
      "acc_stderr,none": 0.033553973696861736,
      "alias": "ogx_mmlux_sv-high_school_government_and_politics"
    },
    "ogx_mmlux_sv-high_school_geography": {
      "acc,none": 0.7272727272727273,
      "acc_stderr,none": 0.03173071239071724,
      "alias": "ogx_mmlux_sv-high_school_geography"
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "acc,none": 0.7636363636363637,
      "acc_stderr,none": 0.033175059300091805,
      "alias": "ogx_mmlux_sv-high_school_european_history"
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_sv-high_school_computer_science"
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "acc,none": 0.4433497536945813,
      "acc_stderr,none": 0.03495334582162933,
      "alias": "ogx_mmlux_sv-high_school_chemistry"
    },
    "ogx_mmlux_sv-high_school_biology": {
      "acc,none": 0.6806451612903226,
      "acc_stderr,none": 0.02652270967466777,
      "alias": "ogx_mmlux_sv-high_school_biology"
    },
    "ogx_mmlux_sv-global_facts": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_sv-global_facts"
    },
    "ogx_mmlux_sv-formal_logic": {
      "acc,none": 0.4365079365079365,
      "acc_stderr,none": 0.04435932892851466,
      "alias": "ogx_mmlux_sv-formal_logic"
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "acc,none": 0.3968253968253968,
      "acc_stderr,none": 0.025197101074246494,
      "alias": "ogx_mmlux_sv-elementary_mathematics"
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "acc,none": 0.6137931034482759,
      "acc_stderr,none": 0.04057324734419035,
      "alias": "ogx_mmlux_sv-electrical_engineering"
    },
    "ogx_mmlux_sv-econometrics": {
      "acc,none": 0.4298245614035088,
      "acc_stderr,none": 0.04657047260594964,
      "alias": "ogx_mmlux_sv-econometrics"
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "acc,none": 0.4978723404255319,
      "acc_stderr,none": 0.032685726586674915,
      "alias": "ogx_mmlux_sv-conceptual_physics"
    },
    "ogx_mmlux_sv-computer_security": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.04408440022768078,
      "alias": "ogx_mmlux_sv-computer_security"
    },
    "ogx_mmlux_sv-college_physics": {
      "acc,none": 0.3627450980392157,
      "acc_stderr,none": 0.04784060704105654,
      "alias": "ogx_mmlux_sv-college_physics"
    },
    "ogx_mmlux_sv-college_medicine": {
      "acc,none": 0.5144508670520231,
      "acc_stderr,none": 0.03810871630454764,
      "alias": "ogx_mmlux_sv-college_medicine"
    },
    "ogx_mmlux_sv-college_mathematics": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_sv-college_mathematics"
    },
    "ogx_mmlux_sv-college_computer_science": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620333,
      "alias": "ogx_mmlux_sv-college_computer_science"
    },
    "ogx_mmlux_sv-college_chemistry": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_sv-college_chemistry"
    },
    "ogx_mmlux_sv-college_biology": {
      "acc,none": 0.6180555555555556,
      "acc_stderr,none": 0.040629907841466674,
      "alias": "ogx_mmlux_sv-college_biology"
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "acc,none": 0.6113207547169811,
      "acc_stderr,none": 0.03000048544867599,
      "alias": "ogx_mmlux_sv-clinical_knowledge"
    },
    "ogx_mmlux_sv-business_ethics": {
      "acc,none": 0.56,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_sv-business_ethics"
    },
    "ogx_mmlux_sv-astronomy": {
      "acc,none": 0.6710526315789473,
      "acc_stderr,none": 0.038234289699266046,
      "alias": "ogx_mmlux_sv-astronomy"
    },
    "ogx_mmlux_sv-anatomy": {
      "acc,none": 0.5703703703703704,
      "acc_stderr,none": 0.04276349494376599,
      "alias": "ogx_mmlux_sv-anatomy"
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_sv-abstract_algebra"
    },
    "ogx_mmlux_sl-world_religions": {
      "acc,none": 0.7426900584795322,
      "acc_stderr,none": 0.03352799844161865,
      "alias": "ogx_mmlux_sl-world_religions"
    },
    "ogx_mmlux_sl-virology": {
      "acc,none": 0.463855421686747,
      "acc_stderr,none": 0.03882310850890593,
      "alias": "ogx_mmlux_sl-virology"
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.04351941398892446,
      "alias": "ogx_mmlux_sl-us_foreign_policy"
    },
    "ogx_mmlux_sl-sociology": {
      "acc,none": 0.6965174129353234,
      "acc_stderr,none": 0.03251006816458618,
      "alias": "ogx_mmlux_sl-sociology"
    },
    "ogx_mmlux_sl-security_studies": {
      "acc,none": 0.6081632653061224,
      "acc_stderr,none": 0.03125127591089165,
      "alias": "ogx_mmlux_sl-security_studies"
    },
    "ogx_mmlux_sl-public_relations": {
      "acc,none": 0.5818181818181818,
      "acc_stderr,none": 0.04724577405731571,
      "alias": "ogx_mmlux_sl-public_relations"
    },
    "ogx_mmlux_sl-professional_psychology": {
      "acc,none": 0.4722222222222222,
      "acc_stderr,none": 0.0201965949335412,
      "alias": "ogx_mmlux_sl-professional_psychology"
    },
    "ogx_mmlux_sl-professional_medicine": {
      "acc,none": 0.4411764705882353,
      "acc_stderr,none": 0.030161911930767102,
      "alias": "ogx_mmlux_sl-professional_medicine"
    },
    "ogx_mmlux_sl-professional_law": {
      "acc,none": 0.3644067796610169,
      "acc_stderr,none": 0.01229169498305648,
      "alias": "ogx_mmlux_sl-professional_law"
    },
    "ogx_mmlux_sl-professional_accounting": {
      "acc,none": 0.35106382978723405,
      "acc_stderr,none": 0.028473501272963758,
      "alias": "ogx_mmlux_sl-professional_accounting"
    },
    "ogx_mmlux_sl-prehistory": {
      "acc,none": 0.6049382716049383,
      "acc_stderr,none": 0.027201117666925664,
      "alias": "ogx_mmlux_sl-prehistory"
    },
    "ogx_mmlux_sl-philosophy": {
      "acc,none": 0.5627009646302251,
      "acc_stderr,none": 0.028173917761762902,
      "alias": "ogx_mmlux_sl-philosophy"
    },
    "ogx_mmlux_sl-nutrition": {
      "acc,none": 0.5849673202614379,
      "acc_stderr,none": 0.0282135041778241,
      "alias": "ogx_mmlux_sl-nutrition"
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "acc,none": 0.26033519553072626,
      "acc_stderr,none": 0.014676252009319471,
      "alias": "ogx_mmlux_sl-moral_scenarios"
    },
    "ogx_mmlux_sl-moral_disputes": {
      "acc,none": 0.5982658959537572,
      "acc_stderr,none": 0.026394104177643627,
      "alias": "ogx_mmlux_sl-moral_disputes"
    },
    "ogx_mmlux_sl-miscellaneous": {
      "acc,none": 0.6296296296296297,
      "acc_stderr,none": 0.017268607560005773,
      "alias": "ogx_mmlux_sl-miscellaneous"
    },
    "ogx_mmlux_sl-medical_genetics": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.04878317312145633,
      "alias": "ogx_mmlux_sl-medical_genetics"
    },
    "ogx_mmlux_sl-marketing": {
      "acc,none": 0.717948717948718,
      "acc_stderr,none": 0.029480360549541194,
      "alias": "ogx_mmlux_sl-marketing"
    },
    "ogx_mmlux_sl-management": {
      "acc,none": 0.6601941747572816,
      "acc_stderr,none": 0.04689765937278134,
      "alias": "ogx_mmlux_sl-management"
    },
    "ogx_mmlux_sl-machine_learning": {
      "acc,none": 0.48214285714285715,
      "acc_stderr,none": 0.047427623612430116,
      "alias": "ogx_mmlux_sl-machine_learning"
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "acc,none": 0.5644171779141104,
      "acc_stderr,none": 0.03895632464138937,
      "alias": "ogx_mmlux_sl-logical_fallacies"
    },
    "ogx_mmlux_sl-jurisprudence": {
      "acc,none": 0.6759259259259259,
      "acc_stderr,none": 0.04524596007030048,
      "alias": "ogx_mmlux_sl-jurisprudence"
    },
    "ogx_mmlux_sl-international_law": {
      "acc,none": 0.6694214876033058,
      "acc_stderr,none": 0.042943408452120954,
      "alias": "ogx_mmlux_sl-international_law"
    },
    "ogx_mmlux_sl-human_sexuality": {
      "acc,none": 0.648854961832061,
      "acc_stderr,none": 0.041864451630137495,
      "alias": "ogx_mmlux_sl-human_sexuality"
    },
    "ogx_mmlux_sl-human_aging": {
      "acc,none": 0.5605381165919282,
      "acc_stderr,none": 0.033310925110381785,
      "alias": "ogx_mmlux_sl-human_aging"
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "acc,none": 0.6835443037974683,
      "acc_stderr,none": 0.030274974880218974,
      "alias": "ogx_mmlux_sl-high_school_world_history"
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "acc,none": 0.696078431372549,
      "acc_stderr,none": 0.03228210387037895,
      "alias": "ogx_mmlux_sl-high_school_us_history"
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "acc,none": 0.42592592592592593,
      "acc_stderr,none": 0.03372343271653063,
      "alias": "ogx_mmlux_sl-high_school_statistics"
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "acc,none": 0.6477064220183486,
      "acc_stderr,none": 0.020480568843999,
      "alias": "ogx_mmlux_sl-high_school_psychology"
    },
    "ogx_mmlux_sl-high_school_physics": {
      "acc,none": 0.40397350993377484,
      "acc_stderr,none": 0.040064856853653415,
      "alias": "ogx_mmlux_sl-high_school_physics"
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "acc,none": 0.5210084033613446,
      "acc_stderr,none": 0.032449808499900284,
      "alias": "ogx_mmlux_sl-high_school_microeconomics"
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "acc,none": 0.362962962962963,
      "acc_stderr,none": 0.029318203645206858,
      "alias": "ogx_mmlux_sl-high_school_mathematics"
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "acc,none": 0.441025641025641,
      "acc_stderr,none": 0.025174048384000742,
      "alias": "ogx_mmlux_sl-high_school_macroeconomics"
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "acc,none": 0.5544041450777202,
      "acc_stderr,none": 0.03587014986075659,
      "alias": "ogx_mmlux_sl-high_school_government_and_politics"
    },
    "ogx_mmlux_sl-high_school_geography": {
      "acc,none": 0.6868686868686869,
      "acc_stderr,none": 0.033042050878136525,
      "alias": "ogx_mmlux_sl-high_school_geography"
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "acc,none": 0.6787878787878788,
      "acc_stderr,none": 0.036462049632538115,
      "alias": "ogx_mmlux_sl-high_school_european_history"
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_sl-high_school_computer_science"
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "acc,none": 0.4236453201970443,
      "acc_stderr,none": 0.034767257476490385,
      "alias": "ogx_mmlux_sl-high_school_chemistry"
    },
    "ogx_mmlux_sl-high_school_biology": {
      "acc,none": 0.5903225806451613,
      "acc_stderr,none": 0.02797605491534736,
      "alias": "ogx_mmlux_sl-high_school_biology"
    },
    "ogx_mmlux_sl-global_facts": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_sl-global_facts"
    },
    "ogx_mmlux_sl-formal_logic": {
      "acc,none": 0.3968253968253968,
      "acc_stderr,none": 0.0437588849272706,
      "alias": "ogx_mmlux_sl-formal_logic"
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "acc,none": 0.3835978835978836,
      "acc_stderr,none": 0.0250437573185202,
      "alias": "ogx_mmlux_sl-elementary_mathematics"
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "acc,none": 0.5586206896551724,
      "acc_stderr,none": 0.04137931034482758,
      "alias": "ogx_mmlux_sl-electrical_engineering"
    },
    "ogx_mmlux_sl-econometrics": {
      "acc,none": 0.43859649122807015,
      "acc_stderr,none": 0.04668000738510455,
      "alias": "ogx_mmlux_sl-econometrics"
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "acc,none": 0.46808510638297873,
      "acc_stderr,none": 0.03261936918467381,
      "alias": "ogx_mmlux_sl-conceptual_physics"
    },
    "ogx_mmlux_sl-computer_security": {
      "acc,none": 0.65,
      "acc_stderr,none": 0.04793724854411019,
      "alias": "ogx_mmlux_sl-computer_security"
    },
    "ogx_mmlux_sl-college_physics": {
      "acc,none": 0.2647058823529412,
      "acc_stderr,none": 0.0438986995680878,
      "alias": "ogx_mmlux_sl-college_physics"
    },
    "ogx_mmlux_sl-college_medicine": {
      "acc,none": 0.4624277456647399,
      "acc_stderr,none": 0.0380168510452446,
      "alias": "ogx_mmlux_sl-college_medicine"
    },
    "ogx_mmlux_sl-college_mathematics": {
      "acc,none": 0.23,
      "acc_stderr,none": 0.04229525846816506,
      "alias": "ogx_mmlux_sl-college_mathematics"
    },
    "ogx_mmlux_sl-college_computer_science": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_sl-college_computer_science"
    },
    "ogx_mmlux_sl-college_chemistry": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_sl-college_chemistry"
    },
    "ogx_mmlux_sl-college_biology": {
      "acc,none": 0.5902777777777778,
      "acc_stderr,none": 0.04112490974670787,
      "alias": "ogx_mmlux_sl-college_biology"
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "acc,none": 0.5169811320754717,
      "acc_stderr,none": 0.030755120364119898,
      "alias": "ogx_mmlux_sl-clinical_knowledge"
    },
    "ogx_mmlux_sl-business_ethics": {
      "acc,none": 0.54,
      "acc_stderr,none": 0.05009082659620333,
      "alias": "ogx_mmlux_sl-business_ethics"
    },
    "ogx_mmlux_sl-astronomy": {
      "acc,none": 0.5921052631578947,
      "acc_stderr,none": 0.039993097127774734,
      "alias": "ogx_mmlux_sl-astronomy"
    },
    "ogx_mmlux_sl-anatomy": {
      "acc,none": 0.5185185185185185,
      "acc_stderr,none": 0.04316378599511324,
      "alias": "ogx_mmlux_sl-anatomy"
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542128,
      "alias": "ogx_mmlux_sl-abstract_algebra"
    },
    "ogx_mmlux_sk-world_religions": {
      "acc,none": 0.7368421052631579,
      "acc_stderr,none": 0.03377310252209205,
      "alias": "ogx_mmlux_sk-world_religions"
    },
    "ogx_mmlux_sk-virology": {
      "acc,none": 0.4879518072289157,
      "acc_stderr,none": 0.03891364495835821,
      "alias": "ogx_mmlux_sk-virology"
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "acc,none": 0.79,
      "acc_stderr,none": 0.040936018074033256,
      "alias": "ogx_mmlux_sk-us_foreign_policy"
    },
    "ogx_mmlux_sk-sociology": {
      "acc,none": 0.7661691542288557,
      "acc_stderr,none": 0.029929415408348373,
      "alias": "ogx_mmlux_sk-sociology"
    },
    "ogx_mmlux_sk-security_studies": {
      "acc,none": 0.5959183673469388,
      "acc_stderr,none": 0.0314147080258659,
      "alias": "ogx_mmlux_sk-security_studies"
    },
    "ogx_mmlux_sk-public_relations": {
      "acc,none": 0.5636363636363636,
      "acc_stderr,none": 0.04750185058907297,
      "alias": "ogx_mmlux_sk-public_relations"
    },
    "ogx_mmlux_sk-professional_psychology": {
      "acc,none": 0.5310457516339869,
      "acc_stderr,none": 0.020188804456361887,
      "alias": "ogx_mmlux_sk-professional_psychology"
    },
    "ogx_mmlux_sk-professional_medicine": {
      "acc,none": 0.46691176470588236,
      "acc_stderr,none": 0.030306257722468314,
      "alias": "ogx_mmlux_sk-professional_medicine"
    },
    "ogx_mmlux_sk-professional_law": {
      "acc,none": 0.37157757496740546,
      "acc_stderr,none": 0.012341828514528294,
      "alias": "ogx_mmlux_sk-professional_law"
    },
    "ogx_mmlux_sk-professional_accounting": {
      "acc,none": 0.40070921985815605,
      "acc_stderr,none": 0.02923346574557309,
      "alias": "ogx_mmlux_sk-professional_accounting"
    },
    "ogx_mmlux_sk-prehistory": {
      "acc,none": 0.6172839506172839,
      "acc_stderr,none": 0.027044538138402602,
      "alias": "ogx_mmlux_sk-prehistory"
    },
    "ogx_mmlux_sk-philosophy": {
      "acc,none": 0.5980707395498392,
      "acc_stderr,none": 0.027846476005930477,
      "alias": "ogx_mmlux_sk-philosophy"
    },
    "ogx_mmlux_sk-nutrition": {
      "acc,none": 0.630718954248366,
      "acc_stderr,none": 0.02763417668960266,
      "alias": "ogx_mmlux_sk-nutrition"
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "acc,none": 0.26145251396648045,
      "acc_stderr,none": 0.014696599650364555,
      "alias": "ogx_mmlux_sk-moral_scenarios"
    },
    "ogx_mmlux_sk-moral_disputes": {
      "acc,none": 0.5433526011560693,
      "acc_stderr,none": 0.026817718130348913,
      "alias": "ogx_mmlux_sk-moral_disputes"
    },
    "ogx_mmlux_sk-miscellaneous": {
      "acc,none": 0.6385696040868455,
      "acc_stderr,none": 0.01717960132890074,
      "alias": "ogx_mmlux_sk-miscellaneous"
    },
    "ogx_mmlux_sk-medical_genetics": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_sk-medical_genetics"
    },
    "ogx_mmlux_sk-marketing": {
      "acc,none": 0.7606837606837606,
      "acc_stderr,none": 0.027951826808924333,
      "alias": "ogx_mmlux_sk-marketing"
    },
    "ogx_mmlux_sk-management": {
      "acc,none": 0.6990291262135923,
      "acc_stderr,none": 0.04541609446503948,
      "alias": "ogx_mmlux_sk-management"
    },
    "ogx_mmlux_sk-machine_learning": {
      "acc,none": 0.375,
      "acc_stderr,none": 0.04595091388086298,
      "alias": "ogx_mmlux_sk-machine_learning"
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "acc,none": 0.5766871165644172,
      "acc_stderr,none": 0.03881891213334384,
      "alias": "ogx_mmlux_sk-logical_fallacies"
    },
    "ogx_mmlux_sk-jurisprudence": {
      "acc,none": 0.6666666666666666,
      "acc_stderr,none": 0.04557239513497751,
      "alias": "ogx_mmlux_sk-jurisprudence"
    },
    "ogx_mmlux_sk-international_law": {
      "acc,none": 0.6611570247933884,
      "acc_stderr,none": 0.04320767807536669,
      "alias": "ogx_mmlux_sk-international_law"
    },
    "ogx_mmlux_sk-human_sexuality": {
      "acc,none": 0.6564885496183206,
      "acc_stderr,none": 0.04164976071944878,
      "alias": "ogx_mmlux_sk-human_sexuality"
    },
    "ogx_mmlux_sk-human_aging": {
      "acc,none": 0.5560538116591929,
      "acc_stderr,none": 0.03334625674242728,
      "alias": "ogx_mmlux_sk-human_aging"
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "acc,none": 0.6962025316455697,
      "acc_stderr,none": 0.02993669638713861,
      "alias": "ogx_mmlux_sk-high_school_world_history"
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "acc,none": 0.7058823529411765,
      "acc_stderr,none": 0.0319800166011507,
      "alias": "ogx_mmlux_sk-high_school_us_history"
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "acc,none": 0.42592592592592593,
      "acc_stderr,none": 0.033723432716530624,
      "alias": "ogx_mmlux_sk-high_school_statistics"
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "acc,none": 0.655045871559633,
      "acc_stderr,none": 0.020380605405066962,
      "alias": "ogx_mmlux_sk-high_school_psychology"
    },
    "ogx_mmlux_sk-high_school_physics": {
      "acc,none": 0.31788079470198677,
      "acc_stderr,none": 0.038020397601079024,
      "alias": "ogx_mmlux_sk-high_school_physics"
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "acc,none": 0.5672268907563025,
      "acc_stderr,none": 0.032183581077426124,
      "alias": "ogx_mmlux_sk-high_school_microeconomics"
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "acc,none": 0.35555555555555557,
      "acc_stderr,none": 0.029185714949857413,
      "alias": "ogx_mmlux_sk-high_school_mathematics"
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "acc,none": 0.47692307692307695,
      "acc_stderr,none": 0.025323990861736114,
      "alias": "ogx_mmlux_sk-high_school_macroeconomics"
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "acc,none": 0.6373056994818653,
      "acc_stderr,none": 0.03469713791704372,
      "alias": "ogx_mmlux_sk-high_school_government_and_politics"
    },
    "ogx_mmlux_sk-high_school_geography": {
      "acc,none": 0.6919191919191919,
      "acc_stderr,none": 0.032894773300986155,
      "alias": "ogx_mmlux_sk-high_school_geography"
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "acc,none": 0.7515151515151515,
      "acc_stderr,none": 0.03374402644139404,
      "alias": "ogx_mmlux_sk-high_school_european_history"
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_sk-high_school_computer_science"
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "acc,none": 0.45320197044334976,
      "acc_stderr,none": 0.03502544650845872,
      "alias": "ogx_mmlux_sk-high_school_chemistry"
    },
    "ogx_mmlux_sk-high_school_biology": {
      "acc,none": 0.6258064516129033,
      "acc_stderr,none": 0.027528904299845707,
      "alias": "ogx_mmlux_sk-high_school_biology"
    },
    "ogx_mmlux_sk-global_facts": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_sk-global_facts"
    },
    "ogx_mmlux_sk-formal_logic": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.04360314860077459,
      "alias": "ogx_mmlux_sk-formal_logic"
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "acc,none": 0.36507936507936506,
      "acc_stderr,none": 0.024796060602699965,
      "alias": "ogx_mmlux_sk-elementary_mathematics"
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "acc,none": 0.6137931034482759,
      "acc_stderr,none": 0.04057324734419034,
      "alias": "ogx_mmlux_sk-electrical_engineering"
    },
    "ogx_mmlux_sk-econometrics": {
      "acc,none": 0.38596491228070173,
      "acc_stderr,none": 0.04579639422070434,
      "alias": "ogx_mmlux_sk-econometrics"
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "acc,none": 0.425531914893617,
      "acc_stderr,none": 0.03232146916224468,
      "alias": "ogx_mmlux_sk-conceptual_physics"
    },
    "ogx_mmlux_sk-computer_security": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_sk-computer_security"
    },
    "ogx_mmlux_sk-college_physics": {
      "acc,none": 0.35294117647058826,
      "acc_stderr,none": 0.047551296160629475,
      "alias": "ogx_mmlux_sk-college_physics"
    },
    "ogx_mmlux_sk-college_medicine": {
      "acc,none": 0.5028901734104047,
      "acc_stderr,none": 0.038124005659748335,
      "alias": "ogx_mmlux_sk-college_medicine"
    },
    "ogx_mmlux_sk-college_mathematics": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_sk-college_mathematics"
    },
    "ogx_mmlux_sk-college_computer_science": {
      "acc,none": 0.41,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_sk-college_computer_science"
    },
    "ogx_mmlux_sk-college_chemistry": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.04960449637488583,
      "alias": "ogx_mmlux_sk-college_chemistry"
    },
    "ogx_mmlux_sk-college_biology": {
      "acc,none": 0.6388888888888888,
      "acc_stderr,none": 0.040166600304512336,
      "alias": "ogx_mmlux_sk-college_biology"
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "acc,none": 0.5924528301886792,
      "acc_stderr,none": 0.030242233800854498,
      "alias": "ogx_mmlux_sk-clinical_knowledge"
    },
    "ogx_mmlux_sk-business_ethics": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_sk-business_ethics"
    },
    "ogx_mmlux_sk-astronomy": {
      "acc,none": 0.5986842105263158,
      "acc_stderr,none": 0.039889037033362836,
      "alias": "ogx_mmlux_sk-astronomy"
    },
    "ogx_mmlux_sk-anatomy": {
      "acc,none": 0.4888888888888889,
      "acc_stderr,none": 0.04318275491977976,
      "alias": "ogx_mmlux_sk-anatomy"
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_sk-abstract_algebra"
    },
    "ogx_mmlux_ro-world_religions": {
      "acc,none": 0.7660818713450293,
      "acc_stderr,none": 0.032467217651178264,
      "alias": "ogx_mmlux_ro-world_religions"
    },
    "ogx_mmlux_ro-virology": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.03892494720807614,
      "alias": "ogx_mmlux_ro-virology"
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "acc,none": 0.83,
      "acc_stderr,none": 0.03775251680686371,
      "alias": "ogx_mmlux_ro-us_foreign_policy"
    },
    "ogx_mmlux_ro-sociology": {
      "acc,none": 0.835820895522388,
      "acc_stderr,none": 0.026193923544454153,
      "alias": "ogx_mmlux_ro-sociology"
    },
    "ogx_mmlux_ro-security_studies": {
      "acc,none": 0.7061224489795919,
      "acc_stderr,none": 0.029162738410249772,
      "alias": "ogx_mmlux_ro-security_studies"
    },
    "ogx_mmlux_ro-public_relations": {
      "acc,none": 0.5909090909090909,
      "acc_stderr,none": 0.04709306978661896,
      "alias": "ogx_mmlux_ro-public_relations"
    },
    "ogx_mmlux_ro-professional_psychology": {
      "acc,none": 0.5522875816993464,
      "acc_stderr,none": 0.02011692534742242,
      "alias": "ogx_mmlux_ro-professional_psychology"
    },
    "ogx_mmlux_ro-professional_medicine": {
      "acc,none": 0.5036764705882353,
      "acc_stderr,none": 0.030372015885428195,
      "alias": "ogx_mmlux_ro-professional_medicine"
    },
    "ogx_mmlux_ro-professional_law": {
      "acc,none": 0.4132985658409387,
      "acc_stderr,none": 0.012576779494860083,
      "alias": "ogx_mmlux_ro-professional_law"
    },
    "ogx_mmlux_ro-professional_accounting": {
      "acc,none": 0.41134751773049644,
      "acc_stderr,none": 0.029354911159940978,
      "alias": "ogx_mmlux_ro-professional_accounting"
    },
    "ogx_mmlux_ro-prehistory": {
      "acc,none": 0.654320987654321,
      "acc_stderr,none": 0.026462487777001876,
      "alias": "ogx_mmlux_ro-prehistory"
    },
    "ogx_mmlux_ro-philosophy": {
      "acc,none": 0.6495176848874598,
      "acc_stderr,none": 0.027098652621301747,
      "alias": "ogx_mmlux_ro-philosophy"
    },
    "ogx_mmlux_ro-nutrition": {
      "acc,none": 0.673202614379085,
      "acc_stderr,none": 0.0268572946632814,
      "alias": "ogx_mmlux_ro-nutrition"
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "acc,none": 0.3318435754189944,
      "acc_stderr,none": 0.015748421208187303,
      "alias": "ogx_mmlux_ro-moral_scenarios"
    },
    "ogx_mmlux_ro-moral_disputes": {
      "acc,none": 0.6213872832369942,
      "acc_stderr,none": 0.02611374936131034,
      "alias": "ogx_mmlux_ro-moral_disputes"
    },
    "ogx_mmlux_ro-miscellaneous": {
      "acc,none": 0.698595146871009,
      "acc_stderr,none": 0.016409091097268794,
      "alias": "ogx_mmlux_ro-miscellaneous"
    },
    "ogx_mmlux_ro-medical_genetics": {
      "acc,none": 0.65,
      "acc_stderr,none": 0.047937248544110196,
      "alias": "ogx_mmlux_ro-medical_genetics"
    },
    "ogx_mmlux_ro-marketing": {
      "acc,none": 0.8034188034188035,
      "acc_stderr,none": 0.02603538609895129,
      "alias": "ogx_mmlux_ro-marketing"
    },
    "ogx_mmlux_ro-management": {
      "acc,none": 0.7184466019417476,
      "acc_stderr,none": 0.044532548363264673,
      "alias": "ogx_mmlux_ro-management"
    },
    "ogx_mmlux_ro-machine_learning": {
      "acc,none": 0.4017857142857143,
      "acc_stderr,none": 0.04653333146973647,
      "alias": "ogx_mmlux_ro-machine_learning"
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "acc,none": 0.6319018404907976,
      "acc_stderr,none": 0.03789213935838396,
      "alias": "ogx_mmlux_ro-logical_fallacies"
    },
    "ogx_mmlux_ro-jurisprudence": {
      "acc,none": 0.7222222222222222,
      "acc_stderr,none": 0.043300437496507416,
      "alias": "ogx_mmlux_ro-jurisprudence"
    },
    "ogx_mmlux_ro-international_law": {
      "acc,none": 0.743801652892562,
      "acc_stderr,none": 0.03984979653302872,
      "alias": "ogx_mmlux_ro-international_law"
    },
    "ogx_mmlux_ro-human_sexuality": {
      "acc,none": 0.6717557251908397,
      "acc_stderr,none": 0.04118438565806299,
      "alias": "ogx_mmlux_ro-human_sexuality"
    },
    "ogx_mmlux_ro-human_aging": {
      "acc,none": 0.5650224215246636,
      "acc_stderr,none": 0.033272833702713445,
      "alias": "ogx_mmlux_ro-human_aging"
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "acc,none": 0.7341772151898734,
      "acc_stderr,none": 0.028756799629658335,
      "alias": "ogx_mmlux_ro-high_school_world_history"
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "acc,none": 0.7401960784313726,
      "acc_stderr,none": 0.03077855467869326,
      "alias": "ogx_mmlux_ro-high_school_us_history"
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "acc,none": 0.46296296296296297,
      "acc_stderr,none": 0.03400603625538272,
      "alias": "ogx_mmlux_ro-high_school_statistics"
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "acc,none": 0.6807339449541284,
      "acc_stderr,none": 0.01998782906975001,
      "alias": "ogx_mmlux_ro-high_school_psychology"
    },
    "ogx_mmlux_ro-high_school_physics": {
      "acc,none": 0.3973509933774834,
      "acc_stderr,none": 0.039955240076816806,
      "alias": "ogx_mmlux_ro-high_school_physics"
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "acc,none": 0.6050420168067226,
      "acc_stderr,none": 0.031753678460966245,
      "alias": "ogx_mmlux_ro-high_school_microeconomics"
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "acc,none": 0.3925925925925926,
      "acc_stderr,none": 0.02977384701253297,
      "alias": "ogx_mmlux_ro-high_school_mathematics"
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "acc,none": 0.5333333333333333,
      "acc_stderr,none": 0.025294608023986472,
      "alias": "ogx_mmlux_ro-high_school_macroeconomics"
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "acc,none": 0.6632124352331606,
      "acc_stderr,none": 0.03410780251836184,
      "alias": "ogx_mmlux_ro-high_school_government_and_politics"
    },
    "ogx_mmlux_ro-high_school_geography": {
      "acc,none": 0.7323232323232324,
      "acc_stderr,none": 0.03154449888270286,
      "alias": "ogx_mmlux_ro-high_school_geography"
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "acc,none": 0.7757575757575758,
      "acc_stderr,none": 0.032568666616811015,
      "alias": "ogx_mmlux_ro-high_school_european_history"
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "acc,none": 0.64,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_ro-high_school_computer_science"
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "acc,none": 0.4630541871921182,
      "acc_stderr,none": 0.035083705204426656,
      "alias": "ogx_mmlux_ro-high_school_chemistry"
    },
    "ogx_mmlux_ro-high_school_biology": {
      "acc,none": 0.6741935483870968,
      "acc_stderr,none": 0.026662010578567107,
      "alias": "ogx_mmlux_ro-high_school_biology"
    },
    "ogx_mmlux_ro-global_facts": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_ro-global_facts"
    },
    "ogx_mmlux_ro-formal_logic": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.04360314860077459,
      "alias": "ogx_mmlux_ro-formal_logic"
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "acc,none": 0.4021164021164021,
      "acc_stderr,none": 0.025253032554997695,
      "alias": "ogx_mmlux_ro-elementary_mathematics"
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "acc,none": 0.6137931034482759,
      "acc_stderr,none": 0.040573247344190336,
      "alias": "ogx_mmlux_ro-electrical_engineering"
    },
    "ogx_mmlux_ro-econometrics": {
      "acc,none": 0.3684210526315789,
      "acc_stderr,none": 0.04537815354939391,
      "alias": "ogx_mmlux_ro-econometrics"
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "acc,none": 0.4978723404255319,
      "acc_stderr,none": 0.03268572658667492,
      "alias": "ogx_mmlux_ro-conceptual_physics"
    },
    "ogx_mmlux_ro-computer_security": {
      "acc,none": 0.76,
      "acc_stderr,none": 0.042923469599092816,
      "alias": "ogx_mmlux_ro-computer_security"
    },
    "ogx_mmlux_ro-college_physics": {
      "acc,none": 0.3627450980392157,
      "acc_stderr,none": 0.04784060704105654,
      "alias": "ogx_mmlux_ro-college_physics"
    },
    "ogx_mmlux_ro-college_medicine": {
      "acc,none": 0.5375722543352601,
      "acc_stderr,none": 0.0380168510452446,
      "alias": "ogx_mmlux_ro-college_medicine"
    },
    "ogx_mmlux_ro-college_mathematics": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_ro-college_mathematics"
    },
    "ogx_mmlux_ro-college_computer_science": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_ro-college_computer_science"
    },
    "ogx_mmlux_ro-college_chemistry": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_ro-college_chemistry"
    },
    "ogx_mmlux_ro-college_biology": {
      "acc,none": 0.5972222222222222,
      "acc_stderr,none": 0.04101405519842426,
      "alias": "ogx_mmlux_ro-college_biology"
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "acc,none": 0.6075471698113207,
      "acc_stderr,none": 0.030052580579557845,
      "alias": "ogx_mmlux_ro-clinical_knowledge"
    },
    "ogx_mmlux_ro-business_ethics": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_ro-business_ethics"
    },
    "ogx_mmlux_ro-astronomy": {
      "acc,none": 0.6578947368421053,
      "acc_stderr,none": 0.03860731599316092,
      "alias": "ogx_mmlux_ro-astronomy"
    },
    "ogx_mmlux_ro-anatomy": {
      "acc,none": 0.5407407407407407,
      "acc_stderr,none": 0.04304979692464242,
      "alias": "ogx_mmlux_ro-anatomy"
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_ro-abstract_algebra"
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "acc,none": 0.7777777777777778,
      "acc_stderr,none": 0.03188578017686398,
      "alias": "ogx_mmlux_pt-pt-world_religions"
    },
    "ogx_mmlux_pt-pt-virology": {
      "acc,none": 0.45180722891566266,
      "acc_stderr,none": 0.038743715565879536,
      "alias": "ogx_mmlux_pt-pt-virology"
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "acc,none": 0.85,
      "acc_stderr,none": 0.0358870281282637,
      "alias": "ogx_mmlux_pt-pt-us_foreign_policy"
    },
    "ogx_mmlux_pt-pt-sociology": {
      "acc,none": 0.8258706467661692,
      "acc_stderr,none": 0.026814951200421603,
      "alias": "ogx_mmlux_pt-pt-sociology"
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "acc,none": 0.7183673469387755,
      "acc_stderr,none": 0.028795185574291303,
      "alias": "ogx_mmlux_pt-pt-security_studies"
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "acc,none": 0.6181818181818182,
      "acc_stderr,none": 0.046534298079135075,
      "alias": "ogx_mmlux_pt-pt-public_relations"
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "acc,none": 0.6013071895424836,
      "acc_stderr,none": 0.01980828131744986,
      "alias": "ogx_mmlux_pt-pt-professional_psychology"
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "acc,none": 0.5735294117647058,
      "acc_stderr,none": 0.03004261583271486,
      "alias": "ogx_mmlux_pt-pt-professional_medicine"
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "acc,none": 0.41395045632333766,
      "acc_stderr,none": 0.012579699631289264,
      "alias": "ogx_mmlux_pt-pt-professional_law"
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "acc,none": 0.4219858156028369,
      "acc_stderr,none": 0.029462189233370593,
      "alias": "ogx_mmlux_pt-pt-professional_accounting"
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "acc,none": 0.6975308641975309,
      "acc_stderr,none": 0.02555765398186806,
      "alias": "ogx_mmlux_pt-pt-prehistory"
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "acc,none": 0.6591639871382636,
      "acc_stderr,none": 0.026920841260776155,
      "alias": "ogx_mmlux_pt-pt-philosophy"
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "acc,none": 0.6797385620915033,
      "acc_stderr,none": 0.026716118380156847,
      "alias": "ogx_mmlux_pt-pt-nutrition"
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "acc,none": 0.3553072625698324,
      "acc_stderr,none": 0.016006989934803182,
      "alias": "ogx_mmlux_pt-pt-moral_scenarios"
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "acc,none": 0.6647398843930635,
      "acc_stderr,none": 0.025416003773165538,
      "alias": "ogx_mmlux_pt-pt-moral_disputes"
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "acc,none": 0.735632183908046,
      "acc_stderr,none": 0.015769984840690518,
      "alias": "ogx_mmlux_pt-pt-miscellaneous"
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_pt-pt-medical_genetics"
    },
    "ogx_mmlux_pt-pt-marketing": {
      "acc,none": 0.7991452991452992,
      "acc_stderr,none": 0.026246772946890484,
      "alias": "ogx_mmlux_pt-pt-marketing"
    },
    "ogx_mmlux_pt-pt-management": {
      "acc,none": 0.7281553398058253,
      "acc_stderr,none": 0.044052680241409216,
      "alias": "ogx_mmlux_pt-pt-management"
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "acc,none": 0.36607142857142855,
      "acc_stderr,none": 0.0457237235873743,
      "alias": "ogx_mmlux_pt-pt-machine_learning"
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "acc,none": 0.6625766871165644,
      "acc_stderr,none": 0.03714908409935573,
      "alias": "ogx_mmlux_pt-pt-logical_fallacies"
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "acc,none": 0.7129629629629629,
      "acc_stderr,none": 0.043733130409147614,
      "alias": "ogx_mmlux_pt-pt-jurisprudence"
    },
    "ogx_mmlux_pt-pt-international_law": {
      "acc,none": 0.743801652892562,
      "acc_stderr,none": 0.03984979653302872,
      "alias": "ogx_mmlux_pt-pt-international_law"
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "acc,none": 0.7251908396946565,
      "acc_stderr,none": 0.03915345408847835,
      "alias": "ogx_mmlux_pt-pt-human_sexuality"
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "acc,none": 0.6278026905829597,
      "acc_stderr,none": 0.032443052830087304,
      "alias": "ogx_mmlux_pt-pt-human_aging"
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "acc,none": 0.7721518987341772,
      "acc_stderr,none": 0.027303484599069446,
      "alias": "ogx_mmlux_pt-pt-high_school_world_history"
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "acc,none": 0.7794117647058824,
      "acc_stderr,none": 0.029102254389674096,
      "alias": "ogx_mmlux_pt-pt-high_school_us_history"
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "acc,none": 0.48148148148148145,
      "acc_stderr,none": 0.034076320938540516,
      "alias": "ogx_mmlux_pt-pt-high_school_statistics"
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "acc,none": 0.7706422018348624,
      "acc_stderr,none": 0.018025349724618684,
      "alias": "ogx_mmlux_pt-pt-high_school_psychology"
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "acc,none": 0.40397350993377484,
      "acc_stderr,none": 0.04006485685365343,
      "alias": "ogx_mmlux_pt-pt-high_school_physics"
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "acc,none": 0.6386554621848739,
      "acc_stderr,none": 0.03120469122515002,
      "alias": "ogx_mmlux_pt-pt-high_school_microeconomics"
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "acc,none": 0.4185185185185185,
      "acc_stderr,none": 0.030078013075022055,
      "alias": "ogx_mmlux_pt-pt-high_school_mathematics"
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "acc,none": 0.5974358974358974,
      "acc_stderr,none": 0.024864995159767762,
      "alias": "ogx_mmlux_pt-pt-high_school_macroeconomics"
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "acc,none": 0.7823834196891192,
      "acc_stderr,none": 0.02977866303775296,
      "alias": "ogx_mmlux_pt-pt-high_school_government_and_politics"
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "acc,none": 0.7727272727272727,
      "acc_stderr,none": 0.029857515673386414,
      "alias": "ogx_mmlux_pt-pt-high_school_geography"
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "acc,none": 0.7818181818181819,
      "acc_stderr,none": 0.03225078108306289,
      "alias": "ogx_mmlux_pt-pt-high_school_european_history"
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_pt-pt-high_school_computer_science"
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "acc,none": 0.5073891625615764,
      "acc_stderr,none": 0.0351760354036101,
      "alias": "ogx_mmlux_pt-pt-high_school_chemistry"
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "acc,none": 0.7129032258064516,
      "acc_stderr,none": 0.025736542745594528,
      "alias": "ogx_mmlux_pt-pt-high_school_biology"
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001974,
      "alias": "ogx_mmlux_pt-pt-global_facts"
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.04360314860077459,
      "alias": "ogx_mmlux_pt-pt-formal_logic"
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "acc,none": 0.42063492063492064,
      "acc_stderr,none": 0.02542483508692399,
      "alias": "ogx_mmlux_pt-pt-elementary_mathematics"
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "acc,none": 0.6068965517241379,
      "acc_stderr,none": 0.0407032901370707,
      "alias": "ogx_mmlux_pt-pt-electrical_engineering"
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "acc,none": 0.3684210526315789,
      "acc_stderr,none": 0.04537815354939392,
      "alias": "ogx_mmlux_pt-pt-econometrics"
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "acc,none": 0.5446808510638298,
      "acc_stderr,none": 0.03255525359340355,
      "alias": "ogx_mmlux_pt-pt-conceptual_physics"
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_pt-pt-computer_security"
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "acc,none": 0.37254901960784315,
      "acc_stderr,none": 0.04810840148082633,
      "alias": "ogx_mmlux_pt-pt-college_physics"
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "acc,none": 0.5375722543352601,
      "acc_stderr,none": 0.0380168510452446,
      "alias": "ogx_mmlux_pt-pt-college_medicine"
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_pt-pt-college_mathematics"
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_pt-pt-college_computer_science"
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_pt-pt-college_chemistry"
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "acc,none": 0.625,
      "acc_stderr,none": 0.04048439222695598,
      "alias": "ogx_mmlux_pt-pt-college_biology"
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "acc,none": 0.6113207547169811,
      "acc_stderr,none": 0.030000485448675986,
      "alias": "ogx_mmlux_pt-pt-clinical_knowledge"
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_pt-pt-business_ethics"
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "acc,none": 0.6907894736842105,
      "acc_stderr,none": 0.03761070869867479,
      "alias": "ogx_mmlux_pt-pt-astronomy"
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "acc,none": 0.5703703703703704,
      "acc_stderr,none": 0.04276349494376599,
      "alias": "ogx_mmlux_pt-pt-anatomy"
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_pt-pt-abstract_algebra"
    },
    "ogx_mmlux_pl-world_religions": {
      "acc,none": 0.7777777777777778,
      "acc_stderr,none": 0.03188578017686399,
      "alias": "ogx_mmlux_pl-world_religions"
    },
    "ogx_mmlux_pl-virology": {
      "acc,none": 0.4879518072289157,
      "acc_stderr,none": 0.03891364495835821,
      "alias": "ogx_mmlux_pl-virology"
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "acc,none": 0.82,
      "acc_stderr,none": 0.03861229196653694,
      "alias": "ogx_mmlux_pl-us_foreign_policy"
    },
    "ogx_mmlux_pl-sociology": {
      "acc,none": 0.7910447761194029,
      "acc_stderr,none": 0.028748298931728655,
      "alias": "ogx_mmlux_pl-sociology"
    },
    "ogx_mmlux_pl-security_studies": {
      "acc,none": 0.5755102040816327,
      "acc_stderr,none": 0.031642094879429414,
      "alias": "ogx_mmlux_pl-security_studies"
    },
    "ogx_mmlux_pl-public_relations": {
      "acc,none": 0.5727272727272728,
      "acc_stderr,none": 0.04738198703545483,
      "alias": "ogx_mmlux_pl-public_relations"
    },
    "ogx_mmlux_pl-professional_psychology": {
      "acc,none": 0.5196078431372549,
      "acc_stderr,none": 0.020212274976302964,
      "alias": "ogx_mmlux_pl-professional_psychology"
    },
    "ogx_mmlux_pl-professional_medicine": {
      "acc,none": 0.49264705882352944,
      "acc_stderr,none": 0.030369552523902173,
      "alias": "ogx_mmlux_pl-professional_medicine"
    },
    "ogx_mmlux_pl-professional_law": {
      "acc,none": 0.3970013037809648,
      "acc_stderr,none": 0.012496346982909556,
      "alias": "ogx_mmlux_pl-professional_law"
    },
    "ogx_mmlux_pl-professional_accounting": {
      "acc,none": 0.36879432624113473,
      "acc_stderr,none": 0.02878222756134725,
      "alias": "ogx_mmlux_pl-professional_accounting"
    },
    "ogx_mmlux_pl-prehistory": {
      "acc,none": 0.6388888888888888,
      "acc_stderr,none": 0.026725868809100783,
      "alias": "ogx_mmlux_pl-prehistory"
    },
    "ogx_mmlux_pl-philosophy": {
      "acc,none": 0.6334405144694534,
      "acc_stderr,none": 0.027368078243971642,
      "alias": "ogx_mmlux_pl-philosophy"
    },
    "ogx_mmlux_pl-nutrition": {
      "acc,none": 0.5980392156862745,
      "acc_stderr,none": 0.02807415894760067,
      "alias": "ogx_mmlux_pl-nutrition"
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "acc,none": 0.3340782122905028,
      "acc_stderr,none": 0.015774911422381632,
      "alias": "ogx_mmlux_pl-moral_scenarios"
    },
    "ogx_mmlux_pl-moral_disputes": {
      "acc,none": 0.5895953757225434,
      "acc_stderr,none": 0.026483392042098177,
      "alias": "ogx_mmlux_pl-moral_disputes"
    },
    "ogx_mmlux_pl-miscellaneous": {
      "acc,none": 0.6845466155810983,
      "acc_stderr,none": 0.016617501738763384,
      "alias": "ogx_mmlux_pl-miscellaneous"
    },
    "ogx_mmlux_pl-medical_genetics": {
      "acc,none": 0.64,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_pl-medical_genetics"
    },
    "ogx_mmlux_pl-marketing": {
      "acc,none": 0.7863247863247863,
      "acc_stderr,none": 0.026853450377009154,
      "alias": "ogx_mmlux_pl-marketing"
    },
    "ogx_mmlux_pl-management": {
      "acc,none": 0.6699029126213593,
      "acc_stderr,none": 0.0465614711001235,
      "alias": "ogx_mmlux_pl-management"
    },
    "ogx_mmlux_pl-machine_learning": {
      "acc,none": 0.44642857142857145,
      "acc_stderr,none": 0.047184714852195886,
      "alias": "ogx_mmlux_pl-machine_learning"
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "acc,none": 0.6012269938650306,
      "acc_stderr,none": 0.03847021420456023,
      "alias": "ogx_mmlux_pl-logical_fallacies"
    },
    "ogx_mmlux_pl-jurisprudence": {
      "acc,none": 0.6851851851851852,
      "acc_stderr,none": 0.04489931073591312,
      "alias": "ogx_mmlux_pl-jurisprudence"
    },
    "ogx_mmlux_pl-international_law": {
      "acc,none": 0.7355371900826446,
      "acc_stderr,none": 0.04026187527591207,
      "alias": "ogx_mmlux_pl-international_law"
    },
    "ogx_mmlux_pl-human_sexuality": {
      "acc,none": 0.5954198473282443,
      "acc_stderr,none": 0.04304693795380665,
      "alias": "ogx_mmlux_pl-human_sexuality"
    },
    "ogx_mmlux_pl-human_aging": {
      "acc,none": 0.5605381165919282,
      "acc_stderr,none": 0.03331092511038179,
      "alias": "ogx_mmlux_pl-human_aging"
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "acc,none": 0.7172995780590717,
      "acc_stderr,none": 0.029312814153955924,
      "alias": "ogx_mmlux_pl-high_school_world_history"
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "acc,none": 0.696078431372549,
      "acc_stderr,none": 0.032282103870378935,
      "alias": "ogx_mmlux_pl-high_school_us_history"
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "acc,none": 0.4398148148148148,
      "acc_stderr,none": 0.033851779760448106,
      "alias": "ogx_mmlux_pl-high_school_statistics"
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "acc,none": 0.6440366972477064,
      "acc_stderr,none": 0.020528559278244214,
      "alias": "ogx_mmlux_pl-high_school_psychology"
    },
    "ogx_mmlux_pl-high_school_physics": {
      "acc,none": 0.3708609271523179,
      "acc_stderr,none": 0.03943966699183629,
      "alias": "ogx_mmlux_pl-high_school_physics"
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "acc,none": 0.5378151260504201,
      "acc_stderr,none": 0.032385469487589795,
      "alias": "ogx_mmlux_pl-high_school_microeconomics"
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "acc,none": 0.362962962962963,
      "acc_stderr,none": 0.029318203645206858,
      "alias": "ogx_mmlux_pl-high_school_mathematics"
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "acc,none": 0.48717948717948717,
      "acc_stderr,none": 0.02534267129380725,
      "alias": "ogx_mmlux_pl-high_school_macroeconomics"
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "acc,none": 0.6476683937823834,
      "acc_stderr,none": 0.03447478286414357,
      "alias": "ogx_mmlux_pl-high_school_government_and_politics"
    },
    "ogx_mmlux_pl-high_school_geography": {
      "acc,none": 0.7070707070707071,
      "acc_stderr,none": 0.032424979581788166,
      "alias": "ogx_mmlux_pl-high_school_geography"
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "acc,none": 0.696969696969697,
      "acc_stderr,none": 0.03588624800091707,
      "alias": "ogx_mmlux_pl-high_school_european_history"
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_pl-high_school_computer_science"
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "acc,none": 0.46798029556650245,
      "acc_stderr,none": 0.03510766597959215,
      "alias": "ogx_mmlux_pl-high_school_chemistry"
    },
    "ogx_mmlux_pl-high_school_biology": {
      "acc,none": 0.635483870967742,
      "acc_stderr,none": 0.02737987122994326,
      "alias": "ogx_mmlux_pl-high_school_biology"
    },
    "ogx_mmlux_pl-global_facts": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_pl-global_facts"
    },
    "ogx_mmlux_pl-formal_logic": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.04360314860077459,
      "alias": "ogx_mmlux_pl-formal_logic"
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "acc,none": 0.3862433862433862,
      "acc_stderr,none": 0.02507598176760168,
      "alias": "ogx_mmlux_pl-elementary_mathematics"
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "acc,none": 0.5724137931034483,
      "acc_stderr,none": 0.04122737111370331,
      "alias": "ogx_mmlux_pl-electrical_engineering"
    },
    "ogx_mmlux_pl-econometrics": {
      "acc,none": 0.37719298245614036,
      "acc_stderr,none": 0.04559522141958216,
      "alias": "ogx_mmlux_pl-econometrics"
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "acc,none": 0.48936170212765956,
      "acc_stderr,none": 0.03267862331014063,
      "alias": "ogx_mmlux_pl-conceptual_physics"
    },
    "ogx_mmlux_pl-computer_security": {
      "acc,none": 0.67,
      "acc_stderr,none": 0.04725815626252606,
      "alias": "ogx_mmlux_pl-computer_security"
    },
    "ogx_mmlux_pl-college_physics": {
      "acc,none": 0.35294117647058826,
      "acc_stderr,none": 0.04755129616062949,
      "alias": "ogx_mmlux_pl-college_physics"
    },
    "ogx_mmlux_pl-college_medicine": {
      "acc,none": 0.5375722543352601,
      "acc_stderr,none": 0.0380168510452446,
      "alias": "ogx_mmlux_pl-college_medicine"
    },
    "ogx_mmlux_pl-college_mathematics": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695236,
      "alias": "ogx_mmlux_pl-college_mathematics"
    },
    "ogx_mmlux_pl-college_computer_science": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_pl-college_computer_science"
    },
    "ogx_mmlux_pl-college_chemistry": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_pl-college_chemistry"
    },
    "ogx_mmlux_pl-college_biology": {
      "acc,none": 0.5694444444444444,
      "acc_stderr,none": 0.04140685639111502,
      "alias": "ogx_mmlux_pl-college_biology"
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "acc,none": 0.6113207547169811,
      "acc_stderr,none": 0.030000485448675986,
      "alias": "ogx_mmlux_pl-clinical_knowledge"
    },
    "ogx_mmlux_pl-business_ethics": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.04923659639173309,
      "alias": "ogx_mmlux_pl-business_ethics"
    },
    "ogx_mmlux_pl-astronomy": {
      "acc,none": 0.5986842105263158,
      "acc_stderr,none": 0.039889037033362836,
      "alias": "ogx_mmlux_pl-astronomy"
    },
    "ogx_mmlux_pl-anatomy": {
      "acc,none": 0.45925925925925926,
      "acc_stderr,none": 0.04304979692464242,
      "alias": "ogx_mmlux_pl-anatomy"
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.0446196043338474,
      "alias": "ogx_mmlux_pl-abstract_algebra"
    },
    "ogx_mmlux_nl-world_religions": {
      "acc,none": 0.7894736842105263,
      "acc_stderr,none": 0.0312678171466318,
      "alias": "ogx_mmlux_nl-world_religions"
    },
    "ogx_mmlux_nl-virology": {
      "acc,none": 0.5301204819277109,
      "acc_stderr,none": 0.03885425420866767,
      "alias": "ogx_mmlux_nl-virology"
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "acc,none": 0.82,
      "acc_stderr,none": 0.03861229196653694,
      "alias": "ogx_mmlux_nl-us_foreign_policy"
    },
    "ogx_mmlux_nl-sociology": {
      "acc,none": 0.8059701492537313,
      "acc_stderr,none": 0.0279626776047689,
      "alias": "ogx_mmlux_nl-sociology"
    },
    "ogx_mmlux_nl-security_studies": {
      "acc,none": 0.6653061224489796,
      "acc_stderr,none": 0.030209235226242307,
      "alias": "ogx_mmlux_nl-security_studies"
    },
    "ogx_mmlux_nl-public_relations": {
      "acc,none": 0.6454545454545455,
      "acc_stderr,none": 0.04582004841505415,
      "alias": "ogx_mmlux_nl-public_relations"
    },
    "ogx_mmlux_nl-professional_psychology": {
      "acc,none": 0.5898692810457516,
      "acc_stderr,none": 0.019898412717635892,
      "alias": "ogx_mmlux_nl-professional_psychology"
    },
    "ogx_mmlux_nl-professional_medicine": {
      "acc,none": 0.5625,
      "acc_stderr,none": 0.030134614954403924,
      "alias": "ogx_mmlux_nl-professional_medicine"
    },
    "ogx_mmlux_nl-professional_law": {
      "acc,none": 0.4172099087353325,
      "acc_stderr,none": 0.012593959992906424,
      "alias": "ogx_mmlux_nl-professional_law"
    },
    "ogx_mmlux_nl-professional_accounting": {
      "acc,none": 0.41843971631205673,
      "acc_stderr,none": 0.029427994039419998,
      "alias": "ogx_mmlux_nl-professional_accounting"
    },
    "ogx_mmlux_nl-prehistory": {
      "acc,none": 0.6820987654320988,
      "acc_stderr,none": 0.025910063528240893,
      "alias": "ogx_mmlux_nl-prehistory"
    },
    "ogx_mmlux_nl-philosophy": {
      "acc,none": 0.6655948553054662,
      "acc_stderr,none": 0.026795422327893947,
      "alias": "ogx_mmlux_nl-philosophy"
    },
    "ogx_mmlux_nl-nutrition": {
      "acc,none": 0.6633986928104575,
      "acc_stderr,none": 0.027057974624494382,
      "alias": "ogx_mmlux_nl-nutrition"
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "acc,none": 0.3329608938547486,
      "acc_stderr,none": 0.015761716178397556,
      "alias": "ogx_mmlux_nl-moral_scenarios"
    },
    "ogx_mmlux_nl-moral_disputes": {
      "acc,none": 0.638728323699422,
      "acc_stderr,none": 0.025862201852277902,
      "alias": "ogx_mmlux_nl-moral_disputes"
    },
    "ogx_mmlux_nl-miscellaneous": {
      "acc,none": 0.7215836526181354,
      "acc_stderr,none": 0.016028295188992462,
      "alias": "ogx_mmlux_nl-miscellaneous"
    },
    "ogx_mmlux_nl-medical_genetics": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.0440844002276808,
      "alias": "ogx_mmlux_nl-medical_genetics"
    },
    "ogx_mmlux_nl-marketing": {
      "acc,none": 0.782051282051282,
      "acc_stderr,none": 0.02704685763071665,
      "alias": "ogx_mmlux_nl-marketing"
    },
    "ogx_mmlux_nl-management": {
      "acc,none": 0.7572815533980582,
      "acc_stderr,none": 0.04245022486384495,
      "alias": "ogx_mmlux_nl-management"
    },
    "ogx_mmlux_nl-machine_learning": {
      "acc,none": 0.42857142857142855,
      "acc_stderr,none": 0.04697113923010213,
      "alias": "ogx_mmlux_nl-machine_learning"
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "acc,none": 0.6993865030674846,
      "acc_stderr,none": 0.03602511318806771,
      "alias": "ogx_mmlux_nl-logical_fallacies"
    },
    "ogx_mmlux_nl-jurisprudence": {
      "acc,none": 0.7037037037037037,
      "acc_stderr,none": 0.04414343666854933,
      "alias": "ogx_mmlux_nl-jurisprudence"
    },
    "ogx_mmlux_nl-international_law": {
      "acc,none": 0.7768595041322314,
      "acc_stderr,none": 0.03800754475228733,
      "alias": "ogx_mmlux_nl-international_law"
    },
    "ogx_mmlux_nl-human_sexuality": {
      "acc,none": 0.6946564885496184,
      "acc_stderr,none": 0.040393149787245626,
      "alias": "ogx_mmlux_nl-human_sexuality"
    },
    "ogx_mmlux_nl-human_aging": {
      "acc,none": 0.5964125560538116,
      "acc_stderr,none": 0.03292802819330314,
      "alias": "ogx_mmlux_nl-human_aging"
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "acc,none": 0.7257383966244726,
      "acc_stderr,none": 0.02904133351059804,
      "alias": "ogx_mmlux_nl-high_school_world_history"
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "acc,none": 0.75,
      "acc_stderr,none": 0.03039153369274154,
      "alias": "ogx_mmlux_nl-high_school_us_history"
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "acc,none": 0.4583333333333333,
      "acc_stderr,none": 0.033981108902946366,
      "alias": "ogx_mmlux_nl-high_school_statistics"
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "acc,none": 0.7357798165137615,
      "acc_stderr,none": 0.018904164171510186,
      "alias": "ogx_mmlux_nl-high_school_psychology"
    },
    "ogx_mmlux_nl-high_school_physics": {
      "acc,none": 0.4370860927152318,
      "acc_stderr,none": 0.04050035722230637,
      "alias": "ogx_mmlux_nl-high_school_physics"
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "acc,none": 0.6386554621848739,
      "acc_stderr,none": 0.031204691225150023,
      "alias": "ogx_mmlux_nl-high_school_microeconomics"
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "acc,none": 0.4074074074074074,
      "acc_stderr,none": 0.02995824925008212,
      "alias": "ogx_mmlux_nl-high_school_mathematics"
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "acc,none": 0.5358974358974359,
      "acc_stderr,none": 0.02528558599001784,
      "alias": "ogx_mmlux_nl-high_school_macroeconomics"
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "acc,none": 0.7150259067357513,
      "acc_stderr,none": 0.03257714077709662,
      "alias": "ogx_mmlux_nl-high_school_government_and_politics"
    },
    "ogx_mmlux_nl-high_school_geography": {
      "acc,none": 0.7676767676767676,
      "acc_stderr,none": 0.03008862949021749,
      "alias": "ogx_mmlux_nl-high_school_geography"
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "acc,none": 0.7757575757575758,
      "acc_stderr,none": 0.032568666616811015,
      "alias": "ogx_mmlux_nl-high_school_european_history"
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.04878317312145633,
      "alias": "ogx_mmlux_nl-high_school_computer_science"
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "acc,none": 0.45320197044334976,
      "acc_stderr,none": 0.03502544650845872,
      "alias": "ogx_mmlux_nl-high_school_chemistry"
    },
    "ogx_mmlux_nl-high_school_biology": {
      "acc,none": 0.7161290322580646,
      "acc_stderr,none": 0.02564938106302926,
      "alias": "ogx_mmlux_nl-high_school_biology"
    },
    "ogx_mmlux_nl-global_facts": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_nl-global_facts"
    },
    "ogx_mmlux_nl-formal_logic": {
      "acc,none": 0.373015873015873,
      "acc_stderr,none": 0.043255060420170854,
      "alias": "ogx_mmlux_nl-formal_logic"
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "acc,none": 0.40476190476190477,
      "acc_stderr,none": 0.02527985039740491,
      "alias": "ogx_mmlux_nl-elementary_mathematics"
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "acc,none": 0.5448275862068965,
      "acc_stderr,none": 0.04149886942192117,
      "alias": "ogx_mmlux_nl-electrical_engineering"
    },
    "ogx_mmlux_nl-econometrics": {
      "acc,none": 0.39473684210526316,
      "acc_stderr,none": 0.04598188057816543,
      "alias": "ogx_mmlux_nl-econometrics"
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "acc,none": 0.4765957446808511,
      "acc_stderr,none": 0.03265019475033582,
      "alias": "ogx_mmlux_nl-conceptual_physics"
    },
    "ogx_mmlux_nl-computer_security": {
      "acc,none": 0.67,
      "acc_stderr,none": 0.04725815626252607,
      "alias": "ogx_mmlux_nl-computer_security"
    },
    "ogx_mmlux_nl-college_physics": {
      "acc,none": 0.3431372549019608,
      "acc_stderr,none": 0.04724007352383889,
      "alias": "ogx_mmlux_nl-college_physics"
    },
    "ogx_mmlux_nl-college_medicine": {
      "acc,none": 0.5260115606936416,
      "acc_stderr,none": 0.03807301726504513,
      "alias": "ogx_mmlux_nl-college_medicine"
    },
    "ogx_mmlux_nl-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_nl-college_mathematics"
    },
    "ogx_mmlux_nl-college_computer_science": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.04975698519562428,
      "alias": "ogx_mmlux_nl-college_computer_science"
    },
    "ogx_mmlux_nl-college_chemistry": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.0498887651569859,
      "alias": "ogx_mmlux_nl-college_chemistry"
    },
    "ogx_mmlux_nl-college_biology": {
      "acc,none": 0.6597222222222222,
      "acc_stderr,none": 0.03962135573486219,
      "alias": "ogx_mmlux_nl-college_biology"
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "acc,none": 0.6377358490566037,
      "acc_stderr,none": 0.029582245128384296,
      "alias": "ogx_mmlux_nl-clinical_knowledge"
    },
    "ogx_mmlux_nl-business_ethics": {
      "acc,none": 0.54,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_nl-business_ethics"
    },
    "ogx_mmlux_nl-astronomy": {
      "acc,none": 0.6381578947368421,
      "acc_stderr,none": 0.03910525752849724,
      "alias": "ogx_mmlux_nl-astronomy"
    },
    "ogx_mmlux_nl-anatomy": {
      "acc,none": 0.5185185185185185,
      "acc_stderr,none": 0.043163785995113245,
      "alias": "ogx_mmlux_nl-anatomy"
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542128,
      "alias": "ogx_mmlux_nl-abstract_algebra"
    },
    "ogx_mmlux_lv-world_religions": {
      "acc,none": 0.5964912280701754,
      "acc_stderr,none": 0.03762738699917057,
      "alias": "ogx_mmlux_lv-world_religions"
    },
    "ogx_mmlux_lv-virology": {
      "acc,none": 0.4819277108433735,
      "acc_stderr,none": 0.038899512528272166,
      "alias": "ogx_mmlux_lv-virology"
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "acc,none": 0.69,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_lv-us_foreign_policy"
    },
    "ogx_mmlux_lv-sociology": {
      "acc,none": 0.681592039800995,
      "acc_stderr,none": 0.03294118479054095,
      "alias": "ogx_mmlux_lv-sociology"
    },
    "ogx_mmlux_lv-security_studies": {
      "acc,none": 0.5836734693877551,
      "acc_stderr,none": 0.03155782816556163,
      "alias": "ogx_mmlux_lv-security_studies"
    },
    "ogx_mmlux_lv-public_relations": {
      "acc,none": 0.509090909090909,
      "acc_stderr,none": 0.04788339768702861,
      "alias": "ogx_mmlux_lv-public_relations"
    },
    "ogx_mmlux_lv-professional_psychology": {
      "acc,none": 0.4444444444444444,
      "acc_stderr,none": 0.020102583895887188,
      "alias": "ogx_mmlux_lv-professional_psychology"
    },
    "ogx_mmlux_lv-professional_medicine": {
      "acc,none": 0.41911764705882354,
      "acc_stderr,none": 0.029972807170464626,
      "alias": "ogx_mmlux_lv-professional_medicine"
    },
    "ogx_mmlux_lv-professional_law": {
      "acc,none": 0.33702737940026073,
      "acc_stderr,none": 0.012072836273691323,
      "alias": "ogx_mmlux_lv-professional_law"
    },
    "ogx_mmlux_lv-professional_accounting": {
      "acc,none": 0.3546099290780142,
      "acc_stderr,none": 0.028538650028878638,
      "alias": "ogx_mmlux_lv-professional_accounting"
    },
    "ogx_mmlux_lv-prehistory": {
      "acc,none": 0.5370370370370371,
      "acc_stderr,none": 0.027744313443376536,
      "alias": "ogx_mmlux_lv-prehistory"
    },
    "ogx_mmlux_lv-philosophy": {
      "acc,none": 0.5241157556270096,
      "acc_stderr,none": 0.028365041542564577,
      "alias": "ogx_mmlux_lv-philosophy"
    },
    "ogx_mmlux_lv-nutrition": {
      "acc,none": 0.5326797385620915,
      "acc_stderr,none": 0.02856869975222587,
      "alias": "ogx_mmlux_lv-nutrition"
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "acc,none": 0.2547486033519553,
      "acc_stderr,none": 0.01457265038340916,
      "alias": "ogx_mmlux_lv-moral_scenarios"
    },
    "ogx_mmlux_lv-moral_disputes": {
      "acc,none": 0.5202312138728323,
      "acc_stderr,none": 0.026897049996382868,
      "alias": "ogx_mmlux_lv-moral_disputes"
    },
    "ogx_mmlux_lv-miscellaneous": {
      "acc,none": 0.5491698595146871,
      "acc_stderr,none": 0.017793297572699037,
      "alias": "ogx_mmlux_lv-miscellaneous"
    },
    "ogx_mmlux_lv-medical_genetics": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_lv-medical_genetics"
    },
    "ogx_mmlux_lv-marketing": {
      "acc,none": 0.688034188034188,
      "acc_stderr,none": 0.030351527323344927,
      "alias": "ogx_mmlux_lv-marketing"
    },
    "ogx_mmlux_lv-management": {
      "acc,none": 0.6893203883495146,
      "acc_stderr,none": 0.04582124160161549,
      "alias": "ogx_mmlux_lv-management"
    },
    "ogx_mmlux_lv-machine_learning": {
      "acc,none": 0.38392857142857145,
      "acc_stderr,none": 0.04616143075028547,
      "alias": "ogx_mmlux_lv-machine_learning"
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "acc,none": 0.5030674846625767,
      "acc_stderr,none": 0.03928297078179663,
      "alias": "ogx_mmlux_lv-logical_fallacies"
    },
    "ogx_mmlux_lv-jurisprudence": {
      "acc,none": 0.5555555555555556,
      "acc_stderr,none": 0.04803752235190193,
      "alias": "ogx_mmlux_lv-jurisprudence"
    },
    "ogx_mmlux_lv-international_law": {
      "acc,none": 0.6942148760330579,
      "acc_stderr,none": 0.04205953933884123,
      "alias": "ogx_mmlux_lv-international_law"
    },
    "ogx_mmlux_lv-human_sexuality": {
      "acc,none": 0.5419847328244275,
      "acc_stderr,none": 0.04369802690578756,
      "alias": "ogx_mmlux_lv-human_sexuality"
    },
    "ogx_mmlux_lv-human_aging": {
      "acc,none": 0.452914798206278,
      "acc_stderr,none": 0.03340867501923324,
      "alias": "ogx_mmlux_lv-human_aging"
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "acc,none": 0.6455696202531646,
      "acc_stderr,none": 0.0311373042971858,
      "alias": "ogx_mmlux_lv-high_school_world_history"
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "acc,none": 0.5735294117647058,
      "acc_stderr,none": 0.03471157907953426,
      "alias": "ogx_mmlux_lv-high_school_us_history"
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.033622774366080424,
      "alias": "ogx_mmlux_lv-high_school_statistics"
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "acc,none": 0.5339449541284403,
      "acc_stderr,none": 0.02138786335035399,
      "alias": "ogx_mmlux_lv-high_school_psychology"
    },
    "ogx_mmlux_lv-high_school_physics": {
      "acc,none": 0.36423841059602646,
      "acc_stderr,none": 0.03929111781242742,
      "alias": "ogx_mmlux_lv-high_school_physics"
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "acc,none": 0.49159663865546216,
      "acc_stderr,none": 0.03247390276569669,
      "alias": "ogx_mmlux_lv-high_school_microeconomics"
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.029723278961476664,
      "alias": "ogx_mmlux_lv-high_school_mathematics"
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "acc,none": 0.41794871794871796,
      "acc_stderr,none": 0.025007329882461213,
      "alias": "ogx_mmlux_lv-high_school_macroeconomics"
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "acc,none": 0.48704663212435234,
      "acc_stderr,none": 0.03607228061047749,
      "alias": "ogx_mmlux_lv-high_school_government_and_politics"
    },
    "ogx_mmlux_lv-high_school_geography": {
      "acc,none": 0.6060606060606061,
      "acc_stderr,none": 0.034812853382329624,
      "alias": "ogx_mmlux_lv-high_school_geography"
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "acc,none": 0.6484848484848484,
      "acc_stderr,none": 0.037282069986826503,
      "alias": "ogx_mmlux_lv-high_school_european_history"
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_lv-high_school_computer_science"
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "acc,none": 0.4236453201970443,
      "acc_stderr,none": 0.03476725747649038,
      "alias": "ogx_mmlux_lv-high_school_chemistry"
    },
    "ogx_mmlux_lv-high_school_biology": {
      "acc,none": 0.535483870967742,
      "acc_stderr,none": 0.028372287797962942,
      "alias": "ogx_mmlux_lv-high_school_biology"
    },
    "ogx_mmlux_lv-global_facts": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_lv-global_facts"
    },
    "ogx_mmlux_lv-formal_logic": {
      "acc,none": 0.3492063492063492,
      "acc_stderr,none": 0.04263906892795132,
      "alias": "ogx_mmlux_lv-formal_logic"
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "acc,none": 0.3783068783068783,
      "acc_stderr,none": 0.024976954053155236,
      "alias": "ogx_mmlux_lv-elementary_mathematics"
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "acc,none": 0.5172413793103449,
      "acc_stderr,none": 0.04164188720169375,
      "alias": "ogx_mmlux_lv-electrical_engineering"
    },
    "ogx_mmlux_lv-econometrics": {
      "acc,none": 0.2807017543859649,
      "acc_stderr,none": 0.042270544512322,
      "alias": "ogx_mmlux_lv-econometrics"
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "acc,none": 0.39148936170212767,
      "acc_stderr,none": 0.03190701242326812,
      "alias": "ogx_mmlux_lv-conceptual_physics"
    },
    "ogx_mmlux_lv-computer_security": {
      "acc,none": 0.57,
      "acc_stderr,none": 0.04975698519562427,
      "alias": "ogx_mmlux_lv-computer_security"
    },
    "ogx_mmlux_lv-college_physics": {
      "acc,none": 0.35294117647058826,
      "acc_stderr,none": 0.04755129616062949,
      "alias": "ogx_mmlux_lv-college_physics"
    },
    "ogx_mmlux_lv-college_medicine": {
      "acc,none": 0.43352601156069365,
      "acc_stderr,none": 0.037786210790920545,
      "alias": "ogx_mmlux_lv-college_medicine"
    },
    "ogx_mmlux_lv-college_mathematics": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.047258156262526045,
      "alias": "ogx_mmlux_lv-college_mathematics"
    },
    "ogx_mmlux_lv-college_computer_science": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.047937248544110196,
      "alias": "ogx_mmlux_lv-college_computer_science"
    },
    "ogx_mmlux_lv-college_chemistry": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_lv-college_chemistry"
    },
    "ogx_mmlux_lv-college_biology": {
      "acc,none": 0.4513888888888889,
      "acc_stderr,none": 0.04161402398403279,
      "alias": "ogx_mmlux_lv-college_biology"
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "acc,none": 0.5132075471698113,
      "acc_stderr,none": 0.030762134874500476,
      "alias": "ogx_mmlux_lv-clinical_knowledge"
    },
    "ogx_mmlux_lv-business_ethics": {
      "acc,none": 0.49,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_lv-business_ethics"
    },
    "ogx_mmlux_lv-astronomy": {
      "acc,none": 0.5592105263157895,
      "acc_stderr,none": 0.04040311062490436,
      "alias": "ogx_mmlux_lv-astronomy"
    },
    "ogx_mmlux_lv-anatomy": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.04232073695151589,
      "alias": "ogx_mmlux_lv-anatomy"
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_lv-abstract_algebra"
    },
    "ogx_mmlux_lt-world_religions": {
      "acc,none": 0.6491228070175439,
      "acc_stderr,none": 0.03660298834049164,
      "alias": "ogx_mmlux_lt-world_religions"
    },
    "ogx_mmlux_lt-virology": {
      "acc,none": 0.43373493975903615,
      "acc_stderr,none": 0.03858158940685517,
      "alias": "ogx_mmlux_lt-virology"
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "acc,none": 0.76,
      "acc_stderr,none": 0.04292346959909283,
      "alias": "ogx_mmlux_lt-us_foreign_policy"
    },
    "ogx_mmlux_lt-sociology": {
      "acc,none": 0.6417910447761194,
      "acc_stderr,none": 0.03390393042268814,
      "alias": "ogx_mmlux_lt-sociology"
    },
    "ogx_mmlux_lt-security_studies": {
      "acc,none": 0.5755102040816327,
      "acc_stderr,none": 0.03164209487942941,
      "alias": "ogx_mmlux_lt-security_studies"
    },
    "ogx_mmlux_lt-public_relations": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.04789131426105757,
      "alias": "ogx_mmlux_lt-public_relations"
    },
    "ogx_mmlux_lt-professional_psychology": {
      "acc,none": 0.4444444444444444,
      "acc_stderr,none": 0.020102583895887184,
      "alias": "ogx_mmlux_lt-professional_psychology"
    },
    "ogx_mmlux_lt-professional_medicine": {
      "acc,none": 0.4411764705882353,
      "acc_stderr,none": 0.030161911930767105,
      "alias": "ogx_mmlux_lt-professional_medicine"
    },
    "ogx_mmlux_lt-professional_law": {
      "acc,none": 0.36897001303780963,
      "acc_stderr,none": 0.012323936650174862,
      "alias": "ogx_mmlux_lt-professional_law"
    },
    "ogx_mmlux_lt-professional_accounting": {
      "acc,none": 0.3546099290780142,
      "acc_stderr,none": 0.02853865002887864,
      "alias": "ogx_mmlux_lt-professional_accounting"
    },
    "ogx_mmlux_lt-prehistory": {
      "acc,none": 0.5524691358024691,
      "acc_stderr,none": 0.027667138569422708,
      "alias": "ogx_mmlux_lt-prehistory"
    },
    "ogx_mmlux_lt-philosophy": {
      "acc,none": 0.572347266881029,
      "acc_stderr,none": 0.02809924077580957,
      "alias": "ogx_mmlux_lt-philosophy"
    },
    "ogx_mmlux_lt-nutrition": {
      "acc,none": 0.5392156862745098,
      "acc_stderr,none": 0.028541722692618874,
      "alias": "ogx_mmlux_lt-nutrition"
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "acc,none": 0.25251396648044694,
      "acc_stderr,none": 0.014530330201468655,
      "alias": "ogx_mmlux_lt-moral_scenarios"
    },
    "ogx_mmlux_lt-moral_disputes": {
      "acc,none": 0.5404624277456648,
      "acc_stderr,none": 0.026830805998952233,
      "alias": "ogx_mmlux_lt-moral_disputes"
    },
    "ogx_mmlux_lt-miscellaneous": {
      "acc,none": 0.5747126436781609,
      "acc_stderr,none": 0.017679225489431447,
      "alias": "ogx_mmlux_lt-miscellaneous"
    },
    "ogx_mmlux_lt-medical_genetics": {
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912,
      "alias": "ogx_mmlux_lt-medical_genetics"
    },
    "ogx_mmlux_lt-marketing": {
      "acc,none": 0.6538461538461539,
      "acc_stderr,none": 0.031166957367235907,
      "alias": "ogx_mmlux_lt-marketing"
    },
    "ogx_mmlux_lt-management": {
      "acc,none": 0.6893203883495146,
      "acc_stderr,none": 0.04582124160161549,
      "alias": "ogx_mmlux_lt-management"
    },
    "ogx_mmlux_lt-machine_learning": {
      "acc,none": 0.39285714285714285,
      "acc_stderr,none": 0.04635550135609976,
      "alias": "ogx_mmlux_lt-machine_learning"
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "acc,none": 0.5214723926380368,
      "acc_stderr,none": 0.03924746876751129,
      "alias": "ogx_mmlux_lt-logical_fallacies"
    },
    "ogx_mmlux_lt-jurisprudence": {
      "acc,none": 0.6203703703703703,
      "acc_stderr,none": 0.04691521224077741,
      "alias": "ogx_mmlux_lt-jurisprudence"
    },
    "ogx_mmlux_lt-international_law": {
      "acc,none": 0.6694214876033058,
      "acc_stderr,none": 0.04294340845212093,
      "alias": "ogx_mmlux_lt-international_law"
    },
    "ogx_mmlux_lt-human_sexuality": {
      "acc,none": 0.6030534351145038,
      "acc_stderr,none": 0.04291135671009224,
      "alias": "ogx_mmlux_lt-human_sexuality"
    },
    "ogx_mmlux_lt-human_aging": {
      "acc,none": 0.4260089686098655,
      "acc_stderr,none": 0.033188332862172806,
      "alias": "ogx_mmlux_lt-human_aging"
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "acc,none": 0.5991561181434599,
      "acc_stderr,none": 0.031900803894732356,
      "alias": "ogx_mmlux_lt-high_school_world_history"
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "acc,none": 0.5588235294117647,
      "acc_stderr,none": 0.034849415144292316,
      "alias": "ogx_mmlux_lt-high_school_us_history"
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "acc,none": 0.38425925925925924,
      "acc_stderr,none": 0.03317354514310742,
      "alias": "ogx_mmlux_lt-high_school_statistics"
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "acc,none": 0.5174311926605505,
      "acc_stderr,none": 0.02142429187185315,
      "alias": "ogx_mmlux_lt-high_school_psychology"
    },
    "ogx_mmlux_lt-high_school_physics": {
      "acc,none": 0.36423841059602646,
      "acc_stderr,none": 0.03929111781242742,
      "alias": "ogx_mmlux_lt-high_school_physics"
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "acc,none": 0.47478991596638653,
      "acc_stderr,none": 0.0324371805513741,
      "alias": "ogx_mmlux_lt-high_school_microeconomics"
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "acc,none": 0.3592592592592593,
      "acc_stderr,none": 0.02925290592725197,
      "alias": "ogx_mmlux_lt-high_school_mathematics"
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "acc,none": 0.3974358974358974,
      "acc_stderr,none": 0.024811920017903832,
      "alias": "ogx_mmlux_lt-high_school_macroeconomics"
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "acc,none": 0.5181347150259067,
      "acc_stderr,none": 0.036060650018329185,
      "alias": "ogx_mmlux_lt-high_school_government_and_politics"
    },
    "ogx_mmlux_lt-high_school_geography": {
      "acc,none": 0.601010101010101,
      "acc_stderr,none": 0.03488901616852732,
      "alias": "ogx_mmlux_lt-high_school_geography"
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "acc,none": 0.6606060606060606,
      "acc_stderr,none": 0.03697442205031595,
      "alias": "ogx_mmlux_lt-high_school_european_history"
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "acc,none": 0.55,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_lt-high_school_computer_science"
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "acc,none": 0.45320197044334976,
      "acc_stderr,none": 0.03502544650845872,
      "alias": "ogx_mmlux_lt-high_school_chemistry"
    },
    "ogx_mmlux_lt-high_school_biology": {
      "acc,none": 0.5419354838709678,
      "acc_stderr,none": 0.02834378725054064,
      "alias": "ogx_mmlux_lt-high_school_biology"
    },
    "ogx_mmlux_lt-global_facts": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695236,
      "alias": "ogx_mmlux_lt-global_facts"
    },
    "ogx_mmlux_lt-formal_logic": {
      "acc,none": 0.3253968253968254,
      "acc_stderr,none": 0.04190596438871137,
      "alias": "ogx_mmlux_lt-formal_logic"
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "acc,none": 0.3835978835978836,
      "acc_stderr,none": 0.025043757318520196,
      "alias": "ogx_mmlux_lt-elementary_mathematics"
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "acc,none": 0.5103448275862069,
      "acc_stderr,none": 0.04165774775728765,
      "alias": "ogx_mmlux_lt-electrical_engineering"
    },
    "ogx_mmlux_lt-econometrics": {
      "acc,none": 0.3684210526315789,
      "acc_stderr,none": 0.04537815354939391,
      "alias": "ogx_mmlux_lt-econometrics"
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "acc,none": 0.4085106382978723,
      "acc_stderr,none": 0.03213418026701576,
      "alias": "ogx_mmlux_lt-conceptual_physics"
    },
    "ogx_mmlux_lt-computer_security": {
      "acc,none": 0.58,
      "acc_stderr,none": 0.04960449637488584,
      "alias": "ogx_mmlux_lt-computer_security"
    },
    "ogx_mmlux_lt-college_physics": {
      "acc,none": 0.2647058823529412,
      "acc_stderr,none": 0.0438986995680878,
      "alias": "ogx_mmlux_lt-college_physics"
    },
    "ogx_mmlux_lt-college_medicine": {
      "acc,none": 0.44508670520231214,
      "acc_stderr,none": 0.03789401760283647,
      "alias": "ogx_mmlux_lt-college_medicine"
    },
    "ogx_mmlux_lt-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_lt-college_mathematics"
    },
    "ogx_mmlux_lt-college_computer_science": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_lt-college_computer_science"
    },
    "ogx_mmlux_lt-college_chemistry": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_lt-college_chemistry"
    },
    "ogx_mmlux_lt-college_biology": {
      "acc,none": 0.4930555555555556,
      "acc_stderr,none": 0.04180806750294938,
      "alias": "ogx_mmlux_lt-college_biology"
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "acc,none": 0.4981132075471698,
      "acc_stderr,none": 0.030772653642075657,
      "alias": "ogx_mmlux_lt-clinical_knowledge"
    },
    "ogx_mmlux_lt-business_ethics": {
      "acc,none": 0.41,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_lt-business_ethics"
    },
    "ogx_mmlux_lt-astronomy": {
      "acc,none": 0.5197368421052632,
      "acc_stderr,none": 0.040657710025626036,
      "alias": "ogx_mmlux_lt-astronomy"
    },
    "ogx_mmlux_lt-anatomy": {
      "acc,none": 0.35555555555555557,
      "acc_stderr,none": 0.04135176749720385,
      "alias": "ogx_mmlux_lt-anatomy"
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.046882617226215034,
      "alias": "ogx_mmlux_lt-abstract_algebra"
    },
    "ogx_mmlux_it-world_religions": {
      "acc,none": 0.7953216374269005,
      "acc_stderr,none": 0.03094445977853321,
      "alias": "ogx_mmlux_it-world_religions"
    },
    "ogx_mmlux_it-virology": {
      "acc,none": 0.4819277108433735,
      "acc_stderr,none": 0.038899512528272166,
      "alias": "ogx_mmlux_it-virology"
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "acc,none": 0.82,
      "acc_stderr,none": 0.038612291966536955,
      "alias": "ogx_mmlux_it-us_foreign_policy"
    },
    "ogx_mmlux_it-sociology": {
      "acc,none": 0.8059701492537313,
      "acc_stderr,none": 0.027962677604768896,
      "alias": "ogx_mmlux_it-sociology"
    },
    "ogx_mmlux_it-security_studies": {
      "acc,none": 0.710204081632653,
      "acc_stderr,none": 0.029043088683304328,
      "alias": "ogx_mmlux_it-security_studies"
    },
    "ogx_mmlux_it-public_relations": {
      "acc,none": 0.6818181818181818,
      "acc_stderr,none": 0.044612721759105085,
      "alias": "ogx_mmlux_it-public_relations"
    },
    "ogx_mmlux_it-professional_psychology": {
      "acc,none": 0.5931372549019608,
      "acc_stderr,none": 0.019873802005061177,
      "alias": "ogx_mmlux_it-professional_psychology"
    },
    "ogx_mmlux_it-professional_medicine": {
      "acc,none": 0.5330882352941176,
      "acc_stderr,none": 0.030306257722468307,
      "alias": "ogx_mmlux_it-professional_medicine"
    },
    "ogx_mmlux_it-professional_law": {
      "acc,none": 0.41003911342894395,
      "acc_stderr,none": 0.012561837621962042,
      "alias": "ogx_mmlux_it-professional_law"
    },
    "ogx_mmlux_it-professional_accounting": {
      "acc,none": 0.4219858156028369,
      "acc_stderr,none": 0.0294621892333706,
      "alias": "ogx_mmlux_it-professional_accounting"
    },
    "ogx_mmlux_it-prehistory": {
      "acc,none": 0.6697530864197531,
      "acc_stderr,none": 0.026168298456732852,
      "alias": "ogx_mmlux_it-prehistory"
    },
    "ogx_mmlux_it-philosophy": {
      "acc,none": 0.6688102893890675,
      "acc_stderr,none": 0.026730620728004924,
      "alias": "ogx_mmlux_it-philosophy"
    },
    "ogx_mmlux_it-nutrition": {
      "acc,none": 0.696078431372549,
      "acc_stderr,none": 0.02633661346904663,
      "alias": "ogx_mmlux_it-nutrition"
    },
    "ogx_mmlux_it-moral_scenarios": {
      "acc,none": 0.37094972067039106,
      "acc_stderr,none": 0.016155910721341777,
      "alias": "ogx_mmlux_it-moral_scenarios"
    },
    "ogx_mmlux_it-moral_disputes": {
      "acc,none": 0.6445086705202312,
      "acc_stderr,none": 0.02577029208297726,
      "alias": "ogx_mmlux_it-moral_disputes"
    },
    "ogx_mmlux_it-miscellaneous": {
      "acc,none": 0.7318007662835249,
      "acc_stderr,none": 0.015842430835269438,
      "alias": "ogx_mmlux_it-miscellaneous"
    },
    "ogx_mmlux_it-medical_genetics": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_it-medical_genetics"
    },
    "ogx_mmlux_it-marketing": {
      "acc,none": 0.8205128205128205,
      "acc_stderr,none": 0.025140935950335435,
      "alias": "ogx_mmlux_it-marketing"
    },
    "ogx_mmlux_it-management": {
      "acc,none": 0.7378640776699029,
      "acc_stderr,none": 0.04354631077260595,
      "alias": "ogx_mmlux_it-management"
    },
    "ogx_mmlux_it-machine_learning": {
      "acc,none": 0.39285714285714285,
      "acc_stderr,none": 0.04635550135609976,
      "alias": "ogx_mmlux_it-machine_learning"
    },
    "ogx_mmlux_it-logical_fallacies": {
      "acc,none": 0.6809815950920245,
      "acc_stderr,none": 0.03661997551073836,
      "alias": "ogx_mmlux_it-logical_fallacies"
    },
    "ogx_mmlux_it-jurisprudence": {
      "acc,none": 0.7407407407407407,
      "acc_stderr,none": 0.04236511258094631,
      "alias": "ogx_mmlux_it-jurisprudence"
    },
    "ogx_mmlux_it-international_law": {
      "acc,none": 0.743801652892562,
      "acc_stderr,none": 0.03984979653302872,
      "alias": "ogx_mmlux_it-international_law"
    },
    "ogx_mmlux_it-human_sexuality": {
      "acc,none": 0.6641221374045801,
      "acc_stderr,none": 0.04142313771996664,
      "alias": "ogx_mmlux_it-human_sexuality"
    },
    "ogx_mmlux_it-human_aging": {
      "acc,none": 0.5919282511210763,
      "acc_stderr,none": 0.03298574607842822,
      "alias": "ogx_mmlux_it-human_aging"
    },
    "ogx_mmlux_it-high_school_world_history": {
      "acc,none": 0.7510548523206751,
      "acc_stderr,none": 0.028146970599422647,
      "alias": "ogx_mmlux_it-high_school_world_history"
    },
    "ogx_mmlux_it-high_school_us_history": {
      "acc,none": 0.7745098039215687,
      "acc_stderr,none": 0.029331162294251728,
      "alias": "ogx_mmlux_it-high_school_us_history"
    },
    "ogx_mmlux_it-high_school_statistics": {
      "acc,none": 0.4537037037037037,
      "acc_stderr,none": 0.033953227263757976,
      "alias": "ogx_mmlux_it-high_school_statistics"
    },
    "ogx_mmlux_it-high_school_psychology": {
      "acc,none": 0.7357798165137615,
      "acc_stderr,none": 0.018904164171510182,
      "alias": "ogx_mmlux_it-high_school_psychology"
    },
    "ogx_mmlux_it-high_school_physics": {
      "acc,none": 0.3576158940397351,
      "acc_stderr,none": 0.03913453431177258,
      "alias": "ogx_mmlux_it-high_school_physics"
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "acc,none": 0.6092436974789915,
      "acc_stderr,none": 0.031693802357129965,
      "alias": "ogx_mmlux_it-high_school_microeconomics"
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "acc,none": 0.4185185185185185,
      "acc_stderr,none": 0.030078013075022055,
      "alias": "ogx_mmlux_it-high_school_mathematics"
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "acc,none": 0.5794871794871795,
      "acc_stderr,none": 0.025028610276710855,
      "alias": "ogx_mmlux_it-high_school_macroeconomics"
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "acc,none": 0.772020725388601,
      "acc_stderr,none": 0.03027690994517826,
      "alias": "ogx_mmlux_it-high_school_government_and_politics"
    },
    "ogx_mmlux_it-high_school_geography": {
      "acc,none": 0.7777777777777778,
      "acc_stderr,none": 0.02962022787479048,
      "alias": "ogx_mmlux_it-high_school_geography"
    },
    "ogx_mmlux_it-high_school_european_history": {
      "acc,none": 0.7393939393939394,
      "acc_stderr,none": 0.034277431758165236,
      "alias": "ogx_mmlux_it-high_school_european_history"
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "acc,none": 0.61,
      "acc_stderr,none": 0.04902071300001974,
      "alias": "ogx_mmlux_it-high_school_computer_science"
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "acc,none": 0.4630541871921182,
      "acc_stderr,none": 0.035083705204426656,
      "alias": "ogx_mmlux_it-high_school_chemistry"
    },
    "ogx_mmlux_it-high_school_biology": {
      "acc,none": 0.7096774193548387,
      "acc_stderr,none": 0.02582210611941589,
      "alias": "ogx_mmlux_it-high_school_biology"
    },
    "ogx_mmlux_it-global_facts": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252606,
      "alias": "ogx_mmlux_it-global_facts"
    },
    "ogx_mmlux_it-formal_logic": {
      "acc,none": 0.42063492063492064,
      "acc_stderr,none": 0.04415438226743744,
      "alias": "ogx_mmlux_it-formal_logic"
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "acc,none": 0.4126984126984127,
      "acc_stderr,none": 0.025355741263055277,
      "alias": "ogx_mmlux_it-elementary_mathematics"
    },
    "ogx_mmlux_it-electrical_engineering": {
      "acc,none": 0.6137931034482759,
      "acc_stderr,none": 0.04057324734419034,
      "alias": "ogx_mmlux_it-electrical_engineering"
    },
    "ogx_mmlux_it-econometrics": {
      "acc,none": 0.4473684210526316,
      "acc_stderr,none": 0.04677473004491199,
      "alias": "ogx_mmlux_it-econometrics"
    },
    "ogx_mmlux_it-conceptual_physics": {
      "acc,none": 0.548936170212766,
      "acc_stderr,none": 0.032529096196131965,
      "alias": "ogx_mmlux_it-conceptual_physics"
    },
    "ogx_mmlux_it-computer_security": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.04408440022768078,
      "alias": "ogx_mmlux_it-computer_security"
    },
    "ogx_mmlux_it-college_physics": {
      "acc,none": 0.3627450980392157,
      "acc_stderr,none": 0.04784060704105655,
      "alias": "ogx_mmlux_it-college_physics"
    },
    "ogx_mmlux_it-college_medicine": {
      "acc,none": 0.5780346820809249,
      "acc_stderr,none": 0.0376574669386515,
      "alias": "ogx_mmlux_it-college_medicine"
    },
    "ogx_mmlux_it-college_mathematics": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_it-college_mathematics"
    },
    "ogx_mmlux_it-college_computer_science": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_it-college_computer_science"
    },
    "ogx_mmlux_it-college_chemistry": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.04923659639173309,
      "alias": "ogx_mmlux_it-college_chemistry"
    },
    "ogx_mmlux_it-college_biology": {
      "acc,none": 0.6319444444444444,
      "acc_stderr,none": 0.04032999053960719,
      "alias": "ogx_mmlux_it-college_biology"
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "acc,none": 0.6415094339622641,
      "acc_stderr,none": 0.02951470358398177,
      "alias": "ogx_mmlux_it-clinical_knowledge"
    },
    "ogx_mmlux_it-business_ethics": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_it-business_ethics"
    },
    "ogx_mmlux_it-astronomy": {
      "acc,none": 0.625,
      "acc_stderr,none": 0.039397364351956274,
      "alias": "ogx_mmlux_it-astronomy"
    },
    "ogx_mmlux_it-anatomy": {
      "acc,none": 0.5333333333333333,
      "acc_stderr,none": 0.043097329010363554,
      "alias": "ogx_mmlux_it-anatomy"
    },
    "ogx_mmlux_it-abstract_algebra": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_it-abstract_algebra"
    },
    "ogx_mmlux_hu-world_religions": {
      "acc,none": 0.6842105263157895,
      "acc_stderr,none": 0.035650796707083106,
      "alias": "ogx_mmlux_hu-world_religions"
    },
    "ogx_mmlux_hu-virology": {
      "acc,none": 0.42771084337349397,
      "acc_stderr,none": 0.038515976837185335,
      "alias": "ogx_mmlux_hu-virology"
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "acc,none": 0.73,
      "acc_stderr,none": 0.044619604333847394,
      "alias": "ogx_mmlux_hu-us_foreign_policy"
    },
    "ogx_mmlux_hu-sociology": {
      "acc,none": 0.7810945273631841,
      "acc_stderr,none": 0.029239174636647,
      "alias": "ogx_mmlux_hu-sociology"
    },
    "ogx_mmlux_hu-security_studies": {
      "acc,none": 0.6571428571428571,
      "acc_stderr,none": 0.03038726291954773,
      "alias": "ogx_mmlux_hu-security_studies"
    },
    "ogx_mmlux_hu-public_relations": {
      "acc,none": 0.5909090909090909,
      "acc_stderr,none": 0.04709306978661896,
      "alias": "ogx_mmlux_hu-public_relations"
    },
    "ogx_mmlux_hu-professional_psychology": {
      "acc,none": 0.5277777777777778,
      "acc_stderr,none": 0.020196594933541197,
      "alias": "ogx_mmlux_hu-professional_psychology"
    },
    "ogx_mmlux_hu-professional_medicine": {
      "acc,none": 0.4889705882352941,
      "acc_stderr,none": 0.030365446477275675,
      "alias": "ogx_mmlux_hu-professional_medicine"
    },
    "ogx_mmlux_hu-professional_law": {
      "acc,none": 0.37809647979139505,
      "acc_stderr,none": 0.012384878406798095,
      "alias": "ogx_mmlux_hu-professional_law"
    },
    "ogx_mmlux_hu-professional_accounting": {
      "acc,none": 0.41134751773049644,
      "acc_stderr,none": 0.029354911159940975,
      "alias": "ogx_mmlux_hu-professional_accounting"
    },
    "ogx_mmlux_hu-prehistory": {
      "acc,none": 0.654320987654321,
      "acc_stderr,none": 0.02646248777700188,
      "alias": "ogx_mmlux_hu-prehistory"
    },
    "ogx_mmlux_hu-philosophy": {
      "acc,none": 0.6334405144694534,
      "acc_stderr,none": 0.027368078243971642,
      "alias": "ogx_mmlux_hu-philosophy"
    },
    "ogx_mmlux_hu-nutrition": {
      "acc,none": 0.5947712418300654,
      "acc_stderr,none": 0.028110928492809065,
      "alias": "ogx_mmlux_hu-nutrition"
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "acc,none": 0.31731843575418994,
      "acc_stderr,none": 0.01556639263005703,
      "alias": "ogx_mmlux_hu-moral_scenarios"
    },
    "ogx_mmlux_hu-moral_disputes": {
      "acc,none": 0.5924855491329479,
      "acc_stderr,none": 0.026454578146931505,
      "alias": "ogx_mmlux_hu-moral_disputes"
    },
    "ogx_mmlux_hu-miscellaneous": {
      "acc,none": 0.6781609195402298,
      "acc_stderr,none": 0.016706381415057904,
      "alias": "ogx_mmlux_hu-miscellaneous"
    },
    "ogx_mmlux_hu-medical_genetics": {
      "acc,none": 0.66,
      "acc_stderr,none": 0.04760952285695238,
      "alias": "ogx_mmlux_hu-medical_genetics"
    },
    "ogx_mmlux_hu-marketing": {
      "acc,none": 0.7051282051282052,
      "acc_stderr,none": 0.0298725777088912,
      "alias": "ogx_mmlux_hu-marketing"
    },
    "ogx_mmlux_hu-management": {
      "acc,none": 0.7572815533980582,
      "acc_stderr,none": 0.04245022486384495,
      "alias": "ogx_mmlux_hu-management"
    },
    "ogx_mmlux_hu-machine_learning": {
      "acc,none": 0.5089285714285714,
      "acc_stderr,none": 0.04745033255489123,
      "alias": "ogx_mmlux_hu-machine_learning"
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "acc,none": 0.6196319018404908,
      "acc_stderr,none": 0.038142698932618374,
      "alias": "ogx_mmlux_hu-logical_fallacies"
    },
    "ogx_mmlux_hu-jurisprudence": {
      "acc,none": 0.6111111111111112,
      "acc_stderr,none": 0.04712821257426769,
      "alias": "ogx_mmlux_hu-jurisprudence"
    },
    "ogx_mmlux_hu-international_law": {
      "acc,none": 0.6942148760330579,
      "acc_stderr,none": 0.04205953933884122,
      "alias": "ogx_mmlux_hu-international_law"
    },
    "ogx_mmlux_hu-human_sexuality": {
      "acc,none": 0.5877862595419847,
      "acc_stderr,none": 0.043171711948702556,
      "alias": "ogx_mmlux_hu-human_sexuality"
    },
    "ogx_mmlux_hu-human_aging": {
      "acc,none": 0.5201793721973094,
      "acc_stderr,none": 0.033530461674123,
      "alias": "ogx_mmlux_hu-human_aging"
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "acc,none": 0.6919831223628692,
      "acc_stderr,none": 0.0300523893356057,
      "alias": "ogx_mmlux_hu-high_school_world_history"
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "acc,none": 0.7205882352941176,
      "acc_stderr,none": 0.03149328104507957,
      "alias": "ogx_mmlux_hu-high_school_us_history"
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "acc,none": 0.39351851851851855,
      "acc_stderr,none": 0.03331747876370312,
      "alias": "ogx_mmlux_hu-high_school_statistics"
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "acc,none": 0.6568807339449542,
      "acc_stderr,none": 0.02035477773608604,
      "alias": "ogx_mmlux_hu-high_school_psychology"
    },
    "ogx_mmlux_hu-high_school_physics": {
      "acc,none": 0.3973509933774834,
      "acc_stderr,none": 0.039955240076816806,
      "alias": "ogx_mmlux_hu-high_school_physics"
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "acc,none": 0.4831932773109244,
      "acc_stderr,none": 0.03246013680375308,
      "alias": "ogx_mmlux_hu-high_school_microeconomics"
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "acc,none": 0.37777777777777777,
      "acc_stderr,none": 0.029560707392465718,
      "alias": "ogx_mmlux_hu-high_school_mathematics"
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "acc,none": 0.49743589743589745,
      "acc_stderr,none": 0.025350672979412188,
      "alias": "ogx_mmlux_hu-high_school_macroeconomics"
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "acc,none": 0.616580310880829,
      "acc_stderr,none": 0.03508984236295341,
      "alias": "ogx_mmlux_hu-high_school_government_and_politics"
    },
    "ogx_mmlux_hu-high_school_geography": {
      "acc,none": 0.6666666666666666,
      "acc_stderr,none": 0.033586181457325226,
      "alias": "ogx_mmlux_hu-high_school_geography"
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "acc,none": 0.7151515151515152,
      "acc_stderr,none": 0.03524390844511781,
      "alias": "ogx_mmlux_hu-high_school_european_history"
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "acc,none": 0.65,
      "acc_stderr,none": 0.04793724854411019,
      "alias": "ogx_mmlux_hu-high_school_computer_science"
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "acc,none": 0.46798029556650245,
      "acc_stderr,none": 0.035107665979592154,
      "alias": "ogx_mmlux_hu-high_school_chemistry"
    },
    "ogx_mmlux_hu-high_school_biology": {
      "acc,none": 0.6741935483870968,
      "acc_stderr,none": 0.026662010578567104,
      "alias": "ogx_mmlux_hu-high_school_biology"
    },
    "ogx_mmlux_hu-global_facts": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_hu-global_facts"
    },
    "ogx_mmlux_hu-formal_logic": {
      "acc,none": 0.35714285714285715,
      "acc_stderr,none": 0.04285714285714281,
      "alias": "ogx_mmlux_hu-formal_logic"
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "acc,none": 0.4021164021164021,
      "acc_stderr,none": 0.025253032554997695,
      "alias": "ogx_mmlux_hu-elementary_mathematics"
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "acc,none": 0.5448275862068965,
      "acc_stderr,none": 0.04149886942192117,
      "alias": "ogx_mmlux_hu-electrical_engineering"
    },
    "ogx_mmlux_hu-econometrics": {
      "acc,none": 0.34210526315789475,
      "acc_stderr,none": 0.04462917535336937,
      "alias": "ogx_mmlux_hu-econometrics"
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "acc,none": 0.46808510638297873,
      "acc_stderr,none": 0.03261936918467382,
      "alias": "ogx_mmlux_hu-conceptual_physics"
    },
    "ogx_mmlux_hu-computer_security": {
      "acc,none": 0.64,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_hu-computer_security"
    },
    "ogx_mmlux_hu-college_physics": {
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.04690650298201942,
      "alias": "ogx_mmlux_hu-college_physics"
    },
    "ogx_mmlux_hu-college_medicine": {
      "acc,none": 0.5028901734104047,
      "acc_stderr,none": 0.038124005659748335,
      "alias": "ogx_mmlux_hu-college_medicine"
    },
    "ogx_mmlux_hu-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_hu-college_mathematics"
    },
    "ogx_mmlux_hu-college_computer_science": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.04975698519562427,
      "alias": "ogx_mmlux_hu-college_computer_science"
    },
    "ogx_mmlux_hu-college_chemistry": {
      "acc,none": 0.41,
      "acc_stderr,none": 0.049431107042371025,
      "alias": "ogx_mmlux_hu-college_chemistry"
    },
    "ogx_mmlux_hu-college_biology": {
      "acc,none": 0.6111111111111112,
      "acc_stderr,none": 0.04076663253918567,
      "alias": "ogx_mmlux_hu-college_biology"
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "acc,none": 0.569811320754717,
      "acc_stderr,none": 0.030471445867183235,
      "alias": "ogx_mmlux_hu-clinical_knowledge"
    },
    "ogx_mmlux_hu-business_ethics": {
      "acc,none": 0.61,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_hu-business_ethics"
    },
    "ogx_mmlux_hu-astronomy": {
      "acc,none": 0.5789473684210527,
      "acc_stderr,none": 0.040179012759817494,
      "alias": "ogx_mmlux_hu-astronomy"
    },
    "ogx_mmlux_hu-anatomy": {
      "acc,none": 0.4888888888888889,
      "acc_stderr,none": 0.043182754919779756,
      "alias": "ogx_mmlux_hu-anatomy"
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_hu-abstract_algebra"
    },
    "ogx_mmlux_fr-world_religions": {
      "acc,none": 0.7894736842105263,
      "acc_stderr,none": 0.03126781714663179,
      "alias": "ogx_mmlux_fr-world_religions"
    },
    "ogx_mmlux_fr-virology": {
      "acc,none": 0.4879518072289157,
      "acc_stderr,none": 0.03891364495835821,
      "alias": "ogx_mmlux_fr-virology"
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "acc,none": 0.85,
      "acc_stderr,none": 0.0358870281282637,
      "alias": "ogx_mmlux_fr-us_foreign_policy"
    },
    "ogx_mmlux_fr-sociology": {
      "acc,none": 0.8208955223880597,
      "acc_stderr,none": 0.027113286753111837,
      "alias": "ogx_mmlux_fr-sociology"
    },
    "ogx_mmlux_fr-security_studies": {
      "acc,none": 0.7061224489795919,
      "acc_stderr,none": 0.02916273841024978,
      "alias": "ogx_mmlux_fr-security_studies"
    },
    "ogx_mmlux_fr-public_relations": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.04389311454644287,
      "alias": "ogx_mmlux_fr-public_relations"
    },
    "ogx_mmlux_fr-professional_psychology": {
      "acc,none": 0.6013071895424836,
      "acc_stderr,none": 0.019808281317449866,
      "alias": "ogx_mmlux_fr-professional_psychology"
    },
    "ogx_mmlux_fr-professional_medicine": {
      "acc,none": 0.5661764705882353,
      "acc_stderr,none": 0.03010563657001664,
      "alias": "ogx_mmlux_fr-professional_medicine"
    },
    "ogx_mmlux_fr-professional_law": {
      "acc,none": 0.4106910039113429,
      "acc_stderr,none": 0.01256487154253435,
      "alias": "ogx_mmlux_fr-professional_law"
    },
    "ogx_mmlux_fr-professional_accounting": {
      "acc,none": 0.4326241134751773,
      "acc_stderr,none": 0.029555454236778852,
      "alias": "ogx_mmlux_fr-professional_accounting"
    },
    "ogx_mmlux_fr-prehistory": {
      "acc,none": 0.6851851851851852,
      "acc_stderr,none": 0.025842248700902164,
      "alias": "ogx_mmlux_fr-prehistory"
    },
    "ogx_mmlux_fr-philosophy": {
      "acc,none": 0.6527331189710611,
      "acc_stderr,none": 0.027040745502307336,
      "alias": "ogx_mmlux_fr-philosophy"
    },
    "ogx_mmlux_fr-nutrition": {
      "acc,none": 0.6993464052287581,
      "acc_stderr,none": 0.026256053835718964,
      "alias": "ogx_mmlux_fr-nutrition"
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "acc,none": 0.28268156424581004,
      "acc_stderr,none": 0.015060381730018082,
      "alias": "ogx_mmlux_fr-moral_scenarios"
    },
    "ogx_mmlux_fr-moral_disputes": {
      "acc,none": 0.6820809248554913,
      "acc_stderr,none": 0.02507071371915319,
      "alias": "ogx_mmlux_fr-moral_disputes"
    },
    "ogx_mmlux_fr-miscellaneous": {
      "acc,none": 0.7318007662835249,
      "acc_stderr,none": 0.01584243083526943,
      "alias": "ogx_mmlux_fr-miscellaneous"
    },
    "ogx_mmlux_fr-medical_genetics": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.044084400227680794,
      "alias": "ogx_mmlux_fr-medical_genetics"
    },
    "ogx_mmlux_fr-marketing": {
      "acc,none": 0.8205128205128205,
      "acc_stderr,none": 0.025140935950335418,
      "alias": "ogx_mmlux_fr-marketing"
    },
    "ogx_mmlux_fr-management": {
      "acc,none": 0.7184466019417476,
      "acc_stderr,none": 0.04453254836326466,
      "alias": "ogx_mmlux_fr-management"
    },
    "ogx_mmlux_fr-machine_learning": {
      "acc,none": 0.38392857142857145,
      "acc_stderr,none": 0.04616143075028547,
      "alias": "ogx_mmlux_fr-machine_learning"
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "acc,none": 0.6993865030674846,
      "acc_stderr,none": 0.03602511318806771,
      "alias": "ogx_mmlux_fr-logical_fallacies"
    },
    "ogx_mmlux_fr-jurisprudence": {
      "acc,none": 0.7314814814814815,
      "acc_stderr,none": 0.042844679680521934,
      "alias": "ogx_mmlux_fr-jurisprudence"
    },
    "ogx_mmlux_fr-international_law": {
      "acc,none": 0.7603305785123967,
      "acc_stderr,none": 0.03896878985070417,
      "alias": "ogx_mmlux_fr-international_law"
    },
    "ogx_mmlux_fr-human_sexuality": {
      "acc,none": 0.6946564885496184,
      "acc_stderr,none": 0.040393149787245626,
      "alias": "ogx_mmlux_fr-human_sexuality"
    },
    "ogx_mmlux_fr-human_aging": {
      "acc,none": 0.6412556053811659,
      "acc_stderr,none": 0.032190792004199956,
      "alias": "ogx_mmlux_fr-human_aging"
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "acc,none": 0.7552742616033755,
      "acc_stderr,none": 0.027985699387036416,
      "alias": "ogx_mmlux_fr-high_school_world_history"
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "acc,none": 0.7990196078431373,
      "acc_stderr,none": 0.02812597226565437,
      "alias": "ogx_mmlux_fr-high_school_us_history"
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "acc,none": 0.4537037037037037,
      "acc_stderr,none": 0.033953227263757976,
      "alias": "ogx_mmlux_fr-high_school_statistics"
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "acc,none": 0.7577981651376147,
      "acc_stderr,none": 0.018368176306598615,
      "alias": "ogx_mmlux_fr-high_school_psychology"
    },
    "ogx_mmlux_fr-high_school_physics": {
      "acc,none": 0.3443708609271523,
      "acc_stderr,none": 0.038796870240733264,
      "alias": "ogx_mmlux_fr-high_school_physics"
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "acc,none": 0.6008403361344538,
      "acc_stderr,none": 0.03181110032413925,
      "alias": "ogx_mmlux_fr-high_school_microeconomics"
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.02986960509531691,
      "alias": "ogx_mmlux_fr-high_school_mathematics"
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "acc,none": 0.5538461538461539,
      "acc_stderr,none": 0.02520357177302833,
      "alias": "ogx_mmlux_fr-high_school_macroeconomics"
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "acc,none": 0.7409326424870466,
      "acc_stderr,none": 0.03161877917935412,
      "alias": "ogx_mmlux_fr-high_school_government_and_politics"
    },
    "ogx_mmlux_fr-high_school_geography": {
      "acc,none": 0.7525252525252525,
      "acc_stderr,none": 0.0307463007421245,
      "alias": "ogx_mmlux_fr-high_school_geography"
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "acc,none": 0.7818181818181819,
      "acc_stderr,none": 0.03225078108306289,
      "alias": "ogx_mmlux_fr-high_school_european_history"
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "acc,none": 0.61,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_fr-high_school_computer_science"
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "acc,none": 0.458128078817734,
      "acc_stderr,none": 0.035056301407857426,
      "alias": "ogx_mmlux_fr-high_school_chemistry"
    },
    "ogx_mmlux_fr-high_school_biology": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.026069362295335134,
      "alias": "ogx_mmlux_fr-high_school_biology"
    },
    "ogx_mmlux_fr-global_facts": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836,
      "alias": "ogx_mmlux_fr-global_facts"
    },
    "ogx_mmlux_fr-formal_logic": {
      "acc,none": 0.48412698412698413,
      "acc_stderr,none": 0.04469881854072606,
      "alias": "ogx_mmlux_fr-formal_logic"
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "acc,none": 0.4417989417989418,
      "acc_stderr,none": 0.02557625706125384,
      "alias": "ogx_mmlux_fr-elementary_mathematics"
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "acc,none": 0.5862068965517241,
      "acc_stderr,none": 0.04104269211806232,
      "alias": "ogx_mmlux_fr-electrical_engineering"
    },
    "ogx_mmlux_fr-econometrics": {
      "acc,none": 0.40350877192982454,
      "acc_stderr,none": 0.04615186962583704,
      "alias": "ogx_mmlux_fr-econometrics"
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "acc,none": 0.5148936170212766,
      "acc_stderr,none": 0.03267151848924777,
      "alias": "ogx_mmlux_fr-conceptual_physics"
    },
    "ogx_mmlux_fr-computer_security": {
      "acc,none": 0.68,
      "acc_stderr,none": 0.04688261722621505,
      "alias": "ogx_mmlux_fr-computer_security"
    },
    "ogx_mmlux_fr-college_physics": {
      "acc,none": 0.35294117647058826,
      "acc_stderr,none": 0.047551296160629475,
      "alias": "ogx_mmlux_fr-college_physics"
    },
    "ogx_mmlux_fr-college_medicine": {
      "acc,none": 0.5317919075144508,
      "acc_stderr,none": 0.03804749744364764,
      "alias": "ogx_mmlux_fr-college_medicine"
    },
    "ogx_mmlux_fr-college_mathematics": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_fr-college_mathematics"
    },
    "ogx_mmlux_fr-college_computer_science": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_fr-college_computer_science"
    },
    "ogx_mmlux_fr-college_chemistry": {
      "acc,none": 0.39,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_fr-college_chemistry"
    },
    "ogx_mmlux_fr-college_biology": {
      "acc,none": 0.6388888888888888,
      "acc_stderr,none": 0.04016660030451233,
      "alias": "ogx_mmlux_fr-college_biology"
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "acc,none": 0.6188679245283019,
      "acc_stderr,none": 0.029890609686286634,
      "alias": "ogx_mmlux_fr-clinical_knowledge"
    },
    "ogx_mmlux_fr-business_ethics": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_fr-business_ethics"
    },
    "ogx_mmlux_fr-astronomy": {
      "acc,none": 0.6710526315789473,
      "acc_stderr,none": 0.03823428969926603,
      "alias": "ogx_mmlux_fr-astronomy"
    },
    "ogx_mmlux_fr-anatomy": {
      "acc,none": 0.5481481481481482,
      "acc_stderr,none": 0.04299268905480864,
      "alias": "ogx_mmlux_fr-anatomy"
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_fr-abstract_algebra"
    },
    "ogx_mmlux_fi-world_religions": {
      "acc,none": 0.7309941520467836,
      "acc_stderr,none": 0.0340105262010409,
      "alias": "ogx_mmlux_fi-world_religions"
    },
    "ogx_mmlux_fi-virology": {
      "acc,none": 0.4819277108433735,
      "acc_stderr,none": 0.038899512528272166,
      "alias": "ogx_mmlux_fi-virology"
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "acc,none": 0.77,
      "acc_stderr,none": 0.04229525846816505,
      "alias": "ogx_mmlux_fi-us_foreign_policy"
    },
    "ogx_mmlux_fi-sociology": {
      "acc,none": 0.6865671641791045,
      "acc_stderr,none": 0.03280188205348643,
      "alias": "ogx_mmlux_fi-sociology"
    },
    "ogx_mmlux_fi-security_studies": {
      "acc,none": 0.6081632653061224,
      "acc_stderr,none": 0.03125127591089165,
      "alias": "ogx_mmlux_fi-security_studies"
    },
    "ogx_mmlux_fi-public_relations": {
      "acc,none": 0.5545454545454546,
      "acc_stderr,none": 0.047605488214603246,
      "alias": "ogx_mmlux_fi-public_relations"
    },
    "ogx_mmlux_fi-professional_psychology": {
      "acc,none": 0.49019607843137253,
      "acc_stderr,none": 0.020223946005074312,
      "alias": "ogx_mmlux_fi-professional_psychology"
    },
    "ogx_mmlux_fi-professional_medicine": {
      "acc,none": 0.44485294117647056,
      "acc_stderr,none": 0.03018753206032938,
      "alias": "ogx_mmlux_fi-professional_medicine"
    },
    "ogx_mmlux_fi-professional_law": {
      "acc,none": 0.37157757496740546,
      "acc_stderr,none": 0.012341828514528289,
      "alias": "ogx_mmlux_fi-professional_law"
    },
    "ogx_mmlux_fi-professional_accounting": {
      "acc,none": 0.3049645390070922,
      "acc_stderr,none": 0.027464708442022163,
      "alias": "ogx_mmlux_fi-professional_accounting"
    },
    "ogx_mmlux_fi-prehistory": {
      "acc,none": 0.5709876543209876,
      "acc_stderr,none": 0.027538925613470863,
      "alias": "ogx_mmlux_fi-prehistory"
    },
    "ogx_mmlux_fi-philosophy": {
      "acc,none": 0.5337620578778135,
      "acc_stderr,none": 0.028333277109562783,
      "alias": "ogx_mmlux_fi-philosophy"
    },
    "ogx_mmlux_fi-nutrition": {
      "acc,none": 0.5522875816993464,
      "acc_stderr,none": 0.028472938478033526,
      "alias": "ogx_mmlux_fi-nutrition"
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "acc,none": 0.3407821229050279,
      "acc_stderr,none": 0.015852002449862113,
      "alias": "ogx_mmlux_fi-moral_scenarios"
    },
    "ogx_mmlux_fi-moral_disputes": {
      "acc,none": 0.5404624277456648,
      "acc_stderr,none": 0.02683080599895224,
      "alias": "ogx_mmlux_fi-moral_disputes"
    },
    "ogx_mmlux_fi-miscellaneous": {
      "acc,none": 0.6283524904214559,
      "acc_stderr,none": 0.01728080252213318,
      "alias": "ogx_mmlux_fi-miscellaneous"
    },
    "ogx_mmlux_fi-medical_genetics": {
      "acc,none": 0.64,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_fi-medical_genetics"
    },
    "ogx_mmlux_fi-marketing": {
      "acc,none": 0.717948717948718,
      "acc_stderr,none": 0.02948036054954119,
      "alias": "ogx_mmlux_fi-marketing"
    },
    "ogx_mmlux_fi-management": {
      "acc,none": 0.6407766990291263,
      "acc_stderr,none": 0.047504583990416946,
      "alias": "ogx_mmlux_fi-management"
    },
    "ogx_mmlux_fi-machine_learning": {
      "acc,none": 0.33035714285714285,
      "acc_stderr,none": 0.04464285714285714,
      "alias": "ogx_mmlux_fi-machine_learning"
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "acc,none": 0.5460122699386503,
      "acc_stderr,none": 0.0391170190467718,
      "alias": "ogx_mmlux_fi-logical_fallacies"
    },
    "ogx_mmlux_fi-jurisprudence": {
      "acc,none": 0.5833333333333334,
      "acc_stderr,none": 0.04766075165356461,
      "alias": "ogx_mmlux_fi-jurisprudence"
    },
    "ogx_mmlux_fi-international_law": {
      "acc,none": 0.7520661157024794,
      "acc_stderr,none": 0.039418975265163005,
      "alias": "ogx_mmlux_fi-international_law"
    },
    "ogx_mmlux_fi-human_sexuality": {
      "acc,none": 0.5648854961832062,
      "acc_stderr,none": 0.043482080516448585,
      "alias": "ogx_mmlux_fi-human_sexuality"
    },
    "ogx_mmlux_fi-human_aging": {
      "acc,none": 0.5426008968609866,
      "acc_stderr,none": 0.03343577705583064,
      "alias": "ogx_mmlux_fi-human_aging"
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "acc,none": 0.6497890295358649,
      "acc_stderr,none": 0.03105239193758435,
      "alias": "ogx_mmlux_fi-high_school_world_history"
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "acc,none": 0.6715686274509803,
      "acc_stderr,none": 0.03296245110172227,
      "alias": "ogx_mmlux_fi-high_school_us_history"
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.03324708911809117,
      "alias": "ogx_mmlux_fi-high_school_statistics"
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "acc,none": 0.5908256880733945,
      "acc_stderr,none": 0.021080670264433738,
      "alias": "ogx_mmlux_fi-high_school_psychology"
    },
    "ogx_mmlux_fi-high_school_physics": {
      "acc,none": 0.40397350993377484,
      "acc_stderr,none": 0.040064856853653415,
      "alias": "ogx_mmlux_fi-high_school_physics"
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "acc,none": 0.44537815126050423,
      "acc_stderr,none": 0.0322841062671639,
      "alias": "ogx_mmlux_fi-high_school_microeconomics"
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "acc,none": 0.3814814814814815,
      "acc_stderr,none": 0.02961671892749759,
      "alias": "ogx_mmlux_fi-high_school_mathematics"
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "acc,none": 0.4461538461538462,
      "acc_stderr,none": 0.02520357177302833,
      "alias": "ogx_mmlux_fi-high_school_macroeconomics"
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "acc,none": 0.5854922279792746,
      "acc_stderr,none": 0.035553003195576686,
      "alias": "ogx_mmlux_fi-high_school_government_and_politics"
    },
    "ogx_mmlux_fi-high_school_geography": {
      "acc,none": 0.6161616161616161,
      "acc_stderr,none": 0.03464881675016339,
      "alias": "ogx_mmlux_fi-high_school_geography"
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "acc,none": 0.6727272727272727,
      "acc_stderr,none": 0.036639749943912434,
      "alias": "ogx_mmlux_fi-high_school_european_history"
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "acc,none": 0.53,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_fi-high_school_computer_science"
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "acc,none": 0.43842364532019706,
      "acc_stderr,none": 0.03491207857486518,
      "alias": "ogx_mmlux_fi-high_school_chemistry"
    },
    "ogx_mmlux_fi-high_school_biology": {
      "acc,none": 0.6096774193548387,
      "acc_stderr,none": 0.02775125663696958,
      "alias": "ogx_mmlux_fi-high_school_biology"
    },
    "ogx_mmlux_fi-global_facts": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.04824181513244218,
      "alias": "ogx_mmlux_fi-global_facts"
    },
    "ogx_mmlux_fi-formal_logic": {
      "acc,none": 0.29365079365079366,
      "acc_stderr,none": 0.04073524322147126,
      "alias": "ogx_mmlux_fi-formal_logic"
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "acc,none": 0.41005291005291006,
      "acc_stderr,none": 0.025331202438944423,
      "alias": "ogx_mmlux_fi-elementary_mathematics"
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "acc,none": 0.5586206896551724,
      "acc_stderr,none": 0.04137931034482758,
      "alias": "ogx_mmlux_fi-electrical_engineering"
    },
    "ogx_mmlux_fi-econometrics": {
      "acc,none": 0.34210526315789475,
      "acc_stderr,none": 0.044629175353369376,
      "alias": "ogx_mmlux_fi-econometrics"
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "acc,none": 0.425531914893617,
      "acc_stderr,none": 0.03232146916224468,
      "alias": "ogx_mmlux_fi-conceptual_physics"
    },
    "ogx_mmlux_fi-computer_security": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.04852365870939098,
      "alias": "ogx_mmlux_fi-computer_security"
    },
    "ogx_mmlux_fi-college_physics": {
      "acc,none": 0.3333333333333333,
      "acc_stderr,none": 0.04690650298201942,
      "alias": "ogx_mmlux_fi-college_physics"
    },
    "ogx_mmlux_fi-college_medicine": {
      "acc,none": 0.5144508670520231,
      "acc_stderr,none": 0.03810871630454764,
      "alias": "ogx_mmlux_fi-college_medicine"
    },
    "ogx_mmlux_fi-college_mathematics": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542128,
      "alias": "ogx_mmlux_fi-college_mathematics"
    },
    "ogx_mmlux_fi-college_computer_science": {
      "acc,none": 0.45,
      "acc_stderr,none": 0.049999999999999996,
      "alias": "ogx_mmlux_fi-college_computer_science"
    },
    "ogx_mmlux_fi-college_chemistry": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_fi-college_chemistry"
    },
    "ogx_mmlux_fi-college_biology": {
      "acc,none": 0.4791666666666667,
      "acc_stderr,none": 0.041775789507399914,
      "alias": "ogx_mmlux_fi-college_biology"
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "acc,none": 0.5358490566037736,
      "acc_stderr,none": 0.030693675018458006,
      "alias": "ogx_mmlux_fi-clinical_knowledge"
    },
    "ogx_mmlux_fi-business_ethics": {
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795,
      "alias": "ogx_mmlux_fi-business_ethics"
    },
    "ogx_mmlux_fi-astronomy": {
      "acc,none": 0.5592105263157895,
      "acc_stderr,none": 0.04040311062490436,
      "alias": "ogx_mmlux_fi-astronomy"
    },
    "ogx_mmlux_fi-anatomy": {
      "acc,none": 0.4888888888888889,
      "acc_stderr,none": 0.04318275491977976,
      "alias": "ogx_mmlux_fi-anatomy"
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695236,
      "alias": "ogx_mmlux_fi-abstract_algebra"
    },
    "ogx_mmlux_et-world_religions": {
      "acc,none": 0.7076023391812866,
      "acc_stderr,none": 0.03488647713457922,
      "alias": "ogx_mmlux_et-world_religions"
    },
    "ogx_mmlux_et-virology": {
      "acc,none": 0.4457831325301205,
      "acc_stderr,none": 0.03869543323472101,
      "alias": "ogx_mmlux_et-virology"
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_et-us_foreign_policy"
    },
    "ogx_mmlux_et-sociology": {
      "acc,none": 0.6567164179104478,
      "acc_stderr,none": 0.03357379665433431,
      "alias": "ogx_mmlux_et-sociology"
    },
    "ogx_mmlux_et-security_studies": {
      "acc,none": 0.563265306122449,
      "acc_stderr,none": 0.031751952375833226,
      "alias": "ogx_mmlux_et-security_studies"
    },
    "ogx_mmlux_et-public_relations": {
      "acc,none": 0.5454545454545454,
      "acc_stderr,none": 0.04769300568972744,
      "alias": "ogx_mmlux_et-public_relations"
    },
    "ogx_mmlux_et-professional_psychology": {
      "acc,none": 0.45751633986928103,
      "acc_stderr,none": 0.02015468571259089,
      "alias": "ogx_mmlux_et-professional_psychology"
    },
    "ogx_mmlux_et-professional_medicine": {
      "acc,none": 0.35661764705882354,
      "acc_stderr,none": 0.02909720956841194,
      "alias": "ogx_mmlux_et-professional_medicine"
    },
    "ogx_mmlux_et-professional_law": {
      "acc,none": 0.3546284224250326,
      "acc_stderr,none": 0.012218576439090184,
      "alias": "ogx_mmlux_et-professional_law"
    },
    "ogx_mmlux_et-professional_accounting": {
      "acc,none": 0.35815602836879434,
      "acc_stderr,none": 0.028602085862759415,
      "alias": "ogx_mmlux_et-professional_accounting"
    },
    "ogx_mmlux_et-prehistory": {
      "acc,none": 0.5617283950617284,
      "acc_stderr,none": 0.027607914087400473,
      "alias": "ogx_mmlux_et-prehistory"
    },
    "ogx_mmlux_et-philosophy": {
      "acc,none": 0.5562700964630225,
      "acc_stderr,none": 0.028217683556652308,
      "alias": "ogx_mmlux_et-philosophy"
    },
    "ogx_mmlux_et-nutrition": {
      "acc,none": 0.5196078431372549,
      "acc_stderr,none": 0.028607893699576063,
      "alias": "ogx_mmlux_et-nutrition"
    },
    "ogx_mmlux_et-moral_scenarios": {
      "acc,none": 0.28938547486033517,
      "acc_stderr,none": 0.01516654455049029,
      "alias": "ogx_mmlux_et-moral_scenarios"
    },
    "ogx_mmlux_et-moral_disputes": {
      "acc,none": 0.546242774566474,
      "acc_stderr,none": 0.02680372058320617,
      "alias": "ogx_mmlux_et-moral_disputes"
    },
    "ogx_mmlux_et-miscellaneous": {
      "acc,none": 0.5964240102171137,
      "acc_stderr,none": 0.017544332237926417,
      "alias": "ogx_mmlux_et-miscellaneous"
    },
    "ogx_mmlux_et-medical_genetics": {
      "acc,none": 0.66,
      "acc_stderr,none": 0.04760952285695237,
      "alias": "ogx_mmlux_et-medical_genetics"
    },
    "ogx_mmlux_et-marketing": {
      "acc,none": 0.6410256410256411,
      "acc_stderr,none": 0.031426169937919225,
      "alias": "ogx_mmlux_et-marketing"
    },
    "ogx_mmlux_et-management": {
      "acc,none": 0.5825242718446602,
      "acc_stderr,none": 0.04882840548212238,
      "alias": "ogx_mmlux_et-management"
    },
    "ogx_mmlux_et-machine_learning": {
      "acc,none": 0.38392857142857145,
      "acc_stderr,none": 0.04616143075028547,
      "alias": "ogx_mmlux_et-machine_learning"
    },
    "ogx_mmlux_et-logical_fallacies": {
      "acc,none": 0.588957055214724,
      "acc_stderr,none": 0.038656978537853624,
      "alias": "ogx_mmlux_et-logical_fallacies"
    },
    "ogx_mmlux_et-jurisprudence": {
      "acc,none": 0.6111111111111112,
      "acc_stderr,none": 0.04712821257426769,
      "alias": "ogx_mmlux_et-jurisprudence"
    },
    "ogx_mmlux_et-international_law": {
      "acc,none": 0.5950413223140496,
      "acc_stderr,none": 0.04481137755942469,
      "alias": "ogx_mmlux_et-international_law"
    },
    "ogx_mmlux_et-human_sexuality": {
      "acc,none": 0.6030534351145038,
      "acc_stderr,none": 0.04291135671009224,
      "alias": "ogx_mmlux_et-human_sexuality"
    },
    "ogx_mmlux_et-human_aging": {
      "acc,none": 0.49327354260089684,
      "acc_stderr,none": 0.03355476596234354,
      "alias": "ogx_mmlux_et-human_aging"
    },
    "ogx_mmlux_et-high_school_world_history": {
      "acc,none": 0.6118143459915611,
      "acc_stderr,none": 0.031722950043323296,
      "alias": "ogx_mmlux_et-high_school_world_history"
    },
    "ogx_mmlux_et-high_school_us_history": {
      "acc,none": 0.6029411764705882,
      "acc_stderr,none": 0.03434131164719128,
      "alias": "ogx_mmlux_et-high_school_us_history"
    },
    "ogx_mmlux_et-high_school_statistics": {
      "acc,none": 0.33796296296296297,
      "acc_stderr,none": 0.03225941352631295,
      "alias": "ogx_mmlux_et-high_school_statistics"
    },
    "ogx_mmlux_et-high_school_psychology": {
      "acc,none": 0.544954128440367,
      "acc_stderr,none": 0.021350503090925167,
      "alias": "ogx_mmlux_et-high_school_psychology"
    },
    "ogx_mmlux_et-high_school_physics": {
      "acc,none": 0.33112582781456956,
      "acc_stderr,none": 0.038425817186598696,
      "alias": "ogx_mmlux_et-high_school_physics"
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "acc,none": 0.453781512605042,
      "acc_stderr,none": 0.03233943468182088,
      "alias": "ogx_mmlux_et-high_school_microeconomics"
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "acc,none": 0.35185185185185186,
      "acc_stderr,none": 0.029116617606083004,
      "alias": "ogx_mmlux_et-high_school_mathematics"
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "acc,none": 0.441025641025641,
      "acc_stderr,none": 0.02517404838400074,
      "alias": "ogx_mmlux_et-high_school_macroeconomics"
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "acc,none": 0.5284974093264249,
      "acc_stderr,none": 0.036025735712884414,
      "alias": "ogx_mmlux_et-high_school_government_and_politics"
    },
    "ogx_mmlux_et-high_school_geography": {
      "acc,none": 0.6111111111111112,
      "acc_stderr,none": 0.0347327959083696,
      "alias": "ogx_mmlux_et-high_school_geography"
    },
    "ogx_mmlux_et-high_school_european_history": {
      "acc,none": 0.6727272727272727,
      "acc_stderr,none": 0.03663974994391244,
      "alias": "ogx_mmlux_et-high_school_european_history"
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "acc,none": 0.56,
      "acc_stderr,none": 0.04988876515698589,
      "alias": "ogx_mmlux_et-high_school_computer_science"
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "acc,none": 0.4039408866995074,
      "acc_stderr,none": 0.03452453903822039,
      "alias": "ogx_mmlux_et-high_school_chemistry"
    },
    "ogx_mmlux_et-high_school_biology": {
      "acc,none": 0.567741935483871,
      "acc_stderr,none": 0.028181739720019416,
      "alias": "ogx_mmlux_et-high_school_biology"
    },
    "ogx_mmlux_et-global_facts": {
      "acc,none": 0.37,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_et-global_facts"
    },
    "ogx_mmlux_et-formal_logic": {
      "acc,none": 0.3412698412698413,
      "acc_stderr,none": 0.04240799327574924,
      "alias": "ogx_mmlux_et-formal_logic"
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "acc,none": 0.34656084656084657,
      "acc_stderr,none": 0.024508777521028424,
      "alias": "ogx_mmlux_et-elementary_mathematics"
    },
    "ogx_mmlux_et-electrical_engineering": {
      "acc,none": 0.496551724137931,
      "acc_stderr,none": 0.0416656757710158,
      "alias": "ogx_mmlux_et-electrical_engineering"
    },
    "ogx_mmlux_et-econometrics": {
      "acc,none": 0.34210526315789475,
      "acc_stderr,none": 0.04462917535336937,
      "alias": "ogx_mmlux_et-econometrics"
    },
    "ogx_mmlux_et-conceptual_physics": {
      "acc,none": 0.39574468085106385,
      "acc_stderr,none": 0.03196758697835363,
      "alias": "ogx_mmlux_et-conceptual_physics"
    },
    "ogx_mmlux_et-computer_security": {
      "acc,none": 0.53,
      "acc_stderr,none": 0.050161355804659205,
      "alias": "ogx_mmlux_et-computer_security"
    },
    "ogx_mmlux_et-college_physics": {
      "acc,none": 0.3431372549019608,
      "acc_stderr,none": 0.04724007352383889,
      "alias": "ogx_mmlux_et-college_physics"
    },
    "ogx_mmlux_et-college_medicine": {
      "acc,none": 0.5375722543352601,
      "acc_stderr,none": 0.03801685104524458,
      "alias": "ogx_mmlux_et-college_medicine"
    },
    "ogx_mmlux_et-college_mathematics": {
      "acc,none": 0.24,
      "acc_stderr,none": 0.042923469599092816,
      "alias": "ogx_mmlux_et-college_mathematics"
    },
    "ogx_mmlux_et-college_computer_science": {
      "acc,none": 0.29,
      "acc_stderr,none": 0.04560480215720684,
      "alias": "ogx_mmlux_et-college_computer_science"
    },
    "ogx_mmlux_et-college_chemistry": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.04688261722621503,
      "alias": "ogx_mmlux_et-college_chemistry"
    },
    "ogx_mmlux_et-college_biology": {
      "acc,none": 0.5277777777777778,
      "acc_stderr,none": 0.04174752578923185,
      "alias": "ogx_mmlux_et-college_biology"
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "acc,none": 0.4830188679245283,
      "acc_stderr,none": 0.030755120364119905,
      "alias": "ogx_mmlux_et-clinical_knowledge"
    },
    "ogx_mmlux_et-business_ethics": {
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919,
      "alias": "ogx_mmlux_et-business_ethics"
    },
    "ogx_mmlux_et-astronomy": {
      "acc,none": 0.5789473684210527,
      "acc_stderr,none": 0.040179012759817494,
      "alias": "ogx_mmlux_et-astronomy"
    },
    "ogx_mmlux_et-anatomy": {
      "acc,none": 0.362962962962963,
      "acc_stderr,none": 0.04153948404742398,
      "alias": "ogx_mmlux_et-anatomy"
    },
    "ogx_mmlux_et-abstract_algebra": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_et-abstract_algebra"
    },
    "ogx_mmlux_es-world_religions": {
      "acc,none": 0.7777777777777778,
      "acc_stderr,none": 0.03188578017686398,
      "alias": "ogx_mmlux_es-world_religions"
    },
    "ogx_mmlux_es-virology": {
      "acc,none": 0.5060240963855421,
      "acc_stderr,none": 0.038922121953330446,
      "alias": "ogx_mmlux_es-virology"
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "acc,none": 0.84,
      "acc_stderr,none": 0.03684529491774708,
      "alias": "ogx_mmlux_es-us_foreign_policy"
    },
    "ogx_mmlux_es-sociology": {
      "acc,none": 0.8208955223880597,
      "acc_stderr,none": 0.027113286753111837,
      "alias": "ogx_mmlux_es-sociology"
    },
    "ogx_mmlux_es-security_studies": {
      "acc,none": 0.7020408163265306,
      "acc_stderr,none": 0.029279567411065688,
      "alias": "ogx_mmlux_es-security_studies"
    },
    "ogx_mmlux_es-public_relations": {
      "acc,none": 0.6909090909090909,
      "acc_stderr,none": 0.044262946482000985,
      "alias": "ogx_mmlux_es-public_relations"
    },
    "ogx_mmlux_es-professional_psychology": {
      "acc,none": 0.6127450980392157,
      "acc_stderr,none": 0.019706875804085627,
      "alias": "ogx_mmlux_es-professional_psychology"
    },
    "ogx_mmlux_es-professional_medicine": {
      "acc,none": 0.5625,
      "acc_stderr,none": 0.030134614954403924,
      "alias": "ogx_mmlux_es-professional_medicine"
    },
    "ogx_mmlux_es-professional_law": {
      "acc,none": 0.4230769230769231,
      "acc_stderr,none": 0.012618204066588397,
      "alias": "ogx_mmlux_es-professional_law"
    },
    "ogx_mmlux_es-professional_accounting": {
      "acc,none": 0.40070921985815605,
      "acc_stderr,none": 0.029233465745573083,
      "alias": "ogx_mmlux_es-professional_accounting"
    },
    "ogx_mmlux_es-prehistory": {
      "acc,none": 0.7037037037037037,
      "acc_stderr,none": 0.025407197798890155,
      "alias": "ogx_mmlux_es-prehistory"
    },
    "ogx_mmlux_es-philosophy": {
      "acc,none": 0.6945337620578779,
      "acc_stderr,none": 0.026160584450140453,
      "alias": "ogx_mmlux_es-philosophy"
    },
    "ogx_mmlux_es-nutrition": {
      "acc,none": 0.6862745098039216,
      "acc_stderr,none": 0.026568921015457138,
      "alias": "ogx_mmlux_es-nutrition"
    },
    "ogx_mmlux_es-moral_scenarios": {
      "acc,none": 0.32513966480446926,
      "acc_stderr,none": 0.01566654278505357,
      "alias": "ogx_mmlux_es-moral_scenarios"
    },
    "ogx_mmlux_es-moral_disputes": {
      "acc,none": 0.6589595375722543,
      "acc_stderr,none": 0.025522474632121615,
      "alias": "ogx_mmlux_es-moral_disputes"
    },
    "ogx_mmlux_es-miscellaneous": {
      "acc,none": 0.7445721583652618,
      "acc_stderr,none": 0.015594955384455777,
      "alias": "ogx_mmlux_es-miscellaneous"
    },
    "ogx_mmlux_es-medical_genetics": {
      "acc,none": 0.72,
      "acc_stderr,none": 0.045126085985421296,
      "alias": "ogx_mmlux_es-medical_genetics"
    },
    "ogx_mmlux_es-marketing": {
      "acc,none": 0.8034188034188035,
      "acc_stderr,none": 0.02603538609895129,
      "alias": "ogx_mmlux_es-marketing"
    },
    "ogx_mmlux_es-management": {
      "acc,none": 0.7572815533980582,
      "acc_stderr,none": 0.04245022486384495,
      "alias": "ogx_mmlux_es-management"
    },
    "ogx_mmlux_es-machine_learning": {
      "acc,none": 0.3482142857142857,
      "acc_stderr,none": 0.04521829902833586,
      "alias": "ogx_mmlux_es-machine_learning"
    },
    "ogx_mmlux_es-logical_fallacies": {
      "acc,none": 0.7177914110429447,
      "acc_stderr,none": 0.03536117886664742,
      "alias": "ogx_mmlux_es-logical_fallacies"
    },
    "ogx_mmlux_es-jurisprudence": {
      "acc,none": 0.7314814814814815,
      "acc_stderr,none": 0.042844679680521934,
      "alias": "ogx_mmlux_es-jurisprudence"
    },
    "ogx_mmlux_es-international_law": {
      "acc,none": 0.743801652892562,
      "acc_stderr,none": 0.03984979653302872,
      "alias": "ogx_mmlux_es-international_law"
    },
    "ogx_mmlux_es-human_sexuality": {
      "acc,none": 0.7022900763358778,
      "acc_stderr,none": 0.04010358942462202,
      "alias": "ogx_mmlux_es-human_sexuality"
    },
    "ogx_mmlux_es-human_aging": {
      "acc,none": 0.6502242152466368,
      "acc_stderr,none": 0.03200736719484503,
      "alias": "ogx_mmlux_es-human_aging"
    },
    "ogx_mmlux_es-high_school_world_history": {
      "acc,none": 0.7510548523206751,
      "acc_stderr,none": 0.028146970599422647,
      "alias": "ogx_mmlux_es-high_school_world_history"
    },
    "ogx_mmlux_es-high_school_us_history": {
      "acc,none": 0.7647058823529411,
      "acc_stderr,none": 0.02977177522814565,
      "alias": "ogx_mmlux_es-high_school_us_history"
    },
    "ogx_mmlux_es-high_school_statistics": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.034099716973523674,
      "alias": "ogx_mmlux_es-high_school_statistics"
    },
    "ogx_mmlux_es-high_school_psychology": {
      "acc,none": 0.7669724770642202,
      "acc_stderr,none": 0.0181256691808615,
      "alias": "ogx_mmlux_es-high_school_psychology"
    },
    "ogx_mmlux_es-high_school_physics": {
      "acc,none": 0.39072847682119205,
      "acc_stderr,none": 0.03983798306659806,
      "alias": "ogx_mmlux_es-high_school_physics"
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "acc,none": 0.6302521008403361,
      "acc_stderr,none": 0.03135709599613591,
      "alias": "ogx_mmlux_es-high_school_microeconomics"
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.02986960509531691,
      "alias": "ogx_mmlux_es-high_school_mathematics"
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "acc,none": 0.5871794871794872,
      "acc_stderr,none": 0.024962683564331813,
      "alias": "ogx_mmlux_es-high_school_macroeconomics"
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "acc,none": 0.7875647668393783,
      "acc_stderr,none": 0.029519282616817234,
      "alias": "ogx_mmlux_es-high_school_government_and_politics"
    },
    "ogx_mmlux_es-high_school_geography": {
      "acc,none": 0.7929292929292929,
      "acc_stderr,none": 0.02886977846026705,
      "alias": "ogx_mmlux_es-high_school_geography"
    },
    "ogx_mmlux_es-high_school_european_history": {
      "acc,none": 0.7454545454545455,
      "acc_stderr,none": 0.0340150671524904,
      "alias": "ogx_mmlux_es-high_school_european_history"
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "acc,none": 0.68,
      "acc_stderr,none": 0.046882617226215034,
      "alias": "ogx_mmlux_es-high_school_computer_science"
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "acc,none": 0.4876847290640394,
      "acc_stderr,none": 0.035169204442208966,
      "alias": "ogx_mmlux_es-high_school_chemistry"
    },
    "ogx_mmlux_es-high_school_biology": {
      "acc,none": 0.7451612903225806,
      "acc_stderr,none": 0.024790118459332208,
      "alias": "ogx_mmlux_es-high_school_biology"
    },
    "ogx_mmlux_es-global_facts": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_es-global_facts"
    },
    "ogx_mmlux_es-formal_logic": {
      "acc,none": 0.4523809523809524,
      "acc_stderr,none": 0.044518079590553275,
      "alias": "ogx_mmlux_es-formal_logic"
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "acc,none": 0.4126984126984127,
      "acc_stderr,none": 0.02535574126305528,
      "alias": "ogx_mmlux_es-elementary_mathematics"
    },
    "ogx_mmlux_es-electrical_engineering": {
      "acc,none": 0.6206896551724138,
      "acc_stderr,none": 0.04043461861916747,
      "alias": "ogx_mmlux_es-electrical_engineering"
    },
    "ogx_mmlux_es-econometrics": {
      "acc,none": 0.40350877192982454,
      "acc_stderr,none": 0.046151869625837026,
      "alias": "ogx_mmlux_es-econometrics"
    },
    "ogx_mmlux_es-conceptual_physics": {
      "acc,none": 0.574468085106383,
      "acc_stderr,none": 0.03232146916224469,
      "alias": "ogx_mmlux_es-conceptual_physics"
    },
    "ogx_mmlux_es-computer_security": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_es-computer_security"
    },
    "ogx_mmlux_es-college_physics": {
      "acc,none": 0.3235294117647059,
      "acc_stderr,none": 0.046550104113196177,
      "alias": "ogx_mmlux_es-college_physics"
    },
    "ogx_mmlux_es-college_medicine": {
      "acc,none": 0.5664739884393064,
      "acc_stderr,none": 0.03778621079092056,
      "alias": "ogx_mmlux_es-college_medicine"
    },
    "ogx_mmlux_es-college_mathematics": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_es-college_mathematics"
    },
    "ogx_mmlux_es-college_computer_science": {
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605,
      "alias": "ogx_mmlux_es-college_computer_science"
    },
    "ogx_mmlux_es-college_chemistry": {
      "acc,none": 0.38,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_es-college_chemistry"
    },
    "ogx_mmlux_es-college_biology": {
      "acc,none": 0.6458333333333334,
      "acc_stderr,none": 0.039994111357535424,
      "alias": "ogx_mmlux_es-college_biology"
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "acc,none": 0.6264150943396226,
      "acc_stderr,none": 0.029773082713319875,
      "alias": "ogx_mmlux_es-clinical_knowledge"
    },
    "ogx_mmlux_es-business_ethics": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_es-business_ethics"
    },
    "ogx_mmlux_es-astronomy": {
      "acc,none": 0.6644736842105263,
      "acc_stderr,none": 0.03842498559395268,
      "alias": "ogx_mmlux_es-astronomy"
    },
    "ogx_mmlux_es-anatomy": {
      "acc,none": 0.5703703703703704,
      "acc_stderr,none": 0.04276349494376599,
      "alias": "ogx_mmlux_es-anatomy"
    },
    "ogx_mmlux_es-abstract_algebra": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252605,
      "alias": "ogx_mmlux_es-abstract_algebra"
    },
    "ogx_mmlux_el-world_religions": {
      "acc,none": 0.631578947368421,
      "acc_stderr,none": 0.036996580176568775,
      "alias": "ogx_mmlux_el-world_religions"
    },
    "ogx_mmlux_el-virology": {
      "acc,none": 0.42771084337349397,
      "acc_stderr,none": 0.038515976837185335,
      "alias": "ogx_mmlux_el-virology"
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "acc,none": 0.72,
      "acc_stderr,none": 0.04512608598542127,
      "alias": "ogx_mmlux_el-us_foreign_policy"
    },
    "ogx_mmlux_el-sociology": {
      "acc,none": 0.6965174129353234,
      "acc_stderr,none": 0.03251006816458618,
      "alias": "ogx_mmlux_el-sociology"
    },
    "ogx_mmlux_el-security_studies": {
      "acc,none": 0.636734693877551,
      "acc_stderr,none": 0.030789051139030806,
      "alias": "ogx_mmlux_el-security_studies"
    },
    "ogx_mmlux_el-public_relations": {
      "acc,none": 0.5545454545454546,
      "acc_stderr,none": 0.047605488214603246,
      "alias": "ogx_mmlux_el-public_relations"
    },
    "ogx_mmlux_el-professional_psychology": {
      "acc,none": 0.47058823529411764,
      "acc_stderr,none": 0.020192808271433795,
      "alias": "ogx_mmlux_el-professional_psychology"
    },
    "ogx_mmlux_el-professional_medicine": {
      "acc,none": 0.47794117647058826,
      "acc_stderr,none": 0.03034326422421352,
      "alias": "ogx_mmlux_el-professional_medicine"
    },
    "ogx_mmlux_el-professional_law": {
      "acc,none": 0.36571056062581486,
      "acc_stderr,none": 0.012301028188840568,
      "alias": "ogx_mmlux_el-professional_law"
    },
    "ogx_mmlux_el-professional_accounting": {
      "acc,none": 0.3900709219858156,
      "acc_stderr,none": 0.029097675599463933,
      "alias": "ogx_mmlux_el-professional_accounting"
    },
    "ogx_mmlux_el-prehistory": {
      "acc,none": 0.5246913580246914,
      "acc_stderr,none": 0.02778680093142745,
      "alias": "ogx_mmlux_el-prehistory"
    },
    "ogx_mmlux_el-philosophy": {
      "acc,none": 0.5980707395498392,
      "acc_stderr,none": 0.027846476005930477,
      "alias": "ogx_mmlux_el-philosophy"
    },
    "ogx_mmlux_el-nutrition": {
      "acc,none": 0.5947712418300654,
      "acc_stderr,none": 0.028110928492809068,
      "alias": "ogx_mmlux_el-nutrition"
    },
    "ogx_mmlux_el-moral_scenarios": {
      "acc,none": 0.2446927374301676,
      "acc_stderr,none": 0.01437816988409842,
      "alias": "ogx_mmlux_el-moral_scenarios"
    },
    "ogx_mmlux_el-moral_disputes": {
      "acc,none": 0.569364161849711,
      "acc_stderr,none": 0.026658800273672376,
      "alias": "ogx_mmlux_el-moral_disputes"
    },
    "ogx_mmlux_el-miscellaneous": {
      "acc,none": 0.6079182630906769,
      "acc_stderr,none": 0.017458524050147636,
      "alias": "ogx_mmlux_el-miscellaneous"
    },
    "ogx_mmlux_el-medical_genetics": {
      "acc,none": 0.55,
      "acc_stderr,none": 0.05,
      "alias": "ogx_mmlux_el-medical_genetics"
    },
    "ogx_mmlux_el-marketing": {
      "acc,none": 0.782051282051282,
      "acc_stderr,none": 0.02704685763071666,
      "alias": "ogx_mmlux_el-marketing"
    },
    "ogx_mmlux_el-management": {
      "acc,none": 0.6407766990291263,
      "acc_stderr,none": 0.047504583990416946,
      "alias": "ogx_mmlux_el-management"
    },
    "ogx_mmlux_el-machine_learning": {
      "acc,none": 0.4375,
      "acc_stderr,none": 0.04708567521880525,
      "alias": "ogx_mmlux_el-machine_learning"
    },
    "ogx_mmlux_el-logical_fallacies": {
      "acc,none": 0.588957055214724,
      "acc_stderr,none": 0.038656978537853624,
      "alias": "ogx_mmlux_el-logical_fallacies"
    },
    "ogx_mmlux_el-jurisprudence": {
      "acc,none": 0.6574074074074074,
      "acc_stderr,none": 0.045879047413018105,
      "alias": "ogx_mmlux_el-jurisprudence"
    },
    "ogx_mmlux_el-international_law": {
      "acc,none": 0.71900826446281,
      "acc_stderr,none": 0.04103203830514512,
      "alias": "ogx_mmlux_el-international_law"
    },
    "ogx_mmlux_el-human_sexuality": {
      "acc,none": 0.5801526717557252,
      "acc_stderr,none": 0.043285772152629735,
      "alias": "ogx_mmlux_el-human_sexuality"
    },
    "ogx_mmlux_el-human_aging": {
      "acc,none": 0.547085201793722,
      "acc_stderr,none": 0.033408675019233246,
      "alias": "ogx_mmlux_el-human_aging"
    },
    "ogx_mmlux_el-high_school_world_history": {
      "acc,none": 0.6877637130801688,
      "acc_stderr,none": 0.030165137867847008,
      "alias": "ogx_mmlux_el-high_school_world_history"
    },
    "ogx_mmlux_el-high_school_us_history": {
      "acc,none": 0.6568627450980392,
      "acc_stderr,none": 0.033321399446680854,
      "alias": "ogx_mmlux_el-high_school_us_history"
    },
    "ogx_mmlux_el-high_school_statistics": {
      "acc,none": 0.4444444444444444,
      "acc_stderr,none": 0.03388857118502325,
      "alias": "ogx_mmlux_el-high_school_statistics"
    },
    "ogx_mmlux_el-high_school_psychology": {
      "acc,none": 0.5908256880733945,
      "acc_stderr,none": 0.021080670264433735,
      "alias": "ogx_mmlux_el-high_school_psychology"
    },
    "ogx_mmlux_el-high_school_physics": {
      "acc,none": 0.32450331125827814,
      "acc_stderr,none": 0.03822746937658752,
      "alias": "ogx_mmlux_el-high_school_physics"
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "acc,none": 0.5672268907563025,
      "acc_stderr,none": 0.03218358107742613,
      "alias": "ogx_mmlux_el-high_school_microeconomics"
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "acc,none": 0.362962962962963,
      "acc_stderr,none": 0.02931820364520686,
      "alias": "ogx_mmlux_el-high_school_mathematics"
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "acc,none": 0.4666666666666667,
      "acc_stderr,none": 0.025294608023986465,
      "alias": "ogx_mmlux_el-high_school_macroeconomics"
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "acc,none": 0.6113989637305699,
      "acc_stderr,none": 0.03517739796373132,
      "alias": "ogx_mmlux_el-high_school_government_and_politics"
    },
    "ogx_mmlux_el-high_school_geography": {
      "acc,none": 0.6666666666666666,
      "acc_stderr,none": 0.033586181457325226,
      "alias": "ogx_mmlux_el-high_school_geography"
    },
    "ogx_mmlux_el-high_school_european_history": {
      "acc,none": 0.6909090909090909,
      "acc_stderr,none": 0.036085410115739666,
      "alias": "ogx_mmlux_el-high_school_european_history"
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "acc,none": 0.61,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_el-high_school_computer_science"
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "acc,none": 0.4187192118226601,
      "acc_stderr,none": 0.03471192860518468,
      "alias": "ogx_mmlux_el-high_school_chemistry"
    },
    "ogx_mmlux_el-high_school_biology": {
      "acc,none": 0.5645161290322581,
      "acc_stderr,none": 0.028206225591502737,
      "alias": "ogx_mmlux_el-high_school_biology"
    },
    "ogx_mmlux_el-global_facts": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_el-global_facts"
    },
    "ogx_mmlux_el-formal_logic": {
      "acc,none": 0.3968253968253968,
      "acc_stderr,none": 0.0437588849272706,
      "alias": "ogx_mmlux_el-formal_logic"
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "acc,none": 0.373015873015873,
      "acc_stderr,none": 0.02490699045899257,
      "alias": "ogx_mmlux_el-elementary_mathematics"
    },
    "ogx_mmlux_el-electrical_engineering": {
      "acc,none": 0.5241379310344828,
      "acc_stderr,none": 0.041618085035015295,
      "alias": "ogx_mmlux_el-electrical_engineering"
    },
    "ogx_mmlux_el-econometrics": {
      "acc,none": 0.34210526315789475,
      "acc_stderr,none": 0.04462917535336938,
      "alias": "ogx_mmlux_el-econometrics"
    },
    "ogx_mmlux_el-conceptual_physics": {
      "acc,none": 0.4085106382978723,
      "acc_stderr,none": 0.03213418026701576,
      "alias": "ogx_mmlux_el-conceptual_physics"
    },
    "ogx_mmlux_el-computer_security": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.048523658709391,
      "alias": "ogx_mmlux_el-computer_security"
    },
    "ogx_mmlux_el-college_physics": {
      "acc,none": 0.29411764705882354,
      "acc_stderr,none": 0.045338381959297736,
      "alias": "ogx_mmlux_el-college_physics"
    },
    "ogx_mmlux_el-college_medicine": {
      "acc,none": 0.43352601156069365,
      "acc_stderr,none": 0.037786210790920545,
      "alias": "ogx_mmlux_el-college_medicine"
    },
    "ogx_mmlux_el-college_mathematics": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.047258156262526045,
      "alias": "ogx_mmlux_el-college_mathematics"
    },
    "ogx_mmlux_el-college_computer_science": {
      "acc,none": 0.36,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_el-college_computer_science"
    },
    "ogx_mmlux_el-college_chemistry": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.047937248544110196,
      "alias": "ogx_mmlux_el-college_chemistry"
    },
    "ogx_mmlux_el-college_biology": {
      "acc,none": 0.4722222222222222,
      "acc_stderr,none": 0.04174752578923185,
      "alias": "ogx_mmlux_el-college_biology"
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "acc,none": 0.5245283018867924,
      "acc_stderr,none": 0.030735822206205608,
      "alias": "ogx_mmlux_el-clinical_knowledge"
    },
    "ogx_mmlux_el-business_ethics": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237101,
      "alias": "ogx_mmlux_el-business_ethics"
    },
    "ogx_mmlux_el-astronomy": {
      "acc,none": 0.5328947368421053,
      "acc_stderr,none": 0.040601270352363966,
      "alias": "ogx_mmlux_el-astronomy"
    },
    "ogx_mmlux_el-anatomy": {
      "acc,none": 0.4148148148148148,
      "acc_stderr,none": 0.04256193767901407,
      "alias": "ogx_mmlux_el-anatomy"
    },
    "ogx_mmlux_el-abstract_algebra": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.04512608598542128,
      "alias": "ogx_mmlux_el-abstract_algebra"
    },
    "ogx_mmlux_de-world_religions": {
      "acc,none": 0.7894736842105263,
      "acc_stderr,none": 0.0312678171466318,
      "alias": "ogx_mmlux_de-world_religions"
    },
    "ogx_mmlux_de-virology": {
      "acc,none": 0.4939759036144578,
      "acc_stderr,none": 0.03892212195333045,
      "alias": "ogx_mmlux_de-virology"
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "acc,none": 0.77,
      "acc_stderr,none": 0.042295258468165065,
      "alias": "ogx_mmlux_de-us_foreign_policy"
    },
    "ogx_mmlux_de-sociology": {
      "acc,none": 0.8258706467661692,
      "acc_stderr,none": 0.026814951200421603,
      "alias": "ogx_mmlux_de-sociology"
    },
    "ogx_mmlux_de-security_studies": {
      "acc,none": 0.689795918367347,
      "acc_stderr,none": 0.029613459872484378,
      "alias": "ogx_mmlux_de-security_studies"
    },
    "ogx_mmlux_de-public_relations": {
      "acc,none": 0.6363636363636364,
      "acc_stderr,none": 0.04607582090719976,
      "alias": "ogx_mmlux_de-public_relations"
    },
    "ogx_mmlux_de-professional_psychology": {
      "acc,none": 0.6143790849673203,
      "acc_stderr,none": 0.019691459052354043,
      "alias": "ogx_mmlux_de-professional_psychology"
    },
    "ogx_mmlux_de-professional_medicine": {
      "acc,none": 0.5441176470588235,
      "acc_stderr,none": 0.030254372573976725,
      "alias": "ogx_mmlux_de-professional_medicine"
    },
    "ogx_mmlux_de-professional_law": {
      "acc,none": 0.409387222946545,
      "acc_stderr,none": 0.012558780895570755,
      "alias": "ogx_mmlux_de-professional_law"
    },
    "ogx_mmlux_de-professional_accounting": {
      "acc,none": 0.4326241134751773,
      "acc_stderr,none": 0.02955545423677885,
      "alias": "ogx_mmlux_de-professional_accounting"
    },
    "ogx_mmlux_de-prehistory": {
      "acc,none": 0.6574074074074074,
      "acc_stderr,none": 0.02640614597362568,
      "alias": "ogx_mmlux_de-prehistory"
    },
    "ogx_mmlux_de-philosophy": {
      "acc,none": 0.6720257234726688,
      "acc_stderr,none": 0.026664410886937606,
      "alias": "ogx_mmlux_de-philosophy"
    },
    "ogx_mmlux_de-nutrition": {
      "acc,none": 0.6895424836601307,
      "acc_stderr,none": 0.026493033225145894,
      "alias": "ogx_mmlux_de-nutrition"
    },
    "ogx_mmlux_de-moral_scenarios": {
      "acc,none": 0.33631284916201115,
      "acc_stderr,none": 0.01580100372914589,
      "alias": "ogx_mmlux_de-moral_scenarios"
    },
    "ogx_mmlux_de-moral_disputes": {
      "acc,none": 0.6676300578034682,
      "acc_stderr,none": 0.025361168749688228,
      "alias": "ogx_mmlux_de-moral_disputes"
    },
    "ogx_mmlux_de-miscellaneous": {
      "acc,none": 0.7241379310344828,
      "acc_stderr,none": 0.015982814774695625,
      "alias": "ogx_mmlux_de-miscellaneous"
    },
    "ogx_mmlux_de-medical_genetics": {
      "acc,none": 0.71,
      "acc_stderr,none": 0.045604802157206845,
      "alias": "ogx_mmlux_de-medical_genetics"
    },
    "ogx_mmlux_de-marketing": {
      "acc,none": 0.7863247863247863,
      "acc_stderr,none": 0.026853450377009137,
      "alias": "ogx_mmlux_de-marketing"
    },
    "ogx_mmlux_de-management": {
      "acc,none": 0.7572815533980582,
      "acc_stderr,none": 0.04245022486384495,
      "alias": "ogx_mmlux_de-management"
    },
    "ogx_mmlux_de-machine_learning": {
      "acc,none": 0.4017857142857143,
      "acc_stderr,none": 0.04653333146973647,
      "alias": "ogx_mmlux_de-machine_learning"
    },
    "ogx_mmlux_de-logical_fallacies": {
      "acc,none": 0.6993865030674846,
      "acc_stderr,none": 0.03602511318806771,
      "alias": "ogx_mmlux_de-logical_fallacies"
    },
    "ogx_mmlux_de-jurisprudence": {
      "acc,none": 0.7037037037037037,
      "acc_stderr,none": 0.044143436668549335,
      "alias": "ogx_mmlux_de-jurisprudence"
    },
    "ogx_mmlux_de-international_law": {
      "acc,none": 0.6942148760330579,
      "acc_stderr,none": 0.04205953933884124,
      "alias": "ogx_mmlux_de-international_law"
    },
    "ogx_mmlux_de-human_sexuality": {
      "acc,none": 0.6793893129770993,
      "acc_stderr,none": 0.04093329229834278,
      "alias": "ogx_mmlux_de-human_sexuality"
    },
    "ogx_mmlux_de-human_aging": {
      "acc,none": 0.5874439461883408,
      "acc_stderr,none": 0.03304062175449297,
      "alias": "ogx_mmlux_de-human_aging"
    },
    "ogx_mmlux_de-high_school_world_history": {
      "acc,none": 0.7468354430379747,
      "acc_stderr,none": 0.028304657943035286,
      "alias": "ogx_mmlux_de-high_school_world_history"
    },
    "ogx_mmlux_de-high_school_us_history": {
      "acc,none": 0.7549019607843137,
      "acc_stderr,none": 0.030190282453501933,
      "alias": "ogx_mmlux_de-high_school_us_history"
    },
    "ogx_mmlux_de-high_school_statistics": {
      "acc,none": 0.44907407407407407,
      "acc_stderr,none": 0.03392238405321617,
      "alias": "ogx_mmlux_de-high_school_statistics"
    },
    "ogx_mmlux_de-high_school_psychology": {
      "acc,none": 0.7394495412844037,
      "acc_stderr,none": 0.01881918203485007,
      "alias": "ogx_mmlux_de-high_school_psychology"
    },
    "ogx_mmlux_de-high_school_physics": {
      "acc,none": 0.3973509933774834,
      "acc_stderr,none": 0.039955240076816806,
      "alias": "ogx_mmlux_de-high_school_physics"
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "acc,none": 0.6134453781512605,
      "acc_stderr,none": 0.03163145807552378,
      "alias": "ogx_mmlux_de-high_school_microeconomics"
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.029723278961476664,
      "alias": "ogx_mmlux_de-high_school_mathematics"
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "acc,none": 0.5615384615384615,
      "acc_stderr,none": 0.025158266016868568,
      "alias": "ogx_mmlux_de-high_school_macroeconomics"
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "acc,none": 0.7461139896373057,
      "acc_stderr,none": 0.03141024780565319,
      "alias": "ogx_mmlux_de-high_school_government_and_politics"
    },
    "ogx_mmlux_de-high_school_geography": {
      "acc,none": 0.7727272727272727,
      "acc_stderr,none": 0.02985751567338641,
      "alias": "ogx_mmlux_de-high_school_geography"
    },
    "ogx_mmlux_de-high_school_european_history": {
      "acc,none": 0.806060606060606,
      "acc_stderr,none": 0.0308741451365621,
      "alias": "ogx_mmlux_de-high_school_european_history"
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "acc,none": 0.6,
      "acc_stderr,none": 0.04923659639173309,
      "alias": "ogx_mmlux_de-high_school_computer_science"
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "acc,none": 0.5172413793103449,
      "acc_stderr,none": 0.035158955511656986,
      "alias": "ogx_mmlux_de-high_school_chemistry"
    },
    "ogx_mmlux_de-high_school_biology": {
      "acc,none": 0.7096774193548387,
      "acc_stderr,none": 0.025822106119415898,
      "alias": "ogx_mmlux_de-high_school_biology"
    },
    "ogx_mmlux_de-global_facts": {
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084,
      "alias": "ogx_mmlux_de-global_facts"
    },
    "ogx_mmlux_de-formal_logic": {
      "acc,none": 0.373015873015873,
      "acc_stderr,none": 0.04325506042017086,
      "alias": "ogx_mmlux_de-formal_logic"
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.025107425481137303,
      "alias": "ogx_mmlux_de-elementary_mathematics"
    },
    "ogx_mmlux_de-electrical_engineering": {
      "acc,none": 0.6344827586206897,
      "acc_stderr,none": 0.040131241954243856,
      "alias": "ogx_mmlux_de-electrical_engineering"
    },
    "ogx_mmlux_de-econometrics": {
      "acc,none": 0.40350877192982454,
      "acc_stderr,none": 0.04615186962583704,
      "alias": "ogx_mmlux_de-econometrics"
    },
    "ogx_mmlux_de-conceptual_physics": {
      "acc,none": 0.5063829787234042,
      "acc_stderr,none": 0.032683358999363366,
      "alias": "ogx_mmlux_de-conceptual_physics"
    },
    "ogx_mmlux_de-computer_security": {
      "acc,none": 0.77,
      "acc_stderr,none": 0.042295258468165065,
      "alias": "ogx_mmlux_de-computer_security"
    },
    "ogx_mmlux_de-college_physics": {
      "acc,none": 0.3137254901960784,
      "acc_stderr,none": 0.04617034827006718,
      "alias": "ogx_mmlux_de-college_physics"
    },
    "ogx_mmlux_de-college_medicine": {
      "acc,none": 0.5491329479768786,
      "acc_stderr,none": 0.03794012674697032,
      "alias": "ogx_mmlux_de-college_medicine"
    },
    "ogx_mmlux_de-college_mathematics": {
      "acc,none": 0.3,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_de-college_mathematics"
    },
    "ogx_mmlux_de-college_computer_science": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.04960449637488584,
      "alias": "ogx_mmlux_de-college_computer_science"
    },
    "ogx_mmlux_de-college_chemistry": {
      "acc,none": 0.41,
      "acc_stderr,none": 0.049431107042371025,
      "alias": "ogx_mmlux_de-college_chemistry"
    },
    "ogx_mmlux_de-college_biology": {
      "acc,none": 0.6458333333333334,
      "acc_stderr,none": 0.039994111357535424,
      "alias": "ogx_mmlux_de-college_biology"
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "acc,none": 0.6377358490566037,
      "acc_stderr,none": 0.0295822451283843,
      "alias": "ogx_mmlux_de-clinical_knowledge"
    },
    "ogx_mmlux_de-business_ethics": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_de-business_ethics"
    },
    "ogx_mmlux_de-astronomy": {
      "acc,none": 0.6776315789473685,
      "acc_stderr,none": 0.03803510248351585,
      "alias": "ogx_mmlux_de-astronomy"
    },
    "ogx_mmlux_de-anatomy": {
      "acc,none": 0.5777777777777777,
      "acc_stderr,none": 0.04266763404099582,
      "alias": "ogx_mmlux_de-anatomy"
    },
    "ogx_mmlux_de-abstract_algebra": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_de-abstract_algebra"
    },
    "ogx_mmlux_da-world_religions": {
      "acc,none": 0.7134502923976608,
      "acc_stderr,none": 0.03467826685703826,
      "alias": "ogx_mmlux_da-world_religions"
    },
    "ogx_mmlux_da-virology": {
      "acc,none": 0.4939759036144578,
      "acc_stderr,none": 0.03892212195333045,
      "alias": "ogx_mmlux_da-virology"
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "acc,none": 0.81,
      "acc_stderr,none": 0.03942772444036623,
      "alias": "ogx_mmlux_da-us_foreign_policy"
    },
    "ogx_mmlux_da-sociology": {
      "acc,none": 0.7810945273631841,
      "acc_stderr,none": 0.029239174636647,
      "alias": "ogx_mmlux_da-sociology"
    },
    "ogx_mmlux_da-security_studies": {
      "acc,none": 0.6244897959183674,
      "acc_stderr,none": 0.03100120903989484,
      "alias": "ogx_mmlux_da-security_studies"
    },
    "ogx_mmlux_da-public_relations": {
      "acc,none": 0.6272727272727273,
      "acc_stderr,none": 0.04631381319425464,
      "alias": "ogx_mmlux_da-public_relations"
    },
    "ogx_mmlux_da-professional_psychology": {
      "acc,none": 0.565359477124183,
      "acc_stderr,none": 0.02005426920072646,
      "alias": "ogx_mmlux_da-professional_psychology"
    },
    "ogx_mmlux_da-professional_medicine": {
      "acc,none": 0.5220588235294118,
      "acc_stderr,none": 0.030343264224213514,
      "alias": "ogx_mmlux_da-professional_medicine"
    },
    "ogx_mmlux_da-professional_law": {
      "acc,none": 0.3898305084745763,
      "acc_stderr,none": 0.012456386619082603,
      "alias": "ogx_mmlux_da-professional_law"
    },
    "ogx_mmlux_da-professional_accounting": {
      "acc,none": 0.3829787234042553,
      "acc_stderr,none": 0.02899908090480618,
      "alias": "ogx_mmlux_da-professional_accounting"
    },
    "ogx_mmlux_da-prehistory": {
      "acc,none": 0.6728395061728395,
      "acc_stderr,none": 0.026105673861409818,
      "alias": "ogx_mmlux_da-prehistory"
    },
    "ogx_mmlux_da-philosophy": {
      "acc,none": 0.6109324758842444,
      "acc_stderr,none": 0.027690337536485376,
      "alias": "ogx_mmlux_da-philosophy"
    },
    "ogx_mmlux_da-nutrition": {
      "acc,none": 0.6633986928104575,
      "acc_stderr,none": 0.027057974624494382,
      "alias": "ogx_mmlux_da-nutrition"
    },
    "ogx_mmlux_da-moral_scenarios": {
      "acc,none": 0.3195530726256983,
      "acc_stderr,none": 0.015595520294147396,
      "alias": "ogx_mmlux_da-moral_scenarios"
    },
    "ogx_mmlux_da-moral_disputes": {
      "acc,none": 0.6184971098265896,
      "acc_stderr,none": 0.0261521986197268,
      "alias": "ogx_mmlux_da-moral_disputes"
    },
    "ogx_mmlux_da-miscellaneous": {
      "acc,none": 0.6845466155810983,
      "acc_stderr,none": 0.016617501738763394,
      "alias": "ogx_mmlux_da-miscellaneous"
    },
    "ogx_mmlux_da-medical_genetics": {
      "acc,none": 0.72,
      "acc_stderr,none": 0.04512608598542128,
      "alias": "ogx_mmlux_da-medical_genetics"
    },
    "ogx_mmlux_da-marketing": {
      "acc,none": 0.7905982905982906,
      "acc_stderr,none": 0.026655699653922765,
      "alias": "ogx_mmlux_da-marketing"
    },
    "ogx_mmlux_da-management": {
      "acc,none": 0.7669902912621359,
      "acc_stderr,none": 0.04185832598928315,
      "alias": "ogx_mmlux_da-management"
    },
    "ogx_mmlux_da-machine_learning": {
      "acc,none": 0.4375,
      "acc_stderr,none": 0.04708567521880525,
      "alias": "ogx_mmlux_da-machine_learning"
    },
    "ogx_mmlux_da-logical_fallacies": {
      "acc,none": 0.6319018404907976,
      "acc_stderr,none": 0.03789213935838396,
      "alias": "ogx_mmlux_da-logical_fallacies"
    },
    "ogx_mmlux_da-jurisprudence": {
      "acc,none": 0.6851851851851852,
      "acc_stderr,none": 0.04489931073591312,
      "alias": "ogx_mmlux_da-jurisprudence"
    },
    "ogx_mmlux_da-international_law": {
      "acc,none": 0.6611570247933884,
      "acc_stderr,none": 0.043207678075366705,
      "alias": "ogx_mmlux_da-international_law"
    },
    "ogx_mmlux_da-human_sexuality": {
      "acc,none": 0.6717557251908397,
      "acc_stderr,none": 0.04118438565806298,
      "alias": "ogx_mmlux_da-human_sexuality"
    },
    "ogx_mmlux_da-human_aging": {
      "acc,none": 0.6053811659192825,
      "acc_stderr,none": 0.03280400504755291,
      "alias": "ogx_mmlux_da-human_aging"
    },
    "ogx_mmlux_da-high_school_world_history": {
      "acc,none": 0.7257383966244726,
      "acc_stderr,none": 0.02904133351059804,
      "alias": "ogx_mmlux_da-high_school_world_history"
    },
    "ogx_mmlux_da-high_school_us_history": {
      "acc,none": 0.7450980392156863,
      "acc_stderr,none": 0.030587591351604257,
      "alias": "ogx_mmlux_da-high_school_us_history"
    },
    "ogx_mmlux_da-high_school_statistics": {
      "acc,none": 0.4444444444444444,
      "acc_stderr,none": 0.03388857118502325,
      "alias": "ogx_mmlux_da-high_school_statistics"
    },
    "ogx_mmlux_da-high_school_psychology": {
      "acc,none": 0.6954128440366972,
      "acc_stderr,none": 0.01973229942035404,
      "alias": "ogx_mmlux_da-high_school_psychology"
    },
    "ogx_mmlux_da-high_school_physics": {
      "acc,none": 0.41721854304635764,
      "acc_stderr,none": 0.040261414976346104,
      "alias": "ogx_mmlux_da-high_school_physics"
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "acc,none": 0.5672268907563025,
      "acc_stderr,none": 0.032183581077426124,
      "alias": "ogx_mmlux_da-high_school_microeconomics"
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.029723278961476664,
      "alias": "ogx_mmlux_da-high_school_mathematics"
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "acc,none": 0.5230769230769231,
      "acc_stderr,none": 0.025323990861736232,
      "alias": "ogx_mmlux_da-high_school_macroeconomics"
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "acc,none": 0.6632124352331606,
      "acc_stderr,none": 0.03410780251836184,
      "alias": "ogx_mmlux_da-high_school_government_and_politics"
    },
    "ogx_mmlux_da-high_school_geography": {
      "acc,none": 0.696969696969697,
      "acc_stderr,none": 0.03274287914026867,
      "alias": "ogx_mmlux_da-high_school_geography"
    },
    "ogx_mmlux_da-high_school_european_history": {
      "acc,none": 0.7333333333333333,
      "acc_stderr,none": 0.03453131801885416,
      "alias": "ogx_mmlux_da-high_school_european_history"
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "acc,none": 0.64,
      "acc_stderr,none": 0.048241815132442176,
      "alias": "ogx_mmlux_da-high_school_computer_science"
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "acc,none": 0.4236453201970443,
      "acc_stderr,none": 0.03476725747649038,
      "alias": "ogx_mmlux_da-high_school_chemistry"
    },
    "ogx_mmlux_da-high_school_biology": {
      "acc,none": 0.6612903225806451,
      "acc_stderr,none": 0.026923446059302844,
      "alias": "ogx_mmlux_da-high_school_biology"
    },
    "ogx_mmlux_da-global_facts": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_da-global_facts"
    },
    "ogx_mmlux_da-formal_logic": {
      "acc,none": 0.3968253968253968,
      "acc_stderr,none": 0.0437588849272706,
      "alias": "ogx_mmlux_da-formal_logic"
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "acc,none": 0.41005291005291006,
      "acc_stderr,none": 0.025331202438944416,
      "alias": "ogx_mmlux_da-elementary_mathematics"
    },
    "ogx_mmlux_da-electrical_engineering": {
      "acc,none": 0.5862068965517241,
      "acc_stderr,none": 0.04104269211806232,
      "alias": "ogx_mmlux_da-electrical_engineering"
    },
    "ogx_mmlux_da-econometrics": {
      "acc,none": 0.39473684210526316,
      "acc_stderr,none": 0.04598188057816543,
      "alias": "ogx_mmlux_da-econometrics"
    },
    "ogx_mmlux_da-conceptual_physics": {
      "acc,none": 0.5063829787234042,
      "acc_stderr,none": 0.032683358999363366,
      "alias": "ogx_mmlux_da-conceptual_physics"
    },
    "ogx_mmlux_da-computer_security": {
      "acc,none": 0.74,
      "acc_stderr,none": 0.04408440022768078,
      "alias": "ogx_mmlux_da-computer_security"
    },
    "ogx_mmlux_da-college_physics": {
      "acc,none": 0.38235294117647056,
      "acc_stderr,none": 0.04835503696107224,
      "alias": "ogx_mmlux_da-college_physics"
    },
    "ogx_mmlux_da-college_medicine": {
      "acc,none": 0.5028901734104047,
      "acc_stderr,none": 0.03812400565974834,
      "alias": "ogx_mmlux_da-college_medicine"
    },
    "ogx_mmlux_da-college_mathematics": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.04688261722621504,
      "alias": "ogx_mmlux_da-college_mathematics"
    },
    "ogx_mmlux_da-college_computer_science": {
      "acc,none": 0.44,
      "acc_stderr,none": 0.049888765156985884,
      "alias": "ogx_mmlux_da-college_computer_science"
    },
    "ogx_mmlux_da-college_chemistry": {
      "acc,none": 0.42,
      "acc_stderr,none": 0.04960449637488583,
      "alias": "ogx_mmlux_da-college_chemistry"
    },
    "ogx_mmlux_da-college_biology": {
      "acc,none": 0.6111111111111112,
      "acc_stderr,none": 0.04076663253918567,
      "alias": "ogx_mmlux_da-college_biology"
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "acc,none": 0.5962264150943396,
      "acc_stderr,none": 0.03019761160019795,
      "alias": "ogx_mmlux_da-clinical_knowledge"
    },
    "ogx_mmlux_da-business_ethics": {
      "acc,none": 0.59,
      "acc_stderr,none": 0.04943110704237102,
      "alias": "ogx_mmlux_da-business_ethics"
    },
    "ogx_mmlux_da-astronomy": {
      "acc,none": 0.631578947368421,
      "acc_stderr,none": 0.039255233810529325,
      "alias": "ogx_mmlux_da-astronomy"
    },
    "ogx_mmlux_da-anatomy": {
      "acc,none": 0.5481481481481482,
      "acc_stderr,none": 0.04299268905480864,
      "alias": "ogx_mmlux_da-anatomy"
    },
    "ogx_mmlux_da-abstract_algebra": {
      "acc,none": 0.28,
      "acc_stderr,none": 0.045126085985421296,
      "alias": "ogx_mmlux_da-abstract_algebra"
    },
    "ogx_mmlux_cs-world_religions": {
      "acc,none": 0.7426900584795322,
      "acc_stderr,none": 0.03352799844161865,
      "alias": "ogx_mmlux_cs-world_religions"
    },
    "ogx_mmlux_cs-virology": {
      "acc,none": 0.4759036144578313,
      "acc_stderr,none": 0.03887971849597264,
      "alias": "ogx_mmlux_cs-virology"
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "acc,none": 0.76,
      "acc_stderr,none": 0.04292346959909282,
      "alias": "ogx_mmlux_cs-us_foreign_policy"
    },
    "ogx_mmlux_cs-sociology": {
      "acc,none": 0.7711442786069652,
      "acc_stderr,none": 0.029705284056772436,
      "alias": "ogx_mmlux_cs-sociology"
    },
    "ogx_mmlux_cs-security_studies": {
      "acc,none": 0.6244897959183674,
      "acc_stderr,none": 0.03100120903989484,
      "alias": "ogx_mmlux_cs-security_studies"
    },
    "ogx_mmlux_cs-public_relations": {
      "acc,none": 0.5909090909090909,
      "acc_stderr,none": 0.04709306978661895,
      "alias": "ogx_mmlux_cs-public_relations"
    },
    "ogx_mmlux_cs-professional_psychology": {
      "acc,none": 0.5375816993464052,
      "acc_stderr,none": 0.020170614974969768,
      "alias": "ogx_mmlux_cs-professional_psychology"
    },
    "ogx_mmlux_cs-professional_medicine": {
      "acc,none": 0.4852941176470588,
      "acc_stderr,none": 0.03035969707904611,
      "alias": "ogx_mmlux_cs-professional_medicine"
    },
    "ogx_mmlux_cs-professional_law": {
      "acc,none": 0.38722294654498046,
      "acc_stderr,none": 0.012441155326854924,
      "alias": "ogx_mmlux_cs-professional_law"
    },
    "ogx_mmlux_cs-professional_accounting": {
      "acc,none": 0.3971631205673759,
      "acc_stderr,none": 0.029189805673587105,
      "alias": "ogx_mmlux_cs-professional_accounting"
    },
    "ogx_mmlux_cs-prehistory": {
      "acc,none": 0.6018518518518519,
      "acc_stderr,none": 0.02723741509459248,
      "alias": "ogx_mmlux_cs-prehistory"
    },
    "ogx_mmlux_cs-philosophy": {
      "acc,none": 0.6109324758842444,
      "acc_stderr,none": 0.027690337536485372,
      "alias": "ogx_mmlux_cs-philosophy"
    },
    "ogx_mmlux_cs-nutrition": {
      "acc,none": 0.6633986928104575,
      "acc_stderr,none": 0.02705797462449438,
      "alias": "ogx_mmlux_cs-nutrition"
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "acc,none": 0.3675977653631285,
      "acc_stderr,none": 0.016125543823552944,
      "alias": "ogx_mmlux_cs-moral_scenarios"
    },
    "ogx_mmlux_cs-moral_disputes": {
      "acc,none": 0.615606936416185,
      "acc_stderr,none": 0.026189666966272035,
      "alias": "ogx_mmlux_cs-moral_disputes"
    },
    "ogx_mmlux_cs-miscellaneous": {
      "acc,none": 0.6960408684546615,
      "acc_stderr,none": 0.016448321686769046,
      "alias": "ogx_mmlux_cs-miscellaneous"
    },
    "ogx_mmlux_cs-medical_genetics": {
      "acc,none": 0.62,
      "acc_stderr,none": 0.048783173121456316,
      "alias": "ogx_mmlux_cs-medical_genetics"
    },
    "ogx_mmlux_cs-marketing": {
      "acc,none": 0.7692307692307693,
      "acc_stderr,none": 0.027601921381417618,
      "alias": "ogx_mmlux_cs-marketing"
    },
    "ogx_mmlux_cs-management": {
      "acc,none": 0.6893203883495146,
      "acc_stderr,none": 0.0458212416016155,
      "alias": "ogx_mmlux_cs-management"
    },
    "ogx_mmlux_cs-machine_learning": {
      "acc,none": 0.42857142857142855,
      "acc_stderr,none": 0.04697113923010213,
      "alias": "ogx_mmlux_cs-machine_learning"
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "acc,none": 0.6073619631901841,
      "acc_stderr,none": 0.03836740907831029,
      "alias": "ogx_mmlux_cs-logical_fallacies"
    },
    "ogx_mmlux_cs-jurisprudence": {
      "acc,none": 0.5833333333333334,
      "acc_stderr,none": 0.04766075165356461,
      "alias": "ogx_mmlux_cs-jurisprudence"
    },
    "ogx_mmlux_cs-international_law": {
      "acc,none": 0.7024793388429752,
      "acc_stderr,none": 0.04173349148083499,
      "alias": "ogx_mmlux_cs-international_law"
    },
    "ogx_mmlux_cs-human_sexuality": {
      "acc,none": 0.6946564885496184,
      "acc_stderr,none": 0.040393149787245626,
      "alias": "ogx_mmlux_cs-human_sexuality"
    },
    "ogx_mmlux_cs-human_aging": {
      "acc,none": 0.600896860986547,
      "acc_stderr,none": 0.03286745312567961,
      "alias": "ogx_mmlux_cs-human_aging"
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "acc,none": 0.7130801687763713,
      "acc_stderr,none": 0.02944377302259469,
      "alias": "ogx_mmlux_cs-high_school_world_history"
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "acc,none": 0.6715686274509803,
      "acc_stderr,none": 0.03296245110172228,
      "alias": "ogx_mmlux_cs-high_school_us_history"
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "acc,none": 0.4305555555555556,
      "acc_stderr,none": 0.03376922151252335,
      "alias": "ogx_mmlux_cs-high_school_statistics"
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "acc,none": 0.653211009174312,
      "acc_stderr,none": 0.020406097104093027,
      "alias": "ogx_mmlux_cs-high_school_psychology"
    },
    "ogx_mmlux_cs-high_school_physics": {
      "acc,none": 0.37748344370860926,
      "acc_stderr,none": 0.03958027231121569,
      "alias": "ogx_mmlux_cs-high_school_physics"
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "acc,none": 0.5798319327731093,
      "acc_stderr,none": 0.03206183783236152,
      "alias": "ogx_mmlux_cs-high_school_microeconomics"
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.029723278961476664,
      "alias": "ogx_mmlux_cs-high_school_mathematics"
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "acc,none": 0.4846153846153846,
      "acc_stderr,none": 0.025339003010106505,
      "alias": "ogx_mmlux_cs-high_school_macroeconomics"
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "acc,none": 0.6632124352331606,
      "acc_stderr,none": 0.03410780251836184,
      "alias": "ogx_mmlux_cs-high_school_government_and_politics"
    },
    "ogx_mmlux_cs-high_school_geography": {
      "acc,none": 0.6919191919191919,
      "acc_stderr,none": 0.03289477330098616,
      "alias": "ogx_mmlux_cs-high_school_geography"
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "acc,none": 0.7515151515151515,
      "acc_stderr,none": 0.03374402644139404,
      "alias": "ogx_mmlux_cs-high_school_european_history"
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "acc,none": 0.61,
      "acc_stderr,none": 0.04902071300001975,
      "alias": "ogx_mmlux_cs-high_school_computer_science"
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "acc,none": 0.45320197044334976,
      "acc_stderr,none": 0.035025446508458714,
      "alias": "ogx_mmlux_cs-high_school_chemistry"
    },
    "ogx_mmlux_cs-high_school_biology": {
      "acc,none": 0.6129032258064516,
      "acc_stderr,none": 0.02770935967503249,
      "alias": "ogx_mmlux_cs-high_school_biology"
    },
    "ogx_mmlux_cs-global_facts": {
      "acc,none": 0.35,
      "acc_stderr,none": 0.0479372485441102,
      "alias": "ogx_mmlux_cs-global_facts"
    },
    "ogx_mmlux_cs-formal_logic": {
      "acc,none": 0.3888888888888889,
      "acc_stderr,none": 0.04360314860077459,
      "alias": "ogx_mmlux_cs-formal_logic"
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "acc,none": 0.3941798941798942,
      "acc_stderr,none": 0.02516798233389414,
      "alias": "ogx_mmlux_cs-elementary_mathematics"
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "acc,none": 0.6137931034482759,
      "acc_stderr,none": 0.04057324734419034,
      "alias": "ogx_mmlux_cs-electrical_engineering"
    },
    "ogx_mmlux_cs-econometrics": {
      "acc,none": 0.42105263157894735,
      "acc_stderr,none": 0.046446020912223177,
      "alias": "ogx_mmlux_cs-econometrics"
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "acc,none": 0.451063829787234,
      "acc_stderr,none": 0.032529096196131965,
      "alias": "ogx_mmlux_cs-conceptual_physics"
    },
    "ogx_mmlux_cs-computer_security": {
      "acc,none": 0.7,
      "acc_stderr,none": 0.046056618647183814,
      "alias": "ogx_mmlux_cs-computer_security"
    },
    "ogx_mmlux_cs-college_physics": {
      "acc,none": 0.3431372549019608,
      "acc_stderr,none": 0.04724007352383889,
      "alias": "ogx_mmlux_cs-college_physics"
    },
    "ogx_mmlux_cs-college_medicine": {
      "acc,none": 0.5028901734104047,
      "acc_stderr,none": 0.03812400565974834,
      "alias": "ogx_mmlux_cs-college_medicine"
    },
    "ogx_mmlux_cs-college_mathematics": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252604,
      "alias": "ogx_mmlux_cs-college_mathematics"
    },
    "ogx_mmlux_cs-college_computer_science": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.04975698519562426,
      "alias": "ogx_mmlux_cs-college_computer_science"
    },
    "ogx_mmlux_cs-college_chemistry": {
      "acc,none": 0.43,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_cs-college_chemistry"
    },
    "ogx_mmlux_cs-college_biology": {
      "acc,none": 0.5972222222222222,
      "acc_stderr,none": 0.041014055198424264,
      "alias": "ogx_mmlux_cs-college_biology"
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "acc,none": 0.5811320754716981,
      "acc_stderr,none": 0.0303650508291152,
      "alias": "ogx_mmlux_cs-clinical_knowledge"
    },
    "ogx_mmlux_cs-business_ethics": {
      "acc,none": 0.63,
      "acc_stderr,none": 0.04852365870939099,
      "alias": "ogx_mmlux_cs-business_ethics"
    },
    "ogx_mmlux_cs-astronomy": {
      "acc,none": 0.6052631578947368,
      "acc_stderr,none": 0.039777499346220734,
      "alias": "ogx_mmlux_cs-astronomy"
    },
    "ogx_mmlux_cs-anatomy": {
      "acc,none": 0.45925925925925926,
      "acc_stderr,none": 0.04304979692464241,
      "alias": "ogx_mmlux_cs-anatomy"
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "acc,none": 0.31,
      "acc_stderr,none": 0.04648231987117316,
      "alias": "ogx_mmlux_cs-abstract_algebra"
    },
    "ogx_mmlux_bg-world_religions": {
      "acc,none": 0.695906432748538,
      "acc_stderr,none": 0.0352821125824523,
      "alias": "ogx_mmlux_bg-world_religions"
    },
    "ogx_mmlux_bg-virology": {
      "acc,none": 0.463855421686747,
      "acc_stderr,none": 0.03882310850890593,
      "alias": "ogx_mmlux_bg-virology"
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "acc,none": 0.81,
      "acc_stderr,none": 0.03942772444036624,
      "alias": "ogx_mmlux_bg-us_foreign_policy"
    },
    "ogx_mmlux_bg-sociology": {
      "acc,none": 0.7512437810945274,
      "acc_stderr,none": 0.030567675938916718,
      "alias": "ogx_mmlux_bg-sociology"
    },
    "ogx_mmlux_bg-security_studies": {
      "acc,none": 0.5877551020408164,
      "acc_stderr,none": 0.031512360446742674,
      "alias": "ogx_mmlux_bg-security_studies"
    },
    "ogx_mmlux_bg-public_relations": {
      "acc,none": 0.5272727272727272,
      "acc_stderr,none": 0.04782001791380061,
      "alias": "ogx_mmlux_bg-public_relations"
    },
    "ogx_mmlux_bg-professional_psychology": {
      "acc,none": 0.5147058823529411,
      "acc_stderr,none": 0.020219083895133924,
      "alias": "ogx_mmlux_bg-professional_psychology"
    },
    "ogx_mmlux_bg-professional_medicine": {
      "acc,none": 0.35661764705882354,
      "acc_stderr,none": 0.029097209568411952,
      "alias": "ogx_mmlux_bg-professional_medicine"
    },
    "ogx_mmlux_bg-professional_law": {
      "acc,none": 0.37157757496740546,
      "acc_stderr,none": 0.012341828514528296,
      "alias": "ogx_mmlux_bg-professional_law"
    },
    "ogx_mmlux_bg-professional_accounting": {
      "acc,none": 0.3829787234042553,
      "acc_stderr,none": 0.028999080904806185,
      "alias": "ogx_mmlux_bg-professional_accounting"
    },
    "ogx_mmlux_bg-prehistory": {
      "acc,none": 0.6080246913580247,
      "acc_stderr,none": 0.027163686038271146,
      "alias": "ogx_mmlux_bg-prehistory"
    },
    "ogx_mmlux_bg-philosophy": {
      "acc,none": 0.5627009646302251,
      "acc_stderr,none": 0.028173917761762906,
      "alias": "ogx_mmlux_bg-philosophy"
    },
    "ogx_mmlux_bg-nutrition": {
      "acc,none": 0.6143790849673203,
      "acc_stderr,none": 0.027870745278290275,
      "alias": "ogx_mmlux_bg-nutrition"
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "acc,none": 0.25139664804469275,
      "acc_stderr,none": 0.014508979453553984,
      "alias": "ogx_mmlux_bg-moral_scenarios"
    },
    "ogx_mmlux_bg-moral_disputes": {
      "acc,none": 0.546242774566474,
      "acc_stderr,none": 0.026803720583206174,
      "alias": "ogx_mmlux_bg-moral_disputes"
    },
    "ogx_mmlux_bg-miscellaneous": {
      "acc,none": 0.6309067688378033,
      "acc_stderr,none": 0.017256283109124616,
      "alias": "ogx_mmlux_bg-miscellaneous"
    },
    "ogx_mmlux_bg-medical_genetics": {
      "acc,none": 0.57,
      "acc_stderr,none": 0.049756985195624284,
      "alias": "ogx_mmlux_bg-medical_genetics"
    },
    "ogx_mmlux_bg-marketing": {
      "acc,none": 0.7264957264957265,
      "acc_stderr,none": 0.029202540153431187,
      "alias": "ogx_mmlux_bg-marketing"
    },
    "ogx_mmlux_bg-management": {
      "acc,none": 0.6213592233009708,
      "acc_stderr,none": 0.04802694698258975,
      "alias": "ogx_mmlux_bg-management"
    },
    "ogx_mmlux_bg-machine_learning": {
      "acc,none": 0.33035714285714285,
      "acc_stderr,none": 0.04464285714285713,
      "alias": "ogx_mmlux_bg-machine_learning"
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "acc,none": 0.5398773006134969,
      "acc_stderr,none": 0.0391585729143697,
      "alias": "ogx_mmlux_bg-logical_fallacies"
    },
    "ogx_mmlux_bg-jurisprudence": {
      "acc,none": 0.6296296296296297,
      "acc_stderr,none": 0.04668408033024931,
      "alias": "ogx_mmlux_bg-jurisprudence"
    },
    "ogx_mmlux_bg-international_law": {
      "acc,none": 0.743801652892562,
      "acc_stderr,none": 0.03984979653302872,
      "alias": "ogx_mmlux_bg-international_law"
    },
    "ogx_mmlux_bg-human_sexuality": {
      "acc,none": 0.5419847328244275,
      "acc_stderr,none": 0.04369802690578756,
      "alias": "ogx_mmlux_bg-human_sexuality"
    },
    "ogx_mmlux_bg-human_aging": {
      "acc,none": 0.5381165919282511,
      "acc_stderr,none": 0.03346015011973228,
      "alias": "ogx_mmlux_bg-human_aging"
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "acc,none": 0.7088607594936709,
      "acc_stderr,none": 0.02957160106575337,
      "alias": "ogx_mmlux_bg-high_school_world_history"
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "acc,none": 0.6029411764705882,
      "acc_stderr,none": 0.03434131164719129,
      "alias": "ogx_mmlux_bg-high_school_us_history"
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "acc,none": 0.4166666666666667,
      "acc_stderr,none": 0.033622774366080424,
      "alias": "ogx_mmlux_bg-high_school_statistics"
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "acc,none": 0.6293577981651376,
      "acc_stderr,none": 0.02070745816435298,
      "alias": "ogx_mmlux_bg-high_school_psychology"
    },
    "ogx_mmlux_bg-high_school_physics": {
      "acc,none": 0.3509933774834437,
      "acc_stderr,none": 0.03896981964257375,
      "alias": "ogx_mmlux_bg-high_school_physics"
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "acc,none": 0.47058823529411764,
      "acc_stderr,none": 0.032422250271150074,
      "alias": "ogx_mmlux_bg-high_school_microeconomics"
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "acc,none": 0.34444444444444444,
      "acc_stderr,none": 0.028972648884844267,
      "alias": "ogx_mmlux_bg-high_school_mathematics"
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "acc,none": 0.4512820512820513,
      "acc_stderr,none": 0.025230381238934833,
      "alias": "ogx_mmlux_bg-high_school_macroeconomics"
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "acc,none": 0.5699481865284974,
      "acc_stderr,none": 0.03572954333144808,
      "alias": "ogx_mmlux_bg-high_school_government_and_politics"
    },
    "ogx_mmlux_bg-high_school_geography": {
      "acc,none": 0.6313131313131313,
      "acc_stderr,none": 0.034373055019806184,
      "alias": "ogx_mmlux_bg-high_school_geography"
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "acc,none": 0.6727272727272727,
      "acc_stderr,none": 0.036639749943912434,
      "alias": "ogx_mmlux_bg-high_school_european_history"
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "acc,none": 0.61,
      "acc_stderr,none": 0.04902071300001974,
      "alias": "ogx_mmlux_bg-high_school_computer_science"
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "acc,none": 0.4187192118226601,
      "acc_stderr,none": 0.03471192860518468,
      "alias": "ogx_mmlux_bg-high_school_chemistry"
    },
    "ogx_mmlux_bg-high_school_biology": {
      "acc,none": 0.5967741935483871,
      "acc_stderr,none": 0.02790615082604115,
      "alias": "ogx_mmlux_bg-high_school_biology"
    },
    "ogx_mmlux_bg-global_facts": {
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695235,
      "alias": "ogx_mmlux_bg-global_facts"
    },
    "ogx_mmlux_bg-formal_logic": {
      "acc,none": 0.2857142857142857,
      "acc_stderr,none": 0.04040610178208841,
      "alias": "ogx_mmlux_bg-formal_logic"
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "acc,none": 0.35978835978835977,
      "acc_stderr,none": 0.02471807594412928,
      "alias": "ogx_mmlux_bg-elementary_mathematics"
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "acc,none": 0.5724137931034483,
      "acc_stderr,none": 0.041227371113703316,
      "alias": "ogx_mmlux_bg-electrical_engineering"
    },
    "ogx_mmlux_bg-econometrics": {
      "acc,none": 0.32456140350877194,
      "acc_stderr,none": 0.04404556157374768,
      "alias": "ogx_mmlux_bg-econometrics"
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "acc,none": 0.4595744680851064,
      "acc_stderr,none": 0.03257901482099835,
      "alias": "ogx_mmlux_bg-conceptual_physics"
    },
    "ogx_mmlux_bg-computer_security": {
      "acc,none": 0.67,
      "acc_stderr,none": 0.047258156262526066,
      "alias": "ogx_mmlux_bg-computer_security"
    },
    "ogx_mmlux_bg-college_physics": {
      "acc,none": 0.3137254901960784,
      "acc_stderr,none": 0.04617034827006719,
      "alias": "ogx_mmlux_bg-college_physics"
    },
    "ogx_mmlux_bg-college_medicine": {
      "acc,none": 0.4913294797687861,
      "acc_stderr,none": 0.038118909889404126,
      "alias": "ogx_mmlux_bg-college_medicine"
    },
    "ogx_mmlux_bg-college_mathematics": {
      "acc,none": 0.27,
      "acc_stderr,none": 0.0446196043338474,
      "alias": "ogx_mmlux_bg-college_mathematics"
    },
    "ogx_mmlux_bg-college_computer_science": {
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332,
      "alias": "ogx_mmlux_bg-college_computer_science"
    },
    "ogx_mmlux_bg-college_chemistry": {
      "acc,none": 0.33,
      "acc_stderr,none": 0.04725815626252606,
      "alias": "ogx_mmlux_bg-college_chemistry"
    },
    "ogx_mmlux_bg-college_biology": {
      "acc,none": 0.5763888888888888,
      "acc_stderr,none": 0.041321250197233685,
      "alias": "ogx_mmlux_bg-college_biology"
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "acc,none": 0.5283018867924528,
      "acc_stderr,none": 0.030723535249006107,
      "alias": "ogx_mmlux_bg-clinical_knowledge"
    },
    "ogx_mmlux_bg-business_ethics": {
      "acc,none": 0.54,
      "acc_stderr,none": 0.05009082659620333,
      "alias": "ogx_mmlux_bg-business_ethics"
    },
    "ogx_mmlux_bg-astronomy": {
      "acc,none": 0.6513157894736842,
      "acc_stderr,none": 0.038781398887976104,
      "alias": "ogx_mmlux_bg-astronomy"
    },
    "ogx_mmlux_bg-anatomy": {
      "acc,none": 0.4444444444444444,
      "acc_stderr,none": 0.04292596718256981,
      "alias": "ogx_mmlux_bg-anatomy"
    },
    "ogx_mmlux_bg-abstract_algebra": {
      "acc,none": 0.32,
      "acc_stderr,none": 0.046882617226215034,
      "alias": "ogx_mmlux_bg-abstract_algebra"
    }
  },
  "group_subtasks": {
    "ogx_mmlux_bg-abstract_algebra": [],
    "ogx_mmlux_bg-anatomy": [],
    "ogx_mmlux_bg-astronomy": [],
    "ogx_mmlux_bg-business_ethics": [],
    "ogx_mmlux_bg-clinical_knowledge": [],
    "ogx_mmlux_bg-college_biology": [],
    "ogx_mmlux_bg-college_chemistry": [],
    "ogx_mmlux_bg-college_computer_science": [],
    "ogx_mmlux_bg-college_mathematics": [],
    "ogx_mmlux_bg-college_medicine": [],
    "ogx_mmlux_bg-college_physics": [],
    "ogx_mmlux_bg-computer_security": [],
    "ogx_mmlux_bg-conceptual_physics": [],
    "ogx_mmlux_bg-econometrics": [],
    "ogx_mmlux_bg-electrical_engineering": [],
    "ogx_mmlux_bg-elementary_mathematics": [],
    "ogx_mmlux_bg-formal_logic": [],
    "ogx_mmlux_bg-global_facts": [],
    "ogx_mmlux_bg-high_school_biology": [],
    "ogx_mmlux_bg-high_school_chemistry": [],
    "ogx_mmlux_bg-high_school_computer_science": [],
    "ogx_mmlux_bg-high_school_european_history": [],
    "ogx_mmlux_bg-high_school_geography": [],
    "ogx_mmlux_bg-high_school_government_and_politics": [],
    "ogx_mmlux_bg-high_school_macroeconomics": [],
    "ogx_mmlux_bg-high_school_mathematics": [],
    "ogx_mmlux_bg-high_school_microeconomics": [],
    "ogx_mmlux_bg-high_school_physics": [],
    "ogx_mmlux_bg-high_school_psychology": [],
    "ogx_mmlux_bg-high_school_statistics": [],
    "ogx_mmlux_bg-high_school_us_history": [],
    "ogx_mmlux_bg-high_school_world_history": [],
    "ogx_mmlux_bg-human_aging": [],
    "ogx_mmlux_bg-human_sexuality": [],
    "ogx_mmlux_bg-international_law": [],
    "ogx_mmlux_bg-jurisprudence": [],
    "ogx_mmlux_bg-logical_fallacies": [],
    "ogx_mmlux_bg-machine_learning": [],
    "ogx_mmlux_bg-management": [],
    "ogx_mmlux_bg-marketing": [],
    "ogx_mmlux_bg-medical_genetics": [],
    "ogx_mmlux_bg-miscellaneous": [],
    "ogx_mmlux_bg-moral_disputes": [],
    "ogx_mmlux_bg-moral_scenarios": [],
    "ogx_mmlux_bg-nutrition": [],
    "ogx_mmlux_bg-philosophy": [],
    "ogx_mmlux_bg-prehistory": [],
    "ogx_mmlux_bg-professional_accounting": [],
    "ogx_mmlux_bg-professional_law": [],
    "ogx_mmlux_bg-professional_medicine": [],
    "ogx_mmlux_bg-professional_psychology": [],
    "ogx_mmlux_bg-public_relations": [],
    "ogx_mmlux_bg-security_studies": [],
    "ogx_mmlux_bg-sociology": [],
    "ogx_mmlux_bg-us_foreign_policy": [],
    "ogx_mmlux_bg-virology": [],
    "ogx_mmlux_bg-world_religions": [],
    "ogx_mmlux_cs-abstract_algebra": [],
    "ogx_mmlux_cs-anatomy": [],
    "ogx_mmlux_cs-astronomy": [],
    "ogx_mmlux_cs-business_ethics": [],
    "ogx_mmlux_cs-clinical_knowledge": [],
    "ogx_mmlux_cs-college_biology": [],
    "ogx_mmlux_cs-college_chemistry": [],
    "ogx_mmlux_cs-college_computer_science": [],
    "ogx_mmlux_cs-college_mathematics": [],
    "ogx_mmlux_cs-college_medicine": [],
    "ogx_mmlux_cs-college_physics": [],
    "ogx_mmlux_cs-computer_security": [],
    "ogx_mmlux_cs-conceptual_physics": [],
    "ogx_mmlux_cs-econometrics": [],
    "ogx_mmlux_cs-electrical_engineering": [],
    "ogx_mmlux_cs-elementary_mathematics": [],
    "ogx_mmlux_cs-formal_logic": [],
    "ogx_mmlux_cs-global_facts": [],
    "ogx_mmlux_cs-high_school_biology": [],
    "ogx_mmlux_cs-high_school_chemistry": [],
    "ogx_mmlux_cs-high_school_computer_science": [],
    "ogx_mmlux_cs-high_school_european_history": [],
    "ogx_mmlux_cs-high_school_geography": [],
    "ogx_mmlux_cs-high_school_government_and_politics": [],
    "ogx_mmlux_cs-high_school_macroeconomics": [],
    "ogx_mmlux_cs-high_school_mathematics": [],
    "ogx_mmlux_cs-high_school_microeconomics": [],
    "ogx_mmlux_cs-high_school_physics": [],
    "ogx_mmlux_cs-high_school_psychology": [],
    "ogx_mmlux_cs-high_school_statistics": [],
    "ogx_mmlux_cs-high_school_us_history": [],
    "ogx_mmlux_cs-high_school_world_history": [],
    "ogx_mmlux_cs-human_aging": [],
    "ogx_mmlux_cs-human_sexuality": [],
    "ogx_mmlux_cs-international_law": [],
    "ogx_mmlux_cs-jurisprudence": [],
    "ogx_mmlux_cs-logical_fallacies": [],
    "ogx_mmlux_cs-machine_learning": [],
    "ogx_mmlux_cs-management": [],
    "ogx_mmlux_cs-marketing": [],
    "ogx_mmlux_cs-medical_genetics": [],
    "ogx_mmlux_cs-miscellaneous": [],
    "ogx_mmlux_cs-moral_disputes": [],
    "ogx_mmlux_cs-moral_scenarios": [],
    "ogx_mmlux_cs-nutrition": [],
    "ogx_mmlux_cs-philosophy": [],
    "ogx_mmlux_cs-prehistory": [],
    "ogx_mmlux_cs-professional_accounting": [],
    "ogx_mmlux_cs-professional_law": [],
    "ogx_mmlux_cs-professional_medicine": [],
    "ogx_mmlux_cs-professional_psychology": [],
    "ogx_mmlux_cs-public_relations": [],
    "ogx_mmlux_cs-security_studies": [],
    "ogx_mmlux_cs-sociology": [],
    "ogx_mmlux_cs-us_foreign_policy": [],
    "ogx_mmlux_cs-virology": [],
    "ogx_mmlux_cs-world_religions": [],
    "ogx_mmlux_da-abstract_algebra": [],
    "ogx_mmlux_da-anatomy": [],
    "ogx_mmlux_da-astronomy": [],
    "ogx_mmlux_da-business_ethics": [],
    "ogx_mmlux_da-clinical_knowledge": [],
    "ogx_mmlux_da-college_biology": [],
    "ogx_mmlux_da-college_chemistry": [],
    "ogx_mmlux_da-college_computer_science": [],
    "ogx_mmlux_da-college_mathematics": [],
    "ogx_mmlux_da-college_medicine": [],
    "ogx_mmlux_da-college_physics": [],
    "ogx_mmlux_da-computer_security": [],
    "ogx_mmlux_da-conceptual_physics": [],
    "ogx_mmlux_da-econometrics": [],
    "ogx_mmlux_da-electrical_engineering": [],
    "ogx_mmlux_da-elementary_mathematics": [],
    "ogx_mmlux_da-formal_logic": [],
    "ogx_mmlux_da-global_facts": [],
    "ogx_mmlux_da-high_school_biology": [],
    "ogx_mmlux_da-high_school_chemistry": [],
    "ogx_mmlux_da-high_school_computer_science": [],
    "ogx_mmlux_da-high_school_european_history": [],
    "ogx_mmlux_da-high_school_geography": [],
    "ogx_mmlux_da-high_school_government_and_politics": [],
    "ogx_mmlux_da-high_school_macroeconomics": [],
    "ogx_mmlux_da-high_school_mathematics": [],
    "ogx_mmlux_da-high_school_microeconomics": [],
    "ogx_mmlux_da-high_school_physics": [],
    "ogx_mmlux_da-high_school_psychology": [],
    "ogx_mmlux_da-high_school_statistics": [],
    "ogx_mmlux_da-high_school_us_history": [],
    "ogx_mmlux_da-high_school_world_history": [],
    "ogx_mmlux_da-human_aging": [],
    "ogx_mmlux_da-human_sexuality": [],
    "ogx_mmlux_da-international_law": [],
    "ogx_mmlux_da-jurisprudence": [],
    "ogx_mmlux_da-logical_fallacies": [],
    "ogx_mmlux_da-machine_learning": [],
    "ogx_mmlux_da-management": [],
    "ogx_mmlux_da-marketing": [],
    "ogx_mmlux_da-medical_genetics": [],
    "ogx_mmlux_da-miscellaneous": [],
    "ogx_mmlux_da-moral_disputes": [],
    "ogx_mmlux_da-moral_scenarios": [],
    "ogx_mmlux_da-nutrition": [],
    "ogx_mmlux_da-philosophy": [],
    "ogx_mmlux_da-prehistory": [],
    "ogx_mmlux_da-professional_accounting": [],
    "ogx_mmlux_da-professional_law": [],
    "ogx_mmlux_da-professional_medicine": [],
    "ogx_mmlux_da-professional_psychology": [],
    "ogx_mmlux_da-public_relations": [],
    "ogx_mmlux_da-security_studies": [],
    "ogx_mmlux_da-sociology": [],
    "ogx_mmlux_da-us_foreign_policy": [],
    "ogx_mmlux_da-virology": [],
    "ogx_mmlux_da-world_religions": [],
    "ogx_mmlux_de-abstract_algebra": [],
    "ogx_mmlux_de-anatomy": [],
    "ogx_mmlux_de-astronomy": [],
    "ogx_mmlux_de-business_ethics": [],
    "ogx_mmlux_de-clinical_knowledge": [],
    "ogx_mmlux_de-college_biology": [],
    "ogx_mmlux_de-college_chemistry": [],
    "ogx_mmlux_de-college_computer_science": [],
    "ogx_mmlux_de-college_mathematics": [],
    "ogx_mmlux_de-college_medicine": [],
    "ogx_mmlux_de-college_physics": [],
    "ogx_mmlux_de-computer_security": [],
    "ogx_mmlux_de-conceptual_physics": [],
    "ogx_mmlux_de-econometrics": [],
    "ogx_mmlux_de-electrical_engineering": [],
    "ogx_mmlux_de-elementary_mathematics": [],
    "ogx_mmlux_de-formal_logic": [],
    "ogx_mmlux_de-global_facts": [],
    "ogx_mmlux_de-high_school_biology": [],
    "ogx_mmlux_de-high_school_chemistry": [],
    "ogx_mmlux_de-high_school_computer_science": [],
    "ogx_mmlux_de-high_school_european_history": [],
    "ogx_mmlux_de-high_school_geography": [],
    "ogx_mmlux_de-high_school_government_and_politics": [],
    "ogx_mmlux_de-high_school_macroeconomics": [],
    "ogx_mmlux_de-high_school_mathematics": [],
    "ogx_mmlux_de-high_school_microeconomics": [],
    "ogx_mmlux_de-high_school_physics": [],
    "ogx_mmlux_de-high_school_psychology": [],
    "ogx_mmlux_de-high_school_statistics": [],
    "ogx_mmlux_de-high_school_us_history": [],
    "ogx_mmlux_de-high_school_world_history": [],
    "ogx_mmlux_de-human_aging": [],
    "ogx_mmlux_de-human_sexuality": [],
    "ogx_mmlux_de-international_law": [],
    "ogx_mmlux_de-jurisprudence": [],
    "ogx_mmlux_de-logical_fallacies": [],
    "ogx_mmlux_de-machine_learning": [],
    "ogx_mmlux_de-management": [],
    "ogx_mmlux_de-marketing": [],
    "ogx_mmlux_de-medical_genetics": [],
    "ogx_mmlux_de-miscellaneous": [],
    "ogx_mmlux_de-moral_disputes": [],
    "ogx_mmlux_de-moral_scenarios": [],
    "ogx_mmlux_de-nutrition": [],
    "ogx_mmlux_de-philosophy": [],
    "ogx_mmlux_de-prehistory": [],
    "ogx_mmlux_de-professional_accounting": [],
    "ogx_mmlux_de-professional_law": [],
    "ogx_mmlux_de-professional_medicine": [],
    "ogx_mmlux_de-professional_psychology": [],
    "ogx_mmlux_de-public_relations": [],
    "ogx_mmlux_de-security_studies": [],
    "ogx_mmlux_de-sociology": [],
    "ogx_mmlux_de-us_foreign_policy": [],
    "ogx_mmlux_de-virology": [],
    "ogx_mmlux_de-world_religions": [],
    "ogx_mmlux_el-abstract_algebra": [],
    "ogx_mmlux_el-anatomy": [],
    "ogx_mmlux_el-astronomy": [],
    "ogx_mmlux_el-business_ethics": [],
    "ogx_mmlux_el-clinical_knowledge": [],
    "ogx_mmlux_el-college_biology": [],
    "ogx_mmlux_el-college_chemistry": [],
    "ogx_mmlux_el-college_computer_science": [],
    "ogx_mmlux_el-college_mathematics": [],
    "ogx_mmlux_el-college_medicine": [],
    "ogx_mmlux_el-college_physics": [],
    "ogx_mmlux_el-computer_security": [],
    "ogx_mmlux_el-conceptual_physics": [],
    "ogx_mmlux_el-econometrics": [],
    "ogx_mmlux_el-electrical_engineering": [],
    "ogx_mmlux_el-elementary_mathematics": [],
    "ogx_mmlux_el-formal_logic": [],
    "ogx_mmlux_el-global_facts": [],
    "ogx_mmlux_el-high_school_biology": [],
    "ogx_mmlux_el-high_school_chemistry": [],
    "ogx_mmlux_el-high_school_computer_science": [],
    "ogx_mmlux_el-high_school_european_history": [],
    "ogx_mmlux_el-high_school_geography": [],
    "ogx_mmlux_el-high_school_government_and_politics": [],
    "ogx_mmlux_el-high_school_macroeconomics": [],
    "ogx_mmlux_el-high_school_mathematics": [],
    "ogx_mmlux_el-high_school_microeconomics": [],
    "ogx_mmlux_el-high_school_physics": [],
    "ogx_mmlux_el-high_school_psychology": [],
    "ogx_mmlux_el-high_school_statistics": [],
    "ogx_mmlux_el-high_school_us_history": [],
    "ogx_mmlux_el-high_school_world_history": [],
    "ogx_mmlux_el-human_aging": [],
    "ogx_mmlux_el-human_sexuality": [],
    "ogx_mmlux_el-international_law": [],
    "ogx_mmlux_el-jurisprudence": [],
    "ogx_mmlux_el-logical_fallacies": [],
    "ogx_mmlux_el-machine_learning": [],
    "ogx_mmlux_el-management": [],
    "ogx_mmlux_el-marketing": [],
    "ogx_mmlux_el-medical_genetics": [],
    "ogx_mmlux_el-miscellaneous": [],
    "ogx_mmlux_el-moral_disputes": [],
    "ogx_mmlux_el-moral_scenarios": [],
    "ogx_mmlux_el-nutrition": [],
    "ogx_mmlux_el-philosophy": [],
    "ogx_mmlux_el-prehistory": [],
    "ogx_mmlux_el-professional_accounting": [],
    "ogx_mmlux_el-professional_law": [],
    "ogx_mmlux_el-professional_medicine": [],
    "ogx_mmlux_el-professional_psychology": [],
    "ogx_mmlux_el-public_relations": [],
    "ogx_mmlux_el-security_studies": [],
    "ogx_mmlux_el-sociology": [],
    "ogx_mmlux_el-us_foreign_policy": [],
    "ogx_mmlux_el-virology": [],
    "ogx_mmlux_el-world_religions": [],
    "ogx_mmlux_es-abstract_algebra": [],
    "ogx_mmlux_es-anatomy": [],
    "ogx_mmlux_es-astronomy": [],
    "ogx_mmlux_es-business_ethics": [],
    "ogx_mmlux_es-clinical_knowledge": [],
    "ogx_mmlux_es-college_biology": [],
    "ogx_mmlux_es-college_chemistry": [],
    "ogx_mmlux_es-college_computer_science": [],
    "ogx_mmlux_es-college_mathematics": [],
    "ogx_mmlux_es-college_medicine": [],
    "ogx_mmlux_es-college_physics": [],
    "ogx_mmlux_es-computer_security": [],
    "ogx_mmlux_es-conceptual_physics": [],
    "ogx_mmlux_es-econometrics": [],
    "ogx_mmlux_es-electrical_engineering": [],
    "ogx_mmlux_es-elementary_mathematics": [],
    "ogx_mmlux_es-formal_logic": [],
    "ogx_mmlux_es-global_facts": [],
    "ogx_mmlux_es-high_school_biology": [],
    "ogx_mmlux_es-high_school_chemistry": [],
    "ogx_mmlux_es-high_school_computer_science": [],
    "ogx_mmlux_es-high_school_european_history": [],
    "ogx_mmlux_es-high_school_geography": [],
    "ogx_mmlux_es-high_school_government_and_politics": [],
    "ogx_mmlux_es-high_school_macroeconomics": [],
    "ogx_mmlux_es-high_school_mathematics": [],
    "ogx_mmlux_es-high_school_microeconomics": [],
    "ogx_mmlux_es-high_school_physics": [],
    "ogx_mmlux_es-high_school_psychology": [],
    "ogx_mmlux_es-high_school_statistics": [],
    "ogx_mmlux_es-high_school_us_history": [],
    "ogx_mmlux_es-high_school_world_history": [],
    "ogx_mmlux_es-human_aging": [],
    "ogx_mmlux_es-human_sexuality": [],
    "ogx_mmlux_es-international_law": [],
    "ogx_mmlux_es-jurisprudence": [],
    "ogx_mmlux_es-logical_fallacies": [],
    "ogx_mmlux_es-machine_learning": [],
    "ogx_mmlux_es-management": [],
    "ogx_mmlux_es-marketing": [],
    "ogx_mmlux_es-medical_genetics": [],
    "ogx_mmlux_es-miscellaneous": [],
    "ogx_mmlux_es-moral_disputes": [],
    "ogx_mmlux_es-moral_scenarios": [],
    "ogx_mmlux_es-nutrition": [],
    "ogx_mmlux_es-philosophy": [],
    "ogx_mmlux_es-prehistory": [],
    "ogx_mmlux_es-professional_accounting": [],
    "ogx_mmlux_es-professional_law": [],
    "ogx_mmlux_es-professional_medicine": [],
    "ogx_mmlux_es-professional_psychology": [],
    "ogx_mmlux_es-public_relations": [],
    "ogx_mmlux_es-security_studies": [],
    "ogx_mmlux_es-sociology": [],
    "ogx_mmlux_es-us_foreign_policy": [],
    "ogx_mmlux_es-virology": [],
    "ogx_mmlux_es-world_religions": [],
    "ogx_mmlux_et-abstract_algebra": [],
    "ogx_mmlux_et-anatomy": [],
    "ogx_mmlux_et-astronomy": [],
    "ogx_mmlux_et-business_ethics": [],
    "ogx_mmlux_et-clinical_knowledge": [],
    "ogx_mmlux_et-college_biology": [],
    "ogx_mmlux_et-college_chemistry": [],
    "ogx_mmlux_et-college_computer_science": [],
    "ogx_mmlux_et-college_mathematics": [],
    "ogx_mmlux_et-college_medicine": [],
    "ogx_mmlux_et-college_physics": [],
    "ogx_mmlux_et-computer_security": [],
    "ogx_mmlux_et-conceptual_physics": [],
    "ogx_mmlux_et-econometrics": [],
    "ogx_mmlux_et-electrical_engineering": [],
    "ogx_mmlux_et-elementary_mathematics": [],
    "ogx_mmlux_et-formal_logic": [],
    "ogx_mmlux_et-global_facts": [],
    "ogx_mmlux_et-high_school_biology": [],
    "ogx_mmlux_et-high_school_chemistry": [],
    "ogx_mmlux_et-high_school_computer_science": [],
    "ogx_mmlux_et-high_school_european_history": [],
    "ogx_mmlux_et-high_school_geography": [],
    "ogx_mmlux_et-high_school_government_and_politics": [],
    "ogx_mmlux_et-high_school_macroeconomics": [],
    "ogx_mmlux_et-high_school_mathematics": [],
    "ogx_mmlux_et-high_school_microeconomics": [],
    "ogx_mmlux_et-high_school_physics": [],
    "ogx_mmlux_et-high_school_psychology": [],
    "ogx_mmlux_et-high_school_statistics": [],
    "ogx_mmlux_et-high_school_us_history": [],
    "ogx_mmlux_et-high_school_world_history": [],
    "ogx_mmlux_et-human_aging": [],
    "ogx_mmlux_et-human_sexuality": [],
    "ogx_mmlux_et-international_law": [],
    "ogx_mmlux_et-jurisprudence": [],
    "ogx_mmlux_et-logical_fallacies": [],
    "ogx_mmlux_et-machine_learning": [],
    "ogx_mmlux_et-management": [],
    "ogx_mmlux_et-marketing": [],
    "ogx_mmlux_et-medical_genetics": [],
    "ogx_mmlux_et-miscellaneous": [],
    "ogx_mmlux_et-moral_disputes": [],
    "ogx_mmlux_et-moral_scenarios": [],
    "ogx_mmlux_et-nutrition": [],
    "ogx_mmlux_et-philosophy": [],
    "ogx_mmlux_et-prehistory": [],
    "ogx_mmlux_et-professional_accounting": [],
    "ogx_mmlux_et-professional_law": [],
    "ogx_mmlux_et-professional_medicine": [],
    "ogx_mmlux_et-professional_psychology": [],
    "ogx_mmlux_et-public_relations": [],
    "ogx_mmlux_et-security_studies": [],
    "ogx_mmlux_et-sociology": [],
    "ogx_mmlux_et-us_foreign_policy": [],
    "ogx_mmlux_et-virology": [],
    "ogx_mmlux_et-world_religions": [],
    "ogx_mmlux_fi-abstract_algebra": [],
    "ogx_mmlux_fi-anatomy": [],
    "ogx_mmlux_fi-astronomy": [],
    "ogx_mmlux_fi-business_ethics": [],
    "ogx_mmlux_fi-clinical_knowledge": [],
    "ogx_mmlux_fi-college_biology": [],
    "ogx_mmlux_fi-college_chemistry": [],
    "ogx_mmlux_fi-college_computer_science": [],
    "ogx_mmlux_fi-college_mathematics": [],
    "ogx_mmlux_fi-college_medicine": [],
    "ogx_mmlux_fi-college_physics": [],
    "ogx_mmlux_fi-computer_security": [],
    "ogx_mmlux_fi-conceptual_physics": [],
    "ogx_mmlux_fi-econometrics": [],
    "ogx_mmlux_fi-electrical_engineering": [],
    "ogx_mmlux_fi-elementary_mathematics": [],
    "ogx_mmlux_fi-formal_logic": [],
    "ogx_mmlux_fi-global_facts": [],
    "ogx_mmlux_fi-high_school_biology": [],
    "ogx_mmlux_fi-high_school_chemistry": [],
    "ogx_mmlux_fi-high_school_computer_science": [],
    "ogx_mmlux_fi-high_school_european_history": [],
    "ogx_mmlux_fi-high_school_geography": [],
    "ogx_mmlux_fi-high_school_government_and_politics": [],
    "ogx_mmlux_fi-high_school_macroeconomics": [],
    "ogx_mmlux_fi-high_school_mathematics": [],
    "ogx_mmlux_fi-high_school_microeconomics": [],
    "ogx_mmlux_fi-high_school_physics": [],
    "ogx_mmlux_fi-high_school_psychology": [],
    "ogx_mmlux_fi-high_school_statistics": [],
    "ogx_mmlux_fi-high_school_us_history": [],
    "ogx_mmlux_fi-high_school_world_history": [],
    "ogx_mmlux_fi-human_aging": [],
    "ogx_mmlux_fi-human_sexuality": [],
    "ogx_mmlux_fi-international_law": [],
    "ogx_mmlux_fi-jurisprudence": [],
    "ogx_mmlux_fi-logical_fallacies": [],
    "ogx_mmlux_fi-machine_learning": [],
    "ogx_mmlux_fi-management": [],
    "ogx_mmlux_fi-marketing": [],
    "ogx_mmlux_fi-medical_genetics": [],
    "ogx_mmlux_fi-miscellaneous": [],
    "ogx_mmlux_fi-moral_disputes": [],
    "ogx_mmlux_fi-moral_scenarios": [],
    "ogx_mmlux_fi-nutrition": [],
    "ogx_mmlux_fi-philosophy": [],
    "ogx_mmlux_fi-prehistory": [],
    "ogx_mmlux_fi-professional_accounting": [],
    "ogx_mmlux_fi-professional_law": [],
    "ogx_mmlux_fi-professional_medicine": [],
    "ogx_mmlux_fi-professional_psychology": [],
    "ogx_mmlux_fi-public_relations": [],
    "ogx_mmlux_fi-security_studies": [],
    "ogx_mmlux_fi-sociology": [],
    "ogx_mmlux_fi-us_foreign_policy": [],
    "ogx_mmlux_fi-virology": [],
    "ogx_mmlux_fi-world_religions": [],
    "ogx_mmlux_fr-abstract_algebra": [],
    "ogx_mmlux_fr-anatomy": [],
    "ogx_mmlux_fr-astronomy": [],
    "ogx_mmlux_fr-business_ethics": [],
    "ogx_mmlux_fr-clinical_knowledge": [],
    "ogx_mmlux_fr-college_biology": [],
    "ogx_mmlux_fr-college_chemistry": [],
    "ogx_mmlux_fr-college_computer_science": [],
    "ogx_mmlux_fr-college_mathematics": [],
    "ogx_mmlux_fr-college_medicine": [],
    "ogx_mmlux_fr-college_physics": [],
    "ogx_mmlux_fr-computer_security": [],
    "ogx_mmlux_fr-conceptual_physics": [],
    "ogx_mmlux_fr-econometrics": [],
    "ogx_mmlux_fr-electrical_engineering": [],
    "ogx_mmlux_fr-elementary_mathematics": [],
    "ogx_mmlux_fr-formal_logic": [],
    "ogx_mmlux_fr-global_facts": [],
    "ogx_mmlux_fr-high_school_biology": [],
    "ogx_mmlux_fr-high_school_chemistry": [],
    "ogx_mmlux_fr-high_school_computer_science": [],
    "ogx_mmlux_fr-high_school_european_history": [],
    "ogx_mmlux_fr-high_school_geography": [],
    "ogx_mmlux_fr-high_school_government_and_politics": [],
    "ogx_mmlux_fr-high_school_macroeconomics": [],
    "ogx_mmlux_fr-high_school_mathematics": [],
    "ogx_mmlux_fr-high_school_microeconomics": [],
    "ogx_mmlux_fr-high_school_physics": [],
    "ogx_mmlux_fr-high_school_psychology": [],
    "ogx_mmlux_fr-high_school_statistics": [],
    "ogx_mmlux_fr-high_school_us_history": [],
    "ogx_mmlux_fr-high_school_world_history": [],
    "ogx_mmlux_fr-human_aging": [],
    "ogx_mmlux_fr-human_sexuality": [],
    "ogx_mmlux_fr-international_law": [],
    "ogx_mmlux_fr-jurisprudence": [],
    "ogx_mmlux_fr-logical_fallacies": [],
    "ogx_mmlux_fr-machine_learning": [],
    "ogx_mmlux_fr-management": [],
    "ogx_mmlux_fr-marketing": [],
    "ogx_mmlux_fr-medical_genetics": [],
    "ogx_mmlux_fr-miscellaneous": [],
    "ogx_mmlux_fr-moral_disputes": [],
    "ogx_mmlux_fr-moral_scenarios": [],
    "ogx_mmlux_fr-nutrition": [],
    "ogx_mmlux_fr-philosophy": [],
    "ogx_mmlux_fr-prehistory": [],
    "ogx_mmlux_fr-professional_accounting": [],
    "ogx_mmlux_fr-professional_law": [],
    "ogx_mmlux_fr-professional_medicine": [],
    "ogx_mmlux_fr-professional_psychology": [],
    "ogx_mmlux_fr-public_relations": [],
    "ogx_mmlux_fr-security_studies": [],
    "ogx_mmlux_fr-sociology": [],
    "ogx_mmlux_fr-us_foreign_policy": [],
    "ogx_mmlux_fr-virology": [],
    "ogx_mmlux_fr-world_religions": [],
    "ogx_mmlux_hu-abstract_algebra": [],
    "ogx_mmlux_hu-anatomy": [],
    "ogx_mmlux_hu-astronomy": [],
    "ogx_mmlux_hu-business_ethics": [],
    "ogx_mmlux_hu-clinical_knowledge": [],
    "ogx_mmlux_hu-college_biology": [],
    "ogx_mmlux_hu-college_chemistry": [],
    "ogx_mmlux_hu-college_computer_science": [],
    "ogx_mmlux_hu-college_mathematics": [],
    "ogx_mmlux_hu-college_medicine": [],
    "ogx_mmlux_hu-college_physics": [],
    "ogx_mmlux_hu-computer_security": [],
    "ogx_mmlux_hu-conceptual_physics": [],
    "ogx_mmlux_hu-econometrics": [],
    "ogx_mmlux_hu-electrical_engineering": [],
    "ogx_mmlux_hu-elementary_mathematics": [],
    "ogx_mmlux_hu-formal_logic": [],
    "ogx_mmlux_hu-global_facts": [],
    "ogx_mmlux_hu-high_school_biology": [],
    "ogx_mmlux_hu-high_school_chemistry": [],
    "ogx_mmlux_hu-high_school_computer_science": [],
    "ogx_mmlux_hu-high_school_european_history": [],
    "ogx_mmlux_hu-high_school_geography": [],
    "ogx_mmlux_hu-high_school_government_and_politics": [],
    "ogx_mmlux_hu-high_school_macroeconomics": [],
    "ogx_mmlux_hu-high_school_mathematics": [],
    "ogx_mmlux_hu-high_school_microeconomics": [],
    "ogx_mmlux_hu-high_school_physics": [],
    "ogx_mmlux_hu-high_school_psychology": [],
    "ogx_mmlux_hu-high_school_statistics": [],
    "ogx_mmlux_hu-high_school_us_history": [],
    "ogx_mmlux_hu-high_school_world_history": [],
    "ogx_mmlux_hu-human_aging": [],
    "ogx_mmlux_hu-human_sexuality": [],
    "ogx_mmlux_hu-international_law": [],
    "ogx_mmlux_hu-jurisprudence": [],
    "ogx_mmlux_hu-logical_fallacies": [],
    "ogx_mmlux_hu-machine_learning": [],
    "ogx_mmlux_hu-management": [],
    "ogx_mmlux_hu-marketing": [],
    "ogx_mmlux_hu-medical_genetics": [],
    "ogx_mmlux_hu-miscellaneous": [],
    "ogx_mmlux_hu-moral_disputes": [],
    "ogx_mmlux_hu-moral_scenarios": [],
    "ogx_mmlux_hu-nutrition": [],
    "ogx_mmlux_hu-philosophy": [],
    "ogx_mmlux_hu-prehistory": [],
    "ogx_mmlux_hu-professional_accounting": [],
    "ogx_mmlux_hu-professional_law": [],
    "ogx_mmlux_hu-professional_medicine": [],
    "ogx_mmlux_hu-professional_psychology": [],
    "ogx_mmlux_hu-public_relations": [],
    "ogx_mmlux_hu-security_studies": [],
    "ogx_mmlux_hu-sociology": [],
    "ogx_mmlux_hu-us_foreign_policy": [],
    "ogx_mmlux_hu-virology": [],
    "ogx_mmlux_hu-world_religions": [],
    "ogx_mmlux_it-abstract_algebra": [],
    "ogx_mmlux_it-anatomy": [],
    "ogx_mmlux_it-astronomy": [],
    "ogx_mmlux_it-business_ethics": [],
    "ogx_mmlux_it-clinical_knowledge": [],
    "ogx_mmlux_it-college_biology": [],
    "ogx_mmlux_it-college_chemistry": [],
    "ogx_mmlux_it-college_computer_science": [],
    "ogx_mmlux_it-college_mathematics": [],
    "ogx_mmlux_it-college_medicine": [],
    "ogx_mmlux_it-college_physics": [],
    "ogx_mmlux_it-computer_security": [],
    "ogx_mmlux_it-conceptual_physics": [],
    "ogx_mmlux_it-econometrics": [],
    "ogx_mmlux_it-electrical_engineering": [],
    "ogx_mmlux_it-elementary_mathematics": [],
    "ogx_mmlux_it-formal_logic": [],
    "ogx_mmlux_it-global_facts": [],
    "ogx_mmlux_it-high_school_biology": [],
    "ogx_mmlux_it-high_school_chemistry": [],
    "ogx_mmlux_it-high_school_computer_science": [],
    "ogx_mmlux_it-high_school_european_history": [],
    "ogx_mmlux_it-high_school_geography": [],
    "ogx_mmlux_it-high_school_government_and_politics": [],
    "ogx_mmlux_it-high_school_macroeconomics": [],
    "ogx_mmlux_it-high_school_mathematics": [],
    "ogx_mmlux_it-high_school_microeconomics": [],
    "ogx_mmlux_it-high_school_physics": [],
    "ogx_mmlux_it-high_school_psychology": [],
    "ogx_mmlux_it-high_school_statistics": [],
    "ogx_mmlux_it-high_school_us_history": [],
    "ogx_mmlux_it-high_school_world_history": [],
    "ogx_mmlux_it-human_aging": [],
    "ogx_mmlux_it-human_sexuality": [],
    "ogx_mmlux_it-international_law": [],
    "ogx_mmlux_it-jurisprudence": [],
    "ogx_mmlux_it-logical_fallacies": [],
    "ogx_mmlux_it-machine_learning": [],
    "ogx_mmlux_it-management": [],
    "ogx_mmlux_it-marketing": [],
    "ogx_mmlux_it-medical_genetics": [],
    "ogx_mmlux_it-miscellaneous": [],
    "ogx_mmlux_it-moral_disputes": [],
    "ogx_mmlux_it-moral_scenarios": [],
    "ogx_mmlux_it-nutrition": [],
    "ogx_mmlux_it-philosophy": [],
    "ogx_mmlux_it-prehistory": [],
    "ogx_mmlux_it-professional_accounting": [],
    "ogx_mmlux_it-professional_law": [],
    "ogx_mmlux_it-professional_medicine": [],
    "ogx_mmlux_it-professional_psychology": [],
    "ogx_mmlux_it-public_relations": [],
    "ogx_mmlux_it-security_studies": [],
    "ogx_mmlux_it-sociology": [],
    "ogx_mmlux_it-us_foreign_policy": [],
    "ogx_mmlux_it-virology": [],
    "ogx_mmlux_it-world_religions": [],
    "ogx_mmlux_lt-abstract_algebra": [],
    "ogx_mmlux_lt-anatomy": [],
    "ogx_mmlux_lt-astronomy": [],
    "ogx_mmlux_lt-business_ethics": [],
    "ogx_mmlux_lt-clinical_knowledge": [],
    "ogx_mmlux_lt-college_biology": [],
    "ogx_mmlux_lt-college_chemistry": [],
    "ogx_mmlux_lt-college_computer_science": [],
    "ogx_mmlux_lt-college_mathematics": [],
    "ogx_mmlux_lt-college_medicine": [],
    "ogx_mmlux_lt-college_physics": [],
    "ogx_mmlux_lt-computer_security": [],
    "ogx_mmlux_lt-conceptual_physics": [],
    "ogx_mmlux_lt-econometrics": [],
    "ogx_mmlux_lt-electrical_engineering": [],
    "ogx_mmlux_lt-elementary_mathematics": [],
    "ogx_mmlux_lt-formal_logic": [],
    "ogx_mmlux_lt-global_facts": [],
    "ogx_mmlux_lt-high_school_biology": [],
    "ogx_mmlux_lt-high_school_chemistry": [],
    "ogx_mmlux_lt-high_school_computer_science": [],
    "ogx_mmlux_lt-high_school_european_history": [],
    "ogx_mmlux_lt-high_school_geography": [],
    "ogx_mmlux_lt-high_school_government_and_politics": [],
    "ogx_mmlux_lt-high_school_macroeconomics": [],
    "ogx_mmlux_lt-high_school_mathematics": [],
    "ogx_mmlux_lt-high_school_microeconomics": [],
    "ogx_mmlux_lt-high_school_physics": [],
    "ogx_mmlux_lt-high_school_psychology": [],
    "ogx_mmlux_lt-high_school_statistics": [],
    "ogx_mmlux_lt-high_school_us_history": [],
    "ogx_mmlux_lt-high_school_world_history": [],
    "ogx_mmlux_lt-human_aging": [],
    "ogx_mmlux_lt-human_sexuality": [],
    "ogx_mmlux_lt-international_law": [],
    "ogx_mmlux_lt-jurisprudence": [],
    "ogx_mmlux_lt-logical_fallacies": [],
    "ogx_mmlux_lt-machine_learning": [],
    "ogx_mmlux_lt-management": [],
    "ogx_mmlux_lt-marketing": [],
    "ogx_mmlux_lt-medical_genetics": [],
    "ogx_mmlux_lt-miscellaneous": [],
    "ogx_mmlux_lt-moral_disputes": [],
    "ogx_mmlux_lt-moral_scenarios": [],
    "ogx_mmlux_lt-nutrition": [],
    "ogx_mmlux_lt-philosophy": [],
    "ogx_mmlux_lt-prehistory": [],
    "ogx_mmlux_lt-professional_accounting": [],
    "ogx_mmlux_lt-professional_law": [],
    "ogx_mmlux_lt-professional_medicine": [],
    "ogx_mmlux_lt-professional_psychology": [],
    "ogx_mmlux_lt-public_relations": [],
    "ogx_mmlux_lt-security_studies": [],
    "ogx_mmlux_lt-sociology": [],
    "ogx_mmlux_lt-us_foreign_policy": [],
    "ogx_mmlux_lt-virology": [],
    "ogx_mmlux_lt-world_religions": [],
    "ogx_mmlux_lv-abstract_algebra": [],
    "ogx_mmlux_lv-anatomy": [],
    "ogx_mmlux_lv-astronomy": [],
    "ogx_mmlux_lv-business_ethics": [],
    "ogx_mmlux_lv-clinical_knowledge": [],
    "ogx_mmlux_lv-college_biology": [],
    "ogx_mmlux_lv-college_chemistry": [],
    "ogx_mmlux_lv-college_computer_science": [],
    "ogx_mmlux_lv-college_mathematics": [],
    "ogx_mmlux_lv-college_medicine": [],
    "ogx_mmlux_lv-college_physics": [],
    "ogx_mmlux_lv-computer_security": [],
    "ogx_mmlux_lv-conceptual_physics": [],
    "ogx_mmlux_lv-econometrics": [],
    "ogx_mmlux_lv-electrical_engineering": [],
    "ogx_mmlux_lv-elementary_mathematics": [],
    "ogx_mmlux_lv-formal_logic": [],
    "ogx_mmlux_lv-global_facts": [],
    "ogx_mmlux_lv-high_school_biology": [],
    "ogx_mmlux_lv-high_school_chemistry": [],
    "ogx_mmlux_lv-high_school_computer_science": [],
    "ogx_mmlux_lv-high_school_european_history": [],
    "ogx_mmlux_lv-high_school_geography": [],
    "ogx_mmlux_lv-high_school_government_and_politics": [],
    "ogx_mmlux_lv-high_school_macroeconomics": [],
    "ogx_mmlux_lv-high_school_mathematics": [],
    "ogx_mmlux_lv-high_school_microeconomics": [],
    "ogx_mmlux_lv-high_school_physics": [],
    "ogx_mmlux_lv-high_school_psychology": [],
    "ogx_mmlux_lv-high_school_statistics": [],
    "ogx_mmlux_lv-high_school_us_history": [],
    "ogx_mmlux_lv-high_school_world_history": [],
    "ogx_mmlux_lv-human_aging": [],
    "ogx_mmlux_lv-human_sexuality": [],
    "ogx_mmlux_lv-international_law": [],
    "ogx_mmlux_lv-jurisprudence": [],
    "ogx_mmlux_lv-logical_fallacies": [],
    "ogx_mmlux_lv-machine_learning": [],
    "ogx_mmlux_lv-management": [],
    "ogx_mmlux_lv-marketing": [],
    "ogx_mmlux_lv-medical_genetics": [],
    "ogx_mmlux_lv-miscellaneous": [],
    "ogx_mmlux_lv-moral_disputes": [],
    "ogx_mmlux_lv-moral_scenarios": [],
    "ogx_mmlux_lv-nutrition": [],
    "ogx_mmlux_lv-philosophy": [],
    "ogx_mmlux_lv-prehistory": [],
    "ogx_mmlux_lv-professional_accounting": [],
    "ogx_mmlux_lv-professional_law": [],
    "ogx_mmlux_lv-professional_medicine": [],
    "ogx_mmlux_lv-professional_psychology": [],
    "ogx_mmlux_lv-public_relations": [],
    "ogx_mmlux_lv-security_studies": [],
    "ogx_mmlux_lv-sociology": [],
    "ogx_mmlux_lv-us_foreign_policy": [],
    "ogx_mmlux_lv-virology": [],
    "ogx_mmlux_lv-world_religions": [],
    "ogx_mmlux_nl-abstract_algebra": [],
    "ogx_mmlux_nl-anatomy": [],
    "ogx_mmlux_nl-astronomy": [],
    "ogx_mmlux_nl-business_ethics": [],
    "ogx_mmlux_nl-clinical_knowledge": [],
    "ogx_mmlux_nl-college_biology": [],
    "ogx_mmlux_nl-college_chemistry": [],
    "ogx_mmlux_nl-college_computer_science": [],
    "ogx_mmlux_nl-college_mathematics": [],
    "ogx_mmlux_nl-college_medicine": [],
    "ogx_mmlux_nl-college_physics": [],
    "ogx_mmlux_nl-computer_security": [],
    "ogx_mmlux_nl-conceptual_physics": [],
    "ogx_mmlux_nl-econometrics": [],
    "ogx_mmlux_nl-electrical_engineering": [],
    "ogx_mmlux_nl-elementary_mathematics": [],
    "ogx_mmlux_nl-formal_logic": [],
    "ogx_mmlux_nl-global_facts": [],
    "ogx_mmlux_nl-high_school_biology": [],
    "ogx_mmlux_nl-high_school_chemistry": [],
    "ogx_mmlux_nl-high_school_computer_science": [],
    "ogx_mmlux_nl-high_school_european_history": [],
    "ogx_mmlux_nl-high_school_geography": [],
    "ogx_mmlux_nl-high_school_government_and_politics": [],
    "ogx_mmlux_nl-high_school_macroeconomics": [],
    "ogx_mmlux_nl-high_school_mathematics": [],
    "ogx_mmlux_nl-high_school_microeconomics": [],
    "ogx_mmlux_nl-high_school_physics": [],
    "ogx_mmlux_nl-high_school_psychology": [],
    "ogx_mmlux_nl-high_school_statistics": [],
    "ogx_mmlux_nl-high_school_us_history": [],
    "ogx_mmlux_nl-high_school_world_history": [],
    "ogx_mmlux_nl-human_aging": [],
    "ogx_mmlux_nl-human_sexuality": [],
    "ogx_mmlux_nl-international_law": [],
    "ogx_mmlux_nl-jurisprudence": [],
    "ogx_mmlux_nl-logical_fallacies": [],
    "ogx_mmlux_nl-machine_learning": [],
    "ogx_mmlux_nl-management": [],
    "ogx_mmlux_nl-marketing": [],
    "ogx_mmlux_nl-medical_genetics": [],
    "ogx_mmlux_nl-miscellaneous": [],
    "ogx_mmlux_nl-moral_disputes": [],
    "ogx_mmlux_nl-moral_scenarios": [],
    "ogx_mmlux_nl-nutrition": [],
    "ogx_mmlux_nl-philosophy": [],
    "ogx_mmlux_nl-prehistory": [],
    "ogx_mmlux_nl-professional_accounting": [],
    "ogx_mmlux_nl-professional_law": [],
    "ogx_mmlux_nl-professional_medicine": [],
    "ogx_mmlux_nl-professional_psychology": [],
    "ogx_mmlux_nl-public_relations": [],
    "ogx_mmlux_nl-security_studies": [],
    "ogx_mmlux_nl-sociology": [],
    "ogx_mmlux_nl-us_foreign_policy": [],
    "ogx_mmlux_nl-virology": [],
    "ogx_mmlux_nl-world_religions": [],
    "ogx_mmlux_pl-abstract_algebra": [],
    "ogx_mmlux_pl-anatomy": [],
    "ogx_mmlux_pl-astronomy": [],
    "ogx_mmlux_pl-business_ethics": [],
    "ogx_mmlux_pl-clinical_knowledge": [],
    "ogx_mmlux_pl-college_biology": [],
    "ogx_mmlux_pl-college_chemistry": [],
    "ogx_mmlux_pl-college_computer_science": [],
    "ogx_mmlux_pl-college_mathematics": [],
    "ogx_mmlux_pl-college_medicine": [],
    "ogx_mmlux_pl-college_physics": [],
    "ogx_mmlux_pl-computer_security": [],
    "ogx_mmlux_pl-conceptual_physics": [],
    "ogx_mmlux_pl-econometrics": [],
    "ogx_mmlux_pl-electrical_engineering": [],
    "ogx_mmlux_pl-elementary_mathematics": [],
    "ogx_mmlux_pl-formal_logic": [],
    "ogx_mmlux_pl-global_facts": [],
    "ogx_mmlux_pl-high_school_biology": [],
    "ogx_mmlux_pl-high_school_chemistry": [],
    "ogx_mmlux_pl-high_school_computer_science": [],
    "ogx_mmlux_pl-high_school_european_history": [],
    "ogx_mmlux_pl-high_school_geography": [],
    "ogx_mmlux_pl-high_school_government_and_politics": [],
    "ogx_mmlux_pl-high_school_macroeconomics": [],
    "ogx_mmlux_pl-high_school_mathematics": [],
    "ogx_mmlux_pl-high_school_microeconomics": [],
    "ogx_mmlux_pl-high_school_physics": [],
    "ogx_mmlux_pl-high_school_psychology": [],
    "ogx_mmlux_pl-high_school_statistics": [],
    "ogx_mmlux_pl-high_school_us_history": [],
    "ogx_mmlux_pl-high_school_world_history": [],
    "ogx_mmlux_pl-human_aging": [],
    "ogx_mmlux_pl-human_sexuality": [],
    "ogx_mmlux_pl-international_law": [],
    "ogx_mmlux_pl-jurisprudence": [],
    "ogx_mmlux_pl-logical_fallacies": [],
    "ogx_mmlux_pl-machine_learning": [],
    "ogx_mmlux_pl-management": [],
    "ogx_mmlux_pl-marketing": [],
    "ogx_mmlux_pl-medical_genetics": [],
    "ogx_mmlux_pl-miscellaneous": [],
    "ogx_mmlux_pl-moral_disputes": [],
    "ogx_mmlux_pl-moral_scenarios": [],
    "ogx_mmlux_pl-nutrition": [],
    "ogx_mmlux_pl-philosophy": [],
    "ogx_mmlux_pl-prehistory": [],
    "ogx_mmlux_pl-professional_accounting": [],
    "ogx_mmlux_pl-professional_law": [],
    "ogx_mmlux_pl-professional_medicine": [],
    "ogx_mmlux_pl-professional_psychology": [],
    "ogx_mmlux_pl-public_relations": [],
    "ogx_mmlux_pl-security_studies": [],
    "ogx_mmlux_pl-sociology": [],
    "ogx_mmlux_pl-us_foreign_policy": [],
    "ogx_mmlux_pl-virology": [],
    "ogx_mmlux_pl-world_religions": [],
    "ogx_mmlux_pt-pt-abstract_algebra": [],
    "ogx_mmlux_pt-pt-anatomy": [],
    "ogx_mmlux_pt-pt-astronomy": [],
    "ogx_mmlux_pt-pt-business_ethics": [],
    "ogx_mmlux_pt-pt-clinical_knowledge": [],
    "ogx_mmlux_pt-pt-college_biology": [],
    "ogx_mmlux_pt-pt-college_chemistry": [],
    "ogx_mmlux_pt-pt-college_computer_science": [],
    "ogx_mmlux_pt-pt-college_mathematics": [],
    "ogx_mmlux_pt-pt-college_medicine": [],
    "ogx_mmlux_pt-pt-college_physics": [],
    "ogx_mmlux_pt-pt-computer_security": [],
    "ogx_mmlux_pt-pt-conceptual_physics": [],
    "ogx_mmlux_pt-pt-econometrics": [],
    "ogx_mmlux_pt-pt-electrical_engineering": [],
    "ogx_mmlux_pt-pt-elementary_mathematics": [],
    "ogx_mmlux_pt-pt-formal_logic": [],
    "ogx_mmlux_pt-pt-global_facts": [],
    "ogx_mmlux_pt-pt-high_school_biology": [],
    "ogx_mmlux_pt-pt-high_school_chemistry": [],
    "ogx_mmlux_pt-pt-high_school_computer_science": [],
    "ogx_mmlux_pt-pt-high_school_european_history": [],
    "ogx_mmlux_pt-pt-high_school_geography": [],
    "ogx_mmlux_pt-pt-high_school_government_and_politics": [],
    "ogx_mmlux_pt-pt-high_school_macroeconomics": [],
    "ogx_mmlux_pt-pt-high_school_mathematics": [],
    "ogx_mmlux_pt-pt-high_school_microeconomics": [],
    "ogx_mmlux_pt-pt-high_school_physics": [],
    "ogx_mmlux_pt-pt-high_school_psychology": [],
    "ogx_mmlux_pt-pt-high_school_statistics": [],
    "ogx_mmlux_pt-pt-high_school_us_history": [],
    "ogx_mmlux_pt-pt-high_school_world_history": [],
    "ogx_mmlux_pt-pt-human_aging": [],
    "ogx_mmlux_pt-pt-human_sexuality": [],
    "ogx_mmlux_pt-pt-international_law": [],
    "ogx_mmlux_pt-pt-jurisprudence": [],
    "ogx_mmlux_pt-pt-logical_fallacies": [],
    "ogx_mmlux_pt-pt-machine_learning": [],
    "ogx_mmlux_pt-pt-management": [],
    "ogx_mmlux_pt-pt-marketing": [],
    "ogx_mmlux_pt-pt-medical_genetics": [],
    "ogx_mmlux_pt-pt-miscellaneous": [],
    "ogx_mmlux_pt-pt-moral_disputes": [],
    "ogx_mmlux_pt-pt-moral_scenarios": [],
    "ogx_mmlux_pt-pt-nutrition": [],
    "ogx_mmlux_pt-pt-philosophy": [],
    "ogx_mmlux_pt-pt-prehistory": [],
    "ogx_mmlux_pt-pt-professional_accounting": [],
    "ogx_mmlux_pt-pt-professional_law": [],
    "ogx_mmlux_pt-pt-professional_medicine": [],
    "ogx_mmlux_pt-pt-professional_psychology": [],
    "ogx_mmlux_pt-pt-public_relations": [],
    "ogx_mmlux_pt-pt-security_studies": [],
    "ogx_mmlux_pt-pt-sociology": [],
    "ogx_mmlux_pt-pt-us_foreign_policy": [],
    "ogx_mmlux_pt-pt-virology": [],
    "ogx_mmlux_pt-pt-world_religions": [],
    "ogx_mmlux_ro-abstract_algebra": [],
    "ogx_mmlux_ro-anatomy": [],
    "ogx_mmlux_ro-astronomy": [],
    "ogx_mmlux_ro-business_ethics": [],
    "ogx_mmlux_ro-clinical_knowledge": [],
    "ogx_mmlux_ro-college_biology": [],
    "ogx_mmlux_ro-college_chemistry": [],
    "ogx_mmlux_ro-college_computer_science": [],
    "ogx_mmlux_ro-college_mathematics": [],
    "ogx_mmlux_ro-college_medicine": [],
    "ogx_mmlux_ro-college_physics": [],
    "ogx_mmlux_ro-computer_security": [],
    "ogx_mmlux_ro-conceptual_physics": [],
    "ogx_mmlux_ro-econometrics": [],
    "ogx_mmlux_ro-electrical_engineering": [],
    "ogx_mmlux_ro-elementary_mathematics": [],
    "ogx_mmlux_ro-formal_logic": [],
    "ogx_mmlux_ro-global_facts": [],
    "ogx_mmlux_ro-high_school_biology": [],
    "ogx_mmlux_ro-high_school_chemistry": [],
    "ogx_mmlux_ro-high_school_computer_science": [],
    "ogx_mmlux_ro-high_school_european_history": [],
    "ogx_mmlux_ro-high_school_geography": [],
    "ogx_mmlux_ro-high_school_government_and_politics": [],
    "ogx_mmlux_ro-high_school_macroeconomics": [],
    "ogx_mmlux_ro-high_school_mathematics": [],
    "ogx_mmlux_ro-high_school_microeconomics": [],
    "ogx_mmlux_ro-high_school_physics": [],
    "ogx_mmlux_ro-high_school_psychology": [],
    "ogx_mmlux_ro-high_school_statistics": [],
    "ogx_mmlux_ro-high_school_us_history": [],
    "ogx_mmlux_ro-high_school_world_history": [],
    "ogx_mmlux_ro-human_aging": [],
    "ogx_mmlux_ro-human_sexuality": [],
    "ogx_mmlux_ro-international_law": [],
    "ogx_mmlux_ro-jurisprudence": [],
    "ogx_mmlux_ro-logical_fallacies": [],
    "ogx_mmlux_ro-machine_learning": [],
    "ogx_mmlux_ro-management": [],
    "ogx_mmlux_ro-marketing": [],
    "ogx_mmlux_ro-medical_genetics": [],
    "ogx_mmlux_ro-miscellaneous": [],
    "ogx_mmlux_ro-moral_disputes": [],
    "ogx_mmlux_ro-moral_scenarios": [],
    "ogx_mmlux_ro-nutrition": [],
    "ogx_mmlux_ro-philosophy": [],
    "ogx_mmlux_ro-prehistory": [],
    "ogx_mmlux_ro-professional_accounting": [],
    "ogx_mmlux_ro-professional_law": [],
    "ogx_mmlux_ro-professional_medicine": [],
    "ogx_mmlux_ro-professional_psychology": [],
    "ogx_mmlux_ro-public_relations": [],
    "ogx_mmlux_ro-security_studies": [],
    "ogx_mmlux_ro-sociology": [],
    "ogx_mmlux_ro-us_foreign_policy": [],
    "ogx_mmlux_ro-virology": [],
    "ogx_mmlux_ro-world_religions": [],
    "ogx_mmlux_sk-abstract_algebra": [],
    "ogx_mmlux_sk-anatomy": [],
    "ogx_mmlux_sk-astronomy": [],
    "ogx_mmlux_sk-business_ethics": [],
    "ogx_mmlux_sk-clinical_knowledge": [],
    "ogx_mmlux_sk-college_biology": [],
    "ogx_mmlux_sk-college_chemistry": [],
    "ogx_mmlux_sk-college_computer_science": [],
    "ogx_mmlux_sk-college_mathematics": [],
    "ogx_mmlux_sk-college_medicine": [],
    "ogx_mmlux_sk-college_physics": [],
    "ogx_mmlux_sk-computer_security": [],
    "ogx_mmlux_sk-conceptual_physics": [],
    "ogx_mmlux_sk-econometrics": [],
    "ogx_mmlux_sk-electrical_engineering": [],
    "ogx_mmlux_sk-elementary_mathematics": [],
    "ogx_mmlux_sk-formal_logic": [],
    "ogx_mmlux_sk-global_facts": [],
    "ogx_mmlux_sk-high_school_biology": [],
    "ogx_mmlux_sk-high_school_chemistry": [],
    "ogx_mmlux_sk-high_school_computer_science": [],
    "ogx_mmlux_sk-high_school_european_history": [],
    "ogx_mmlux_sk-high_school_geography": [],
    "ogx_mmlux_sk-high_school_government_and_politics": [],
    "ogx_mmlux_sk-high_school_macroeconomics": [],
    "ogx_mmlux_sk-high_school_mathematics": [],
    "ogx_mmlux_sk-high_school_microeconomics": [],
    "ogx_mmlux_sk-high_school_physics": [],
    "ogx_mmlux_sk-high_school_psychology": [],
    "ogx_mmlux_sk-high_school_statistics": [],
    "ogx_mmlux_sk-high_school_us_history": [],
    "ogx_mmlux_sk-high_school_world_history": [],
    "ogx_mmlux_sk-human_aging": [],
    "ogx_mmlux_sk-human_sexuality": [],
    "ogx_mmlux_sk-international_law": [],
    "ogx_mmlux_sk-jurisprudence": [],
    "ogx_mmlux_sk-logical_fallacies": [],
    "ogx_mmlux_sk-machine_learning": [],
    "ogx_mmlux_sk-management": [],
    "ogx_mmlux_sk-marketing": [],
    "ogx_mmlux_sk-medical_genetics": [],
    "ogx_mmlux_sk-miscellaneous": [],
    "ogx_mmlux_sk-moral_disputes": [],
    "ogx_mmlux_sk-moral_scenarios": [],
    "ogx_mmlux_sk-nutrition": [],
    "ogx_mmlux_sk-philosophy": [],
    "ogx_mmlux_sk-prehistory": [],
    "ogx_mmlux_sk-professional_accounting": [],
    "ogx_mmlux_sk-professional_law": [],
    "ogx_mmlux_sk-professional_medicine": [],
    "ogx_mmlux_sk-professional_psychology": [],
    "ogx_mmlux_sk-public_relations": [],
    "ogx_mmlux_sk-security_studies": [],
    "ogx_mmlux_sk-sociology": [],
    "ogx_mmlux_sk-us_foreign_policy": [],
    "ogx_mmlux_sk-virology": [],
    "ogx_mmlux_sk-world_religions": [],
    "ogx_mmlux_sl-abstract_algebra": [],
    "ogx_mmlux_sl-anatomy": [],
    "ogx_mmlux_sl-astronomy": [],
    "ogx_mmlux_sl-business_ethics": [],
    "ogx_mmlux_sl-clinical_knowledge": [],
    "ogx_mmlux_sl-college_biology": [],
    "ogx_mmlux_sl-college_chemistry": [],
    "ogx_mmlux_sl-college_computer_science": [],
    "ogx_mmlux_sl-college_mathematics": [],
    "ogx_mmlux_sl-college_medicine": [],
    "ogx_mmlux_sl-college_physics": [],
    "ogx_mmlux_sl-computer_security": [],
    "ogx_mmlux_sl-conceptual_physics": [],
    "ogx_mmlux_sl-econometrics": [],
    "ogx_mmlux_sl-electrical_engineering": [],
    "ogx_mmlux_sl-elementary_mathematics": [],
    "ogx_mmlux_sl-formal_logic": [],
    "ogx_mmlux_sl-global_facts": [],
    "ogx_mmlux_sl-high_school_biology": [],
    "ogx_mmlux_sl-high_school_chemistry": [],
    "ogx_mmlux_sl-high_school_computer_science": [],
    "ogx_mmlux_sl-high_school_european_history": [],
    "ogx_mmlux_sl-high_school_geography": [],
    "ogx_mmlux_sl-high_school_government_and_politics": [],
    "ogx_mmlux_sl-high_school_macroeconomics": [],
    "ogx_mmlux_sl-high_school_mathematics": [],
    "ogx_mmlux_sl-high_school_microeconomics": [],
    "ogx_mmlux_sl-high_school_physics": [],
    "ogx_mmlux_sl-high_school_psychology": [],
    "ogx_mmlux_sl-high_school_statistics": [],
    "ogx_mmlux_sl-high_school_us_history": [],
    "ogx_mmlux_sl-high_school_world_history": [],
    "ogx_mmlux_sl-human_aging": [],
    "ogx_mmlux_sl-human_sexuality": [],
    "ogx_mmlux_sl-international_law": [],
    "ogx_mmlux_sl-jurisprudence": [],
    "ogx_mmlux_sl-logical_fallacies": [],
    "ogx_mmlux_sl-machine_learning": [],
    "ogx_mmlux_sl-management": [],
    "ogx_mmlux_sl-marketing": [],
    "ogx_mmlux_sl-medical_genetics": [],
    "ogx_mmlux_sl-miscellaneous": [],
    "ogx_mmlux_sl-moral_disputes": [],
    "ogx_mmlux_sl-moral_scenarios": [],
    "ogx_mmlux_sl-nutrition": [],
    "ogx_mmlux_sl-philosophy": [],
    "ogx_mmlux_sl-prehistory": [],
    "ogx_mmlux_sl-professional_accounting": [],
    "ogx_mmlux_sl-professional_law": [],
    "ogx_mmlux_sl-professional_medicine": [],
    "ogx_mmlux_sl-professional_psychology": [],
    "ogx_mmlux_sl-public_relations": [],
    "ogx_mmlux_sl-security_studies": [],
    "ogx_mmlux_sl-sociology": [],
    "ogx_mmlux_sl-us_foreign_policy": [],
    "ogx_mmlux_sl-virology": [],
    "ogx_mmlux_sl-world_religions": [],
    "ogx_mmlux_sv-abstract_algebra": [],
    "ogx_mmlux_sv-anatomy": [],
    "ogx_mmlux_sv-astronomy": [],
    "ogx_mmlux_sv-business_ethics": [],
    "ogx_mmlux_sv-clinical_knowledge": [],
    "ogx_mmlux_sv-college_biology": [],
    "ogx_mmlux_sv-college_chemistry": [],
    "ogx_mmlux_sv-college_computer_science": [],
    "ogx_mmlux_sv-college_mathematics": [],
    "ogx_mmlux_sv-college_medicine": [],
    "ogx_mmlux_sv-college_physics": [],
    "ogx_mmlux_sv-computer_security": [],
    "ogx_mmlux_sv-conceptual_physics": [],
    "ogx_mmlux_sv-econometrics": [],
    "ogx_mmlux_sv-electrical_engineering": [],
    "ogx_mmlux_sv-elementary_mathematics": [],
    "ogx_mmlux_sv-formal_logic": [],
    "ogx_mmlux_sv-global_facts": [],
    "ogx_mmlux_sv-high_school_biology": [],
    "ogx_mmlux_sv-high_school_chemistry": [],
    "ogx_mmlux_sv-high_school_computer_science": [],
    "ogx_mmlux_sv-high_school_european_history": [],
    "ogx_mmlux_sv-high_school_geography": [],
    "ogx_mmlux_sv-high_school_government_and_politics": [],
    "ogx_mmlux_sv-high_school_macroeconomics": [],
    "ogx_mmlux_sv-high_school_mathematics": [],
    "ogx_mmlux_sv-high_school_microeconomics": [],
    "ogx_mmlux_sv-high_school_physics": [],
    "ogx_mmlux_sv-high_school_psychology": [],
    "ogx_mmlux_sv-high_school_statistics": [],
    "ogx_mmlux_sv-high_school_us_history": [],
    "ogx_mmlux_sv-high_school_world_history": [],
    "ogx_mmlux_sv-human_aging": [],
    "ogx_mmlux_sv-human_sexuality": [],
    "ogx_mmlux_sv-international_law": [],
    "ogx_mmlux_sv-jurisprudence": [],
    "ogx_mmlux_sv-logical_fallacies": [],
    "ogx_mmlux_sv-machine_learning": [],
    "ogx_mmlux_sv-management": [],
    "ogx_mmlux_sv-marketing": [],
    "ogx_mmlux_sv-medical_genetics": [],
    "ogx_mmlux_sv-miscellaneous": [],
    "ogx_mmlux_sv-moral_disputes": [],
    "ogx_mmlux_sv-moral_scenarios": [],
    "ogx_mmlux_sv-nutrition": [],
    "ogx_mmlux_sv-philosophy": [],
    "ogx_mmlux_sv-prehistory": [],
    "ogx_mmlux_sv-professional_accounting": [],
    "ogx_mmlux_sv-professional_law": [],
    "ogx_mmlux_sv-professional_medicine": [],
    "ogx_mmlux_sv-professional_psychology": [],
    "ogx_mmlux_sv-public_relations": [],
    "ogx_mmlux_sv-security_studies": [],
    "ogx_mmlux_sv-sociology": [],
    "ogx_mmlux_sv-us_foreign_policy": [],
    "ogx_mmlux_sv-virology": [],
    "ogx_mmlux_sv-world_religions": []
  },
  "configs": {
    "ogx_mmlux_bg-abstract_algebra": {
      "task": "ogx_mmlux_bg-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за абстрактната алгебра.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-anatomy": {
      "task": "ogx_mmlux_bg-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за анатомията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-astronomy": {
      "task": "ogx_mmlux_bg-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за астрономията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-business_ethics": {
      "task": "ogx_mmlux_bg-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за бизнес етиката.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "task": "ogx_mmlux_bg-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за клинични знания.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_biology": {
      "task": "ogx_mmlux_bg-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по биология в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_chemistry": {
      "task": "ogx_mmlux_bg-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по химия в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_computer_science": {
      "task": "ogx_mmlux_bg-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по информатика в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_mathematics": {
      "task": "ogx_mmlux_bg-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по математика в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_medicine": {
      "task": "ogx_mmlux_bg-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за университетската медицина.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-college_physics": {
      "task": "ogx_mmlux_bg-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по физика в колежа.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-computer_security": {
      "task": "ogx_mmlux_bg-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за компютърната сигурност.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "task": "ogx_mmlux_bg-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за концептуалната физика.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-econometrics": {
      "task": "ogx_mmlux_bg-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за иконометрията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "task": "ogx_mmlux_bg-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за електротехниката.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "task": "ogx_mmlux_bg-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по елементарна математика.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-formal_logic": {
      "task": "ogx_mmlux_bg-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за формалната логика.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-global_facts": {
      "task": "ogx_mmlux_bg-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за глобалните факти.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_biology": {
      "task": "ogx_mmlux_bg-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по биология за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "task": "ogx_mmlux_bg-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по химия за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "task": "ogx_mmlux_bg-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по информатика в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "task": "ogx_mmlux_bg-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по история на Европа в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_geography": {
      "task": "ogx_mmlux_bg-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по география за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "task": "ogx_mmlux_bg-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за управлението и политиката в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "task": "ogx_mmlux_bg-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по макроикономика за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "task": "ogx_mmlux_bg-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за математиката в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "task": "ogx_mmlux_bg-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по микроикономика за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_physics": {
      "task": "ogx_mmlux_bg-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по физика за гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "task": "ogx_mmlux_bg-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по психология в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "task": "ogx_mmlux_bg-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за статистиката в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "task": "ogx_mmlux_bg-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по история на САЩ в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "task": "ogx_mmlux_bg-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по история на света в гимназията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-human_aging": {
      "task": "ogx_mmlux_bg-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за човешкото стареене.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-human_sexuality": {
      "task": "ogx_mmlux_bg-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за човешката сексуалност.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-international_law": {
      "task": "ogx_mmlux_bg-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за международното право.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-jurisprudence": {
      "task": "ogx_mmlux_bg-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за юриспруденцията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "task": "ogx_mmlux_bg-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за логическите грешки.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-machine_learning": {
      "task": "ogx_mmlux_bg-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за машинното обучение.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-management": {
      "task": "ogx_mmlux_bg-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за управлението.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-marketing": {
      "task": "ogx_mmlux_bg-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за маркетинга.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-medical_genetics": {
      "task": "ogx_mmlux_bg-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за медицинската генетика.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-miscellaneous": {
      "task": "ogx_mmlux_bg-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с въпроси с избор (с отговори) за miscellaneous.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-moral_disputes": {
      "task": "ogx_mmlux_bg-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за морални спорове.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "task": "ogx_mmlux_bg-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за морални сценарии.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-nutrition": {
      "task": "ogx_mmlux_bg-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за храненето.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-philosophy": {
      "task": "ogx_mmlux_bg-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за философията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-prehistory": {
      "task": "ogx_mmlux_bg-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за праисторията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_accounting": {
      "task": "ogx_mmlux_bg-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за професионалното счетоводство.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_law": {
      "task": "ogx_mmlux_bg-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора, свързани с професионалното право.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_medicine": {
      "task": "ogx_mmlux_bg-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за професионалната медицина.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-professional_psychology": {
      "task": "ogx_mmlux_bg-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за професионалната психология.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-public_relations": {
      "task": "ogx_mmlux_bg-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избор между няколко отговора за връзките с обществеността.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-security_studies": {
      "task": "ogx_mmlux_bg-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за проучвания в областта на сигурността.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-sociology": {
      "task": "ogx_mmlux_bg-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) по социология.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "task": "ogx_mmlux_bg-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с въпроси с избор (с отговори) за външната политика на САЩ.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-virology": {
      "task": "ogx_mmlux_bg-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор за вирусологията.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_bg-world_religions": {
      "task": "ogx_mmlux_bg-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_BG",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nА. {{choices[0]}}\nБ. {{choices[1]}}\nВ. {{choices[2]}}\nГ. {{choices[3]}}\nОтговор:",
      "doc_to_target": "answer",
      "doc_to_choice": "['А', 'Б', 'В', 'Г']",
      "description": "Следват въпроси с избираем отговор (с отговори) за световните религии.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "task": "ogx_mmlux_cs-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o abstraktní algebře.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-anatomy": {
      "task": "ogx_mmlux_cs-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o anatomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-astronomy": {
      "task": "ogx_mmlux_cs-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o astronomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-business_ethics": {
      "task": "ogx_mmlux_cs-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o etice podnikání.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "task": "ogx_mmlux_cs-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o klinických znalostech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_biology": {
      "task": "ogx_mmlux_cs-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské biologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_chemistry": {
      "task": "ogx_mmlux_cs-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské chemii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_computer_science": {
      "task": "ogx_mmlux_cs-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské informatice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_mathematics": {
      "task": "ogx_mmlux_cs-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_medicine": {
      "task": "ogx_mmlux_cs-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vysokoškolské medicíně.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-college_physics": {
      "task": "ogx_mmlux_cs-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z vysokoškolské fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-computer_security": {
      "task": "ogx_mmlux_cs-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o počítačové bezpečnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "task": "ogx_mmlux_cs-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z konceptuální fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-econometrics": {
      "task": "ogx_mmlux_cs-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "task": "ogx_mmlux_cs-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o elektrotechnice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "task": "ogx_mmlux_cs-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o elementární matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-formal_logic": {
      "task": "ogx_mmlux_cs-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o formální logice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-global_facts": {
      "task": "ogx_mmlux_cs-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o globálních faktech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_biology": {
      "task": "ogx_mmlux_cs-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské biologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "task": "ogx_mmlux_cs-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské chemii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "task": "ogx_mmlux_cs-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské informatice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "task": "ogx_mmlux_cs-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z dějin Evropy pro střední školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_geography": {
      "task": "ogx_mmlux_cs-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolském zeměpisu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "task": "ogx_mmlux_cs-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské vládě a politice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "task": "ogx_mmlux_cs-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z makroekonomie pro střední školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "task": "ogx_mmlux_cs-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské matematice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "task": "ogx_mmlux_cs-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí z mikroekonomie pro střední školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_physics": {
      "task": "ogx_mmlux_cs-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí ze středoškolské fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "task": "ogx_mmlux_cs-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské psychologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "task": "ogx_mmlux_cs-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o středoškolské statistice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "task": "ogx_mmlux_cs-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky s výběrem odpovědí se týkají středoškolské historie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "task": "ogx_mmlux_cs-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí ze světových dějin pro střední školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-human_aging": {
      "task": "ogx_mmlux_cs-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o stárnutí člověka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-human_sexuality": {
      "task": "ogx_mmlux_cs-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o lidské sexualitě.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-international_law": {
      "task": "ogx_mmlux_cs-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o mezinárodním právu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-jurisprudence": {
      "task": "ogx_mmlux_cs-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o právu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "task": "ogx_mmlux_cs-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o logických klamech.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-machine_learning": {
      "task": "ogx_mmlux_cs-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o strojovém učení.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-management": {
      "task": "ogx_mmlux_cs-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky (s odpověďmi) se týkají managementu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-marketing": {
      "task": "ogx_mmlux_cs-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky (s odpověďmi) se týkají marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-medical_genetics": {
      "task": "ogx_mmlux_cs-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o lékařské genetice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-miscellaneous": {
      "task": "ogx_mmlux_cs-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky s výběrem odpovědi se týkají tématu miscellaneous.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-moral_disputes": {
      "task": "ogx_mmlux_cs-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky s výběrem odpovědí se týkají morálních sporů.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "task": "ogx_mmlux_cs-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o morálních scénářích.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-nutrition": {
      "task": "ogx_mmlux_cs-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o výživě.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-philosophy": {
      "task": "ogx_mmlux_cs-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-prehistory": {
      "task": "ogx_mmlux_cs-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o pravěku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_accounting": {
      "task": "ogx_mmlux_cs-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o odborném účetnictví.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_law": {
      "task": "ogx_mmlux_cs-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o profesním právu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_medicine": {
      "task": "ogx_mmlux_cs-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o profesionální medicíně.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-professional_psychology": {
      "task": "ogx_mmlux_cs-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o odborné psychologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-public_relations": {
      "task": "ogx_mmlux_cs-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o vztazích s veřejností.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-security_studies": {
      "task": "ogx_mmlux_cs-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o bezpečnostních studiích.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-sociology": {
      "task": "ogx_mmlux_cs-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o sociologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "task": "ogx_mmlux_cs-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následující otázky s výběrem odpovědí se týkají zahraniční politiky USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-virology": {
      "task": "ogx_mmlux_cs-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o virologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_cs-world_religions": {
      "task": "ogx_mmlux_cs-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_CS",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpověď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Následují otázky s výběrem odpovědí o světových náboženstvích.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-abstract_algebra": {
      "task": "ogx_mmlux_da-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om abstrakt algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-anatomy": {
      "task": "ogx_mmlux_da-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om anatomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-astronomy": {
      "task": "ogx_mmlux_da-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om astronomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-business_ethics": {
      "task": "ogx_mmlux_da-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om forretningsetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "task": "ogx_mmlux_da-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om klinisk viden.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_biology": {
      "task": "ogx_mmlux_da-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om universitetsbiologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_chemistry": {
      "task": "ogx_mmlux_da-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om kemi på college.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_computer_science": {
      "task": "ogx_mmlux_da-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om computervidenskab på college.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_mathematics": {
      "task": "ogx_mmlux_da-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om universitetsmatematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_medicine": {
      "task": "ogx_mmlux_da-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om universitetsmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-college_physics": {
      "task": "ogx_mmlux_da-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om universitetsfysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-computer_security": {
      "task": "ogx_mmlux_da-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om computersikkerhed.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-conceptual_physics": {
      "task": "ogx_mmlux_da-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om konceptuel fysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-econometrics": {
      "task": "ogx_mmlux_da-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om økonometri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-electrical_engineering": {
      "task": "ogx_mmlux_da-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om elektroteknik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "task": "ogx_mmlux_da-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om elementær matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-formal_logic": {
      "task": "ogx_mmlux_da-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om formel logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-global_facts": {
      "task": "ogx_mmlux_da-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om globale fakta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_biology": {
      "task": "ogx_mmlux_da-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om biologi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "task": "ogx_mmlux_da-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om kemi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "task": "ogx_mmlux_da-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om computervidenskab i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_european_history": {
      "task": "ogx_mmlux_da-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om europæisk historie i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_geography": {
      "task": "ogx_mmlux_da-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om geografi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "task": "ogx_mmlux_da-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om regering og politik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "task": "ogx_mmlux_da-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om makroøkonomi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "task": "ogx_mmlux_da-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om matematik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "task": "ogx_mmlux_da-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det følgende er multiple choice-spørgsmål (med svar) om mikroøkonomi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_physics": {
      "task": "ogx_mmlux_da-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om fysik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_psychology": {
      "task": "ogx_mmlux_da-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om psykologi i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_statistics": {
      "task": "ogx_mmlux_da-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om statistik i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_us_history": {
      "task": "ogx_mmlux_da-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om amerikansk historie i high school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-high_school_world_history": {
      "task": "ogx_mmlux_da-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om verdenshistorie i gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-human_aging": {
      "task": "ogx_mmlux_da-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om menneskets aldring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-human_sexuality": {
      "task": "ogx_mmlux_da-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om menneskelig seksualitet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-international_law": {
      "task": "ogx_mmlux_da-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om international lov.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-jurisprudence": {
      "task": "ogx_mmlux_da-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om retsvidenskab.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-logical_fallacies": {
      "task": "ogx_mmlux_da-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om logiske fejlslutninger.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-machine_learning": {
      "task": "ogx_mmlux_da-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om maskinlæring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-management": {
      "task": "ogx_mmlux_da-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om ledelse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-marketing": {
      "task": "ogx_mmlux_da-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-medical_genetics": {
      "task": "ogx_mmlux_da-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om medicinsk genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-miscellaneous": {
      "task": "ogx_mmlux_da-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-moral_disputes": {
      "task": "ogx_mmlux_da-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om moralske tvister.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-moral_scenarios": {
      "task": "ogx_mmlux_da-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om moralske scenarier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-nutrition": {
      "task": "ogx_mmlux_da-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om ernæring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-philosophy": {
      "task": "ogx_mmlux_da-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om filosofi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-prehistory": {
      "task": "ogx_mmlux_da-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det følgende er multiple choice-spørgsmål (med svar) om forhistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_accounting": {
      "task": "ogx_mmlux_da-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om professionelt regnskab.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_law": {
      "task": "ogx_mmlux_da-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om erhvervsret.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_medicine": {
      "task": "ogx_mmlux_da-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om professionel medicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-professional_psychology": {
      "task": "ogx_mmlux_da-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om professionel psykologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-public_relations": {
      "task": "ogx_mmlux_da-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-security_studies": {
      "task": "ogx_mmlux_da-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om sikkerhedsstudier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-sociology": {
      "task": "ogx_mmlux_da-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om sociologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "task": "ogx_mmlux_da-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om amerikansk udenrigspolitik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-virology": {
      "task": "ogx_mmlux_da-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Følgende er multiple choice-spørgsmål (med svar) om virologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_da-world_religions": {
      "task": "ogx_mmlux_da-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_DA",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Det følgende er multiple choice-spørgsmål (med svar) om verdensreligioner.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-abstract_algebra": {
      "task": "ogx_mmlux_de-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur abstrakten Algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-anatomy": {
      "task": "ogx_mmlux_de-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-astronomy": {
      "task": "ogx_mmlux_de-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-business_ethics": {
      "task": "ogx_mmlux_de-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Unternehmensethik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "task": "ogx_mmlux_de-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu klinischen Kenntnissen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_biology": {
      "task": "ogx_mmlux_de-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Biologie an der Universität.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_chemistry": {
      "task": "ogx_mmlux_de-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Chemie an Hochschulen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_computer_science": {
      "task": "ogx_mmlux_de-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulinformatik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_mathematics": {
      "task": "ogx_mmlux_de-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulmathematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_medicine": {
      "task": "ogx_mmlux_de-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Hochschulmedizin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-college_physics": {
      "task": "ogx_mmlux_de-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Hochschulphysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-computer_security": {
      "task": "ogx_mmlux_de-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Computersicherheit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-conceptual_physics": {
      "task": "ogx_mmlux_de-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur konzeptionellen Physik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-econometrics": {
      "task": "ogx_mmlux_de-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Ökonometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-electrical_engineering": {
      "task": "ogx_mmlux_de-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Elektrotechnik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "task": "ogx_mmlux_de-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur elementaren Mathematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-formal_logic": {
      "task": "ogx_mmlux_de-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur formalen Logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-global_facts": {
      "task": "ogx_mmlux_de-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu globalen Fakten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_biology": {
      "task": "ogx_mmlux_de-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Biologie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "task": "ogx_mmlux_de-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Chemie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "task": "ogx_mmlux_de-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Informatik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_european_history": {
      "task": "ogx_mmlux_de-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur europäischen Geschichte in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_geography": {
      "task": "ogx_mmlux_de-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Geografie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "task": "ogx_mmlux_de-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Regierung und Politik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "task": "ogx_mmlux_de-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Makroökonomie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "task": "ogx_mmlux_de-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Mathematik in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "task": "ogx_mmlux_de-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Mikroökonomie in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_physics": {
      "task": "ogx_mmlux_de-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Physik in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_psychology": {
      "task": "ogx_mmlux_de-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Schulpsychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_statistics": {
      "task": "ogx_mmlux_de-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nachfolgend finden Sie Multiple-Choice-Fragen (mit Antworten) zur Statistik in der Schule.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_us_history": {
      "task": "ogx_mmlux_de-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Geschichte der USA in der High School.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-high_school_world_history": {
      "task": "ogx_mmlux_de-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Weltgeschichte in der Oberstufe.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-human_aging": {
      "task": "ogx_mmlux_de-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum menschlichen Altern.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-human_sexuality": {
      "task": "ogx_mmlux_de-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur menschlichen Sexualität.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-international_law": {
      "task": "ogx_mmlux_de-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum internationalen Recht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-jurisprudence": {
      "task": "ogx_mmlux_de-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Rechtswissenschaft.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-logical_fallacies": {
      "task": "ogx_mmlux_de-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu logischen Fehlschlüssen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-machine_learning": {
      "task": "ogx_mmlux_de-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum maschinellen Lernen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-management": {
      "task": "ogx_mmlux_de-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-marketing": {
      "task": "ogx_mmlux_de-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-medical_genetics": {
      "task": "ogx_mmlux_de-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur medizinischen Genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-miscellaneous": {
      "task": "ogx_mmlux_de-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Verschiedenes.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-moral_disputes": {
      "task": "ogx_mmlux_de-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu moralischen Streitigkeiten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-moral_scenarios": {
      "task": "ogx_mmlux_de-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu moralischen Szenarien.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-nutrition": {
      "task": "ogx_mmlux_de-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Ernährung.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-philosophy": {
      "task": "ogx_mmlux_de-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Philosophie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-prehistory": {
      "task": "ogx_mmlux_de-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Vorgeschichte.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_accounting": {
      "task": "ogx_mmlux_de-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema professionelle Buchhaltung.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_law": {
      "task": "ogx_mmlux_de-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Berufsrecht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_medicine": {
      "task": "ogx_mmlux_de-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Berufsmedizin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-professional_psychology": {
      "task": "ogx_mmlux_de-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Berufspsychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-public_relations": {
      "task": "ogx_mmlux_de-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zum Thema Öffentlichkeitsarbeit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-security_studies": {
      "task": "ogx_mmlux_de-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Es folgen Multiple-Choice-Fragen (mit Antworten) zu Sicherheitsstudien.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-sociology": {
      "task": "ogx_mmlux_de-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Soziologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "task": "ogx_mmlux_de-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Außenpolitik der USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-virology": {
      "task": "ogx_mmlux_de-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zur Virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_de-world_religions": {
      "task": "ogx_mmlux_de-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_DE",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwort:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Im Folgenden finden Sie Multiple-Choice-Fragen (mit Antworten) zu den Weltreligionen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-abstract_algebra": {
      "task": "ogx_mmlux_el-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την αφηρημένη άλγεβρα.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-anatomy": {
      "task": "ogx_mmlux_el-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ανατομία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-astronomy": {
      "task": "ogx_mmlux_el-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την αστρονομία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-business_ethics": {
      "task": "ogx_mmlux_el-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επιχειρηματική ηθική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "task": "ogx_mmlux_el-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις κλινικές γνώσεις.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_biology": {
      "task": "ogx_mmlux_el-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη βιολογία του κολεγίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_chemistry": {
      "task": "ogx_mmlux_el-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη χημεία του πανεπιστημίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_computer_science": {
      "task": "ogx_mmlux_el-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επιστήμη των υπολογιστών στο κολέγιο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_mathematics": {
      "task": "ogx_mmlux_el-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα μαθηματικά του πανεπιστημίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_medicine": {
      "task": "ogx_mmlux_el-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ιατρική στο κολέγιο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-college_physics": {
      "task": "ogx_mmlux_el-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη φυσική του πανεπιστημίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-computer_security": {
      "task": "ogx_mmlux_el-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ασφάλεια των υπολογιστών.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-conceptual_physics": {
      "task": "ogx_mmlux_el-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την εννοιολογική φυσική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-econometrics": {
      "task": "ogx_mmlux_el-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την οικονομετρία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-electrical_engineering": {
      "task": "ogx_mmlux_el-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ηλεκτρολογική μηχανική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "task": "ogx_mmlux_el-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα στοιχειώδη μαθηματικά.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-formal_logic": {
      "task": "ogx_mmlux_el-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την τυπική λογική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-global_facts": {
      "task": "ogx_mmlux_el-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα παγκόσμια γεγονότα.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_biology": {
      "task": "ogx_mmlux_el-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη βιολογία γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "task": "ogx_mmlux_el-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη χημεία του γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "task": "ogx_mmlux_el-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επιστήμη των υπολογιστών στο λύκειο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_european_history": {
      "task": "ogx_mmlux_el-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ευρωπαϊκή ιστορία του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_geography": {
      "task": "ogx_mmlux_el-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη γεωγραφία του γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "task": "ogx_mmlux_el-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την κυβέρνηση και την πολιτική στο λύκειο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "task": "ogx_mmlux_el-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα μακροοικονομικά του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "task": "ogx_mmlux_el-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα μαθηματικά του γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "task": "ogx_mmlux_el-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη μικροοικονομία του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_physics": {
      "task": "ogx_mmlux_el-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη φυσική γυμνασίου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_psychology": {
      "task": "ogx_mmlux_el-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ψυχολογία του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_statistics": {
      "task": "ogx_mmlux_el-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη στατιστική του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_us_history": {
      "task": "ogx_mmlux_el-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ιστορία μας στο λύκειο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-high_school_world_history": {
      "task": "ogx_mmlux_el-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την παγκόσμια ιστορία του λυκείου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-human_aging": {
      "task": "ogx_mmlux_el-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη γήρανση του ανθρώπου.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-human_sexuality": {
      "task": "ogx_mmlux_el-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ανθρώπινη σεξουαλικότητα.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-international_law": {
      "task": "ogx_mmlux_el-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με το διεθνές δίκαιο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-jurisprudence": {
      "task": "ogx_mmlux_el-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη νομική επιστήμη.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-logical_fallacies": {
      "task": "ogx_mmlux_el-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις λογικές πλάνες.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-machine_learning": {
      "task": "ogx_mmlux_el-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη μηχανική μάθηση.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-management": {
      "task": "ogx_mmlux_el-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη διαχείριση.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-marketing": {
      "task": "ogx_mmlux_el-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με το μάρκετινγκ.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-medical_genetics": {
      "task": "ogx_mmlux_el-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ιατρική γενετική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-miscellaneous": {
      "task": "ogx_mmlux_el-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τα διάφορα.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-moral_disputes": {
      "task": "ogx_mmlux_el-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις ηθικές διαμάχες.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-moral_scenarios": {
      "task": "ogx_mmlux_el-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με ηθικά σενάρια.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-nutrition": {
      "task": "ogx_mmlux_el-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη διατροφή.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-philosophy": {
      "task": "ogx_mmlux_el-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τη φιλοσοφία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-prehistory": {
      "task": "ogx_mmlux_el-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την προϊστορία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_accounting": {
      "task": "ogx_mmlux_el-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επαγγελματική λογιστική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_law": {
      "task": "ogx_mmlux_el-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με το επαγγελματικό δίκαιο.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_medicine": {
      "task": "ogx_mmlux_el-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επαγγελματική ιατρική.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-professional_psychology": {
      "task": "ogx_mmlux_el-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την επαγγελματική ψυχολογία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-public_relations": {
      "task": "ogx_mmlux_el-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις δημόσιες σχέσεις.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-security_studies": {
      "task": "ogx_mmlux_el-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις μελέτες ασφάλειας.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-sociology": {
      "task": "ogx_mmlux_el-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την κοινωνιολογία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "task": "ogx_mmlux_el-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την εξωτερική πολιτική των ΗΠΑ.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-virology": {
      "task": "ogx_mmlux_el-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με την ιολογία.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_el-world_religions": {
      "task": "ogx_mmlux_el-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_EL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nΑ. {{choices[0]}}\nΒ. {{choices[1]}}\nΓ. {{choices[2]}}\nΔ. {{choices[3]}}\nΑπάντηση:",
      "doc_to_target": "answer",
      "doc_to_choice": "['Α', 'Β', 'Γ', 'Δ']",
      "description": "Ακολουθούν ερωτήσεις πολλαπλής επιλογής (με απαντήσεις) σχετικά με τις παγκόσμιες θρησκείες.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-abstract_algebra": {
      "task": "ogx_mmlux_es-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre álgebra abstracta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-anatomy": {
      "task": "ogx_mmlux_es-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre anatomía.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-astronomy": {
      "task": "ogx_mmlux_es-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre astronomía.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-business_ethics": {
      "task": "ogx_mmlux_es-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre ética empresarial.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "task": "ogx_mmlux_es-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A continuación se presentan preguntas tipo test (con respuesta) sobre conocimientos clínicos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_biology": {
      "task": "ogx_mmlux_es-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre biología universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_chemistry": {
      "task": "ogx_mmlux_es-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre química universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_computer_science": {
      "task": "ogx_mmlux_es-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre informática universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_mathematics": {
      "task": "ogx_mmlux_es-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemáticas universitarias.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_medicine": {
      "task": "ogx_mmlux_es-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre medicina universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-college_physics": {
      "task": "ogx_mmlux_es-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre física universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-computer_security": {
      "task": "ogx_mmlux_es-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre seguridad informática.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-conceptual_physics": {
      "task": "ogx_mmlux_es-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre física conceptual.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-econometrics": {
      "task": "ogx_mmlux_es-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre econometría.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-electrical_engineering": {
      "task": "ogx_mmlux_es-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre ingeniería eléctrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "task": "ogx_mmlux_es-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemáticas elementales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-formal_logic": {
      "task": "ogx_mmlux_es-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre lógica formal.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-global_facts": {
      "task": "ogx_mmlux_es-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre hechos globales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_biology": {
      "task": "ogx_mmlux_es-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre biología de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "task": "ogx_mmlux_es-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre química de bachillerato.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "task": "ogx_mmlux_es-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre informática en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_european_history": {
      "task": "ogx_mmlux_es-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre historia europea de bachillerato.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_geography": {
      "task": "ogx_mmlux_es-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre geografía de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "task": "ogx_mmlux_es-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre el gobierno y la política en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "task": "ogx_mmlux_es-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre macroeconomía en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "task": "ogx_mmlux_es-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre matemáticas de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "task": "ogx_mmlux_es-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre microeconomía en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_physics": {
      "task": "ogx_mmlux_es-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre física de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_psychology": {
      "task": "ogx_mmlux_es-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre psicología en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_statistics": {
      "task": "ogx_mmlux_es-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre estadística de secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_us_history": {
      "task": "ogx_mmlux_es-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre la historia de EE.UU. en la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-high_school_world_history": {
      "task": "ogx_mmlux_es-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre la historia mundial de la escuela secundaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-human_aging": {
      "task": "ogx_mmlux_es-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre el envejecimiento humano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-human_sexuality": {
      "task": "ogx_mmlux_es-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre la sexualidad humana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-international_law": {
      "task": "ogx_mmlux_es-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre Derecho internacional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-jurisprudence": {
      "task": "ogx_mmlux_es-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre jurisprudencia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-logical_fallacies": {
      "task": "ogx_mmlux_es-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre falacias lógicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-machine_learning": {
      "task": "ogx_mmlux_es-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre aprendizaje automático.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-management": {
      "task": "ogx_mmlux_es-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre gestión.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-marketing": {
      "task": "ogx_mmlux_es-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-medical_genetics": {
      "task": "ogx_mmlux_es-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre genética médica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-miscellaneous": {
      "task": "ogx_mmlux_es-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre miscelánea.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-moral_disputes": {
      "task": "ogx_mmlux_es-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre disputas morales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-moral_scenarios": {
      "task": "ogx_mmlux_es-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre escenarios morales.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-nutrition": {
      "task": "ogx_mmlux_es-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre nutrición.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-philosophy": {
      "task": "ogx_mmlux_es-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre filosofía.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-prehistory": {
      "task": "ogx_mmlux_es-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre la prehistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_accounting": {
      "task": "ogx_mmlux_es-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre contabilidad profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_law": {
      "task": "ogx_mmlux_es-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A continuación se presentan preguntas tipo test (con respuesta) sobre Derecho profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_medicine": {
      "task": "ogx_mmlux_es-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre medicina profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-professional_psychology": {
      "task": "ogx_mmlux_es-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre psicología profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-public_relations": {
      "task": "ogx_mmlux_es-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre relaciones públicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-security_studies": {
      "task": "ogx_mmlux_es-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuesta) sobre estudios de seguridad.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-sociology": {
      "task": "ogx_mmlux_es-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre sociología.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "task": "ogx_mmlux_es-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas tipo test (con respuestas) sobre la política exterior estadounidense.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-virology": {
      "task": "ogx_mmlux_es-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre virología.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_es-world_religions": {
      "task": "ogx_mmlux_es-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_ES",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRespuesta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Las siguientes son preguntas de opción múltiple (con respuestas) sobre las religiones del mundo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-abstract_algebra": {
      "task": "ogx_mmlux_et-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) abstraktse algebra kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-anatomy": {
      "task": "ogx_mmlux_et-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) anatoomia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-astronomy": {
      "task": "ogx_mmlux_et-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) astronoomia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-business_ethics": {
      "task": "ogx_mmlux_et-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) ärieetika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "task": "ogx_mmlux_et-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kliiniliste teadmiste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_biology": {
      "task": "ogx_mmlux_et-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži bioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_chemistry": {
      "task": "ogx_mmlux_et-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži keemia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_computer_science": {
      "task": "ogx_mmlux_et-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kõrgkooli informaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_mathematics": {
      "task": "ogx_mmlux_et-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži matemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_medicine": {
      "task": "ogx_mmlux_et-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži meditsiini kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-college_physics": {
      "task": "ogx_mmlux_et-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kolledži füüsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-computer_security": {
      "task": "ogx_mmlux_et-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) arvutiturbe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-conceptual_physics": {
      "task": "ogx_mmlux_et-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kontseptuaalse füüsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-econometrics": {
      "task": "ogx_mmlux_et-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) ökonomeetria kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-electrical_engineering": {
      "task": "ogx_mmlux_et-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) elektrotehnika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "task": "ogx_mmlux_et-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) elementaarmatemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-formal_logic": {
      "task": "ogx_mmlux_et-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) formaalloogika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-global_facts": {
      "task": "ogx_mmlux_et-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) globaalsete faktide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_biology": {
      "task": "ogx_mmlux_et-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli bioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "task": "ogx_mmlux_et-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli keemia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "task": "ogx_mmlux_et-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli informaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_european_history": {
      "task": "ogx_mmlux_et-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli Euroopa ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_geography": {
      "task": "ogx_mmlux_et-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli geograafia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "task": "ogx_mmlux_et-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli valitsuse ja poliitika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "task": "ogx_mmlux_et-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli makromajanduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "task": "ogx_mmlux_et-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli matemaatika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "task": "ogx_mmlux_et-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli mikroökonoomika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_physics": {
      "task": "ogx_mmlux_et-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkoolifüüsika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_psychology": {
      "task": "ogx_mmlux_et-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkoolipsühholoogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_statistics": {
      "task": "ogx_mmlux_et-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli statistika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_us_history": {
      "task": "ogx_mmlux_et-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) meie keskkooli ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-high_school_world_history": {
      "task": "ogx_mmlux_et-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) keskkooli maailma ajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-human_aging": {
      "task": "ogx_mmlux_et-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) inimese vananemise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-human_sexuality": {
      "task": "ogx_mmlux_et-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) inimese seksuaalsuse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-international_law": {
      "task": "ogx_mmlux_et-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) rahvusvahelise õiguse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-jurisprudence": {
      "task": "ogx_mmlux_et-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) õigusteaduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-logical_fallacies": {
      "task": "ogx_mmlux_et-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) loogiliste eksituste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-machine_learning": {
      "task": "ogx_mmlux_et-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) masinõppe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-management": {
      "task": "ogx_mmlux_et-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) juhtimise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-marketing": {
      "task": "ogx_mmlux_et-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) turunduse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-medical_genetics": {
      "task": "ogx_mmlux_et-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) meditsiinigeneetika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-miscellaneous": {
      "task": "ogx_mmlux_et-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) mitmesuguste küsimuste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-moral_disputes": {
      "task": "ogx_mmlux_et-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) moraalsete vaidluste kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-moral_scenarios": {
      "task": "ogx_mmlux_et-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) moraalsete stsenaariumide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-nutrition": {
      "task": "ogx_mmlux_et-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) toitumise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-philosophy": {
      "task": "ogx_mmlux_et-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) filosoofia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-prehistory": {
      "task": "ogx_mmlux_et-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) eelajaloo kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_accounting": {
      "task": "ogx_mmlux_et-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kutsealase raamatupidamise kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_law": {
      "task": "ogx_mmlux_et-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) kutseõiguse kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_medicine": {
      "task": "ogx_mmlux_et-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) erialase meditsiini kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-professional_psychology": {
      "task": "ogx_mmlux_et-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) erialase psühholoogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-public_relations": {
      "task": "ogx_mmlux_et-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) avalike suhete kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-security_studies": {
      "task": "ogx_mmlux_et-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) julgeolekuõppe kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-sociology": {
      "task": "ogx_mmlux_et-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) sotsioloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "task": "ogx_mmlux_et-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) meie välispoliitika kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-virology": {
      "task": "ogx_mmlux_et-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) viroloogia kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_et-world_religions": {
      "task": "ogx_mmlux_et-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_ET",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastus:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Järgnevalt on esitatud valikvastustega küsimused (koos vastustega) maailmareligioonide kohta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "task": "ogx_mmlux_fi-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) abstraktista algebrasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-anatomy": {
      "task": "ogx_mmlux_fi-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) anatomiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-astronomy": {
      "task": "ogx_mmlux_fi-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) tähtitieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-business_ethics": {
      "task": "ogx_mmlux_fi-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) liike-elämän etiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "task": "ogx_mmlux_fi-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) kliinisestä tietämyksestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_biology": {
      "task": "ogx_mmlux_fi-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistobiologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_chemistry": {
      "task": "ogx_mmlux_fi-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistokemiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_computer_science": {
      "task": "ogx_mmlux_fi-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistojen tietotekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_mathematics": {
      "task": "ogx_mmlux_fi-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistomatematiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_medicine": {
      "task": "ogx_mmlux_fi-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistolääketieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-college_physics": {
      "task": "ogx_mmlux_fi-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) yliopistofysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-computer_security": {
      "task": "ogx_mmlux_fi-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) tietoturvasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "task": "ogx_mmlux_fi-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) käsitteellisestä fysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-econometrics": {
      "task": "ogx_mmlux_fi-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ekonometriasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "task": "ogx_mmlux_fi-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) sähkötekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "task": "ogx_mmlux_fi-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) matematiikan alkeista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-formal_logic": {
      "task": "ogx_mmlux_fi-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) muodollisesta logiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-global_facts": {
      "task": "ogx_mmlux_fi-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) globaaleista tosiasioista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_biology": {
      "task": "ogx_mmlux_fi-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion biologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "task": "ogx_mmlux_fi-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion kemiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "task": "ogx_mmlux_fi-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion tietotekniikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "task": "ogx_mmlux_fi-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion Euroopan historiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_geography": {
      "task": "ogx_mmlux_fi-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion maantiedosta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "task": "ogx_mmlux_fi-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion hallituksesta ja politiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "task": "ogx_mmlux_fi-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion makrotaloudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "task": "ogx_mmlux_fi-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion matematiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "task": "ogx_mmlux_fi-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion mikrotaloustieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_physics": {
      "task": "ogx_mmlux_fi-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion fysiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "task": "ogx_mmlux_fi-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion psykologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "task": "ogx_mmlux_fi-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion tilastoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "task": "ogx_mmlux_fi-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion historiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "task": "ogx_mmlux_fi-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) lukion maailmanhistoriasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-human_aging": {
      "task": "ogx_mmlux_fi-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ihmisen ikääntymisestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-human_sexuality": {
      "task": "ogx_mmlux_fi-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ihmisen seksuaalisuudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-international_law": {
      "task": "ogx_mmlux_fi-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) kansainvälisestä oikeudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-jurisprudence": {
      "task": "ogx_mmlux_fi-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) oikeustieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "task": "ogx_mmlux_fi-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) loogisista virheistä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-machine_learning": {
      "task": "ogx_mmlux_fi-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) koneoppimisesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-management": {
      "task": "ogx_mmlux_fi-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) johtamisesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-marketing": {
      "task": "ogx_mmlux_fi-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) markkinoinnista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-medical_genetics": {
      "task": "ogx_mmlux_fi-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) lääketieteellisestä genetiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-miscellaneous": {
      "task": "ogx_mmlux_fi-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) aiheesta sekalaiset.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-moral_disputes": {
      "task": "ogx_mmlux_fi-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) moraalisista kiistoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "task": "ogx_mmlux_fi-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) moraalisista skenaarioista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-nutrition": {
      "task": "ogx_mmlux_fi-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ravitsemuksesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-philosophy": {
      "task": "ogx_mmlux_fi-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) filosofiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-prehistory": {
      "task": "ogx_mmlux_fi-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on esihistoriaa koskevia monivalintakysymyksiä (vastauksineen).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_accounting": {
      "task": "ogx_mmlux_fi-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ammattimaisesta kirjanpidosta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_law": {
      "task": "ogx_mmlux_fi-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ammattioikeudesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_medicine": {
      "task": "ogx_mmlux_fi-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (ja vastauksia) ammatillisesta lääketieteestä.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-professional_psychology": {
      "task": "ogx_mmlux_fi-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) ammattipsykologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-public_relations": {
      "task": "ogx_mmlux_fi-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) suhdetoiminnasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-security_studies": {
      "task": "ogx_mmlux_fi-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) turvallisuustutkimuksesta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-sociology": {
      "task": "ogx_mmlux_fi-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on sosiologiaa koskevia monivalintakysymyksiä (vastauksineen).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "task": "ogx_mmlux_fi-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavat ovat monivalintakysymyksiä (vastauksineen) Yhdysvaltojen ulkopolitiikasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-virology": {
      "task": "ogx_mmlux_fi-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) virologiasta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fi-world_religions": {
      "task": "ogx_mmlux_fi-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_FI",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVastaa:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seuraavassa on monivalintakysymyksiä (vastauksineen) maailmanuskonnoista.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "task": "ogx_mmlux_fr-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'algèbre abstraite.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-anatomy": {
      "task": "ogx_mmlux_fr-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-astronomy": {
      "task": "ogx_mmlux_fr-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-business_ethics": {
      "task": "ogx_mmlux_fr-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'éthique des affaires.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "task": "ogx_mmlux_fr-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les connaissances cliniques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_biology": {
      "task": "ogx_mmlux_fr-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la biologie au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_chemistry": {
      "task": "ogx_mmlux_fr-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la chimie au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_computer_science": {
      "task": "ogx_mmlux_fr-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'informatique au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_mathematics": {
      "task": "ogx_mmlux_fr-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les mathématiques au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_medicine": {
      "task": "ogx_mmlux_fr-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la médecine universitaire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-college_physics": {
      "task": "ogx_mmlux_fr-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la physique au collège.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-computer_security": {
      "task": "ogx_mmlux_fr-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la sécurité informatique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "task": "ogx_mmlux_fr-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la physique conceptuelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-econometrics": {
      "task": "ogx_mmlux_fr-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'économétrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "task": "ogx_mmlux_fr-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le génie électrique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "task": "ogx_mmlux_fr-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les mathématiques élémentaires.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-formal_logic": {
      "task": "ogx_mmlux_fr-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la logique formelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-global_facts": {
      "task": "ogx_mmlux_fr-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les faits mondiaux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_biology": {
      "task": "ogx_mmlux_fr-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la biologie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "task": "ogx_mmlux_fr-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la chimie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "task": "ogx_mmlux_fr-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'informatique au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "task": "ogx_mmlux_fr-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'histoire de l'Europe au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_geography": {
      "task": "ogx_mmlux_fr-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la géographie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "task": "ogx_mmlux_fr-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le gouvernement et la politique au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "task": "ogx_mmlux_fr-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la macroéconomie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "task": "ogx_mmlux_fr-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les mathématiques au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "task": "ogx_mmlux_fr-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la microéconomie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_physics": {
      "task": "ogx_mmlux_fr-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la physique au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "task": "ogx_mmlux_fr-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la psychologie au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "task": "ogx_mmlux_fr-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les statistiques de l'enseignement secondaire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "task": "ogx_mmlux_fr-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'histoire des États-Unis au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "task": "ogx_mmlux_fr-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'histoire du monde au lycée.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-human_aging": {
      "task": "ogx_mmlux_fr-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le vieillissement humain.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-human_sexuality": {
      "task": "ogx_mmlux_fr-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la sexualité humaine.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-international_law": {
      "task": "ogx_mmlux_fr-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le droit international.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-jurisprudence": {
      "task": "ogx_mmlux_fr-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la jurisprudence.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "task": "ogx_mmlux_fr-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les sophismes logiques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-machine_learning": {
      "task": "ogx_mmlux_fr-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur l'apprentissage automatique.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-management": {
      "task": "ogx_mmlux_fr-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-marketing": {
      "task": "ogx_mmlux_fr-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-medical_genetics": {
      "task": "ogx_mmlux_fr-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la génétique médicale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-miscellaneous": {
      "task": "ogx_mmlux_fr-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les divers.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-moral_disputes": {
      "task": "ogx_mmlux_fr-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les différends moraux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "task": "ogx_mmlux_fr-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur des scénarios moraux.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-nutrition": {
      "task": "ogx_mmlux_fr-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la nutrition.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-philosophy": {
      "task": "ogx_mmlux_fr-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la philosophie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-prehistory": {
      "task": "ogx_mmlux_fr-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la préhistoire.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_accounting": {
      "task": "ogx_mmlux_fr-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la comptabilité professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_law": {
      "task": "ogx_mmlux_fr-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur le droit professionnel.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_medicine": {
      "task": "ogx_mmlux_fr-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la médecine professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-professional_psychology": {
      "task": "ogx_mmlux_fr-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la psychologie professionnelle.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-public_relations": {
      "task": "ogx_mmlux_fr-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les relations publiques.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-security_studies": {
      "task": "ogx_mmlux_fr-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur les études de sécurité.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-sociology": {
      "task": "ogx_mmlux_fr-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "task": "ogx_mmlux_fr-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Voici des questions à choix multiples (avec réponses) sur la politique étrangère des États-Unis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-virology": {
      "task": "ogx_mmlux_fr-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Les questions suivantes sont des questions à choix multiples (avec réponses) sur la virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_fr-world_religions": {
      "task": "ogx_mmlux_fr-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_FR",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRéponse:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Voici des questions à choix multiples (avec réponses) sur les religions du monde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "task": "ogx_mmlux_hu-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) az absztrakt algebráról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-anatomy": {
      "task": "ogx_mmlux_hu-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) az anatómiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-astronomy": {
      "task": "ogx_mmlux_hu-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a csillagászatról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-business_ethics": {
      "task": "ogx_mmlux_hu-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az üzleti etikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "task": "ogx_mmlux_hu-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban a klinikai ismeretekkel kapcsolatos feleletválasztós kérdések (válaszokkal) következnek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_biology": {
      "task": "ogx_mmlux_hu-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai biológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_chemistry": {
      "task": "ogx_mmlux_hu-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai kémiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_computer_science": {
      "task": "ogx_mmlux_hu-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai informatikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_mathematics": {
      "task": "ogx_mmlux_hu-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai matematikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_medicine": {
      "task": "ogx_mmlux_hu-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a főiskolai orvostudományról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-college_physics": {
      "task": "ogx_mmlux_hu-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) az egyetemi fizikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-computer_security": {
      "task": "ogx_mmlux_hu-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a számítógépes biztonságról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "task": "ogx_mmlux_hu-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a fogalmi fizikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-econometrics": {
      "task": "ogx_mmlux_hu-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban az ökonometriával kapcsolatos feleletválasztós kérdések (válaszokkal) következnek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "task": "ogx_mmlux_hu-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a villamosmérnöki tudományokról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "task": "ogx_mmlux_hu-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az elemi matematikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-formal_logic": {
      "task": "ogx_mmlux_hu-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a formális logikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-global_facts": {
      "task": "ogx_mmlux_hu-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a globális tényekről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_biology": {
      "task": "ogx_mmlux_hu-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai biológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "task": "ogx_mmlux_hu-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai kémiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "task": "ogx_mmlux_hu-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai informatikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "task": "ogx_mmlux_hu-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai európai történelemről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_geography": {
      "task": "ogx_mmlux_hu-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai földrajzról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "task": "ogx_mmlux_hu-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a középiskolai kormányzatról és politikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "task": "ogx_mmlux_hu-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai makroökonómiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "task": "ogx_mmlux_hu-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai matematikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "task": "ogx_mmlux_hu-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai mikroökonómiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_physics": {
      "task": "ogx_mmlux_hu-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai fizikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "task": "ogx_mmlux_hu-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a középiskolai pszichológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "task": "ogx_mmlux_hu-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban a középiskolai statisztikával kapcsolatos feleletválasztós kérdések (válaszokkal) találhatók.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "task": "ogx_mmlux_hu-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai történelemről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "task": "ogx_mmlux_hu-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a középiskolai világtörténelemről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-human_aging": {
      "task": "ogx_mmlux_hu-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az emberi öregedéssel kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-human_sexuality": {
      "task": "ogx_mmlux_hu-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az emberi szexualitásról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-international_law": {
      "task": "ogx_mmlux_hu-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a nemzetközi jogról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-jurisprudence": {
      "task": "ogx_mmlux_hu-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a jogtudományról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "task": "ogx_mmlux_hu-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban a logikai tévedésekkel kapcsolatos feleletválasztós kérdések (válaszokkal) találhatók.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-machine_learning": {
      "task": "ogx_mmlux_hu-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a gépi tanulásról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-management": {
      "task": "ogx_mmlux_hu-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a menedzsmentről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-marketing": {
      "task": "ogx_mmlux_hu-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a marketingről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-medical_genetics": {
      "task": "ogx_mmlux_hu-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az orvosi genetikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-miscellaneous": {
      "task": "ogx_mmlux_hu-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a különféle kérdésekről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-moral_disputes": {
      "task": "ogx_mmlux_hu-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az erkölcsi vitákról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "task": "ogx_mmlux_hu-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbiakban erkölcsi forgatókönyvekkel kapcsolatos feleletválasztós kérdések (válaszokkal) következnek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-nutrition": {
      "task": "ogx_mmlux_hu-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a táplálkozással kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-philosophy": {
      "task": "ogx_mmlux_hu-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a filozófiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-prehistory": {
      "task": "ogx_mmlux_hu-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) az őstörténetről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_accounting": {
      "task": "ogx_mmlux_hu-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a szakmai számvitelről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_law": {
      "task": "ogx_mmlux_hu-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a szakmai joggal kapcsolatosak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_medicine": {
      "task": "ogx_mmlux_hu-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a hivatásos orvoslásról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-professional_psychology": {
      "task": "ogx_mmlux_hu-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a szakpszichológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-public_relations": {
      "task": "ogx_mmlux_hu-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a public relationsről szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-security_studies": {
      "task": "ogx_mmlux_hu-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a biztonsági tanulmányokról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-sociology": {
      "task": "ogx_mmlux_hu-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a szociológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "task": "ogx_mmlux_hu-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) az amerikai külpolitikáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-virology": {
      "task": "ogx_mmlux_hu-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "A következő feleletválasztós kérdések (válaszokkal) a virológiáról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_hu-world_religions": {
      "task": "ogx_mmlux_hu-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_HU",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nVálasz:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Az alábbi feleletválasztós kérdések (válaszokkal) a világvallásokról szólnak.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-abstract_algebra": {
      "task": "ogx_mmlux_it-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'algebra astratta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-anatomy": {
      "task": "ogx_mmlux_it-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'anatomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-astronomy": {
      "task": "ogx_mmlux_it-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'astronomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-business_ethics": {
      "task": "ogx_mmlux_it-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'etica aziendale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "task": "ogx_mmlux_it-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla conoscenza clinica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_biology": {
      "task": "ogx_mmlux_it-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla biologia universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_chemistry": {
      "task": "ogx_mmlux_it-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla chimica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_computer_science": {
      "task": "ogx_mmlux_it-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'informatica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_mathematics": {
      "task": "ogx_mmlux_it-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_medicine": {
      "task": "ogx_mmlux_it-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla medicina universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-college_physics": {
      "task": "ogx_mmlux_it-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica universitaria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-computer_security": {
      "task": "ogx_mmlux_it-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sicurezza informatica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-conceptual_physics": {
      "task": "ogx_mmlux_it-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica concettuale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-econometrics": {
      "task": "ogx_mmlux_it-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'econometria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-electrical_engineering": {
      "task": "ogx_mmlux_it-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'ingegneria elettrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "task": "ogx_mmlux_it-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica elementare.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-formal_logic": {
      "task": "ogx_mmlux_it-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla logica formale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-global_facts": {
      "task": "ogx_mmlux_it-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sui fatti globali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_biology": {
      "task": "ogx_mmlux_it-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla biologia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "task": "ogx_mmlux_it-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla chimica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "task": "ogx_mmlux_it-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'informatica per le scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_european_history": {
      "task": "ogx_mmlux_it-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia europea delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_geography": {
      "task": "ogx_mmlux_it-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla geografia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "task": "ogx_mmlux_it-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul governo e la politica nelle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "task": "ogx_mmlux_it-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla macroeconomia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "task": "ogx_mmlux_it-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla matematica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "task": "ogx_mmlux_it-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla microeconomia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_physics": {
      "task": "ogx_mmlux_it-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla fisica delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_psychology": {
      "task": "ogx_mmlux_it-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla psicologia delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_statistics": {
      "task": "ogx_mmlux_it-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla statistica della scuola superiore.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_us_history": {
      "task": "ogx_mmlux_it-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia degli Stati Uniti al liceo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-high_school_world_history": {
      "task": "ogx_mmlux_it-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla storia mondiale delle scuole superiori.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-human_aging": {
      "task": "ogx_mmlux_it-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'invecchiamento umano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-human_sexuality": {
      "task": "ogx_mmlux_it-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sessualità umana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-international_law": {
      "task": "ogx_mmlux_it-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul diritto internazionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-jurisprudence": {
      "task": "ogx_mmlux_it-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla giurisprudenza.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-logical_fallacies": {
      "task": "ogx_mmlux_it-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle fallacie logiche.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-machine_learning": {
      "task": "ogx_mmlux_it-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'apprendimento automatico.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-management": {
      "task": "ogx_mmlux_it-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla gestione.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-marketing": {
      "task": "ogx_mmlux_it-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-medical_genetics": {
      "task": "ogx_mmlux_it-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla genetica medica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-miscellaneous": {
      "task": "ogx_mmlux_it-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) su varie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-moral_disputes": {
      "task": "ogx_mmlux_it-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle controversie morali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-moral_scenarios": {
      "task": "ogx_mmlux_it-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) su scenari morali.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-nutrition": {
      "task": "ogx_mmlux_it-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sull'alimentazione.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-philosophy": {
      "task": "ogx_mmlux_it-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla filosofia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-prehistory": {
      "task": "ogx_mmlux_it-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla preistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_accounting": {
      "task": "ogx_mmlux_it-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla contabilità professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_law": {
      "task": "ogx_mmlux_it-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sul diritto professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_medicine": {
      "task": "ogx_mmlux_it-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla medicina professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-professional_psychology": {
      "task": "ogx_mmlux_it-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla psicologia professionale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-public_relations": {
      "task": "ogx_mmlux_it-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle relazioni pubbliche.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-security_studies": {
      "task": "ogx_mmlux_it-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sugli studi sulla sicurezza.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-sociology": {
      "task": "ogx_mmlux_it-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla sociologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "task": "ogx_mmlux_it-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla politica estera degli Stati Uniti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-virology": {
      "task": "ogx_mmlux_it-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulla virologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_it-world_religions": {
      "task": "ogx_mmlux_it-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_IT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRisposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Le seguenti sono domande a scelta multipla (con relative risposte) sulle religioni del mondo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "task": "ogx_mmlux_lt-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie abstrakčiąją algebrą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-anatomy": {
      "task": "ogx_mmlux_lt-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie anatomiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-astronomy": {
      "task": "ogx_mmlux_lt-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie astronomiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-business_ethics": {
      "task": "ogx_mmlux_lt-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie verslo etiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "task": "ogx_mmlux_lt-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie klinikines žinias.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_biology": {
      "task": "ogx_mmlux_lt-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos biologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_chemistry": {
      "task": "ogx_mmlux_lt-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos chemiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_computer_science": {
      "task": "ogx_mmlux_lt-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos informatiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_mathematics": {
      "task": "ogx_mmlux_lt-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos matematiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_medicine": {
      "task": "ogx_mmlux_lt-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie koledžo mediciną.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-college_physics": {
      "task": "ogx_mmlux_lt-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kolegijos fiziką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-computer_security": {
      "task": "ogx_mmlux_lt-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie kompiuterių saugumą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "task": "ogx_mmlux_lt-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie konceptualiąją fiziką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-econometrics": {
      "task": "ogx_mmlux_lt-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie ekonometriją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "task": "ogx_mmlux_lt-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie elektrotechniką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "task": "ogx_mmlux_lt-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai su atsakymais apie elementariąją matematiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-formal_logic": {
      "task": "ogx_mmlux_lt-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie formaliąją logiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-global_facts": {
      "task": "ogx_mmlux_lt-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie visuotinius faktus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_biology": {
      "task": "ogx_mmlux_lt-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurinės mokyklos biologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "task": "ogx_mmlux_lt-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie chemiją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "task": "ogx_mmlux_lt-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie informatiką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "task": "ogx_mmlux_lt-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie Europos istoriją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_geography": {
      "task": "ogx_mmlux_lt-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie geografiją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "task": "ogx_mmlux_lt-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vyriausybę ir politiką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "task": "ogx_mmlux_lt-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie makroekonomiką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "task": "ogx_mmlux_lt-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurinės mokyklos matematiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "task": "ogx_mmlux_lt-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mikroekonomiką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_physics": {
      "task": "ogx_mmlux_lt-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie fiziką vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "task": "ogx_mmlux_lt-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie psichologiją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "task": "ogx_mmlux_lt-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie vidurinės mokyklos statistiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "task": "ogx_mmlux_lt-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie JAV vidurinės mokyklos istoriją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "task": "ogx_mmlux_lt-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie pasaulio istoriją vidurinėje mokykloje.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-human_aging": {
      "task": "ogx_mmlux_lt-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie žmogaus senėjimą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-human_sexuality": {
      "task": "ogx_mmlux_lt-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie žmogaus lytiškumą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-international_law": {
      "task": "ogx_mmlux_lt-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie tarptautinę teisę.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-jurisprudence": {
      "task": "ogx_mmlux_lt-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie jurisprudenciją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "task": "ogx_mmlux_lt-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie logines klaidas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-machine_learning": {
      "task": "ogx_mmlux_lt-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mašininį mokymąsi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-management": {
      "task": "ogx_mmlux_lt-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie valdymą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-marketing": {
      "task": "ogx_mmlux_lt-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie rinkodarą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-medical_genetics": {
      "task": "ogx_mmlux_lt-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie medicininę genetiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-miscellaneous": {
      "task": "ogx_mmlux_lt-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie įvairius dalykus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-moral_disputes": {
      "task": "ogx_mmlux_lt-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie moralinius ginčus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "task": "ogx_mmlux_lt-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie moralinius scenarijus.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-nutrition": {
      "task": "ogx_mmlux_lt-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie mitybą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-philosophy": {
      "task": "ogx_mmlux_lt-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie filosofiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-prehistory": {
      "task": "ogx_mmlux_lt-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie priešistorę.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_accounting": {
      "task": "ogx_mmlux_lt-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesinę apskaitą.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_law": {
      "task": "ogx_mmlux_lt-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesinę teisę.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_medicine": {
      "task": "ogx_mmlux_lt-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesinę mediciną.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-professional_psychology": {
      "task": "ogx_mmlux_lt-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie profesinę psichologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-public_relations": {
      "task": "ogx_mmlux_lt-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie viešuosius ryšius.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-security_studies": {
      "task": "ogx_mmlux_lt-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie saugumo studijas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-sociology": {
      "task": "ogx_mmlux_lt-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie sociologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "task": "ogx_mmlux_lt-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie JAV užsienio politiką.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-virology": {
      "task": "ogx_mmlux_lt-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie virusologiją.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lt-world_religions": {
      "task": "ogx_mmlux_lt-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_LT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtsakymas:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Toliau pateikiami klausimai (su atsakymais) apie pasaulio religijas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "task": "ogx_mmlux_lv-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par abstrakto algebru.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-anatomy": {
      "task": "ogx_mmlux_lv-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem par anatomiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-astronomy": {
      "task": "ogx_mmlux_lv-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par astronomiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-business_ethics": {
      "task": "ogx_mmlux_lv-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par uzņēmējdarbības ētiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "task": "ogx_mmlux_lv-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par klīniskajām zināšanām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_biology": {
      "task": "ogx_mmlux_lv-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas bioloģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_chemistry": {
      "task": "ogx_mmlux_lv-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas ķīmiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_computer_science": {
      "task": "ogx_mmlux_lv-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par datorzinātnēm koledžā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_mathematics": {
      "task": "ogx_mmlux_lv-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas matemātiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_medicine": {
      "task": "ogx_mmlux_lv-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas medicīnu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-college_physics": {
      "task": "ogx_mmlux_lv-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par koledžas fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-computer_security": {
      "task": "ogx_mmlux_lv-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par datoru drošību.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "task": "ogx_mmlux_lv-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par konceptuālo fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-econometrics": {
      "task": "ogx_mmlux_lv-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par ekonometriju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "task": "ogx_mmlux_lv-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par elektrotehniku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "task": "ogx_mmlux_lv-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par elementāro matemātiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-formal_logic": {
      "task": "ogx_mmlux_lv-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem par formālo loģiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-global_facts": {
      "task": "ogx_mmlux_lv-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par pasaules faktiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_biology": {
      "task": "ogx_mmlux_lv-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas bioloģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "task": "ogx_mmlux_lv-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas ķīmiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "task": "ogx_mmlux_lv-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas informātiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "task": "ogx_mmlux_lv-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas Eiropas vēsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_geography": {
      "task": "ogx_mmlux_lv-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas ģeogrāfiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "task": "ogx_mmlux_lv-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par valsts pārvaldi un politiku vidusskolā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "task": "ogx_mmlux_lv-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par makroekonomiku vidusskolā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "task": "ogx_mmlux_lv-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas matemātiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "task": "ogx_mmlux_lv-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par mikroekonomiku vidusskolā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_physics": {
      "task": "ogx_mmlux_lv-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas fiziku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "task": "ogx_mmlux_lv-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas psiholoģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "task": "ogx_mmlux_lv-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par vidusskolas statistiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "task": "ogx_mmlux_lv-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par ASV vidusskolas vēsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "task": "ogx_mmlux_lv-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par pasaules vēsturi vidusskolā.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-human_aging": {
      "task": "ogx_mmlux_lv-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par cilvēka novecošanu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-human_sexuality": {
      "task": "ogx_mmlux_lv-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par cilvēka seksualitāti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-international_law": {
      "task": "ogx_mmlux_lv-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par starptautiskajām tiesībām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-jurisprudence": {
      "task": "ogx_mmlux_lv-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par jurisprudenci.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "task": "ogx_mmlux_lv-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par loģiskajām kļūdām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-machine_learning": {
      "task": "ogx_mmlux_lv-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par mašīnmācīšanos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-management": {
      "task": "ogx_mmlux_lv-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par vadību.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-marketing": {
      "task": "ogx_mmlux_lv-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par mārketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-medical_genetics": {
      "task": "ogx_mmlux_lv-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par medicīnas ģenētiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-miscellaneous": {
      "task": "ogx_mmlux_lv-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par dažādiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-moral_disputes": {
      "task": "ogx_mmlux_lv-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par morāles strīdiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "task": "ogx_mmlux_lv-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par morāles scenārijiem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-nutrition": {
      "task": "ogx_mmlux_lv-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par uzturu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-philosophy": {
      "task": "ogx_mmlux_lv-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par filozofiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-prehistory": {
      "task": "ogx_mmlux_lv-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem (ar atbildēm) par aizvēsturi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_accounting": {
      "task": "ogx_mmlux_lv-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par profesionālo grāmatvedību.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_law": {
      "task": "ogx_mmlux_lv-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par profesionālajām tiesībām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_medicine": {
      "task": "ogx_mmlux_lv-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par profesionālo medicīnu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-professional_psychology": {
      "task": "ogx_mmlux_lv-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par profesionālo psiholoģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-public_relations": {
      "task": "ogx_mmlux_lv-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par sabiedriskajām attiecībām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-security_studies": {
      "task": "ogx_mmlux_lv-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par drošības studijām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-sociology": {
      "task": "ogx_mmlux_lv-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Turpmāk ir jautājumi ar atbilžu variantiem par socioloģiju (ar atbildēm).",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "task": "ogx_mmlux_lv-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem par ASV ārpolitiku.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-virology": {
      "task": "ogx_mmlux_lv-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir jautājumi ar atbilžu variantiem par virusoloģiju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_lv-world_religions": {
      "task": "ogx_mmlux_lv-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_LV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAtbilde:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Tālāk ir iekļauti jautājumi ar atbilžu variantiem (ar atbildēm) par pasaules reliģijām.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "task": "ogx_mmlux_nl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over abstracte algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-anatomy": {
      "task": "ogx_mmlux_nl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-astronomy": {
      "task": "ogx_mmlux_nl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-business_ethics": {
      "task": "ogx_mmlux_nl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over bedrijfsethiek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "task": "ogx_mmlux_nl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over klinische kennis.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_biology": {
      "task": "ogx_mmlux_nl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over biologie op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_chemistry": {
      "task": "ogx_mmlux_nl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over scheikunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_computer_science": {
      "task": "ogx_mmlux_nl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over informatica op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_mathematics": {
      "task": "ogx_mmlux_nl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wiskunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_medicine": {
      "task": "ogx_mmlux_nl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over geneeskunde aan de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-college_physics": {
      "task": "ogx_mmlux_nl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over natuurkunde op de universiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-computer_security": {
      "task": "ogx_mmlux_nl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over computerbeveiliging.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "task": "ogx_mmlux_nl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over conceptuele fysica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-econometrics": {
      "task": "ogx_mmlux_nl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over econometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "task": "ogx_mmlux_nl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over elektrotechniek.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "task": "ogx_mmlux_nl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over elementaire wiskunde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-formal_logic": {
      "task": "ogx_mmlux_nl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over formele logica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-global_facts": {
      "task": "ogx_mmlux_nl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over globale feiten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_biology": {
      "task": "ogx_mmlux_nl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over biologie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "task": "ogx_mmlux_nl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over scheikunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "task": "ogx_mmlux_nl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over informatica op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "task": "ogx_mmlux_nl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over Europese geschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_geography": {
      "task": "ogx_mmlux_nl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over aardrijkskunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "task": "ogx_mmlux_nl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over bestuur en politiek op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "task": "ogx_mmlux_nl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over macro-economie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "task": "ogx_mmlux_nl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wiskunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "task": "ogx_mmlux_nl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over micro-economie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_physics": {
      "task": "ogx_mmlux_nl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over natuurkunde op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "task": "ogx_mmlux_nl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over psychologie op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "task": "ogx_mmlux_nl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over statistiek op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "task": "ogx_mmlux_nl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over geschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "task": "ogx_mmlux_nl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wereldgeschiedenis op de middelbare school.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-human_aging": {
      "task": "ogx_mmlux_nl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over menselijke veroudering.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-human_sexuality": {
      "task": "ogx_mmlux_nl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over menselijke seksualiteit.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-international_law": {
      "task": "ogx_mmlux_nl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over internationaal recht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-jurisprudence": {
      "task": "ogx_mmlux_nl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over jurisprudentie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "task": "ogx_mmlux_nl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over logische drogredenen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-machine_learning": {
      "task": "ogx_mmlux_nl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over machinaal leren.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-management": {
      "task": "ogx_mmlux_nl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-marketing": {
      "task": "ogx_mmlux_nl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-medical_genetics": {
      "task": "ogx_mmlux_nl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over medische genetica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-miscellaneous": {
      "task": "ogx_mmlux_nl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over diversen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-moral_disputes": {
      "task": "ogx_mmlux_nl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over morele geschillen.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "task": "ogx_mmlux_nl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over morele scenario's.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-nutrition": {
      "task": "ogx_mmlux_nl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over voeding.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-philosophy": {
      "task": "ogx_mmlux_nl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over filosofie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-prehistory": {
      "task": "ogx_mmlux_nl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over de prehistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_accounting": {
      "task": "ogx_mmlux_nl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over professioneel boekhouden.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_law": {
      "task": "ogx_mmlux_nl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over het beroepsrecht.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_medicine": {
      "task": "ogx_mmlux_nl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over professionele geneeskunde.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-professional_psychology": {
      "task": "ogx_mmlux_nl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over professionele psychologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-public_relations": {
      "task": "ogx_mmlux_nl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-security_studies": {
      "task": "ogx_mmlux_nl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over veiligheidsstudies.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-sociology": {
      "task": "ogx_mmlux_nl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "task": "ogx_mmlux_nl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder volgen meerkeuzevragen (met antwoorden) over het buitenlands beleid van de Verenigde Staten.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-virology": {
      "task": "ogx_mmlux_nl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over virologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_nl-world_religions": {
      "task": "ogx_mmlux_nl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_NL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAntwoord:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Hieronder staan meerkeuzevragen (met antwoorden) over wereldreligies.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "task": "ogx_mmlux_pl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące algebry abstrakcyjnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-anatomy": {
      "task": "ogx_mmlux_pl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące anatomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-astronomy": {
      "task": "ogx_mmlux_pl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące astronomii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-business_ethics": {
      "task": "ogx_mmlux_pl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące etyki biznesu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "task": "ogx_mmlux_pl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące wiedzy klinicznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_biology": {
      "task": "ogx_mmlux_pl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące biologii na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_chemistry": {
      "task": "ogx_mmlux_pl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące chemii na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_computer_science": {
      "task": "ogx_mmlux_pl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące informatyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_mathematics": {
      "task": "ogx_mmlux_pl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące matematyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_medicine": {
      "task": "ogx_mmlux_pl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące medycyny uniwersyteckiej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-college_physics": {
      "task": "ogx_mmlux_pl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące fizyki na studiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-computer_security": {
      "task": "ogx_mmlux_pl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące bezpieczeństwa komputerowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "task": "ogx_mmlux_pl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące fizyki konceptualnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-econometrics": {
      "task": "ogx_mmlux_pl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "task": "ogx_mmlux_pl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące inżynierii elektrycznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "task": "ogx_mmlux_pl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące matematyki elementarnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-formal_logic": {
      "task": "ogx_mmlux_pl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące logiki formalnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-global_facts": {
      "task": "ogx_mmlux_pl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące globalnych faktów.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_biology": {
      "task": "ogx_mmlux_pl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące biologii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "task": "ogx_mmlux_pl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące chemii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "task": "ogx_mmlux_pl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące informatyki w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "task": "ogx_mmlux_pl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące historii Europy w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_geography": {
      "task": "ogx_mmlux_pl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące geografii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "task": "ogx_mmlux_pl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące rządów i polityki w szkołach średnich.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "task": "ogx_mmlux_pl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące makroekonomii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "task": "ogx_mmlux_pl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące matematyki w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "task": "ogx_mmlux_pl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące mikroekonomii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_physics": {
      "task": "ogx_mmlux_pl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące fizyki w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "task": "ogx_mmlux_pl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące psychologii w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "task": "ogx_mmlux_pl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące statystyki w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "task": "ogx_mmlux_pl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące historii Stanów Zjednoczonych w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "task": "ogx_mmlux_pl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące historii świata w szkole średniej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-human_aging": {
      "task": "ogx_mmlux_pl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące starzenia się człowieka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-human_sexuality": {
      "task": "ogx_mmlux_pl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące ludzkiej seksualności.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-international_law": {
      "task": "ogx_mmlux_pl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące prawa międzynarodowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-jurisprudence": {
      "task": "ogx_mmlux_pl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące orzecznictwa.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "task": "ogx_mmlux_pl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące błędów logicznych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-machine_learning": {
      "task": "ogx_mmlux_pl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące uczenia maszynowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-management": {
      "task": "ogx_mmlux_pl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące zarządzania.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-marketing": {
      "task": "ogx_mmlux_pl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-medical_genetics": {
      "task": "ogx_mmlux_pl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące genetyki medycznej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-miscellaneous": {
      "task": "ogx_mmlux_pl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące różnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-moral_disputes": {
      "task": "ogx_mmlux_pl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące sporów moralnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "task": "ogx_mmlux_pl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące scenariuszy moralnych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-nutrition": {
      "task": "ogx_mmlux_pl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące odżywiania.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-philosophy": {
      "task": "ogx_mmlux_pl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-prehistory": {
      "task": "ogx_mmlux_pl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące prehistorii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_accounting": {
      "task": "ogx_mmlux_pl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące profesjonalnej księgowości.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_law": {
      "task": "ogx_mmlux_pl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące prawa zawodowego.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_medicine": {
      "task": "ogx_mmlux_pl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące medycyny profesjonalnej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-professional_psychology": {
      "task": "ogx_mmlux_pl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące psychologii zawodowej.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-public_relations": {
      "task": "ogx_mmlux_pl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-security_studies": {
      "task": "ogx_mmlux_pl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące studiów nad bezpieczeństwem.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-sociology": {
      "task": "ogx_mmlux_pl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące socjologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "task": "ogx_mmlux_pl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące polityki zagranicznej Stanów Zjednoczonych.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-virology": {
      "task": "ogx_mmlux_pl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące wirusologii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pl-world_religions": {
      "task": "ogx_mmlux_pl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_PL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpowiedź:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Poniżej znajdują się pytania wielokrotnego wyboru (wraz z odpowiedziami) dotyczące religii świata.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "task": "ogx_mmlux_pt-pt-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre álgebra abstrata.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "task": "ogx_mmlux_pt-pt-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre anatomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "task": "ogx_mmlux_pt-pt-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre astronomia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "task": "ogx_mmlux_pt-pt-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre ética empresarial.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "task": "ogx_mmlux_pt-pt-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre conhecimentos clínicos.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "task": "ogx_mmlux_pt-pt-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes são de escolha múltipla (com respostas) sobre biologia universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "task": "ogx_mmlux_pt-pt-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes são de escolha múltipla (com respostas) sobre química universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "task": "ogx_mmlux_pt-pt-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre informática universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "task": "ogx_mmlux_pt-pt-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre matemática universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "task": "ogx_mmlux_pt-pt-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre medicina universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "task": "ogx_mmlux_pt-pt-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes são de escolha múltipla (com respostas) sobre física universitária.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "task": "ogx_mmlux_pt-pt-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre segurança informática.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "task": "ogx_mmlux_pt-pt-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre física concetual.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "task": "ogx_mmlux_pt-pt-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre econometria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "task": "ogx_mmlux_pt-pt-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre engenharia eléctrica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "task": "ogx_mmlux_pt-pt-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre matemática elementar.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "task": "ogx_mmlux_pt-pt-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre lógica formal.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "task": "ogx_mmlux_pt-pt-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre factos globais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "task": "ogx_mmlux_pt-pt-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre biologia do ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "task": "ogx_mmlux_pt-pt-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre química no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "task": "ogx_mmlux_pt-pt-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre informática no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "task": "ogx_mmlux_pt-pt-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre história europeia no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "task": "ogx_mmlux_pt-pt-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre geografia do ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "task": "ogx_mmlux_pt-pt-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre governo e política no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "task": "ogx_mmlux_pt-pt-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre macroeconomia no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "task": "ogx_mmlux_pt-pt-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre matemática do ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "task": "ogx_mmlux_pt-pt-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre microeconomia no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "task": "ogx_mmlux_pt-pt-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre física do ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "task": "ogx_mmlux_pt-pt-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre psicologia no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "task": "ogx_mmlux_pt-pt-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre estatística no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "task": "ogx_mmlux_pt-pt-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre História dos EUA no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "task": "ogx_mmlux_pt-pt-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre história mundial no ensino secundário.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "task": "ogx_mmlux_pt-pt-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre o envelhecimento humano.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "task": "ogx_mmlux_pt-pt-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre a sexualidade humana.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-international_law": {
      "task": "ogx_mmlux_pt-pt-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre direito internacional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "task": "ogx_mmlux_pt-pt-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre jurisprudência.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "task": "ogx_mmlux_pt-pt-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre falácias lógicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "task": "ogx_mmlux_pt-pt-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre aprendizagem automática.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-management": {
      "task": "ogx_mmlux_pt-pt-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre gestão.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-marketing": {
      "task": "ogx_mmlux_pt-pt-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "task": "ogx_mmlux_pt-pt-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre genética médica.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "task": "ogx_mmlux_pt-pt-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre miscelânea.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "task": "ogx_mmlux_pt-pt-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre disputas morais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "task": "ogx_mmlux_pt-pt-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre cenários morais.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "task": "ogx_mmlux_pt-pt-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre nutrição.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "task": "ogx_mmlux_pt-pt-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre filosofia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "task": "ogx_mmlux_pt-pt-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre a pré-história.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "task": "ogx_mmlux_pt-pt-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre contabilidade profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "task": "ogx_mmlux_pt-pt-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre direito profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "task": "ogx_mmlux_pt-pt-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre medicina profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "task": "ogx_mmlux_pt-pt-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre psicologia profissional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "task": "ogx_mmlux_pt-pt-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre relações públicas.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "task": "ogx_mmlux_pt-pt-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre estudos de segurança.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-sociology": {
      "task": "ogx_mmlux_pt-pt-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre sociologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "task": "ogx_mmlux_pt-pt-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "As perguntas seguintes são de escolha múltipla (com respostas) sobre a política externa dos EUA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-virology": {
      "task": "ogx_mmlux_pt-pt-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre virologia.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "task": "ogx_mmlux_pt-pt-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_PT-PT",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nResposta:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Seguem-se perguntas de escolha múltipla (com respostas) sobre as religiões do mundo.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "task": "ogx_mmlux_ro-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre algebra abstractă.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-anatomy": {
      "task": "ogx_mmlux_ro-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre anatomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-astronomy": {
      "task": "ogx_mmlux_ro-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu răspunsuri multiple (cu răspunsuri) despre astronomie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-business_ethics": {
      "task": "ogx_mmlux_ro-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre etica în afaceri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "task": "ogx_mmlux_ro-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre cunoștințele clinice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_biology": {
      "task": "ogx_mmlux_ro-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre biologia universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_chemistry": {
      "task": "ogx_mmlux_ro-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre chimia universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_computer_science": {
      "task": "ogx_mmlux_ro-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre informatică universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_mathematics": {
      "task": "ogx_mmlux_ro-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre matematica universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_medicine": {
      "task": "ogx_mmlux_ro-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre medicina universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-college_physics": {
      "task": "ogx_mmlux_ro-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre fizica universitară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-computer_security": {
      "task": "ogx_mmlux_ro-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre securitatea calculatoarelor.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "task": "ogx_mmlux_ro-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre fizica conceptuală.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-econometrics": {
      "task": "ogx_mmlux_ro-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre econometrie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "task": "ogx_mmlux_ro-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre inginerie electrică.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "task": "ogx_mmlux_ro-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre matematică elementară.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-formal_logic": {
      "task": "ogx_mmlux_ro-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre logica formală.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-global_facts": {
      "task": "ogx_mmlux_ro-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre fapte globale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_biology": {
      "task": "ogx_mmlux_ro-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre biologia de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "task": "ogx_mmlux_ro-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre chimia de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "task": "ogx_mmlux_ro-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre informatică la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "task": "ogx_mmlux_ro-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre istoria europeană la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_geography": {
      "task": "ogx_mmlux_ro-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre geografia liceului.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "task": "ogx_mmlux_ro-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre guvernare și politică în liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "task": "ogx_mmlux_ro-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre macroeconomie la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "task": "ogx_mmlux_ro-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre matematica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "task": "ogx_mmlux_ro-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre microeconomie la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_physics": {
      "task": "ogx_mmlux_ro-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre fizica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "task": "ogx_mmlux_ro-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre psihologia liceului.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "task": "ogx_mmlux_ro-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre statistica de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "task": "ogx_mmlux_ro-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre istoria noastră la liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "task": "ogx_mmlux_ro-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre istoria universală de liceu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-human_aging": {
      "task": "ogx_mmlux_ro-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre îmbătrânirea umană.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-human_sexuality": {
      "task": "ogx_mmlux_ro-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre sexualitatea umană.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-international_law": {
      "task": "ogx_mmlux_ro-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre dreptul internațional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-jurisprudence": {
      "task": "ogx_mmlux_ro-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre jurisprudență.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "task": "ogx_mmlux_ro-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre erori logice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-machine_learning": {
      "task": "ogx_mmlux_ro-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre învățarea automată.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-management": {
      "task": "ogx_mmlux_ro-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-marketing": {
      "task": "ogx_mmlux_ro-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre marketing.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-medical_genetics": {
      "task": "ogx_mmlux_ro-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre genetica medicală.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-miscellaneous": {
      "task": "ogx_mmlux_ro-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-moral_disputes": {
      "task": "ogx_mmlux_ro-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre disputele morale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "task": "ogx_mmlux_ro-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre scenarii morale.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-nutrition": {
      "task": "ogx_mmlux_ro-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre nutriție.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-philosophy": {
      "task": "ogx_mmlux_ro-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre filosofie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-prehistory": {
      "task": "ogx_mmlux_ro-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre preistorie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_accounting": {
      "task": "ogx_mmlux_ro-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre contabilitatea profesională.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_law": {
      "task": "ogx_mmlux_ro-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre dreptul profesional.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_medicine": {
      "task": "ogx_mmlux_ro-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre medicina profesională.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-professional_psychology": {
      "task": "ogx_mmlux_ro-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre psihologia profesională.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-public_relations": {
      "task": "ogx_mmlux_ro-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre relațiile publice.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-security_studies": {
      "task": "ogx_mmlux_ro-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre studiile de securitate.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-sociology": {
      "task": "ogx_mmlux_ro-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre sociologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "task": "ogx_mmlux_ro-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu alegere multiplă (cu răspunsuri) despre politica externă a SUA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-virology": {
      "task": "ogx_mmlux_ro-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre virusologie.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_ro-world_religions": {
      "task": "ogx_mmlux_ro-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_RO",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nRăspuns:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Următoarele sunt întrebări cu variante multiple de răspuns (cu răspunsuri) despre religiile lumii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "task": "ogx_mmlux_sk-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o abstraktnej algebre.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-anatomy": {
      "task": "ogx_mmlux_sk-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o anatómii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-astronomy": {
      "task": "ogx_mmlux_sk-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o astronómii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-business_ethics": {
      "task": "ogx_mmlux_sk-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o etike v podnikaní.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "task": "ogx_mmlux_sk-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o klinických znalostiach.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_biology": {
      "task": "ogx_mmlux_sk-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o vysokoškolskej biológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_chemistry": {
      "task": "ogx_mmlux_sk-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o vysokoškolskej chémii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_computer_science": {
      "task": "ogx_mmlux_sk-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o informatike na vysokej škole.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_mathematics": {
      "task": "ogx_mmlux_sk-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o vysokoškolskej matematike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_medicine": {
      "task": "ogx_mmlux_sk-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o vysokoškolskej medicíne.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-college_physics": {
      "task": "ogx_mmlux_sk-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o vysokoškolskej fyzike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-computer_security": {
      "task": "ogx_mmlux_sk-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o počítačovej bezpečnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "task": "ogx_mmlux_sk-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o konceptuálnej fyzike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-econometrics": {
      "task": "ogx_mmlux_sk-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o ekonometrii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "task": "ogx_mmlux_sk-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o elektrotechnike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "task": "ogx_mmlux_sk-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o elementárnej matematike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-formal_logic": {
      "task": "ogx_mmlux_sk-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o formálnej logike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-global_facts": {
      "task": "ogx_mmlux_sk-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o globálnych faktoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_biology": {
      "task": "ogx_mmlux_sk-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolskej biológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "task": "ogx_mmlux_sk-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolskej chémii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "task": "ogx_mmlux_sk-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolskej informatike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "task": "ogx_mmlux_sk-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolských európskych dejinách.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_geography": {
      "task": "ogx_mmlux_sk-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o stredoškolskom zemepise.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "task": "ogx_mmlux_sk-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú vlády a politiky na stredných školách.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "task": "ogx_mmlux_sk-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o stredoškolskej makroekonómii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "task": "ogx_mmlux_sk-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú stredoškolskej matematiky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "task": "ogx_mmlux_sk-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) z mikroekonómie pre stredné školy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_physics": {
      "task": "ogx_mmlux_sk-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) zo stredoškolskej fyziky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "task": "ogx_mmlux_sk-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o stredoškolskej psychológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "task": "ogx_mmlux_sk-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú stredoškolskej štatistiky.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "task": "ogx_mmlux_sk-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) o stredoškolskej histórii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "task": "ogx_mmlux_sk-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede (s odpoveďami) zo svetových dejín na strednej škole.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-human_aging": {
      "task": "ogx_mmlux_sk-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o starnutí človeka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-human_sexuality": {
      "task": "ogx_mmlux_sk-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o ľudskej sexualite.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-international_law": {
      "task": "ogx_mmlux_sk-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o medzinárodnom práve.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-jurisprudence": {
      "task": "ogx_mmlux_sk-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú právnej vedy.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "task": "ogx_mmlux_sk-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o logických klamoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-machine_learning": {
      "task": "ogx_mmlux_sk-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o strojovom učení.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-management": {
      "task": "ogx_mmlux_sk-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o manažmente.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-marketing": {
      "task": "ogx_mmlux_sk-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o marketingu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-medical_genetics": {
      "task": "ogx_mmlux_sk-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o lekárskej genetike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-miscellaneous": {
      "task": "ogx_mmlux_sk-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky s výberom odpovede sa týkajú rôzneho.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-moral_disputes": {
      "task": "ogx_mmlux_sk-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o morálnych sporoch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "task": "ogx_mmlux_sk-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o morálnych scenároch.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-nutrition": {
      "task": "ogx_mmlux_sk-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o výžive.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-philosophy": {
      "task": "ogx_mmlux_sk-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o filozofii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-prehistory": {
      "task": "ogx_mmlux_sk-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o prehistórii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_accounting": {
      "task": "ogx_mmlux_sk-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o odbornom účtovníctve.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_law": {
      "task": "ogx_mmlux_sk-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú profesijného práva.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_medicine": {
      "task": "ogx_mmlux_sk-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky (s odpoveďami) sa týkajú profesionálnej medicíny.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-professional_psychology": {
      "task": "ogx_mmlux_sk-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o profesionálnej psychológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-public_relations": {
      "task": "ogx_mmlux_sk-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o vzťahoch s verejnosťou.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-security_studies": {
      "task": "ogx_mmlux_sk-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o bezpečnostných štúdiách.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-sociology": {
      "task": "ogx_mmlux_sk-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o sociológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "task": "ogx_mmlux_sk-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujúce otázky s výberom odpovede sa týkajú zahraničnej politiky USA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-virology": {
      "task": "ogx_mmlux_sk-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o virológii.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sk-world_religions": {
      "task": "ogx_mmlux_sk-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SK",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdpoveď:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Nasledujú otázky s výberom odpovede o svetových náboženstvách.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "task": "ogx_mmlux_sl-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o abstraktni algebri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-anatomy": {
      "task": "ogx_mmlux_sl-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o anatomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-astronomy": {
      "task": "ogx_mmlux_sl-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o astronomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-business_ethics": {
      "task": "ogx_mmlux_sl-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o poslovni etiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "task": "ogx_mmlux_sl-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o kliničnem znanju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_biology": {
      "task": "ogx_mmlux_sl-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o biologiji na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_chemistry": {
      "task": "ogx_mmlux_sl-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o kemiji na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_computer_science": {
      "task": "ogx_mmlux_sl-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o računalništvu na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_mathematics": {
      "task": "ogx_mmlux_sl-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o matematiki na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_medicine": {
      "task": "ogx_mmlux_sl-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o univerzitetni medicini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-college_physics": {
      "task": "ogx_mmlux_sl-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o fiziki na fakulteti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-computer_security": {
      "task": "ogx_mmlux_sl-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o računalniški varnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "task": "ogx_mmlux_sl-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o konceptualni fiziki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-econometrics": {
      "task": "ogx_mmlux_sl-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o ekonometriji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "task": "ogx_mmlux_sl-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o elektrotehniki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "task": "ogx_mmlux_sl-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o osnovni matematiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-formal_logic": {
      "task": "ogx_mmlux_sl-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o formalni logiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-global_facts": {
      "task": "ogx_mmlux_sl-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o globalnih dejstvih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_biology": {
      "task": "ogx_mmlux_sl-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski biologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "task": "ogx_mmlux_sl-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o kemiji v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "task": "ogx_mmlux_sl-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o računalništvu v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "task": "ogx_mmlux_sl-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o evropski zgodovini v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_geography": {
      "task": "ogx_mmlux_sl-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o geografiji v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "task": "ogx_mmlux_sl-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o vladi in politiki v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "task": "ogx_mmlux_sl-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski makroekonomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "task": "ogx_mmlux_sl-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o matematiki v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "task": "ogx_mmlux_sl-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski mikroekonomiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_physics": {
      "task": "ogx_mmlux_sl-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) s področja srednješolske fizike.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "task": "ogx_mmlux_sl-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski psihologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "task": "ogx_mmlux_sl-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski statistiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "task": "ogx_mmlux_sl-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o srednješolski zgodovini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "task": "ogx_mmlux_sl-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o svetovni zgodovini v srednji šoli.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-human_aging": {
      "task": "ogx_mmlux_sl-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o staranju človeka.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-human_sexuality": {
      "task": "ogx_mmlux_sl-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o človeški spolnosti.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-international_law": {
      "task": "ogx_mmlux_sl-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o mednarodnem pravu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-jurisprudence": {
      "task": "ogx_mmlux_sl-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o sodni praksi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "task": "ogx_mmlux_sl-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o logičnih zmotah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-machine_learning": {
      "task": "ogx_mmlux_sl-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o strojnem učenju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-management": {
      "task": "ogx_mmlux_sl-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o upravljanju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-marketing": {
      "task": "ogx_mmlux_sl-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o trženju.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-medical_genetics": {
      "task": "ogx_mmlux_sl-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o medicinski genetiki.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-miscellaneous": {
      "task": "ogx_mmlux_sl-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o raznih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-moral_disputes": {
      "task": "ogx_mmlux_sl-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o moralnih sporih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "task": "ogx_mmlux_sl-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o moralnih scenarijih.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-nutrition": {
      "task": "ogx_mmlux_sl-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o prehrani.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-philosophy": {
      "task": "ogx_mmlux_sl-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o filozofiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-prehistory": {
      "task": "ogx_mmlux_sl-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o prazgodovini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_accounting": {
      "task": "ogx_mmlux_sl-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o strokovnem računovodstvu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_law": {
      "task": "ogx_mmlux_sl-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o poklicnem pravu.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_medicine": {
      "task": "ogx_mmlux_sl-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o poklicni medicini.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-professional_psychology": {
      "task": "ogx_mmlux_sl-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o poklicni psihologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-public_relations": {
      "task": "ogx_mmlux_sl-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o odnosih z javnostmi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-security_studies": {
      "task": "ogx_mmlux_sl-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o varnostnih študijah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-sociology": {
      "task": "ogx_mmlux_sl-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o sociologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "task": "ogx_mmlux_sl-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o zunanji politiki ZDA.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-virology": {
      "task": "ogx_mmlux_sl-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o virologiji.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sl-world_religions": {
      "task": "ogx_mmlux_sl-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SL",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nOdgovor:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "V nadaljevanju so vprašanja (z odgovori) o svetovnih religijah.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "task": "ogx_mmlux_sv-abstract_algebra",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "abstract_algebra_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om abstrakt algebra.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-anatomy": {
      "task": "ogx_mmlux_sv-anatomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "anatomy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om anatomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-astronomy": {
      "task": "ogx_mmlux_sv-astronomy",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "astronomy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om astronomi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-business_ethics": {
      "task": "ogx_mmlux_sv-business_ethics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "business_ethics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om affärsetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "task": "ogx_mmlux_sv-clinical_knowledge",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "clinical_knowledge_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om klinisk kunskap.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_biology": {
      "task": "ogx_mmlux_sv-college_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_biology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om biologi på högskolenivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_chemistry": {
      "task": "ogx_mmlux_sv-college_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_chemistry_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om kemi på högskolenivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_computer_science": {
      "task": "ogx_mmlux_sv-college_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_computer_science_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om datavetenskap på högskolenivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_mathematics": {
      "task": "ogx_mmlux_sv-college_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om matematik på högskolenivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_medicine": {
      "task": "ogx_mmlux_sv-college_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_medicine_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om universitetsmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-college_physics": {
      "task": "ogx_mmlux_sv-college_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "college_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om högskolefysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-computer_security": {
      "task": "ogx_mmlux_sv-computer_security",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "computer_security_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om datasäkerhet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "task": "ogx_mmlux_sv-conceptual_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "conceptual_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om konceptuell fysik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-econometrics": {
      "task": "ogx_mmlux_sv-econometrics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "econometrics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om ekonometri.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "task": "ogx_mmlux_sv-electrical_engineering",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "electrical_engineering_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om elektroteknik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "task": "ogx_mmlux_sv-elementary_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "elementary_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om elementär matematik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-formal_logic": {
      "task": "ogx_mmlux_sv-formal_logic",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "formal_logic_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om formell logik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-global_facts": {
      "task": "ogx_mmlux_sv-global_facts",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "global_facts_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om globala fakta.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_biology": {
      "task": "ogx_mmlux_sv-high_school_biology",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_biology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om biologi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "task": "ogx_mmlux_sv-high_school_chemistry",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_chemistry_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om kemi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "task": "ogx_mmlux_sv-high_school_computer_science",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_computer_science_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om datavetenskap på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "task": "ogx_mmlux_sv-high_school_european_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_european_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om europeisk historia på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_geography": {
      "task": "ogx_mmlux_sv-high_school_geography",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_geography_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om geografi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "task": "ogx_mmlux_sv-high_school_government_and_politics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_government_and_politics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om regering och politik på gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "task": "ogx_mmlux_sv-high_school_macroeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_macroeconomics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om makroekonomi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "task": "ogx_mmlux_sv-high_school_mathematics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_mathematics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om matematik på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "task": "ogx_mmlux_sv-high_school_microeconomics",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_microeconomics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om mikroekonomi på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_physics": {
      "task": "ogx_mmlux_sv-high_school_physics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_physics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om fysik på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "task": "ogx_mmlux_sv-high_school_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_psychology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om psykologi på gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "task": "ogx_mmlux_sv-high_school_statistics",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_statistics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om statistik på gymnasienivå.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "task": "ogx_mmlux_sv-high_school_us_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_us_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om historia i USA på gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "task": "ogx_mmlux_sv-high_school_world_history",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "high_school_world_history_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om världshistoria på gymnasiet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-human_aging": {
      "task": "ogx_mmlux_sv-human_aging",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_aging_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om människans åldrande.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-human_sexuality": {
      "task": "ogx_mmlux_sv-human_sexuality",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "human_sexuality_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om mänsklig sexualitet.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-international_law": {
      "task": "ogx_mmlux_sv-international_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "international_law_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om internationell rätt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-jurisprudence": {
      "task": "ogx_mmlux_sv-jurisprudence",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "jurisprudence_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om rättsvetenskap.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "task": "ogx_mmlux_sv-logical_fallacies",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "logical_fallacies_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om logiska felslut.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-machine_learning": {
      "task": "ogx_mmlux_sv-machine_learning",
      "group": "ogx_mmlux_stem",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "machine_learning_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om maskininlärning.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-management": {
      "task": "ogx_mmlux_sv-management",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "management_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om management.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-marketing": {
      "task": "ogx_mmlux_sv-marketing",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "marketing_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om marknadsföring.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-medical_genetics": {
      "task": "ogx_mmlux_sv-medical_genetics",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "medical_genetics_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om medicinsk genetik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-miscellaneous": {
      "task": "ogx_mmlux_sv-miscellaneous",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "miscellaneous_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om diverse.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-moral_disputes": {
      "task": "ogx_mmlux_sv-moral_disputes",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_disputes_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om moraliska tvister.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "task": "ogx_mmlux_sv-moral_scenarios",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "moral_scenarios_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om moraliska scenarier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-nutrition": {
      "task": "ogx_mmlux_sv-nutrition",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "nutrition_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om näringslära.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-philosophy": {
      "task": "ogx_mmlux_sv-philosophy",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "philosophy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om filosofi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-prehistory": {
      "task": "ogx_mmlux_sv-prehistory",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "prehistory_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om förhistoria.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_accounting": {
      "task": "ogx_mmlux_sv-professional_accounting",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_accounting_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om professionell redovisning.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_law": {
      "task": "ogx_mmlux_sv-professional_law",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_law_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om yrkesrätt.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_medicine": {
      "task": "ogx_mmlux_sv-professional_medicine",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_medicine_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om yrkesmedicin.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-professional_psychology": {
      "task": "ogx_mmlux_sv-professional_psychology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "professional_psychology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om professionell psykologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-public_relations": {
      "task": "ogx_mmlux_sv-public_relations",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "public_relations_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om public relations.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-security_studies": {
      "task": "ogx_mmlux_sv-security_studies",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "security_studies_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om säkerhetsstudier.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-sociology": {
      "task": "ogx_mmlux_sv-sociology",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "sociology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om sociologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "task": "ogx_mmlux_sv-us_foreign_policy",
      "group": "ogx_mmlux_social_sciences",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "us_foreign_policy_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om USA:s utrikespolitik.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-virology": {
      "task": "ogx_mmlux_sv-virology",
      "group": "ogx_mmlux_other",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "virology_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om virologi.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    },
    "ogx_mmlux_sv-world_religions": {
      "task": "ogx_mmlux_sv-world_religions",
      "group": "ogx_mmlux_humanities",
      "dataset_path": "openGPT-X/mmlux",
      "dataset_name": "world_religions_SV",
      "test_split": "test",
      "fewshot_split": "dev",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nSvar:",
      "doc_to_target": "answer",
      "doc_to_choice": "['A', 'B', 'C', 'D']",
      "description": "Följande är flervalsfrågor (med svar) om världsreligioner.",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0
      }
    }
  },
  "versions": {
    "ogx_mmlux_bg-abstract_algebra": 0,
    "ogx_mmlux_bg-anatomy": 0,
    "ogx_mmlux_bg-astronomy": 0,
    "ogx_mmlux_bg-business_ethics": 0,
    "ogx_mmlux_bg-clinical_knowledge": 0,
    "ogx_mmlux_bg-college_biology": 0,
    "ogx_mmlux_bg-college_chemistry": 0,
    "ogx_mmlux_bg-college_computer_science": 0,
    "ogx_mmlux_bg-college_mathematics": 0,
    "ogx_mmlux_bg-college_medicine": 0,
    "ogx_mmlux_bg-college_physics": 0,
    "ogx_mmlux_bg-computer_security": 0,
    "ogx_mmlux_bg-conceptual_physics": 0,
    "ogx_mmlux_bg-econometrics": 0,
    "ogx_mmlux_bg-electrical_engineering": 0,
    "ogx_mmlux_bg-elementary_mathematics": 0,
    "ogx_mmlux_bg-formal_logic": 0,
    "ogx_mmlux_bg-global_facts": 0,
    "ogx_mmlux_bg-high_school_biology": 0,
    "ogx_mmlux_bg-high_school_chemistry": 0,
    "ogx_mmlux_bg-high_school_computer_science": 0,
    "ogx_mmlux_bg-high_school_european_history": 0,
    "ogx_mmlux_bg-high_school_geography": 0,
    "ogx_mmlux_bg-high_school_government_and_politics": 0,
    "ogx_mmlux_bg-high_school_macroeconomics": 0,
    "ogx_mmlux_bg-high_school_mathematics": 0,
    "ogx_mmlux_bg-high_school_microeconomics": 0,
    "ogx_mmlux_bg-high_school_physics": 0,
    "ogx_mmlux_bg-high_school_psychology": 0,
    "ogx_mmlux_bg-high_school_statistics": 0,
    "ogx_mmlux_bg-high_school_us_history": 0,
    "ogx_mmlux_bg-high_school_world_history": 0,
    "ogx_mmlux_bg-human_aging": 0,
    "ogx_mmlux_bg-human_sexuality": 0,
    "ogx_mmlux_bg-international_law": 0,
    "ogx_mmlux_bg-jurisprudence": 0,
    "ogx_mmlux_bg-logical_fallacies": 0,
    "ogx_mmlux_bg-machine_learning": 0,
    "ogx_mmlux_bg-management": 0,
    "ogx_mmlux_bg-marketing": 0,
    "ogx_mmlux_bg-medical_genetics": 0,
    "ogx_mmlux_bg-miscellaneous": 0,
    "ogx_mmlux_bg-moral_disputes": 0,
    "ogx_mmlux_bg-moral_scenarios": 0,
    "ogx_mmlux_bg-nutrition": 0,
    "ogx_mmlux_bg-philosophy": 0,
    "ogx_mmlux_bg-prehistory": 0,
    "ogx_mmlux_bg-professional_accounting": 0,
    "ogx_mmlux_bg-professional_law": 0,
    "ogx_mmlux_bg-professional_medicine": 0,
    "ogx_mmlux_bg-professional_psychology": 0,
    "ogx_mmlux_bg-public_relations": 0,
    "ogx_mmlux_bg-security_studies": 0,
    "ogx_mmlux_bg-sociology": 0,
    "ogx_mmlux_bg-us_foreign_policy": 0,
    "ogx_mmlux_bg-virology": 0,
    "ogx_mmlux_bg-world_religions": 0,
    "ogx_mmlux_cs-abstract_algebra": 0,
    "ogx_mmlux_cs-anatomy": 0,
    "ogx_mmlux_cs-astronomy": 0,
    "ogx_mmlux_cs-business_ethics": 0,
    "ogx_mmlux_cs-clinical_knowledge": 0,
    "ogx_mmlux_cs-college_biology": 0,
    "ogx_mmlux_cs-college_chemistry": 0,
    "ogx_mmlux_cs-college_computer_science": 0,
    "ogx_mmlux_cs-college_mathematics": 0,
    "ogx_mmlux_cs-college_medicine": 0,
    "ogx_mmlux_cs-college_physics": 0,
    "ogx_mmlux_cs-computer_security": 0,
    "ogx_mmlux_cs-conceptual_physics": 0,
    "ogx_mmlux_cs-econometrics": 0,
    "ogx_mmlux_cs-electrical_engineering": 0,
    "ogx_mmlux_cs-elementary_mathematics": 0,
    "ogx_mmlux_cs-formal_logic": 0,
    "ogx_mmlux_cs-global_facts": 0,
    "ogx_mmlux_cs-high_school_biology": 0,
    "ogx_mmlux_cs-high_school_chemistry": 0,
    "ogx_mmlux_cs-high_school_computer_science": 0,
    "ogx_mmlux_cs-high_school_european_history": 0,
    "ogx_mmlux_cs-high_school_geography": 0,
    "ogx_mmlux_cs-high_school_government_and_politics": 0,
    "ogx_mmlux_cs-high_school_macroeconomics": 0,
    "ogx_mmlux_cs-high_school_mathematics": 0,
    "ogx_mmlux_cs-high_school_microeconomics": 0,
    "ogx_mmlux_cs-high_school_physics": 0,
    "ogx_mmlux_cs-high_school_psychology": 0,
    "ogx_mmlux_cs-high_school_statistics": 0,
    "ogx_mmlux_cs-high_school_us_history": 0,
    "ogx_mmlux_cs-high_school_world_history": 0,
    "ogx_mmlux_cs-human_aging": 0,
    "ogx_mmlux_cs-human_sexuality": 0,
    "ogx_mmlux_cs-international_law": 0,
    "ogx_mmlux_cs-jurisprudence": 0,
    "ogx_mmlux_cs-logical_fallacies": 0,
    "ogx_mmlux_cs-machine_learning": 0,
    "ogx_mmlux_cs-management": 0,
    "ogx_mmlux_cs-marketing": 0,
    "ogx_mmlux_cs-medical_genetics": 0,
    "ogx_mmlux_cs-miscellaneous": 0,
    "ogx_mmlux_cs-moral_disputes": 0,
    "ogx_mmlux_cs-moral_scenarios": 0,
    "ogx_mmlux_cs-nutrition": 0,
    "ogx_mmlux_cs-philosophy": 0,
    "ogx_mmlux_cs-prehistory": 0,
    "ogx_mmlux_cs-professional_accounting": 0,
    "ogx_mmlux_cs-professional_law": 0,
    "ogx_mmlux_cs-professional_medicine": 0,
    "ogx_mmlux_cs-professional_psychology": 0,
    "ogx_mmlux_cs-public_relations": 0,
    "ogx_mmlux_cs-security_studies": 0,
    "ogx_mmlux_cs-sociology": 0,
    "ogx_mmlux_cs-us_foreign_policy": 0,
    "ogx_mmlux_cs-virology": 0,
    "ogx_mmlux_cs-world_religions": 0,
    "ogx_mmlux_da-abstract_algebra": 0,
    "ogx_mmlux_da-anatomy": 0,
    "ogx_mmlux_da-astronomy": 0,
    "ogx_mmlux_da-business_ethics": 0,
    "ogx_mmlux_da-clinical_knowledge": 0,
    "ogx_mmlux_da-college_biology": 0,
    "ogx_mmlux_da-college_chemistry": 0,
    "ogx_mmlux_da-college_computer_science": 0,
    "ogx_mmlux_da-college_mathematics": 0,
    "ogx_mmlux_da-college_medicine": 0,
    "ogx_mmlux_da-college_physics": 0,
    "ogx_mmlux_da-computer_security": 0,
    "ogx_mmlux_da-conceptual_physics": 0,
    "ogx_mmlux_da-econometrics": 0,
    "ogx_mmlux_da-electrical_engineering": 0,
    "ogx_mmlux_da-elementary_mathematics": 0,
    "ogx_mmlux_da-formal_logic": 0,
    "ogx_mmlux_da-global_facts": 0,
    "ogx_mmlux_da-high_school_biology": 0,
    "ogx_mmlux_da-high_school_chemistry": 0,
    "ogx_mmlux_da-high_school_computer_science": 0,
    "ogx_mmlux_da-high_school_european_history": 0,
    "ogx_mmlux_da-high_school_geography": 0,
    "ogx_mmlux_da-high_school_government_and_politics": 0,
    "ogx_mmlux_da-high_school_macroeconomics": 0,
    "ogx_mmlux_da-high_school_mathematics": 0,
    "ogx_mmlux_da-high_school_microeconomics": 0,
    "ogx_mmlux_da-high_school_physics": 0,
    "ogx_mmlux_da-high_school_psychology": 0,
    "ogx_mmlux_da-high_school_statistics": 0,
    "ogx_mmlux_da-high_school_us_history": 0,
    "ogx_mmlux_da-high_school_world_history": 0,
    "ogx_mmlux_da-human_aging": 0,
    "ogx_mmlux_da-human_sexuality": 0,
    "ogx_mmlux_da-international_law": 0,
    "ogx_mmlux_da-jurisprudence": 0,
    "ogx_mmlux_da-logical_fallacies": 0,
    "ogx_mmlux_da-machine_learning": 0,
    "ogx_mmlux_da-management": 0,
    "ogx_mmlux_da-marketing": 0,
    "ogx_mmlux_da-medical_genetics": 0,
    "ogx_mmlux_da-miscellaneous": 0,
    "ogx_mmlux_da-moral_disputes": 0,
    "ogx_mmlux_da-moral_scenarios": 0,
    "ogx_mmlux_da-nutrition": 0,
    "ogx_mmlux_da-philosophy": 0,
    "ogx_mmlux_da-prehistory": 0,
    "ogx_mmlux_da-professional_accounting": 0,
    "ogx_mmlux_da-professional_law": 0,
    "ogx_mmlux_da-professional_medicine": 0,
    "ogx_mmlux_da-professional_psychology": 0,
    "ogx_mmlux_da-public_relations": 0,
    "ogx_mmlux_da-security_studies": 0,
    "ogx_mmlux_da-sociology": 0,
    "ogx_mmlux_da-us_foreign_policy": 0,
    "ogx_mmlux_da-virology": 0,
    "ogx_mmlux_da-world_religions": 0,
    "ogx_mmlux_de-abstract_algebra": 0,
    "ogx_mmlux_de-anatomy": 0,
    "ogx_mmlux_de-astronomy": 0,
    "ogx_mmlux_de-business_ethics": 0,
    "ogx_mmlux_de-clinical_knowledge": 0,
    "ogx_mmlux_de-college_biology": 0,
    "ogx_mmlux_de-college_chemistry": 0,
    "ogx_mmlux_de-college_computer_science": 0,
    "ogx_mmlux_de-college_mathematics": 0,
    "ogx_mmlux_de-college_medicine": 0,
    "ogx_mmlux_de-college_physics": 0,
    "ogx_mmlux_de-computer_security": 0,
    "ogx_mmlux_de-conceptual_physics": 0,
    "ogx_mmlux_de-econometrics": 0,
    "ogx_mmlux_de-electrical_engineering": 0,
    "ogx_mmlux_de-elementary_mathematics": 0,
    "ogx_mmlux_de-formal_logic": 0,
    "ogx_mmlux_de-global_facts": 0,
    "ogx_mmlux_de-high_school_biology": 0,
    "ogx_mmlux_de-high_school_chemistry": 0,
    "ogx_mmlux_de-high_school_computer_science": 0,
    "ogx_mmlux_de-high_school_european_history": 0,
    "ogx_mmlux_de-high_school_geography": 0,
    "ogx_mmlux_de-high_school_government_and_politics": 0,
    "ogx_mmlux_de-high_school_macroeconomics": 0,
    "ogx_mmlux_de-high_school_mathematics": 0,
    "ogx_mmlux_de-high_school_microeconomics": 0,
    "ogx_mmlux_de-high_school_physics": 0,
    "ogx_mmlux_de-high_school_psychology": 0,
    "ogx_mmlux_de-high_school_statistics": 0,
    "ogx_mmlux_de-high_school_us_history": 0,
    "ogx_mmlux_de-high_school_world_history": 0,
    "ogx_mmlux_de-human_aging": 0,
    "ogx_mmlux_de-human_sexuality": 0,
    "ogx_mmlux_de-international_law": 0,
    "ogx_mmlux_de-jurisprudence": 0,
    "ogx_mmlux_de-logical_fallacies": 0,
    "ogx_mmlux_de-machine_learning": 0,
    "ogx_mmlux_de-management": 0,
    "ogx_mmlux_de-marketing": 0,
    "ogx_mmlux_de-medical_genetics": 0,
    "ogx_mmlux_de-miscellaneous": 0,
    "ogx_mmlux_de-moral_disputes": 0,
    "ogx_mmlux_de-moral_scenarios": 0,
    "ogx_mmlux_de-nutrition": 0,
    "ogx_mmlux_de-philosophy": 0,
    "ogx_mmlux_de-prehistory": 0,
    "ogx_mmlux_de-professional_accounting": 0,
    "ogx_mmlux_de-professional_law": 0,
    "ogx_mmlux_de-professional_medicine": 0,
    "ogx_mmlux_de-professional_psychology": 0,
    "ogx_mmlux_de-public_relations": 0,
    "ogx_mmlux_de-security_studies": 0,
    "ogx_mmlux_de-sociology": 0,
    "ogx_mmlux_de-us_foreign_policy": 0,
    "ogx_mmlux_de-virology": 0,
    "ogx_mmlux_de-world_religions": 0,
    "ogx_mmlux_el-abstract_algebra": 0,
    "ogx_mmlux_el-anatomy": 0,
    "ogx_mmlux_el-astronomy": 0,
    "ogx_mmlux_el-business_ethics": 0,
    "ogx_mmlux_el-clinical_knowledge": 0,
    "ogx_mmlux_el-college_biology": 0,
    "ogx_mmlux_el-college_chemistry": 0,
    "ogx_mmlux_el-college_computer_science": 0,
    "ogx_mmlux_el-college_mathematics": 0,
    "ogx_mmlux_el-college_medicine": 0,
    "ogx_mmlux_el-college_physics": 0,
    "ogx_mmlux_el-computer_security": 0,
    "ogx_mmlux_el-conceptual_physics": 0,
    "ogx_mmlux_el-econometrics": 0,
    "ogx_mmlux_el-electrical_engineering": 0,
    "ogx_mmlux_el-elementary_mathematics": 0,
    "ogx_mmlux_el-formal_logic": 0,
    "ogx_mmlux_el-global_facts": 0,
    "ogx_mmlux_el-high_school_biology": 0,
    "ogx_mmlux_el-high_school_chemistry": 0,
    "ogx_mmlux_el-high_school_computer_science": 0,
    "ogx_mmlux_el-high_school_european_history": 0,
    "ogx_mmlux_el-high_school_geography": 0,
    "ogx_mmlux_el-high_school_government_and_politics": 0,
    "ogx_mmlux_el-high_school_macroeconomics": 0,
    "ogx_mmlux_el-high_school_mathematics": 0,
    "ogx_mmlux_el-high_school_microeconomics": 0,
    "ogx_mmlux_el-high_school_physics": 0,
    "ogx_mmlux_el-high_school_psychology": 0,
    "ogx_mmlux_el-high_school_statistics": 0,
    "ogx_mmlux_el-high_school_us_history": 0,
    "ogx_mmlux_el-high_school_world_history": 0,
    "ogx_mmlux_el-human_aging": 0,
    "ogx_mmlux_el-human_sexuality": 0,
    "ogx_mmlux_el-international_law": 0,
    "ogx_mmlux_el-jurisprudence": 0,
    "ogx_mmlux_el-logical_fallacies": 0,
    "ogx_mmlux_el-machine_learning": 0,
    "ogx_mmlux_el-management": 0,
    "ogx_mmlux_el-marketing": 0,
    "ogx_mmlux_el-medical_genetics": 0,
    "ogx_mmlux_el-miscellaneous": 0,
    "ogx_mmlux_el-moral_disputes": 0,
    "ogx_mmlux_el-moral_scenarios": 0,
    "ogx_mmlux_el-nutrition": 0,
    "ogx_mmlux_el-philosophy": 0,
    "ogx_mmlux_el-prehistory": 0,
    "ogx_mmlux_el-professional_accounting": 0,
    "ogx_mmlux_el-professional_law": 0,
    "ogx_mmlux_el-professional_medicine": 0,
    "ogx_mmlux_el-professional_psychology": 0,
    "ogx_mmlux_el-public_relations": 0,
    "ogx_mmlux_el-security_studies": 0,
    "ogx_mmlux_el-sociology": 0,
    "ogx_mmlux_el-us_foreign_policy": 0,
    "ogx_mmlux_el-virology": 0,
    "ogx_mmlux_el-world_religions": 0,
    "ogx_mmlux_es-abstract_algebra": 0,
    "ogx_mmlux_es-anatomy": 0,
    "ogx_mmlux_es-astronomy": 0,
    "ogx_mmlux_es-business_ethics": 0,
    "ogx_mmlux_es-clinical_knowledge": 0,
    "ogx_mmlux_es-college_biology": 0,
    "ogx_mmlux_es-college_chemistry": 0,
    "ogx_mmlux_es-college_computer_science": 0,
    "ogx_mmlux_es-college_mathematics": 0,
    "ogx_mmlux_es-college_medicine": 0,
    "ogx_mmlux_es-college_physics": 0,
    "ogx_mmlux_es-computer_security": 0,
    "ogx_mmlux_es-conceptual_physics": 0,
    "ogx_mmlux_es-econometrics": 0,
    "ogx_mmlux_es-electrical_engineering": 0,
    "ogx_mmlux_es-elementary_mathematics": 0,
    "ogx_mmlux_es-formal_logic": 0,
    "ogx_mmlux_es-global_facts": 0,
    "ogx_mmlux_es-high_school_biology": 0,
    "ogx_mmlux_es-high_school_chemistry": 0,
    "ogx_mmlux_es-high_school_computer_science": 0,
    "ogx_mmlux_es-high_school_european_history": 0,
    "ogx_mmlux_es-high_school_geography": 0,
    "ogx_mmlux_es-high_school_government_and_politics": 0,
    "ogx_mmlux_es-high_school_macroeconomics": 0,
    "ogx_mmlux_es-high_school_mathematics": 0,
    "ogx_mmlux_es-high_school_microeconomics": 0,
    "ogx_mmlux_es-high_school_physics": 0,
    "ogx_mmlux_es-high_school_psychology": 0,
    "ogx_mmlux_es-high_school_statistics": 0,
    "ogx_mmlux_es-high_school_us_history": 0,
    "ogx_mmlux_es-high_school_world_history": 0,
    "ogx_mmlux_es-human_aging": 0,
    "ogx_mmlux_es-human_sexuality": 0,
    "ogx_mmlux_es-international_law": 0,
    "ogx_mmlux_es-jurisprudence": 0,
    "ogx_mmlux_es-logical_fallacies": 0,
    "ogx_mmlux_es-machine_learning": 0,
    "ogx_mmlux_es-management": 0,
    "ogx_mmlux_es-marketing": 0,
    "ogx_mmlux_es-medical_genetics": 0,
    "ogx_mmlux_es-miscellaneous": 0,
    "ogx_mmlux_es-moral_disputes": 0,
    "ogx_mmlux_es-moral_scenarios": 0,
    "ogx_mmlux_es-nutrition": 0,
    "ogx_mmlux_es-philosophy": 0,
    "ogx_mmlux_es-prehistory": 0,
    "ogx_mmlux_es-professional_accounting": 0,
    "ogx_mmlux_es-professional_law": 0,
    "ogx_mmlux_es-professional_medicine": 0,
    "ogx_mmlux_es-professional_psychology": 0,
    "ogx_mmlux_es-public_relations": 0,
    "ogx_mmlux_es-security_studies": 0,
    "ogx_mmlux_es-sociology": 0,
    "ogx_mmlux_es-us_foreign_policy": 0,
    "ogx_mmlux_es-virology": 0,
    "ogx_mmlux_es-world_religions": 0,
    "ogx_mmlux_et-abstract_algebra": 0,
    "ogx_mmlux_et-anatomy": 0,
    "ogx_mmlux_et-astronomy": 0,
    "ogx_mmlux_et-business_ethics": 0,
    "ogx_mmlux_et-clinical_knowledge": 0,
    "ogx_mmlux_et-college_biology": 0,
    "ogx_mmlux_et-college_chemistry": 0,
    "ogx_mmlux_et-college_computer_science": 0,
    "ogx_mmlux_et-college_mathematics": 0,
    "ogx_mmlux_et-college_medicine": 0,
    "ogx_mmlux_et-college_physics": 0,
    "ogx_mmlux_et-computer_security": 0,
    "ogx_mmlux_et-conceptual_physics": 0,
    "ogx_mmlux_et-econometrics": 0,
    "ogx_mmlux_et-electrical_engineering": 0,
    "ogx_mmlux_et-elementary_mathematics": 0,
    "ogx_mmlux_et-formal_logic": 0,
    "ogx_mmlux_et-global_facts": 0,
    "ogx_mmlux_et-high_school_biology": 0,
    "ogx_mmlux_et-high_school_chemistry": 0,
    "ogx_mmlux_et-high_school_computer_science": 0,
    "ogx_mmlux_et-high_school_european_history": 0,
    "ogx_mmlux_et-high_school_geography": 0,
    "ogx_mmlux_et-high_school_government_and_politics": 0,
    "ogx_mmlux_et-high_school_macroeconomics": 0,
    "ogx_mmlux_et-high_school_mathematics": 0,
    "ogx_mmlux_et-high_school_microeconomics": 0,
    "ogx_mmlux_et-high_school_physics": 0,
    "ogx_mmlux_et-high_school_psychology": 0,
    "ogx_mmlux_et-high_school_statistics": 0,
    "ogx_mmlux_et-high_school_us_history": 0,
    "ogx_mmlux_et-high_school_world_history": 0,
    "ogx_mmlux_et-human_aging": 0,
    "ogx_mmlux_et-human_sexuality": 0,
    "ogx_mmlux_et-international_law": 0,
    "ogx_mmlux_et-jurisprudence": 0,
    "ogx_mmlux_et-logical_fallacies": 0,
    "ogx_mmlux_et-machine_learning": 0,
    "ogx_mmlux_et-management": 0,
    "ogx_mmlux_et-marketing": 0,
    "ogx_mmlux_et-medical_genetics": 0,
    "ogx_mmlux_et-miscellaneous": 0,
    "ogx_mmlux_et-moral_disputes": 0,
    "ogx_mmlux_et-moral_scenarios": 0,
    "ogx_mmlux_et-nutrition": 0,
    "ogx_mmlux_et-philosophy": 0,
    "ogx_mmlux_et-prehistory": 0,
    "ogx_mmlux_et-professional_accounting": 0,
    "ogx_mmlux_et-professional_law": 0,
    "ogx_mmlux_et-professional_medicine": 0,
    "ogx_mmlux_et-professional_psychology": 0,
    "ogx_mmlux_et-public_relations": 0,
    "ogx_mmlux_et-security_studies": 0,
    "ogx_mmlux_et-sociology": 0,
    "ogx_mmlux_et-us_foreign_policy": 0,
    "ogx_mmlux_et-virology": 0,
    "ogx_mmlux_et-world_religions": 0,
    "ogx_mmlux_fi-abstract_algebra": 0,
    "ogx_mmlux_fi-anatomy": 0,
    "ogx_mmlux_fi-astronomy": 0,
    "ogx_mmlux_fi-business_ethics": 0,
    "ogx_mmlux_fi-clinical_knowledge": 0,
    "ogx_mmlux_fi-college_biology": 0,
    "ogx_mmlux_fi-college_chemistry": 0,
    "ogx_mmlux_fi-college_computer_science": 0,
    "ogx_mmlux_fi-college_mathematics": 0,
    "ogx_mmlux_fi-college_medicine": 0,
    "ogx_mmlux_fi-college_physics": 0,
    "ogx_mmlux_fi-computer_security": 0,
    "ogx_mmlux_fi-conceptual_physics": 0,
    "ogx_mmlux_fi-econometrics": 0,
    "ogx_mmlux_fi-electrical_engineering": 0,
    "ogx_mmlux_fi-elementary_mathematics": 0,
    "ogx_mmlux_fi-formal_logic": 0,
    "ogx_mmlux_fi-global_facts": 0,
    "ogx_mmlux_fi-high_school_biology": 0,
    "ogx_mmlux_fi-high_school_chemistry": 0,
    "ogx_mmlux_fi-high_school_computer_science": 0,
    "ogx_mmlux_fi-high_school_european_history": 0,
    "ogx_mmlux_fi-high_school_geography": 0,
    "ogx_mmlux_fi-high_school_government_and_politics": 0,
    "ogx_mmlux_fi-high_school_macroeconomics": 0,
    "ogx_mmlux_fi-high_school_mathematics": 0,
    "ogx_mmlux_fi-high_school_microeconomics": 0,
    "ogx_mmlux_fi-high_school_physics": 0,
    "ogx_mmlux_fi-high_school_psychology": 0,
    "ogx_mmlux_fi-high_school_statistics": 0,
    "ogx_mmlux_fi-high_school_us_history": 0,
    "ogx_mmlux_fi-high_school_world_history": 0,
    "ogx_mmlux_fi-human_aging": 0,
    "ogx_mmlux_fi-human_sexuality": 0,
    "ogx_mmlux_fi-international_law": 0,
    "ogx_mmlux_fi-jurisprudence": 0,
    "ogx_mmlux_fi-logical_fallacies": 0,
    "ogx_mmlux_fi-machine_learning": 0,
    "ogx_mmlux_fi-management": 0,
    "ogx_mmlux_fi-marketing": 0,
    "ogx_mmlux_fi-medical_genetics": 0,
    "ogx_mmlux_fi-miscellaneous": 0,
    "ogx_mmlux_fi-moral_disputes": 0,
    "ogx_mmlux_fi-moral_scenarios": 0,
    "ogx_mmlux_fi-nutrition": 0,
    "ogx_mmlux_fi-philosophy": 0,
    "ogx_mmlux_fi-prehistory": 0,
    "ogx_mmlux_fi-professional_accounting": 0,
    "ogx_mmlux_fi-professional_law": 0,
    "ogx_mmlux_fi-professional_medicine": 0,
    "ogx_mmlux_fi-professional_psychology": 0,
    "ogx_mmlux_fi-public_relations": 0,
    "ogx_mmlux_fi-security_studies": 0,
    "ogx_mmlux_fi-sociology": 0,
    "ogx_mmlux_fi-us_foreign_policy": 0,
    "ogx_mmlux_fi-virology": 0,
    "ogx_mmlux_fi-world_religions": 0,
    "ogx_mmlux_fr-abstract_algebra": 0,
    "ogx_mmlux_fr-anatomy": 0,
    "ogx_mmlux_fr-astronomy": 0,
    "ogx_mmlux_fr-business_ethics": 0,
    "ogx_mmlux_fr-clinical_knowledge": 0,
    "ogx_mmlux_fr-college_biology": 0,
    "ogx_mmlux_fr-college_chemistry": 0,
    "ogx_mmlux_fr-college_computer_science": 0,
    "ogx_mmlux_fr-college_mathematics": 0,
    "ogx_mmlux_fr-college_medicine": 0,
    "ogx_mmlux_fr-college_physics": 0,
    "ogx_mmlux_fr-computer_security": 0,
    "ogx_mmlux_fr-conceptual_physics": 0,
    "ogx_mmlux_fr-econometrics": 0,
    "ogx_mmlux_fr-electrical_engineering": 0,
    "ogx_mmlux_fr-elementary_mathematics": 0,
    "ogx_mmlux_fr-formal_logic": 0,
    "ogx_mmlux_fr-global_facts": 0,
    "ogx_mmlux_fr-high_school_biology": 0,
    "ogx_mmlux_fr-high_school_chemistry": 0,
    "ogx_mmlux_fr-high_school_computer_science": 0,
    "ogx_mmlux_fr-high_school_european_history": 0,
    "ogx_mmlux_fr-high_school_geography": 0,
    "ogx_mmlux_fr-high_school_government_and_politics": 0,
    "ogx_mmlux_fr-high_school_macroeconomics": 0,
    "ogx_mmlux_fr-high_school_mathematics": 0,
    "ogx_mmlux_fr-high_school_microeconomics": 0,
    "ogx_mmlux_fr-high_school_physics": 0,
    "ogx_mmlux_fr-high_school_psychology": 0,
    "ogx_mmlux_fr-high_school_statistics": 0,
    "ogx_mmlux_fr-high_school_us_history": 0,
    "ogx_mmlux_fr-high_school_world_history": 0,
    "ogx_mmlux_fr-human_aging": 0,
    "ogx_mmlux_fr-human_sexuality": 0,
    "ogx_mmlux_fr-international_law": 0,
    "ogx_mmlux_fr-jurisprudence": 0,
    "ogx_mmlux_fr-logical_fallacies": 0,
    "ogx_mmlux_fr-machine_learning": 0,
    "ogx_mmlux_fr-management": 0,
    "ogx_mmlux_fr-marketing": 0,
    "ogx_mmlux_fr-medical_genetics": 0,
    "ogx_mmlux_fr-miscellaneous": 0,
    "ogx_mmlux_fr-moral_disputes": 0,
    "ogx_mmlux_fr-moral_scenarios": 0,
    "ogx_mmlux_fr-nutrition": 0,
    "ogx_mmlux_fr-philosophy": 0,
    "ogx_mmlux_fr-prehistory": 0,
    "ogx_mmlux_fr-professional_accounting": 0,
    "ogx_mmlux_fr-professional_law": 0,
    "ogx_mmlux_fr-professional_medicine": 0,
    "ogx_mmlux_fr-professional_psychology": 0,
    "ogx_mmlux_fr-public_relations": 0,
    "ogx_mmlux_fr-security_studies": 0,
    "ogx_mmlux_fr-sociology": 0,
    "ogx_mmlux_fr-us_foreign_policy": 0,
    "ogx_mmlux_fr-virology": 0,
    "ogx_mmlux_fr-world_religions": 0,
    "ogx_mmlux_hu-abstract_algebra": 0,
    "ogx_mmlux_hu-anatomy": 0,
    "ogx_mmlux_hu-astronomy": 0,
    "ogx_mmlux_hu-business_ethics": 0,
    "ogx_mmlux_hu-clinical_knowledge": 0,
    "ogx_mmlux_hu-college_biology": 0,
    "ogx_mmlux_hu-college_chemistry": 0,
    "ogx_mmlux_hu-college_computer_science": 0,
    "ogx_mmlux_hu-college_mathematics": 0,
    "ogx_mmlux_hu-college_medicine": 0,
    "ogx_mmlux_hu-college_physics": 0,
    "ogx_mmlux_hu-computer_security": 0,
    "ogx_mmlux_hu-conceptual_physics": 0,
    "ogx_mmlux_hu-econometrics": 0,
    "ogx_mmlux_hu-electrical_engineering": 0,
    "ogx_mmlux_hu-elementary_mathematics": 0,
    "ogx_mmlux_hu-formal_logic": 0,
    "ogx_mmlux_hu-global_facts": 0,
    "ogx_mmlux_hu-high_school_biology": 0,
    "ogx_mmlux_hu-high_school_chemistry": 0,
    "ogx_mmlux_hu-high_school_computer_science": 0,
    "ogx_mmlux_hu-high_school_european_history": 0,
    "ogx_mmlux_hu-high_school_geography": 0,
    "ogx_mmlux_hu-high_school_government_and_politics": 0,
    "ogx_mmlux_hu-high_school_macroeconomics": 0,
    "ogx_mmlux_hu-high_school_mathematics": 0,
    "ogx_mmlux_hu-high_school_microeconomics": 0,
    "ogx_mmlux_hu-high_school_physics": 0,
    "ogx_mmlux_hu-high_school_psychology": 0,
    "ogx_mmlux_hu-high_school_statistics": 0,
    "ogx_mmlux_hu-high_school_us_history": 0,
    "ogx_mmlux_hu-high_school_world_history": 0,
    "ogx_mmlux_hu-human_aging": 0,
    "ogx_mmlux_hu-human_sexuality": 0,
    "ogx_mmlux_hu-international_law": 0,
    "ogx_mmlux_hu-jurisprudence": 0,
    "ogx_mmlux_hu-logical_fallacies": 0,
    "ogx_mmlux_hu-machine_learning": 0,
    "ogx_mmlux_hu-management": 0,
    "ogx_mmlux_hu-marketing": 0,
    "ogx_mmlux_hu-medical_genetics": 0,
    "ogx_mmlux_hu-miscellaneous": 0,
    "ogx_mmlux_hu-moral_disputes": 0,
    "ogx_mmlux_hu-moral_scenarios": 0,
    "ogx_mmlux_hu-nutrition": 0,
    "ogx_mmlux_hu-philosophy": 0,
    "ogx_mmlux_hu-prehistory": 0,
    "ogx_mmlux_hu-professional_accounting": 0,
    "ogx_mmlux_hu-professional_law": 0,
    "ogx_mmlux_hu-professional_medicine": 0,
    "ogx_mmlux_hu-professional_psychology": 0,
    "ogx_mmlux_hu-public_relations": 0,
    "ogx_mmlux_hu-security_studies": 0,
    "ogx_mmlux_hu-sociology": 0,
    "ogx_mmlux_hu-us_foreign_policy": 0,
    "ogx_mmlux_hu-virology": 0,
    "ogx_mmlux_hu-world_religions": 0,
    "ogx_mmlux_it-abstract_algebra": 0,
    "ogx_mmlux_it-anatomy": 0,
    "ogx_mmlux_it-astronomy": 0,
    "ogx_mmlux_it-business_ethics": 0,
    "ogx_mmlux_it-clinical_knowledge": 0,
    "ogx_mmlux_it-college_biology": 0,
    "ogx_mmlux_it-college_chemistry": 0,
    "ogx_mmlux_it-college_computer_science": 0,
    "ogx_mmlux_it-college_mathematics": 0,
    "ogx_mmlux_it-college_medicine": 0,
    "ogx_mmlux_it-college_physics": 0,
    "ogx_mmlux_it-computer_security": 0,
    "ogx_mmlux_it-conceptual_physics": 0,
    "ogx_mmlux_it-econometrics": 0,
    "ogx_mmlux_it-electrical_engineering": 0,
    "ogx_mmlux_it-elementary_mathematics": 0,
    "ogx_mmlux_it-formal_logic": 0,
    "ogx_mmlux_it-global_facts": 0,
    "ogx_mmlux_it-high_school_biology": 0,
    "ogx_mmlux_it-high_school_chemistry": 0,
    "ogx_mmlux_it-high_school_computer_science": 0,
    "ogx_mmlux_it-high_school_european_history": 0,
    "ogx_mmlux_it-high_school_geography": 0,
    "ogx_mmlux_it-high_school_government_and_politics": 0,
    "ogx_mmlux_it-high_school_macroeconomics": 0,
    "ogx_mmlux_it-high_school_mathematics": 0,
    "ogx_mmlux_it-high_school_microeconomics": 0,
    "ogx_mmlux_it-high_school_physics": 0,
    "ogx_mmlux_it-high_school_psychology": 0,
    "ogx_mmlux_it-high_school_statistics": 0,
    "ogx_mmlux_it-high_school_us_history": 0,
    "ogx_mmlux_it-high_school_world_history": 0,
    "ogx_mmlux_it-human_aging": 0,
    "ogx_mmlux_it-human_sexuality": 0,
    "ogx_mmlux_it-international_law": 0,
    "ogx_mmlux_it-jurisprudence": 0,
    "ogx_mmlux_it-logical_fallacies": 0,
    "ogx_mmlux_it-machine_learning": 0,
    "ogx_mmlux_it-management": 0,
    "ogx_mmlux_it-marketing": 0,
    "ogx_mmlux_it-medical_genetics": 0,
    "ogx_mmlux_it-miscellaneous": 0,
    "ogx_mmlux_it-moral_disputes": 0,
    "ogx_mmlux_it-moral_scenarios": 0,
    "ogx_mmlux_it-nutrition": 0,
    "ogx_mmlux_it-philosophy": 0,
    "ogx_mmlux_it-prehistory": 0,
    "ogx_mmlux_it-professional_accounting": 0,
    "ogx_mmlux_it-professional_law": 0,
    "ogx_mmlux_it-professional_medicine": 0,
    "ogx_mmlux_it-professional_psychology": 0,
    "ogx_mmlux_it-public_relations": 0,
    "ogx_mmlux_it-security_studies": 0,
    "ogx_mmlux_it-sociology": 0,
    "ogx_mmlux_it-us_foreign_policy": 0,
    "ogx_mmlux_it-virology": 0,
    "ogx_mmlux_it-world_religions": 0,
    "ogx_mmlux_lt-abstract_algebra": 0,
    "ogx_mmlux_lt-anatomy": 0,
    "ogx_mmlux_lt-astronomy": 0,
    "ogx_mmlux_lt-business_ethics": 0,
    "ogx_mmlux_lt-clinical_knowledge": 0,
    "ogx_mmlux_lt-college_biology": 0,
    "ogx_mmlux_lt-college_chemistry": 0,
    "ogx_mmlux_lt-college_computer_science": 0,
    "ogx_mmlux_lt-college_mathematics": 0,
    "ogx_mmlux_lt-college_medicine": 0,
    "ogx_mmlux_lt-college_physics": 0,
    "ogx_mmlux_lt-computer_security": 0,
    "ogx_mmlux_lt-conceptual_physics": 0,
    "ogx_mmlux_lt-econometrics": 0,
    "ogx_mmlux_lt-electrical_engineering": 0,
    "ogx_mmlux_lt-elementary_mathematics": 0,
    "ogx_mmlux_lt-formal_logic": 0,
    "ogx_mmlux_lt-global_facts": 0,
    "ogx_mmlux_lt-high_school_biology": 0,
    "ogx_mmlux_lt-high_school_chemistry": 0,
    "ogx_mmlux_lt-high_school_computer_science": 0,
    "ogx_mmlux_lt-high_school_european_history": 0,
    "ogx_mmlux_lt-high_school_geography": 0,
    "ogx_mmlux_lt-high_school_government_and_politics": 0,
    "ogx_mmlux_lt-high_school_macroeconomics": 0,
    "ogx_mmlux_lt-high_school_mathematics": 0,
    "ogx_mmlux_lt-high_school_microeconomics": 0,
    "ogx_mmlux_lt-high_school_physics": 0,
    "ogx_mmlux_lt-high_school_psychology": 0,
    "ogx_mmlux_lt-high_school_statistics": 0,
    "ogx_mmlux_lt-high_school_us_history": 0,
    "ogx_mmlux_lt-high_school_world_history": 0,
    "ogx_mmlux_lt-human_aging": 0,
    "ogx_mmlux_lt-human_sexuality": 0,
    "ogx_mmlux_lt-international_law": 0,
    "ogx_mmlux_lt-jurisprudence": 0,
    "ogx_mmlux_lt-logical_fallacies": 0,
    "ogx_mmlux_lt-machine_learning": 0,
    "ogx_mmlux_lt-management": 0,
    "ogx_mmlux_lt-marketing": 0,
    "ogx_mmlux_lt-medical_genetics": 0,
    "ogx_mmlux_lt-miscellaneous": 0,
    "ogx_mmlux_lt-moral_disputes": 0,
    "ogx_mmlux_lt-moral_scenarios": 0,
    "ogx_mmlux_lt-nutrition": 0,
    "ogx_mmlux_lt-philosophy": 0,
    "ogx_mmlux_lt-prehistory": 0,
    "ogx_mmlux_lt-professional_accounting": 0,
    "ogx_mmlux_lt-professional_law": 0,
    "ogx_mmlux_lt-professional_medicine": 0,
    "ogx_mmlux_lt-professional_psychology": 0,
    "ogx_mmlux_lt-public_relations": 0,
    "ogx_mmlux_lt-security_studies": 0,
    "ogx_mmlux_lt-sociology": 0,
    "ogx_mmlux_lt-us_foreign_policy": 0,
    "ogx_mmlux_lt-virology": 0,
    "ogx_mmlux_lt-world_religions": 0,
    "ogx_mmlux_lv-abstract_algebra": 0,
    "ogx_mmlux_lv-anatomy": 0,
    "ogx_mmlux_lv-astronomy": 0,
    "ogx_mmlux_lv-business_ethics": 0,
    "ogx_mmlux_lv-clinical_knowledge": 0,
    "ogx_mmlux_lv-college_biology": 0,
    "ogx_mmlux_lv-college_chemistry": 0,
    "ogx_mmlux_lv-college_computer_science": 0,
    "ogx_mmlux_lv-college_mathematics": 0,
    "ogx_mmlux_lv-college_medicine": 0,
    "ogx_mmlux_lv-college_physics": 0,
    "ogx_mmlux_lv-computer_security": 0,
    "ogx_mmlux_lv-conceptual_physics": 0,
    "ogx_mmlux_lv-econometrics": 0,
    "ogx_mmlux_lv-electrical_engineering": 0,
    "ogx_mmlux_lv-elementary_mathematics": 0,
    "ogx_mmlux_lv-formal_logic": 0,
    "ogx_mmlux_lv-global_facts": 0,
    "ogx_mmlux_lv-high_school_biology": 0,
    "ogx_mmlux_lv-high_school_chemistry": 0,
    "ogx_mmlux_lv-high_school_computer_science": 0,
    "ogx_mmlux_lv-high_school_european_history": 0,
    "ogx_mmlux_lv-high_school_geography": 0,
    "ogx_mmlux_lv-high_school_government_and_politics": 0,
    "ogx_mmlux_lv-high_school_macroeconomics": 0,
    "ogx_mmlux_lv-high_school_mathematics": 0,
    "ogx_mmlux_lv-high_school_microeconomics": 0,
    "ogx_mmlux_lv-high_school_physics": 0,
    "ogx_mmlux_lv-high_school_psychology": 0,
    "ogx_mmlux_lv-high_school_statistics": 0,
    "ogx_mmlux_lv-high_school_us_history": 0,
    "ogx_mmlux_lv-high_school_world_history": 0,
    "ogx_mmlux_lv-human_aging": 0,
    "ogx_mmlux_lv-human_sexuality": 0,
    "ogx_mmlux_lv-international_law": 0,
    "ogx_mmlux_lv-jurisprudence": 0,
    "ogx_mmlux_lv-logical_fallacies": 0,
    "ogx_mmlux_lv-machine_learning": 0,
    "ogx_mmlux_lv-management": 0,
    "ogx_mmlux_lv-marketing": 0,
    "ogx_mmlux_lv-medical_genetics": 0,
    "ogx_mmlux_lv-miscellaneous": 0,
    "ogx_mmlux_lv-moral_disputes": 0,
    "ogx_mmlux_lv-moral_scenarios": 0,
    "ogx_mmlux_lv-nutrition": 0,
    "ogx_mmlux_lv-philosophy": 0,
    "ogx_mmlux_lv-prehistory": 0,
    "ogx_mmlux_lv-professional_accounting": 0,
    "ogx_mmlux_lv-professional_law": 0,
    "ogx_mmlux_lv-professional_medicine": 0,
    "ogx_mmlux_lv-professional_psychology": 0,
    "ogx_mmlux_lv-public_relations": 0,
    "ogx_mmlux_lv-security_studies": 0,
    "ogx_mmlux_lv-sociology": 0,
    "ogx_mmlux_lv-us_foreign_policy": 0,
    "ogx_mmlux_lv-virology": 0,
    "ogx_mmlux_lv-world_religions": 0,
    "ogx_mmlux_nl-abstract_algebra": 0,
    "ogx_mmlux_nl-anatomy": 0,
    "ogx_mmlux_nl-astronomy": 0,
    "ogx_mmlux_nl-business_ethics": 0,
    "ogx_mmlux_nl-clinical_knowledge": 0,
    "ogx_mmlux_nl-college_biology": 0,
    "ogx_mmlux_nl-college_chemistry": 0,
    "ogx_mmlux_nl-college_computer_science": 0,
    "ogx_mmlux_nl-college_mathematics": 0,
    "ogx_mmlux_nl-college_medicine": 0,
    "ogx_mmlux_nl-college_physics": 0,
    "ogx_mmlux_nl-computer_security": 0,
    "ogx_mmlux_nl-conceptual_physics": 0,
    "ogx_mmlux_nl-econometrics": 0,
    "ogx_mmlux_nl-electrical_engineering": 0,
    "ogx_mmlux_nl-elementary_mathematics": 0,
    "ogx_mmlux_nl-formal_logic": 0,
    "ogx_mmlux_nl-global_facts": 0,
    "ogx_mmlux_nl-high_school_biology": 0,
    "ogx_mmlux_nl-high_school_chemistry": 0,
    "ogx_mmlux_nl-high_school_computer_science": 0,
    "ogx_mmlux_nl-high_school_european_history": 0,
    "ogx_mmlux_nl-high_school_geography": 0,
    "ogx_mmlux_nl-high_school_government_and_politics": 0,
    "ogx_mmlux_nl-high_school_macroeconomics": 0,
    "ogx_mmlux_nl-high_school_mathematics": 0,
    "ogx_mmlux_nl-high_school_microeconomics": 0,
    "ogx_mmlux_nl-high_school_physics": 0,
    "ogx_mmlux_nl-high_school_psychology": 0,
    "ogx_mmlux_nl-high_school_statistics": 0,
    "ogx_mmlux_nl-high_school_us_history": 0,
    "ogx_mmlux_nl-high_school_world_history": 0,
    "ogx_mmlux_nl-human_aging": 0,
    "ogx_mmlux_nl-human_sexuality": 0,
    "ogx_mmlux_nl-international_law": 0,
    "ogx_mmlux_nl-jurisprudence": 0,
    "ogx_mmlux_nl-logical_fallacies": 0,
    "ogx_mmlux_nl-machine_learning": 0,
    "ogx_mmlux_nl-management": 0,
    "ogx_mmlux_nl-marketing": 0,
    "ogx_mmlux_nl-medical_genetics": 0,
    "ogx_mmlux_nl-miscellaneous": 0,
    "ogx_mmlux_nl-moral_disputes": 0,
    "ogx_mmlux_nl-moral_scenarios": 0,
    "ogx_mmlux_nl-nutrition": 0,
    "ogx_mmlux_nl-philosophy": 0,
    "ogx_mmlux_nl-prehistory": 0,
    "ogx_mmlux_nl-professional_accounting": 0,
    "ogx_mmlux_nl-professional_law": 0,
    "ogx_mmlux_nl-professional_medicine": 0,
    "ogx_mmlux_nl-professional_psychology": 0,
    "ogx_mmlux_nl-public_relations": 0,
    "ogx_mmlux_nl-security_studies": 0,
    "ogx_mmlux_nl-sociology": 0,
    "ogx_mmlux_nl-us_foreign_policy": 0,
    "ogx_mmlux_nl-virology": 0,
    "ogx_mmlux_nl-world_religions": 0,
    "ogx_mmlux_pl-abstract_algebra": 0,
    "ogx_mmlux_pl-anatomy": 0,
    "ogx_mmlux_pl-astronomy": 0,
    "ogx_mmlux_pl-business_ethics": 0,
    "ogx_mmlux_pl-clinical_knowledge": 0,
    "ogx_mmlux_pl-college_biology": 0,
    "ogx_mmlux_pl-college_chemistry": 0,
    "ogx_mmlux_pl-college_computer_science": 0,
    "ogx_mmlux_pl-college_mathematics": 0,
    "ogx_mmlux_pl-college_medicine": 0,
    "ogx_mmlux_pl-college_physics": 0,
    "ogx_mmlux_pl-computer_security": 0,
    "ogx_mmlux_pl-conceptual_physics": 0,
    "ogx_mmlux_pl-econometrics": 0,
    "ogx_mmlux_pl-electrical_engineering": 0,
    "ogx_mmlux_pl-elementary_mathematics": 0,
    "ogx_mmlux_pl-formal_logic": 0,
    "ogx_mmlux_pl-global_facts": 0,
    "ogx_mmlux_pl-high_school_biology": 0,
    "ogx_mmlux_pl-high_school_chemistry": 0,
    "ogx_mmlux_pl-high_school_computer_science": 0,
    "ogx_mmlux_pl-high_school_european_history": 0,
    "ogx_mmlux_pl-high_school_geography": 0,
    "ogx_mmlux_pl-high_school_government_and_politics": 0,
    "ogx_mmlux_pl-high_school_macroeconomics": 0,
    "ogx_mmlux_pl-high_school_mathematics": 0,
    "ogx_mmlux_pl-high_school_microeconomics": 0,
    "ogx_mmlux_pl-high_school_physics": 0,
    "ogx_mmlux_pl-high_school_psychology": 0,
    "ogx_mmlux_pl-high_school_statistics": 0,
    "ogx_mmlux_pl-high_school_us_history": 0,
    "ogx_mmlux_pl-high_school_world_history": 0,
    "ogx_mmlux_pl-human_aging": 0,
    "ogx_mmlux_pl-human_sexuality": 0,
    "ogx_mmlux_pl-international_law": 0,
    "ogx_mmlux_pl-jurisprudence": 0,
    "ogx_mmlux_pl-logical_fallacies": 0,
    "ogx_mmlux_pl-machine_learning": 0,
    "ogx_mmlux_pl-management": 0,
    "ogx_mmlux_pl-marketing": 0,
    "ogx_mmlux_pl-medical_genetics": 0,
    "ogx_mmlux_pl-miscellaneous": 0,
    "ogx_mmlux_pl-moral_disputes": 0,
    "ogx_mmlux_pl-moral_scenarios": 0,
    "ogx_mmlux_pl-nutrition": 0,
    "ogx_mmlux_pl-philosophy": 0,
    "ogx_mmlux_pl-prehistory": 0,
    "ogx_mmlux_pl-professional_accounting": 0,
    "ogx_mmlux_pl-professional_law": 0,
    "ogx_mmlux_pl-professional_medicine": 0,
    "ogx_mmlux_pl-professional_psychology": 0,
    "ogx_mmlux_pl-public_relations": 0,
    "ogx_mmlux_pl-security_studies": 0,
    "ogx_mmlux_pl-sociology": 0,
    "ogx_mmlux_pl-us_foreign_policy": 0,
    "ogx_mmlux_pl-virology": 0,
    "ogx_mmlux_pl-world_religions": 0,
    "ogx_mmlux_pt-pt-abstract_algebra": 0,
    "ogx_mmlux_pt-pt-anatomy": 0,
    "ogx_mmlux_pt-pt-astronomy": 0,
    "ogx_mmlux_pt-pt-business_ethics": 0,
    "ogx_mmlux_pt-pt-clinical_knowledge": 0,
    "ogx_mmlux_pt-pt-college_biology": 0,
    "ogx_mmlux_pt-pt-college_chemistry": 0,
    "ogx_mmlux_pt-pt-college_computer_science": 0,
    "ogx_mmlux_pt-pt-college_mathematics": 0,
    "ogx_mmlux_pt-pt-college_medicine": 0,
    "ogx_mmlux_pt-pt-college_physics": 0,
    "ogx_mmlux_pt-pt-computer_security": 0,
    "ogx_mmlux_pt-pt-conceptual_physics": 0,
    "ogx_mmlux_pt-pt-econometrics": 0,
    "ogx_mmlux_pt-pt-electrical_engineering": 0,
    "ogx_mmlux_pt-pt-elementary_mathematics": 0,
    "ogx_mmlux_pt-pt-formal_logic": 0,
    "ogx_mmlux_pt-pt-global_facts": 0,
    "ogx_mmlux_pt-pt-high_school_biology": 0,
    "ogx_mmlux_pt-pt-high_school_chemistry": 0,
    "ogx_mmlux_pt-pt-high_school_computer_science": 0,
    "ogx_mmlux_pt-pt-high_school_european_history": 0,
    "ogx_mmlux_pt-pt-high_school_geography": 0,
    "ogx_mmlux_pt-pt-high_school_government_and_politics": 0,
    "ogx_mmlux_pt-pt-high_school_macroeconomics": 0,
    "ogx_mmlux_pt-pt-high_school_mathematics": 0,
    "ogx_mmlux_pt-pt-high_school_microeconomics": 0,
    "ogx_mmlux_pt-pt-high_school_physics": 0,
    "ogx_mmlux_pt-pt-high_school_psychology": 0,
    "ogx_mmlux_pt-pt-high_school_statistics": 0,
    "ogx_mmlux_pt-pt-high_school_us_history": 0,
    "ogx_mmlux_pt-pt-high_school_world_history": 0,
    "ogx_mmlux_pt-pt-human_aging": 0,
    "ogx_mmlux_pt-pt-human_sexuality": 0,
    "ogx_mmlux_pt-pt-international_law": 0,
    "ogx_mmlux_pt-pt-jurisprudence": 0,
    "ogx_mmlux_pt-pt-logical_fallacies": 0,
    "ogx_mmlux_pt-pt-machine_learning": 0,
    "ogx_mmlux_pt-pt-management": 0,
    "ogx_mmlux_pt-pt-marketing": 0,
    "ogx_mmlux_pt-pt-medical_genetics": 0,
    "ogx_mmlux_pt-pt-miscellaneous": 0,
    "ogx_mmlux_pt-pt-moral_disputes": 0,
    "ogx_mmlux_pt-pt-moral_scenarios": 0,
    "ogx_mmlux_pt-pt-nutrition": 0,
    "ogx_mmlux_pt-pt-philosophy": 0,
    "ogx_mmlux_pt-pt-prehistory": 0,
    "ogx_mmlux_pt-pt-professional_accounting": 0,
    "ogx_mmlux_pt-pt-professional_law": 0,
    "ogx_mmlux_pt-pt-professional_medicine": 0,
    "ogx_mmlux_pt-pt-professional_psychology": 0,
    "ogx_mmlux_pt-pt-public_relations": 0,
    "ogx_mmlux_pt-pt-security_studies": 0,
    "ogx_mmlux_pt-pt-sociology": 0,
    "ogx_mmlux_pt-pt-us_foreign_policy": 0,
    "ogx_mmlux_pt-pt-virology": 0,
    "ogx_mmlux_pt-pt-world_religions": 0,
    "ogx_mmlux_ro-abstract_algebra": 0,
    "ogx_mmlux_ro-anatomy": 0,
    "ogx_mmlux_ro-astronomy": 0,
    "ogx_mmlux_ro-business_ethics": 0,
    "ogx_mmlux_ro-clinical_knowledge": 0,
    "ogx_mmlux_ro-college_biology": 0,
    "ogx_mmlux_ro-college_chemistry": 0,
    "ogx_mmlux_ro-college_computer_science": 0,
    "ogx_mmlux_ro-college_mathematics": 0,
    "ogx_mmlux_ro-college_medicine": 0,
    "ogx_mmlux_ro-college_physics": 0,
    "ogx_mmlux_ro-computer_security": 0,
    "ogx_mmlux_ro-conceptual_physics": 0,
    "ogx_mmlux_ro-econometrics": 0,
    "ogx_mmlux_ro-electrical_engineering": 0,
    "ogx_mmlux_ro-elementary_mathematics": 0,
    "ogx_mmlux_ro-formal_logic": 0,
    "ogx_mmlux_ro-global_facts": 0,
    "ogx_mmlux_ro-high_school_biology": 0,
    "ogx_mmlux_ro-high_school_chemistry": 0,
    "ogx_mmlux_ro-high_school_computer_science": 0,
    "ogx_mmlux_ro-high_school_european_history": 0,
    "ogx_mmlux_ro-high_school_geography": 0,
    "ogx_mmlux_ro-high_school_government_and_politics": 0,
    "ogx_mmlux_ro-high_school_macroeconomics": 0,
    "ogx_mmlux_ro-high_school_mathematics": 0,
    "ogx_mmlux_ro-high_school_microeconomics": 0,
    "ogx_mmlux_ro-high_school_physics": 0,
    "ogx_mmlux_ro-high_school_psychology": 0,
    "ogx_mmlux_ro-high_school_statistics": 0,
    "ogx_mmlux_ro-high_school_us_history": 0,
    "ogx_mmlux_ro-high_school_world_history": 0,
    "ogx_mmlux_ro-human_aging": 0,
    "ogx_mmlux_ro-human_sexuality": 0,
    "ogx_mmlux_ro-international_law": 0,
    "ogx_mmlux_ro-jurisprudence": 0,
    "ogx_mmlux_ro-logical_fallacies": 0,
    "ogx_mmlux_ro-machine_learning": 0,
    "ogx_mmlux_ro-management": 0,
    "ogx_mmlux_ro-marketing": 0,
    "ogx_mmlux_ro-medical_genetics": 0,
    "ogx_mmlux_ro-miscellaneous": 0,
    "ogx_mmlux_ro-moral_disputes": 0,
    "ogx_mmlux_ro-moral_scenarios": 0,
    "ogx_mmlux_ro-nutrition": 0,
    "ogx_mmlux_ro-philosophy": 0,
    "ogx_mmlux_ro-prehistory": 0,
    "ogx_mmlux_ro-professional_accounting": 0,
    "ogx_mmlux_ro-professional_law": 0,
    "ogx_mmlux_ro-professional_medicine": 0,
    "ogx_mmlux_ro-professional_psychology": 0,
    "ogx_mmlux_ro-public_relations": 0,
    "ogx_mmlux_ro-security_studies": 0,
    "ogx_mmlux_ro-sociology": 0,
    "ogx_mmlux_ro-us_foreign_policy": 0,
    "ogx_mmlux_ro-virology": 0,
    "ogx_mmlux_ro-world_religions": 0,
    "ogx_mmlux_sk-abstract_algebra": 0,
    "ogx_mmlux_sk-anatomy": 0,
    "ogx_mmlux_sk-astronomy": 0,
    "ogx_mmlux_sk-business_ethics": 0,
    "ogx_mmlux_sk-clinical_knowledge": 0,
    "ogx_mmlux_sk-college_biology": 0,
    "ogx_mmlux_sk-college_chemistry": 0,
    "ogx_mmlux_sk-college_computer_science": 0,
    "ogx_mmlux_sk-college_mathematics": 0,
    "ogx_mmlux_sk-college_medicine": 0,
    "ogx_mmlux_sk-college_physics": 0,
    "ogx_mmlux_sk-computer_security": 0,
    "ogx_mmlux_sk-conceptual_physics": 0,
    "ogx_mmlux_sk-econometrics": 0,
    "ogx_mmlux_sk-electrical_engineering": 0,
    "ogx_mmlux_sk-elementary_mathematics": 0,
    "ogx_mmlux_sk-formal_logic": 0,
    "ogx_mmlux_sk-global_facts": 0,
    "ogx_mmlux_sk-high_school_biology": 0,
    "ogx_mmlux_sk-high_school_chemistry": 0,
    "ogx_mmlux_sk-high_school_computer_science": 0,
    "ogx_mmlux_sk-high_school_european_history": 0,
    "ogx_mmlux_sk-high_school_geography": 0,
    "ogx_mmlux_sk-high_school_government_and_politics": 0,
    "ogx_mmlux_sk-high_school_macroeconomics": 0,
    "ogx_mmlux_sk-high_school_mathematics": 0,
    "ogx_mmlux_sk-high_school_microeconomics": 0,
    "ogx_mmlux_sk-high_school_physics": 0,
    "ogx_mmlux_sk-high_school_psychology": 0,
    "ogx_mmlux_sk-high_school_statistics": 0,
    "ogx_mmlux_sk-high_school_us_history": 0,
    "ogx_mmlux_sk-high_school_world_history": 0,
    "ogx_mmlux_sk-human_aging": 0,
    "ogx_mmlux_sk-human_sexuality": 0,
    "ogx_mmlux_sk-international_law": 0,
    "ogx_mmlux_sk-jurisprudence": 0,
    "ogx_mmlux_sk-logical_fallacies": 0,
    "ogx_mmlux_sk-machine_learning": 0,
    "ogx_mmlux_sk-management": 0,
    "ogx_mmlux_sk-marketing": 0,
    "ogx_mmlux_sk-medical_genetics": 0,
    "ogx_mmlux_sk-miscellaneous": 0,
    "ogx_mmlux_sk-moral_disputes": 0,
    "ogx_mmlux_sk-moral_scenarios": 0,
    "ogx_mmlux_sk-nutrition": 0,
    "ogx_mmlux_sk-philosophy": 0,
    "ogx_mmlux_sk-prehistory": 0,
    "ogx_mmlux_sk-professional_accounting": 0,
    "ogx_mmlux_sk-professional_law": 0,
    "ogx_mmlux_sk-professional_medicine": 0,
    "ogx_mmlux_sk-professional_psychology": 0,
    "ogx_mmlux_sk-public_relations": 0,
    "ogx_mmlux_sk-security_studies": 0,
    "ogx_mmlux_sk-sociology": 0,
    "ogx_mmlux_sk-us_foreign_policy": 0,
    "ogx_mmlux_sk-virology": 0,
    "ogx_mmlux_sk-world_religions": 0,
    "ogx_mmlux_sl-abstract_algebra": 0,
    "ogx_mmlux_sl-anatomy": 0,
    "ogx_mmlux_sl-astronomy": 0,
    "ogx_mmlux_sl-business_ethics": 0,
    "ogx_mmlux_sl-clinical_knowledge": 0,
    "ogx_mmlux_sl-college_biology": 0,
    "ogx_mmlux_sl-college_chemistry": 0,
    "ogx_mmlux_sl-college_computer_science": 0,
    "ogx_mmlux_sl-college_mathematics": 0,
    "ogx_mmlux_sl-college_medicine": 0,
    "ogx_mmlux_sl-college_physics": 0,
    "ogx_mmlux_sl-computer_security": 0,
    "ogx_mmlux_sl-conceptual_physics": 0,
    "ogx_mmlux_sl-econometrics": 0,
    "ogx_mmlux_sl-electrical_engineering": 0,
    "ogx_mmlux_sl-elementary_mathematics": 0,
    "ogx_mmlux_sl-formal_logic": 0,
    "ogx_mmlux_sl-global_facts": 0,
    "ogx_mmlux_sl-high_school_biology": 0,
    "ogx_mmlux_sl-high_school_chemistry": 0,
    "ogx_mmlux_sl-high_school_computer_science": 0,
    "ogx_mmlux_sl-high_school_european_history": 0,
    "ogx_mmlux_sl-high_school_geography": 0,
    "ogx_mmlux_sl-high_school_government_and_politics": 0,
    "ogx_mmlux_sl-high_school_macroeconomics": 0,
    "ogx_mmlux_sl-high_school_mathematics": 0,
    "ogx_mmlux_sl-high_school_microeconomics": 0,
    "ogx_mmlux_sl-high_school_physics": 0,
    "ogx_mmlux_sl-high_school_psychology": 0,
    "ogx_mmlux_sl-high_school_statistics": 0,
    "ogx_mmlux_sl-high_school_us_history": 0,
    "ogx_mmlux_sl-high_school_world_history": 0,
    "ogx_mmlux_sl-human_aging": 0,
    "ogx_mmlux_sl-human_sexuality": 0,
    "ogx_mmlux_sl-international_law": 0,
    "ogx_mmlux_sl-jurisprudence": 0,
    "ogx_mmlux_sl-logical_fallacies": 0,
    "ogx_mmlux_sl-machine_learning": 0,
    "ogx_mmlux_sl-management": 0,
    "ogx_mmlux_sl-marketing": 0,
    "ogx_mmlux_sl-medical_genetics": 0,
    "ogx_mmlux_sl-miscellaneous": 0,
    "ogx_mmlux_sl-moral_disputes": 0,
    "ogx_mmlux_sl-moral_scenarios": 0,
    "ogx_mmlux_sl-nutrition": 0,
    "ogx_mmlux_sl-philosophy": 0,
    "ogx_mmlux_sl-prehistory": 0,
    "ogx_mmlux_sl-professional_accounting": 0,
    "ogx_mmlux_sl-professional_law": 0,
    "ogx_mmlux_sl-professional_medicine": 0,
    "ogx_mmlux_sl-professional_psychology": 0,
    "ogx_mmlux_sl-public_relations": 0,
    "ogx_mmlux_sl-security_studies": 0,
    "ogx_mmlux_sl-sociology": 0,
    "ogx_mmlux_sl-us_foreign_policy": 0,
    "ogx_mmlux_sl-virology": 0,
    "ogx_mmlux_sl-world_religions": 0,
    "ogx_mmlux_sv-abstract_algebra": 0,
    "ogx_mmlux_sv-anatomy": 0,
    "ogx_mmlux_sv-astronomy": 0,
    "ogx_mmlux_sv-business_ethics": 0,
    "ogx_mmlux_sv-clinical_knowledge": 0,
    "ogx_mmlux_sv-college_biology": 0,
    "ogx_mmlux_sv-college_chemistry": 0,
    "ogx_mmlux_sv-college_computer_science": 0,
    "ogx_mmlux_sv-college_mathematics": 0,
    "ogx_mmlux_sv-college_medicine": 0,
    "ogx_mmlux_sv-college_physics": 0,
    "ogx_mmlux_sv-computer_security": 0,
    "ogx_mmlux_sv-conceptual_physics": 0,
    "ogx_mmlux_sv-econometrics": 0,
    "ogx_mmlux_sv-electrical_engineering": 0,
    "ogx_mmlux_sv-elementary_mathematics": 0,
    "ogx_mmlux_sv-formal_logic": 0,
    "ogx_mmlux_sv-global_facts": 0,
    "ogx_mmlux_sv-high_school_biology": 0,
    "ogx_mmlux_sv-high_school_chemistry": 0,
    "ogx_mmlux_sv-high_school_computer_science": 0,
    "ogx_mmlux_sv-high_school_european_history": 0,
    "ogx_mmlux_sv-high_school_geography": 0,
    "ogx_mmlux_sv-high_school_government_and_politics": 0,
    "ogx_mmlux_sv-high_school_macroeconomics": 0,
    "ogx_mmlux_sv-high_school_mathematics": 0,
    "ogx_mmlux_sv-high_school_microeconomics": 0,
    "ogx_mmlux_sv-high_school_physics": 0,
    "ogx_mmlux_sv-high_school_psychology": 0,
    "ogx_mmlux_sv-high_school_statistics": 0,
    "ogx_mmlux_sv-high_school_us_history": 0,
    "ogx_mmlux_sv-high_school_world_history": 0,
    "ogx_mmlux_sv-human_aging": 0,
    "ogx_mmlux_sv-human_sexuality": 0,
    "ogx_mmlux_sv-international_law": 0,
    "ogx_mmlux_sv-jurisprudence": 0,
    "ogx_mmlux_sv-logical_fallacies": 0,
    "ogx_mmlux_sv-machine_learning": 0,
    "ogx_mmlux_sv-management": 0,
    "ogx_mmlux_sv-marketing": 0,
    "ogx_mmlux_sv-medical_genetics": 0,
    "ogx_mmlux_sv-miscellaneous": 0,
    "ogx_mmlux_sv-moral_disputes": 0,
    "ogx_mmlux_sv-moral_scenarios": 0,
    "ogx_mmlux_sv-nutrition": 0,
    "ogx_mmlux_sv-philosophy": 0,
    "ogx_mmlux_sv-prehistory": 0,
    "ogx_mmlux_sv-professional_accounting": 0,
    "ogx_mmlux_sv-professional_law": 0,
    "ogx_mmlux_sv-professional_medicine": 0,
    "ogx_mmlux_sv-professional_psychology": 0,
    "ogx_mmlux_sv-public_relations": 0,
    "ogx_mmlux_sv-security_studies": 0,
    "ogx_mmlux_sv-sociology": 0,
    "ogx_mmlux_sv-us_foreign_policy": 0,
    "ogx_mmlux_sv-virology": 0,
    "ogx_mmlux_sv-world_religions": 0
  },
  "n-shot": {
    "ogx_mmlux_bg-abstract_algebra": 5,
    "ogx_mmlux_bg-anatomy": 5,
    "ogx_mmlux_bg-astronomy": 5,
    "ogx_mmlux_bg-business_ethics": 5,
    "ogx_mmlux_bg-clinical_knowledge": 5,
    "ogx_mmlux_bg-college_biology": 5,
    "ogx_mmlux_bg-college_chemistry": 5,
    "ogx_mmlux_bg-college_computer_science": 5,
    "ogx_mmlux_bg-college_mathematics": 5,
    "ogx_mmlux_bg-college_medicine": 5,
    "ogx_mmlux_bg-college_physics": 5,
    "ogx_mmlux_bg-computer_security": 5,
    "ogx_mmlux_bg-conceptual_physics": 5,
    "ogx_mmlux_bg-econometrics": 5,
    "ogx_mmlux_bg-electrical_engineering": 5,
    "ogx_mmlux_bg-elementary_mathematics": 5,
    "ogx_mmlux_bg-formal_logic": 5,
    "ogx_mmlux_bg-global_facts": 5,
    "ogx_mmlux_bg-high_school_biology": 5,
    "ogx_mmlux_bg-high_school_chemistry": 5,
    "ogx_mmlux_bg-high_school_computer_science": 5,
    "ogx_mmlux_bg-high_school_european_history": 5,
    "ogx_mmlux_bg-high_school_geography": 5,
    "ogx_mmlux_bg-high_school_government_and_politics": 5,
    "ogx_mmlux_bg-high_school_macroeconomics": 5,
    "ogx_mmlux_bg-high_school_mathematics": 5,
    "ogx_mmlux_bg-high_school_microeconomics": 5,
    "ogx_mmlux_bg-high_school_physics": 5,
    "ogx_mmlux_bg-high_school_psychology": 5,
    "ogx_mmlux_bg-high_school_statistics": 5,
    "ogx_mmlux_bg-high_school_us_history": 5,
    "ogx_mmlux_bg-high_school_world_history": 5,
    "ogx_mmlux_bg-human_aging": 5,
    "ogx_mmlux_bg-human_sexuality": 5,
    "ogx_mmlux_bg-international_law": 5,
    "ogx_mmlux_bg-jurisprudence": 5,
    "ogx_mmlux_bg-logical_fallacies": 5,
    "ogx_mmlux_bg-machine_learning": 5,
    "ogx_mmlux_bg-management": 5,
    "ogx_mmlux_bg-marketing": 5,
    "ogx_mmlux_bg-medical_genetics": 5,
    "ogx_mmlux_bg-miscellaneous": 5,
    "ogx_mmlux_bg-moral_disputes": 5,
    "ogx_mmlux_bg-moral_scenarios": 5,
    "ogx_mmlux_bg-nutrition": 5,
    "ogx_mmlux_bg-philosophy": 5,
    "ogx_mmlux_bg-prehistory": 5,
    "ogx_mmlux_bg-professional_accounting": 5,
    "ogx_mmlux_bg-professional_law": 5,
    "ogx_mmlux_bg-professional_medicine": 5,
    "ogx_mmlux_bg-professional_psychology": 5,
    "ogx_mmlux_bg-public_relations": 5,
    "ogx_mmlux_bg-security_studies": 5,
    "ogx_mmlux_bg-sociology": 5,
    "ogx_mmlux_bg-us_foreign_policy": 5,
    "ogx_mmlux_bg-virology": 5,
    "ogx_mmlux_bg-world_religions": 5,
    "ogx_mmlux_cs-abstract_algebra": 5,
    "ogx_mmlux_cs-anatomy": 5,
    "ogx_mmlux_cs-astronomy": 5,
    "ogx_mmlux_cs-business_ethics": 5,
    "ogx_mmlux_cs-clinical_knowledge": 5,
    "ogx_mmlux_cs-college_biology": 5,
    "ogx_mmlux_cs-college_chemistry": 5,
    "ogx_mmlux_cs-college_computer_science": 5,
    "ogx_mmlux_cs-college_mathematics": 5,
    "ogx_mmlux_cs-college_medicine": 5,
    "ogx_mmlux_cs-college_physics": 5,
    "ogx_mmlux_cs-computer_security": 5,
    "ogx_mmlux_cs-conceptual_physics": 5,
    "ogx_mmlux_cs-econometrics": 5,
    "ogx_mmlux_cs-electrical_engineering": 5,
    "ogx_mmlux_cs-elementary_mathematics": 5,
    "ogx_mmlux_cs-formal_logic": 5,
    "ogx_mmlux_cs-global_facts": 5,
    "ogx_mmlux_cs-high_school_biology": 5,
    "ogx_mmlux_cs-high_school_chemistry": 5,
    "ogx_mmlux_cs-high_school_computer_science": 5,
    "ogx_mmlux_cs-high_school_european_history": 5,
    "ogx_mmlux_cs-high_school_geography": 5,
    "ogx_mmlux_cs-high_school_government_and_politics": 5,
    "ogx_mmlux_cs-high_school_macroeconomics": 5,
    "ogx_mmlux_cs-high_school_mathematics": 5,
    "ogx_mmlux_cs-high_school_microeconomics": 5,
    "ogx_mmlux_cs-high_school_physics": 5,
    "ogx_mmlux_cs-high_school_psychology": 5,
    "ogx_mmlux_cs-high_school_statistics": 5,
    "ogx_mmlux_cs-high_school_us_history": 5,
    "ogx_mmlux_cs-high_school_world_history": 5,
    "ogx_mmlux_cs-human_aging": 5,
    "ogx_mmlux_cs-human_sexuality": 5,
    "ogx_mmlux_cs-international_law": 5,
    "ogx_mmlux_cs-jurisprudence": 5,
    "ogx_mmlux_cs-logical_fallacies": 5,
    "ogx_mmlux_cs-machine_learning": 5,
    "ogx_mmlux_cs-management": 5,
    "ogx_mmlux_cs-marketing": 5,
    "ogx_mmlux_cs-medical_genetics": 5,
    "ogx_mmlux_cs-miscellaneous": 5,
    "ogx_mmlux_cs-moral_disputes": 5,
    "ogx_mmlux_cs-moral_scenarios": 5,
    "ogx_mmlux_cs-nutrition": 5,
    "ogx_mmlux_cs-philosophy": 5,
    "ogx_mmlux_cs-prehistory": 5,
    "ogx_mmlux_cs-professional_accounting": 5,
    "ogx_mmlux_cs-professional_law": 5,
    "ogx_mmlux_cs-professional_medicine": 5,
    "ogx_mmlux_cs-professional_psychology": 5,
    "ogx_mmlux_cs-public_relations": 5,
    "ogx_mmlux_cs-security_studies": 5,
    "ogx_mmlux_cs-sociology": 5,
    "ogx_mmlux_cs-us_foreign_policy": 5,
    "ogx_mmlux_cs-virology": 5,
    "ogx_mmlux_cs-world_religions": 5,
    "ogx_mmlux_da-abstract_algebra": 5,
    "ogx_mmlux_da-anatomy": 5,
    "ogx_mmlux_da-astronomy": 5,
    "ogx_mmlux_da-business_ethics": 5,
    "ogx_mmlux_da-clinical_knowledge": 5,
    "ogx_mmlux_da-college_biology": 5,
    "ogx_mmlux_da-college_chemistry": 5,
    "ogx_mmlux_da-college_computer_science": 5,
    "ogx_mmlux_da-college_mathematics": 5,
    "ogx_mmlux_da-college_medicine": 5,
    "ogx_mmlux_da-college_physics": 5,
    "ogx_mmlux_da-computer_security": 5,
    "ogx_mmlux_da-conceptual_physics": 5,
    "ogx_mmlux_da-econometrics": 5,
    "ogx_mmlux_da-electrical_engineering": 5,
    "ogx_mmlux_da-elementary_mathematics": 5,
    "ogx_mmlux_da-formal_logic": 5,
    "ogx_mmlux_da-global_facts": 5,
    "ogx_mmlux_da-high_school_biology": 5,
    "ogx_mmlux_da-high_school_chemistry": 5,
    "ogx_mmlux_da-high_school_computer_science": 5,
    "ogx_mmlux_da-high_school_european_history": 5,
    "ogx_mmlux_da-high_school_geography": 5,
    "ogx_mmlux_da-high_school_government_and_politics": 5,
    "ogx_mmlux_da-high_school_macroeconomics": 5,
    "ogx_mmlux_da-high_school_mathematics": 5,
    "ogx_mmlux_da-high_school_microeconomics": 5,
    "ogx_mmlux_da-high_school_physics": 5,
    "ogx_mmlux_da-high_school_psychology": 5,
    "ogx_mmlux_da-high_school_statistics": 5,
    "ogx_mmlux_da-high_school_us_history": 5,
    "ogx_mmlux_da-high_school_world_history": 5,
    "ogx_mmlux_da-human_aging": 5,
    "ogx_mmlux_da-human_sexuality": 5,
    "ogx_mmlux_da-international_law": 5,
    "ogx_mmlux_da-jurisprudence": 5,
    "ogx_mmlux_da-logical_fallacies": 5,
    "ogx_mmlux_da-machine_learning": 5,
    "ogx_mmlux_da-management": 5,
    "ogx_mmlux_da-marketing": 5,
    "ogx_mmlux_da-medical_genetics": 5,
    "ogx_mmlux_da-miscellaneous": 5,
    "ogx_mmlux_da-moral_disputes": 5,
    "ogx_mmlux_da-moral_scenarios": 5,
    "ogx_mmlux_da-nutrition": 5,
    "ogx_mmlux_da-philosophy": 5,
    "ogx_mmlux_da-prehistory": 5,
    "ogx_mmlux_da-professional_accounting": 5,
    "ogx_mmlux_da-professional_law": 5,
    "ogx_mmlux_da-professional_medicine": 5,
    "ogx_mmlux_da-professional_psychology": 5,
    "ogx_mmlux_da-public_relations": 5,
    "ogx_mmlux_da-security_studies": 5,
    "ogx_mmlux_da-sociology": 5,
    "ogx_mmlux_da-us_foreign_policy": 5,
    "ogx_mmlux_da-virology": 5,
    "ogx_mmlux_da-world_religions": 5,
    "ogx_mmlux_de-abstract_algebra": 5,
    "ogx_mmlux_de-anatomy": 5,
    "ogx_mmlux_de-astronomy": 5,
    "ogx_mmlux_de-business_ethics": 5,
    "ogx_mmlux_de-clinical_knowledge": 5,
    "ogx_mmlux_de-college_biology": 5,
    "ogx_mmlux_de-college_chemistry": 5,
    "ogx_mmlux_de-college_computer_science": 5,
    "ogx_mmlux_de-college_mathematics": 5,
    "ogx_mmlux_de-college_medicine": 5,
    "ogx_mmlux_de-college_physics": 5,
    "ogx_mmlux_de-computer_security": 5,
    "ogx_mmlux_de-conceptual_physics": 5,
    "ogx_mmlux_de-econometrics": 5,
    "ogx_mmlux_de-electrical_engineering": 5,
    "ogx_mmlux_de-elementary_mathematics": 5,
    "ogx_mmlux_de-formal_logic": 5,
    "ogx_mmlux_de-global_facts": 5,
    "ogx_mmlux_de-high_school_biology": 5,
    "ogx_mmlux_de-high_school_chemistry": 5,
    "ogx_mmlux_de-high_school_computer_science": 5,
    "ogx_mmlux_de-high_school_european_history": 5,
    "ogx_mmlux_de-high_school_geography": 5,
    "ogx_mmlux_de-high_school_government_and_politics": 5,
    "ogx_mmlux_de-high_school_macroeconomics": 5,
    "ogx_mmlux_de-high_school_mathematics": 5,
    "ogx_mmlux_de-high_school_microeconomics": 5,
    "ogx_mmlux_de-high_school_physics": 5,
    "ogx_mmlux_de-high_school_psychology": 5,
    "ogx_mmlux_de-high_school_statistics": 5,
    "ogx_mmlux_de-high_school_us_history": 5,
    "ogx_mmlux_de-high_school_world_history": 5,
    "ogx_mmlux_de-human_aging": 5,
    "ogx_mmlux_de-human_sexuality": 5,
    "ogx_mmlux_de-international_law": 5,
    "ogx_mmlux_de-jurisprudence": 5,
    "ogx_mmlux_de-logical_fallacies": 5,
    "ogx_mmlux_de-machine_learning": 5,
    "ogx_mmlux_de-management": 5,
    "ogx_mmlux_de-marketing": 5,
    "ogx_mmlux_de-medical_genetics": 5,
    "ogx_mmlux_de-miscellaneous": 5,
    "ogx_mmlux_de-moral_disputes": 5,
    "ogx_mmlux_de-moral_scenarios": 5,
    "ogx_mmlux_de-nutrition": 5,
    "ogx_mmlux_de-philosophy": 5,
    "ogx_mmlux_de-prehistory": 5,
    "ogx_mmlux_de-professional_accounting": 5,
    "ogx_mmlux_de-professional_law": 5,
    "ogx_mmlux_de-professional_medicine": 5,
    "ogx_mmlux_de-professional_psychology": 5,
    "ogx_mmlux_de-public_relations": 5,
    "ogx_mmlux_de-security_studies": 5,
    "ogx_mmlux_de-sociology": 5,
    "ogx_mmlux_de-us_foreign_policy": 5,
    "ogx_mmlux_de-virology": 5,
    "ogx_mmlux_de-world_religions": 5,
    "ogx_mmlux_el-abstract_algebra": 5,
    "ogx_mmlux_el-anatomy": 5,
    "ogx_mmlux_el-astronomy": 5,
    "ogx_mmlux_el-business_ethics": 5,
    "ogx_mmlux_el-clinical_knowledge": 5,
    "ogx_mmlux_el-college_biology": 5,
    "ogx_mmlux_el-college_chemistry": 5,
    "ogx_mmlux_el-college_computer_science": 5,
    "ogx_mmlux_el-college_mathematics": 5,
    "ogx_mmlux_el-college_medicine": 5,
    "ogx_mmlux_el-college_physics": 5,
    "ogx_mmlux_el-computer_security": 5,
    "ogx_mmlux_el-conceptual_physics": 5,
    "ogx_mmlux_el-econometrics": 5,
    "ogx_mmlux_el-electrical_engineering": 5,
    "ogx_mmlux_el-elementary_mathematics": 5,
    "ogx_mmlux_el-formal_logic": 5,
    "ogx_mmlux_el-global_facts": 5,
    "ogx_mmlux_el-high_school_biology": 5,
    "ogx_mmlux_el-high_school_chemistry": 5,
    "ogx_mmlux_el-high_school_computer_science": 5,
    "ogx_mmlux_el-high_school_european_history": 5,
    "ogx_mmlux_el-high_school_geography": 5,
    "ogx_mmlux_el-high_school_government_and_politics": 5,
    "ogx_mmlux_el-high_school_macroeconomics": 5,
    "ogx_mmlux_el-high_school_mathematics": 5,
    "ogx_mmlux_el-high_school_microeconomics": 5,
    "ogx_mmlux_el-high_school_physics": 5,
    "ogx_mmlux_el-high_school_psychology": 5,
    "ogx_mmlux_el-high_school_statistics": 5,
    "ogx_mmlux_el-high_school_us_history": 5,
    "ogx_mmlux_el-high_school_world_history": 5,
    "ogx_mmlux_el-human_aging": 5,
    "ogx_mmlux_el-human_sexuality": 5,
    "ogx_mmlux_el-international_law": 5,
    "ogx_mmlux_el-jurisprudence": 5,
    "ogx_mmlux_el-logical_fallacies": 5,
    "ogx_mmlux_el-machine_learning": 5,
    "ogx_mmlux_el-management": 5,
    "ogx_mmlux_el-marketing": 5,
    "ogx_mmlux_el-medical_genetics": 5,
    "ogx_mmlux_el-miscellaneous": 5,
    "ogx_mmlux_el-moral_disputes": 5,
    "ogx_mmlux_el-moral_scenarios": 5,
    "ogx_mmlux_el-nutrition": 5,
    "ogx_mmlux_el-philosophy": 5,
    "ogx_mmlux_el-prehistory": 5,
    "ogx_mmlux_el-professional_accounting": 5,
    "ogx_mmlux_el-professional_law": 5,
    "ogx_mmlux_el-professional_medicine": 5,
    "ogx_mmlux_el-professional_psychology": 5,
    "ogx_mmlux_el-public_relations": 5,
    "ogx_mmlux_el-security_studies": 5,
    "ogx_mmlux_el-sociology": 5,
    "ogx_mmlux_el-us_foreign_policy": 5,
    "ogx_mmlux_el-virology": 5,
    "ogx_mmlux_el-world_religions": 5,
    "ogx_mmlux_es-abstract_algebra": 5,
    "ogx_mmlux_es-anatomy": 5,
    "ogx_mmlux_es-astronomy": 5,
    "ogx_mmlux_es-business_ethics": 5,
    "ogx_mmlux_es-clinical_knowledge": 5,
    "ogx_mmlux_es-college_biology": 5,
    "ogx_mmlux_es-college_chemistry": 5,
    "ogx_mmlux_es-college_computer_science": 5,
    "ogx_mmlux_es-college_mathematics": 5,
    "ogx_mmlux_es-college_medicine": 5,
    "ogx_mmlux_es-college_physics": 5,
    "ogx_mmlux_es-computer_security": 5,
    "ogx_mmlux_es-conceptual_physics": 5,
    "ogx_mmlux_es-econometrics": 5,
    "ogx_mmlux_es-electrical_engineering": 5,
    "ogx_mmlux_es-elementary_mathematics": 5,
    "ogx_mmlux_es-formal_logic": 5,
    "ogx_mmlux_es-global_facts": 5,
    "ogx_mmlux_es-high_school_biology": 5,
    "ogx_mmlux_es-high_school_chemistry": 5,
    "ogx_mmlux_es-high_school_computer_science": 5,
    "ogx_mmlux_es-high_school_european_history": 5,
    "ogx_mmlux_es-high_school_geography": 5,
    "ogx_mmlux_es-high_school_government_and_politics": 5,
    "ogx_mmlux_es-high_school_macroeconomics": 5,
    "ogx_mmlux_es-high_school_mathematics": 5,
    "ogx_mmlux_es-high_school_microeconomics": 5,
    "ogx_mmlux_es-high_school_physics": 5,
    "ogx_mmlux_es-high_school_psychology": 5,
    "ogx_mmlux_es-high_school_statistics": 5,
    "ogx_mmlux_es-high_school_us_history": 5,
    "ogx_mmlux_es-high_school_world_history": 5,
    "ogx_mmlux_es-human_aging": 5,
    "ogx_mmlux_es-human_sexuality": 5,
    "ogx_mmlux_es-international_law": 5,
    "ogx_mmlux_es-jurisprudence": 5,
    "ogx_mmlux_es-logical_fallacies": 5,
    "ogx_mmlux_es-machine_learning": 5,
    "ogx_mmlux_es-management": 5,
    "ogx_mmlux_es-marketing": 5,
    "ogx_mmlux_es-medical_genetics": 5,
    "ogx_mmlux_es-miscellaneous": 5,
    "ogx_mmlux_es-moral_disputes": 5,
    "ogx_mmlux_es-moral_scenarios": 5,
    "ogx_mmlux_es-nutrition": 5,
    "ogx_mmlux_es-philosophy": 5,
    "ogx_mmlux_es-prehistory": 5,
    "ogx_mmlux_es-professional_accounting": 5,
    "ogx_mmlux_es-professional_law": 5,
    "ogx_mmlux_es-professional_medicine": 5,
    "ogx_mmlux_es-professional_psychology": 5,
    "ogx_mmlux_es-public_relations": 5,
    "ogx_mmlux_es-security_studies": 5,
    "ogx_mmlux_es-sociology": 5,
    "ogx_mmlux_es-us_foreign_policy": 5,
    "ogx_mmlux_es-virology": 5,
    "ogx_mmlux_es-world_religions": 5,
    "ogx_mmlux_et-abstract_algebra": 5,
    "ogx_mmlux_et-anatomy": 5,
    "ogx_mmlux_et-astronomy": 5,
    "ogx_mmlux_et-business_ethics": 5,
    "ogx_mmlux_et-clinical_knowledge": 5,
    "ogx_mmlux_et-college_biology": 5,
    "ogx_mmlux_et-college_chemistry": 5,
    "ogx_mmlux_et-college_computer_science": 5,
    "ogx_mmlux_et-college_mathematics": 5,
    "ogx_mmlux_et-college_medicine": 5,
    "ogx_mmlux_et-college_physics": 5,
    "ogx_mmlux_et-computer_security": 5,
    "ogx_mmlux_et-conceptual_physics": 5,
    "ogx_mmlux_et-econometrics": 5,
    "ogx_mmlux_et-electrical_engineering": 5,
    "ogx_mmlux_et-elementary_mathematics": 5,
    "ogx_mmlux_et-formal_logic": 5,
    "ogx_mmlux_et-global_facts": 5,
    "ogx_mmlux_et-high_school_biology": 5,
    "ogx_mmlux_et-high_school_chemistry": 5,
    "ogx_mmlux_et-high_school_computer_science": 5,
    "ogx_mmlux_et-high_school_european_history": 5,
    "ogx_mmlux_et-high_school_geography": 5,
    "ogx_mmlux_et-high_school_government_and_politics": 5,
    "ogx_mmlux_et-high_school_macroeconomics": 5,
    "ogx_mmlux_et-high_school_mathematics": 5,
    "ogx_mmlux_et-high_school_microeconomics": 5,
    "ogx_mmlux_et-high_school_physics": 5,
    "ogx_mmlux_et-high_school_psychology": 5,
    "ogx_mmlux_et-high_school_statistics": 5,
    "ogx_mmlux_et-high_school_us_history": 5,
    "ogx_mmlux_et-high_school_world_history": 5,
    "ogx_mmlux_et-human_aging": 5,
    "ogx_mmlux_et-human_sexuality": 5,
    "ogx_mmlux_et-international_law": 5,
    "ogx_mmlux_et-jurisprudence": 5,
    "ogx_mmlux_et-logical_fallacies": 5,
    "ogx_mmlux_et-machine_learning": 5,
    "ogx_mmlux_et-management": 5,
    "ogx_mmlux_et-marketing": 5,
    "ogx_mmlux_et-medical_genetics": 5,
    "ogx_mmlux_et-miscellaneous": 5,
    "ogx_mmlux_et-moral_disputes": 5,
    "ogx_mmlux_et-moral_scenarios": 5,
    "ogx_mmlux_et-nutrition": 5,
    "ogx_mmlux_et-philosophy": 5,
    "ogx_mmlux_et-prehistory": 5,
    "ogx_mmlux_et-professional_accounting": 5,
    "ogx_mmlux_et-professional_law": 5,
    "ogx_mmlux_et-professional_medicine": 5,
    "ogx_mmlux_et-professional_psychology": 5,
    "ogx_mmlux_et-public_relations": 5,
    "ogx_mmlux_et-security_studies": 5,
    "ogx_mmlux_et-sociology": 5,
    "ogx_mmlux_et-us_foreign_policy": 5,
    "ogx_mmlux_et-virology": 5,
    "ogx_mmlux_et-world_religions": 5,
    "ogx_mmlux_fi-abstract_algebra": 5,
    "ogx_mmlux_fi-anatomy": 5,
    "ogx_mmlux_fi-astronomy": 5,
    "ogx_mmlux_fi-business_ethics": 5,
    "ogx_mmlux_fi-clinical_knowledge": 5,
    "ogx_mmlux_fi-college_biology": 5,
    "ogx_mmlux_fi-college_chemistry": 5,
    "ogx_mmlux_fi-college_computer_science": 5,
    "ogx_mmlux_fi-college_mathematics": 5,
    "ogx_mmlux_fi-college_medicine": 5,
    "ogx_mmlux_fi-college_physics": 5,
    "ogx_mmlux_fi-computer_security": 5,
    "ogx_mmlux_fi-conceptual_physics": 5,
    "ogx_mmlux_fi-econometrics": 5,
    "ogx_mmlux_fi-electrical_engineering": 5,
    "ogx_mmlux_fi-elementary_mathematics": 5,
    "ogx_mmlux_fi-formal_logic": 5,
    "ogx_mmlux_fi-global_facts": 5,
    "ogx_mmlux_fi-high_school_biology": 5,
    "ogx_mmlux_fi-high_school_chemistry": 5,
    "ogx_mmlux_fi-high_school_computer_science": 5,
    "ogx_mmlux_fi-high_school_european_history": 5,
    "ogx_mmlux_fi-high_school_geography": 5,
    "ogx_mmlux_fi-high_school_government_and_politics": 5,
    "ogx_mmlux_fi-high_school_macroeconomics": 5,
    "ogx_mmlux_fi-high_school_mathematics": 5,
    "ogx_mmlux_fi-high_school_microeconomics": 5,
    "ogx_mmlux_fi-high_school_physics": 5,
    "ogx_mmlux_fi-high_school_psychology": 5,
    "ogx_mmlux_fi-high_school_statistics": 5,
    "ogx_mmlux_fi-high_school_us_history": 5,
    "ogx_mmlux_fi-high_school_world_history": 5,
    "ogx_mmlux_fi-human_aging": 5,
    "ogx_mmlux_fi-human_sexuality": 5,
    "ogx_mmlux_fi-international_law": 5,
    "ogx_mmlux_fi-jurisprudence": 5,
    "ogx_mmlux_fi-logical_fallacies": 5,
    "ogx_mmlux_fi-machine_learning": 5,
    "ogx_mmlux_fi-management": 5,
    "ogx_mmlux_fi-marketing": 5,
    "ogx_mmlux_fi-medical_genetics": 5,
    "ogx_mmlux_fi-miscellaneous": 5,
    "ogx_mmlux_fi-moral_disputes": 5,
    "ogx_mmlux_fi-moral_scenarios": 5,
    "ogx_mmlux_fi-nutrition": 5,
    "ogx_mmlux_fi-philosophy": 5,
    "ogx_mmlux_fi-prehistory": 5,
    "ogx_mmlux_fi-professional_accounting": 5,
    "ogx_mmlux_fi-professional_law": 5,
    "ogx_mmlux_fi-professional_medicine": 5,
    "ogx_mmlux_fi-professional_psychology": 5,
    "ogx_mmlux_fi-public_relations": 5,
    "ogx_mmlux_fi-security_studies": 5,
    "ogx_mmlux_fi-sociology": 5,
    "ogx_mmlux_fi-us_foreign_policy": 5,
    "ogx_mmlux_fi-virology": 5,
    "ogx_mmlux_fi-world_religions": 5,
    "ogx_mmlux_fr-abstract_algebra": 5,
    "ogx_mmlux_fr-anatomy": 5,
    "ogx_mmlux_fr-astronomy": 5,
    "ogx_mmlux_fr-business_ethics": 5,
    "ogx_mmlux_fr-clinical_knowledge": 5,
    "ogx_mmlux_fr-college_biology": 5,
    "ogx_mmlux_fr-college_chemistry": 5,
    "ogx_mmlux_fr-college_computer_science": 5,
    "ogx_mmlux_fr-college_mathematics": 5,
    "ogx_mmlux_fr-college_medicine": 5,
    "ogx_mmlux_fr-college_physics": 5,
    "ogx_mmlux_fr-computer_security": 5,
    "ogx_mmlux_fr-conceptual_physics": 5,
    "ogx_mmlux_fr-econometrics": 5,
    "ogx_mmlux_fr-electrical_engineering": 5,
    "ogx_mmlux_fr-elementary_mathematics": 5,
    "ogx_mmlux_fr-formal_logic": 5,
    "ogx_mmlux_fr-global_facts": 5,
    "ogx_mmlux_fr-high_school_biology": 5,
    "ogx_mmlux_fr-high_school_chemistry": 5,
    "ogx_mmlux_fr-high_school_computer_science": 5,
    "ogx_mmlux_fr-high_school_european_history": 5,
    "ogx_mmlux_fr-high_school_geography": 5,
    "ogx_mmlux_fr-high_school_government_and_politics": 5,
    "ogx_mmlux_fr-high_school_macroeconomics": 5,
    "ogx_mmlux_fr-high_school_mathematics": 5,
    "ogx_mmlux_fr-high_school_microeconomics": 5,
    "ogx_mmlux_fr-high_school_physics": 5,
    "ogx_mmlux_fr-high_school_psychology": 5,
    "ogx_mmlux_fr-high_school_statistics": 5,
    "ogx_mmlux_fr-high_school_us_history": 5,
    "ogx_mmlux_fr-high_school_world_history": 5,
    "ogx_mmlux_fr-human_aging": 5,
    "ogx_mmlux_fr-human_sexuality": 5,
    "ogx_mmlux_fr-international_law": 5,
    "ogx_mmlux_fr-jurisprudence": 5,
    "ogx_mmlux_fr-logical_fallacies": 5,
    "ogx_mmlux_fr-machine_learning": 5,
    "ogx_mmlux_fr-management": 5,
    "ogx_mmlux_fr-marketing": 5,
    "ogx_mmlux_fr-medical_genetics": 5,
    "ogx_mmlux_fr-miscellaneous": 5,
    "ogx_mmlux_fr-moral_disputes": 5,
    "ogx_mmlux_fr-moral_scenarios": 5,
    "ogx_mmlux_fr-nutrition": 5,
    "ogx_mmlux_fr-philosophy": 5,
    "ogx_mmlux_fr-prehistory": 5,
    "ogx_mmlux_fr-professional_accounting": 5,
    "ogx_mmlux_fr-professional_law": 5,
    "ogx_mmlux_fr-professional_medicine": 5,
    "ogx_mmlux_fr-professional_psychology": 5,
    "ogx_mmlux_fr-public_relations": 5,
    "ogx_mmlux_fr-security_studies": 5,
    "ogx_mmlux_fr-sociology": 5,
    "ogx_mmlux_fr-us_foreign_policy": 5,
    "ogx_mmlux_fr-virology": 5,
    "ogx_mmlux_fr-world_religions": 5,
    "ogx_mmlux_hu-abstract_algebra": 5,
    "ogx_mmlux_hu-anatomy": 5,
    "ogx_mmlux_hu-astronomy": 5,
    "ogx_mmlux_hu-business_ethics": 5,
    "ogx_mmlux_hu-clinical_knowledge": 5,
    "ogx_mmlux_hu-college_biology": 5,
    "ogx_mmlux_hu-college_chemistry": 5,
    "ogx_mmlux_hu-college_computer_science": 5,
    "ogx_mmlux_hu-college_mathematics": 5,
    "ogx_mmlux_hu-college_medicine": 5,
    "ogx_mmlux_hu-college_physics": 5,
    "ogx_mmlux_hu-computer_security": 5,
    "ogx_mmlux_hu-conceptual_physics": 5,
    "ogx_mmlux_hu-econometrics": 5,
    "ogx_mmlux_hu-electrical_engineering": 5,
    "ogx_mmlux_hu-elementary_mathematics": 5,
    "ogx_mmlux_hu-formal_logic": 5,
    "ogx_mmlux_hu-global_facts": 5,
    "ogx_mmlux_hu-high_school_biology": 5,
    "ogx_mmlux_hu-high_school_chemistry": 5,
    "ogx_mmlux_hu-high_school_computer_science": 5,
    "ogx_mmlux_hu-high_school_european_history": 5,
    "ogx_mmlux_hu-high_school_geography": 5,
    "ogx_mmlux_hu-high_school_government_and_politics": 5,
    "ogx_mmlux_hu-high_school_macroeconomics": 5,
    "ogx_mmlux_hu-high_school_mathematics": 5,
    "ogx_mmlux_hu-high_school_microeconomics": 5,
    "ogx_mmlux_hu-high_school_physics": 5,
    "ogx_mmlux_hu-high_school_psychology": 5,
    "ogx_mmlux_hu-high_school_statistics": 5,
    "ogx_mmlux_hu-high_school_us_history": 5,
    "ogx_mmlux_hu-high_school_world_history": 5,
    "ogx_mmlux_hu-human_aging": 5,
    "ogx_mmlux_hu-human_sexuality": 5,
    "ogx_mmlux_hu-international_law": 5,
    "ogx_mmlux_hu-jurisprudence": 5,
    "ogx_mmlux_hu-logical_fallacies": 5,
    "ogx_mmlux_hu-machine_learning": 5,
    "ogx_mmlux_hu-management": 5,
    "ogx_mmlux_hu-marketing": 5,
    "ogx_mmlux_hu-medical_genetics": 5,
    "ogx_mmlux_hu-miscellaneous": 5,
    "ogx_mmlux_hu-moral_disputes": 5,
    "ogx_mmlux_hu-moral_scenarios": 5,
    "ogx_mmlux_hu-nutrition": 5,
    "ogx_mmlux_hu-philosophy": 5,
    "ogx_mmlux_hu-prehistory": 5,
    "ogx_mmlux_hu-professional_accounting": 5,
    "ogx_mmlux_hu-professional_law": 5,
    "ogx_mmlux_hu-professional_medicine": 5,
    "ogx_mmlux_hu-professional_psychology": 5,
    "ogx_mmlux_hu-public_relations": 5,
    "ogx_mmlux_hu-security_studies": 5,
    "ogx_mmlux_hu-sociology": 5,
    "ogx_mmlux_hu-us_foreign_policy": 5,
    "ogx_mmlux_hu-virology": 5,
    "ogx_mmlux_hu-world_religions": 5,
    "ogx_mmlux_it-abstract_algebra": 5,
    "ogx_mmlux_it-anatomy": 5,
    "ogx_mmlux_it-astronomy": 5,
    "ogx_mmlux_it-business_ethics": 5,
    "ogx_mmlux_it-clinical_knowledge": 5,
    "ogx_mmlux_it-college_biology": 5,
    "ogx_mmlux_it-college_chemistry": 5,
    "ogx_mmlux_it-college_computer_science": 5,
    "ogx_mmlux_it-college_mathematics": 5,
    "ogx_mmlux_it-college_medicine": 5,
    "ogx_mmlux_it-college_physics": 5,
    "ogx_mmlux_it-computer_security": 5,
    "ogx_mmlux_it-conceptual_physics": 5,
    "ogx_mmlux_it-econometrics": 5,
    "ogx_mmlux_it-electrical_engineering": 5,
    "ogx_mmlux_it-elementary_mathematics": 5,
    "ogx_mmlux_it-formal_logic": 5,
    "ogx_mmlux_it-global_facts": 5,
    "ogx_mmlux_it-high_school_biology": 5,
    "ogx_mmlux_it-high_school_chemistry": 5,
    "ogx_mmlux_it-high_school_computer_science": 5,
    "ogx_mmlux_it-high_school_european_history": 5,
    "ogx_mmlux_it-high_school_geography": 5,
    "ogx_mmlux_it-high_school_government_and_politics": 5,
    "ogx_mmlux_it-high_school_macroeconomics": 5,
    "ogx_mmlux_it-high_school_mathematics": 5,
    "ogx_mmlux_it-high_school_microeconomics": 5,
    "ogx_mmlux_it-high_school_physics": 5,
    "ogx_mmlux_it-high_school_psychology": 5,
    "ogx_mmlux_it-high_school_statistics": 5,
    "ogx_mmlux_it-high_school_us_history": 5,
    "ogx_mmlux_it-high_school_world_history": 5,
    "ogx_mmlux_it-human_aging": 5,
    "ogx_mmlux_it-human_sexuality": 5,
    "ogx_mmlux_it-international_law": 5,
    "ogx_mmlux_it-jurisprudence": 5,
    "ogx_mmlux_it-logical_fallacies": 5,
    "ogx_mmlux_it-machine_learning": 5,
    "ogx_mmlux_it-management": 5,
    "ogx_mmlux_it-marketing": 5,
    "ogx_mmlux_it-medical_genetics": 5,
    "ogx_mmlux_it-miscellaneous": 5,
    "ogx_mmlux_it-moral_disputes": 5,
    "ogx_mmlux_it-moral_scenarios": 5,
    "ogx_mmlux_it-nutrition": 5,
    "ogx_mmlux_it-philosophy": 5,
    "ogx_mmlux_it-prehistory": 5,
    "ogx_mmlux_it-professional_accounting": 5,
    "ogx_mmlux_it-professional_law": 5,
    "ogx_mmlux_it-professional_medicine": 5,
    "ogx_mmlux_it-professional_psychology": 5,
    "ogx_mmlux_it-public_relations": 5,
    "ogx_mmlux_it-security_studies": 5,
    "ogx_mmlux_it-sociology": 5,
    "ogx_mmlux_it-us_foreign_policy": 5,
    "ogx_mmlux_it-virology": 5,
    "ogx_mmlux_it-world_religions": 5,
    "ogx_mmlux_lt-abstract_algebra": 5,
    "ogx_mmlux_lt-anatomy": 5,
    "ogx_mmlux_lt-astronomy": 5,
    "ogx_mmlux_lt-business_ethics": 5,
    "ogx_mmlux_lt-clinical_knowledge": 5,
    "ogx_mmlux_lt-college_biology": 5,
    "ogx_mmlux_lt-college_chemistry": 5,
    "ogx_mmlux_lt-college_computer_science": 5,
    "ogx_mmlux_lt-college_mathematics": 5,
    "ogx_mmlux_lt-college_medicine": 5,
    "ogx_mmlux_lt-college_physics": 5,
    "ogx_mmlux_lt-computer_security": 5,
    "ogx_mmlux_lt-conceptual_physics": 5,
    "ogx_mmlux_lt-econometrics": 5,
    "ogx_mmlux_lt-electrical_engineering": 5,
    "ogx_mmlux_lt-elementary_mathematics": 5,
    "ogx_mmlux_lt-formal_logic": 5,
    "ogx_mmlux_lt-global_facts": 5,
    "ogx_mmlux_lt-high_school_biology": 5,
    "ogx_mmlux_lt-high_school_chemistry": 5,
    "ogx_mmlux_lt-high_school_computer_science": 5,
    "ogx_mmlux_lt-high_school_european_history": 5,
    "ogx_mmlux_lt-high_school_geography": 5,
    "ogx_mmlux_lt-high_school_government_and_politics": 5,
    "ogx_mmlux_lt-high_school_macroeconomics": 5,
    "ogx_mmlux_lt-high_school_mathematics": 5,
    "ogx_mmlux_lt-high_school_microeconomics": 5,
    "ogx_mmlux_lt-high_school_physics": 5,
    "ogx_mmlux_lt-high_school_psychology": 5,
    "ogx_mmlux_lt-high_school_statistics": 5,
    "ogx_mmlux_lt-high_school_us_history": 5,
    "ogx_mmlux_lt-high_school_world_history": 5,
    "ogx_mmlux_lt-human_aging": 5,
    "ogx_mmlux_lt-human_sexuality": 5,
    "ogx_mmlux_lt-international_law": 5,
    "ogx_mmlux_lt-jurisprudence": 5,
    "ogx_mmlux_lt-logical_fallacies": 5,
    "ogx_mmlux_lt-machine_learning": 5,
    "ogx_mmlux_lt-management": 5,
    "ogx_mmlux_lt-marketing": 5,
    "ogx_mmlux_lt-medical_genetics": 5,
    "ogx_mmlux_lt-miscellaneous": 5,
    "ogx_mmlux_lt-moral_disputes": 5,
    "ogx_mmlux_lt-moral_scenarios": 5,
    "ogx_mmlux_lt-nutrition": 5,
    "ogx_mmlux_lt-philosophy": 5,
    "ogx_mmlux_lt-prehistory": 5,
    "ogx_mmlux_lt-professional_accounting": 5,
    "ogx_mmlux_lt-professional_law": 5,
    "ogx_mmlux_lt-professional_medicine": 5,
    "ogx_mmlux_lt-professional_psychology": 5,
    "ogx_mmlux_lt-public_relations": 5,
    "ogx_mmlux_lt-security_studies": 5,
    "ogx_mmlux_lt-sociology": 5,
    "ogx_mmlux_lt-us_foreign_policy": 5,
    "ogx_mmlux_lt-virology": 5,
    "ogx_mmlux_lt-world_religions": 5,
    "ogx_mmlux_lv-abstract_algebra": 5,
    "ogx_mmlux_lv-anatomy": 5,
    "ogx_mmlux_lv-astronomy": 5,
    "ogx_mmlux_lv-business_ethics": 5,
    "ogx_mmlux_lv-clinical_knowledge": 5,
    "ogx_mmlux_lv-college_biology": 5,
    "ogx_mmlux_lv-college_chemistry": 5,
    "ogx_mmlux_lv-college_computer_science": 5,
    "ogx_mmlux_lv-college_mathematics": 5,
    "ogx_mmlux_lv-college_medicine": 5,
    "ogx_mmlux_lv-college_physics": 5,
    "ogx_mmlux_lv-computer_security": 5,
    "ogx_mmlux_lv-conceptual_physics": 5,
    "ogx_mmlux_lv-econometrics": 5,
    "ogx_mmlux_lv-electrical_engineering": 5,
    "ogx_mmlux_lv-elementary_mathematics": 5,
    "ogx_mmlux_lv-formal_logic": 5,
    "ogx_mmlux_lv-global_facts": 5,
    "ogx_mmlux_lv-high_school_biology": 5,
    "ogx_mmlux_lv-high_school_chemistry": 5,
    "ogx_mmlux_lv-high_school_computer_science": 5,
    "ogx_mmlux_lv-high_school_european_history": 5,
    "ogx_mmlux_lv-high_school_geography": 5,
    "ogx_mmlux_lv-high_school_government_and_politics": 5,
    "ogx_mmlux_lv-high_school_macroeconomics": 5,
    "ogx_mmlux_lv-high_school_mathematics": 5,
    "ogx_mmlux_lv-high_school_microeconomics": 5,
    "ogx_mmlux_lv-high_school_physics": 5,
    "ogx_mmlux_lv-high_school_psychology": 5,
    "ogx_mmlux_lv-high_school_statistics": 5,
    "ogx_mmlux_lv-high_school_us_history": 5,
    "ogx_mmlux_lv-high_school_world_history": 5,
    "ogx_mmlux_lv-human_aging": 5,
    "ogx_mmlux_lv-human_sexuality": 5,
    "ogx_mmlux_lv-international_law": 5,
    "ogx_mmlux_lv-jurisprudence": 5,
    "ogx_mmlux_lv-logical_fallacies": 5,
    "ogx_mmlux_lv-machine_learning": 5,
    "ogx_mmlux_lv-management": 5,
    "ogx_mmlux_lv-marketing": 5,
    "ogx_mmlux_lv-medical_genetics": 5,
    "ogx_mmlux_lv-miscellaneous": 5,
    "ogx_mmlux_lv-moral_disputes": 5,
    "ogx_mmlux_lv-moral_scenarios": 5,
    "ogx_mmlux_lv-nutrition": 5,
    "ogx_mmlux_lv-philosophy": 5,
    "ogx_mmlux_lv-prehistory": 5,
    "ogx_mmlux_lv-professional_accounting": 5,
    "ogx_mmlux_lv-professional_law": 5,
    "ogx_mmlux_lv-professional_medicine": 5,
    "ogx_mmlux_lv-professional_psychology": 5,
    "ogx_mmlux_lv-public_relations": 5,
    "ogx_mmlux_lv-security_studies": 5,
    "ogx_mmlux_lv-sociology": 5,
    "ogx_mmlux_lv-us_foreign_policy": 5,
    "ogx_mmlux_lv-virology": 5,
    "ogx_mmlux_lv-world_religions": 5,
    "ogx_mmlux_nl-abstract_algebra": 5,
    "ogx_mmlux_nl-anatomy": 5,
    "ogx_mmlux_nl-astronomy": 5,
    "ogx_mmlux_nl-business_ethics": 5,
    "ogx_mmlux_nl-clinical_knowledge": 5,
    "ogx_mmlux_nl-college_biology": 5,
    "ogx_mmlux_nl-college_chemistry": 5,
    "ogx_mmlux_nl-college_computer_science": 5,
    "ogx_mmlux_nl-college_mathematics": 5,
    "ogx_mmlux_nl-college_medicine": 5,
    "ogx_mmlux_nl-college_physics": 5,
    "ogx_mmlux_nl-computer_security": 5,
    "ogx_mmlux_nl-conceptual_physics": 5,
    "ogx_mmlux_nl-econometrics": 5,
    "ogx_mmlux_nl-electrical_engineering": 5,
    "ogx_mmlux_nl-elementary_mathematics": 5,
    "ogx_mmlux_nl-formal_logic": 5,
    "ogx_mmlux_nl-global_facts": 5,
    "ogx_mmlux_nl-high_school_biology": 5,
    "ogx_mmlux_nl-high_school_chemistry": 5,
    "ogx_mmlux_nl-high_school_computer_science": 5,
    "ogx_mmlux_nl-high_school_european_history": 5,
    "ogx_mmlux_nl-high_school_geography": 5,
    "ogx_mmlux_nl-high_school_government_and_politics": 5,
    "ogx_mmlux_nl-high_school_macroeconomics": 5,
    "ogx_mmlux_nl-high_school_mathematics": 5,
    "ogx_mmlux_nl-high_school_microeconomics": 5,
    "ogx_mmlux_nl-high_school_physics": 5,
    "ogx_mmlux_nl-high_school_psychology": 5,
    "ogx_mmlux_nl-high_school_statistics": 5,
    "ogx_mmlux_nl-high_school_us_history": 5,
    "ogx_mmlux_nl-high_school_world_history": 5,
    "ogx_mmlux_nl-human_aging": 5,
    "ogx_mmlux_nl-human_sexuality": 5,
    "ogx_mmlux_nl-international_law": 5,
    "ogx_mmlux_nl-jurisprudence": 5,
    "ogx_mmlux_nl-logical_fallacies": 5,
    "ogx_mmlux_nl-machine_learning": 5,
    "ogx_mmlux_nl-management": 5,
    "ogx_mmlux_nl-marketing": 5,
    "ogx_mmlux_nl-medical_genetics": 5,
    "ogx_mmlux_nl-miscellaneous": 5,
    "ogx_mmlux_nl-moral_disputes": 5,
    "ogx_mmlux_nl-moral_scenarios": 5,
    "ogx_mmlux_nl-nutrition": 5,
    "ogx_mmlux_nl-philosophy": 5,
    "ogx_mmlux_nl-prehistory": 5,
    "ogx_mmlux_nl-professional_accounting": 5,
    "ogx_mmlux_nl-professional_law": 5,
    "ogx_mmlux_nl-professional_medicine": 5,
    "ogx_mmlux_nl-professional_psychology": 5,
    "ogx_mmlux_nl-public_relations": 5,
    "ogx_mmlux_nl-security_studies": 5,
    "ogx_mmlux_nl-sociology": 5,
    "ogx_mmlux_nl-us_foreign_policy": 5,
    "ogx_mmlux_nl-virology": 5,
    "ogx_mmlux_nl-world_religions": 5,
    "ogx_mmlux_pl-abstract_algebra": 5,
    "ogx_mmlux_pl-anatomy": 5,
    "ogx_mmlux_pl-astronomy": 5,
    "ogx_mmlux_pl-business_ethics": 5,
    "ogx_mmlux_pl-clinical_knowledge": 5,
    "ogx_mmlux_pl-college_biology": 5,
    "ogx_mmlux_pl-college_chemistry": 5,
    "ogx_mmlux_pl-college_computer_science": 5,
    "ogx_mmlux_pl-college_mathematics": 5,
    "ogx_mmlux_pl-college_medicine": 5,
    "ogx_mmlux_pl-college_physics": 5,
    "ogx_mmlux_pl-computer_security": 5,
    "ogx_mmlux_pl-conceptual_physics": 5,
    "ogx_mmlux_pl-econometrics": 5,
    "ogx_mmlux_pl-electrical_engineering": 5,
    "ogx_mmlux_pl-elementary_mathematics": 5,
    "ogx_mmlux_pl-formal_logic": 5,
    "ogx_mmlux_pl-global_facts": 5,
    "ogx_mmlux_pl-high_school_biology": 5,
    "ogx_mmlux_pl-high_school_chemistry": 5,
    "ogx_mmlux_pl-high_school_computer_science": 5,
    "ogx_mmlux_pl-high_school_european_history": 5,
    "ogx_mmlux_pl-high_school_geography": 5,
    "ogx_mmlux_pl-high_school_government_and_politics": 5,
    "ogx_mmlux_pl-high_school_macroeconomics": 5,
    "ogx_mmlux_pl-high_school_mathematics": 5,
    "ogx_mmlux_pl-high_school_microeconomics": 5,
    "ogx_mmlux_pl-high_school_physics": 5,
    "ogx_mmlux_pl-high_school_psychology": 5,
    "ogx_mmlux_pl-high_school_statistics": 5,
    "ogx_mmlux_pl-high_school_us_history": 5,
    "ogx_mmlux_pl-high_school_world_history": 5,
    "ogx_mmlux_pl-human_aging": 5,
    "ogx_mmlux_pl-human_sexuality": 5,
    "ogx_mmlux_pl-international_law": 5,
    "ogx_mmlux_pl-jurisprudence": 5,
    "ogx_mmlux_pl-logical_fallacies": 5,
    "ogx_mmlux_pl-machine_learning": 5,
    "ogx_mmlux_pl-management": 5,
    "ogx_mmlux_pl-marketing": 5,
    "ogx_mmlux_pl-medical_genetics": 5,
    "ogx_mmlux_pl-miscellaneous": 5,
    "ogx_mmlux_pl-moral_disputes": 5,
    "ogx_mmlux_pl-moral_scenarios": 5,
    "ogx_mmlux_pl-nutrition": 5,
    "ogx_mmlux_pl-philosophy": 5,
    "ogx_mmlux_pl-prehistory": 5,
    "ogx_mmlux_pl-professional_accounting": 5,
    "ogx_mmlux_pl-professional_law": 5,
    "ogx_mmlux_pl-professional_medicine": 5,
    "ogx_mmlux_pl-professional_psychology": 5,
    "ogx_mmlux_pl-public_relations": 5,
    "ogx_mmlux_pl-security_studies": 5,
    "ogx_mmlux_pl-sociology": 5,
    "ogx_mmlux_pl-us_foreign_policy": 5,
    "ogx_mmlux_pl-virology": 5,
    "ogx_mmlux_pl-world_religions": 5,
    "ogx_mmlux_pt-pt-abstract_algebra": 5,
    "ogx_mmlux_pt-pt-anatomy": 5,
    "ogx_mmlux_pt-pt-astronomy": 5,
    "ogx_mmlux_pt-pt-business_ethics": 5,
    "ogx_mmlux_pt-pt-clinical_knowledge": 5,
    "ogx_mmlux_pt-pt-college_biology": 5,
    "ogx_mmlux_pt-pt-college_chemistry": 5,
    "ogx_mmlux_pt-pt-college_computer_science": 5,
    "ogx_mmlux_pt-pt-college_mathematics": 5,
    "ogx_mmlux_pt-pt-college_medicine": 5,
    "ogx_mmlux_pt-pt-college_physics": 5,
    "ogx_mmlux_pt-pt-computer_security": 5,
    "ogx_mmlux_pt-pt-conceptual_physics": 5,
    "ogx_mmlux_pt-pt-econometrics": 5,
    "ogx_mmlux_pt-pt-electrical_engineering": 5,
    "ogx_mmlux_pt-pt-elementary_mathematics": 5,
    "ogx_mmlux_pt-pt-formal_logic": 5,
    "ogx_mmlux_pt-pt-global_facts": 5,
    "ogx_mmlux_pt-pt-high_school_biology": 5,
    "ogx_mmlux_pt-pt-high_school_chemistry": 5,
    "ogx_mmlux_pt-pt-high_school_computer_science": 5,
    "ogx_mmlux_pt-pt-high_school_european_history": 5,
    "ogx_mmlux_pt-pt-high_school_geography": 5,
    "ogx_mmlux_pt-pt-high_school_government_and_politics": 5,
    "ogx_mmlux_pt-pt-high_school_macroeconomics": 5,
    "ogx_mmlux_pt-pt-high_school_mathematics": 5,
    "ogx_mmlux_pt-pt-high_school_microeconomics": 5,
    "ogx_mmlux_pt-pt-high_school_physics": 5,
    "ogx_mmlux_pt-pt-high_school_psychology": 5,
    "ogx_mmlux_pt-pt-high_school_statistics": 5,
    "ogx_mmlux_pt-pt-high_school_us_history": 5,
    "ogx_mmlux_pt-pt-high_school_world_history": 5,
    "ogx_mmlux_pt-pt-human_aging": 5,
    "ogx_mmlux_pt-pt-human_sexuality": 5,
    "ogx_mmlux_pt-pt-international_law": 5,
    "ogx_mmlux_pt-pt-jurisprudence": 5,
    "ogx_mmlux_pt-pt-logical_fallacies": 5,
    "ogx_mmlux_pt-pt-machine_learning": 5,
    "ogx_mmlux_pt-pt-management": 5,
    "ogx_mmlux_pt-pt-marketing": 5,
    "ogx_mmlux_pt-pt-medical_genetics": 5,
    "ogx_mmlux_pt-pt-miscellaneous": 5,
    "ogx_mmlux_pt-pt-moral_disputes": 5,
    "ogx_mmlux_pt-pt-moral_scenarios": 5,
    "ogx_mmlux_pt-pt-nutrition": 5,
    "ogx_mmlux_pt-pt-philosophy": 5,
    "ogx_mmlux_pt-pt-prehistory": 5,
    "ogx_mmlux_pt-pt-professional_accounting": 5,
    "ogx_mmlux_pt-pt-professional_law": 5,
    "ogx_mmlux_pt-pt-professional_medicine": 5,
    "ogx_mmlux_pt-pt-professional_psychology": 5,
    "ogx_mmlux_pt-pt-public_relations": 5,
    "ogx_mmlux_pt-pt-security_studies": 5,
    "ogx_mmlux_pt-pt-sociology": 5,
    "ogx_mmlux_pt-pt-us_foreign_policy": 5,
    "ogx_mmlux_pt-pt-virology": 5,
    "ogx_mmlux_pt-pt-world_religions": 5,
    "ogx_mmlux_ro-abstract_algebra": 5,
    "ogx_mmlux_ro-anatomy": 5,
    "ogx_mmlux_ro-astronomy": 5,
    "ogx_mmlux_ro-business_ethics": 5,
    "ogx_mmlux_ro-clinical_knowledge": 5,
    "ogx_mmlux_ro-college_biology": 5,
    "ogx_mmlux_ro-college_chemistry": 5,
    "ogx_mmlux_ro-college_computer_science": 5,
    "ogx_mmlux_ro-college_mathematics": 5,
    "ogx_mmlux_ro-college_medicine": 5,
    "ogx_mmlux_ro-college_physics": 5,
    "ogx_mmlux_ro-computer_security": 5,
    "ogx_mmlux_ro-conceptual_physics": 5,
    "ogx_mmlux_ro-econometrics": 5,
    "ogx_mmlux_ro-electrical_engineering": 5,
    "ogx_mmlux_ro-elementary_mathematics": 5,
    "ogx_mmlux_ro-formal_logic": 5,
    "ogx_mmlux_ro-global_facts": 5,
    "ogx_mmlux_ro-high_school_biology": 5,
    "ogx_mmlux_ro-high_school_chemistry": 5,
    "ogx_mmlux_ro-high_school_computer_science": 5,
    "ogx_mmlux_ro-high_school_european_history": 5,
    "ogx_mmlux_ro-high_school_geography": 5,
    "ogx_mmlux_ro-high_school_government_and_politics": 5,
    "ogx_mmlux_ro-high_school_macroeconomics": 5,
    "ogx_mmlux_ro-high_school_mathematics": 5,
    "ogx_mmlux_ro-high_school_microeconomics": 5,
    "ogx_mmlux_ro-high_school_physics": 5,
    "ogx_mmlux_ro-high_school_psychology": 5,
    "ogx_mmlux_ro-high_school_statistics": 5,
    "ogx_mmlux_ro-high_school_us_history": 5,
    "ogx_mmlux_ro-high_school_world_history": 5,
    "ogx_mmlux_ro-human_aging": 5,
    "ogx_mmlux_ro-human_sexuality": 5,
    "ogx_mmlux_ro-international_law": 5,
    "ogx_mmlux_ro-jurisprudence": 5,
    "ogx_mmlux_ro-logical_fallacies": 5,
    "ogx_mmlux_ro-machine_learning": 5,
    "ogx_mmlux_ro-management": 5,
    "ogx_mmlux_ro-marketing": 5,
    "ogx_mmlux_ro-medical_genetics": 5,
    "ogx_mmlux_ro-miscellaneous": 5,
    "ogx_mmlux_ro-moral_disputes": 5,
    "ogx_mmlux_ro-moral_scenarios": 5,
    "ogx_mmlux_ro-nutrition": 5,
    "ogx_mmlux_ro-philosophy": 5,
    "ogx_mmlux_ro-prehistory": 5,
    "ogx_mmlux_ro-professional_accounting": 5,
    "ogx_mmlux_ro-professional_law": 5,
    "ogx_mmlux_ro-professional_medicine": 5,
    "ogx_mmlux_ro-professional_psychology": 5,
    "ogx_mmlux_ro-public_relations": 5,
    "ogx_mmlux_ro-security_studies": 5,
    "ogx_mmlux_ro-sociology": 5,
    "ogx_mmlux_ro-us_foreign_policy": 5,
    "ogx_mmlux_ro-virology": 5,
    "ogx_mmlux_ro-world_religions": 5,
    "ogx_mmlux_sk-abstract_algebra": 5,
    "ogx_mmlux_sk-anatomy": 5,
    "ogx_mmlux_sk-astronomy": 5,
    "ogx_mmlux_sk-business_ethics": 5,
    "ogx_mmlux_sk-clinical_knowledge": 5,
    "ogx_mmlux_sk-college_biology": 5,
    "ogx_mmlux_sk-college_chemistry": 5,
    "ogx_mmlux_sk-college_computer_science": 5,
    "ogx_mmlux_sk-college_mathematics": 5,
    "ogx_mmlux_sk-college_medicine": 5,
    "ogx_mmlux_sk-college_physics": 5,
    "ogx_mmlux_sk-computer_security": 5,
    "ogx_mmlux_sk-conceptual_physics": 5,
    "ogx_mmlux_sk-econometrics": 5,
    "ogx_mmlux_sk-electrical_engineering": 5,
    "ogx_mmlux_sk-elementary_mathematics": 5,
    "ogx_mmlux_sk-formal_logic": 5,
    "ogx_mmlux_sk-global_facts": 5,
    "ogx_mmlux_sk-high_school_biology": 5,
    "ogx_mmlux_sk-high_school_chemistry": 5,
    "ogx_mmlux_sk-high_school_computer_science": 5,
    "ogx_mmlux_sk-high_school_european_history": 5,
    "ogx_mmlux_sk-high_school_geography": 5,
    "ogx_mmlux_sk-high_school_government_and_politics": 5,
    "ogx_mmlux_sk-high_school_macroeconomics": 5,
    "ogx_mmlux_sk-high_school_mathematics": 5,
    "ogx_mmlux_sk-high_school_microeconomics": 5,
    "ogx_mmlux_sk-high_school_physics": 5,
    "ogx_mmlux_sk-high_school_psychology": 5,
    "ogx_mmlux_sk-high_school_statistics": 5,
    "ogx_mmlux_sk-high_school_us_history": 5,
    "ogx_mmlux_sk-high_school_world_history": 5,
    "ogx_mmlux_sk-human_aging": 5,
    "ogx_mmlux_sk-human_sexuality": 5,
    "ogx_mmlux_sk-international_law": 5,
    "ogx_mmlux_sk-jurisprudence": 5,
    "ogx_mmlux_sk-logical_fallacies": 5,
    "ogx_mmlux_sk-machine_learning": 5,
    "ogx_mmlux_sk-management": 5,
    "ogx_mmlux_sk-marketing": 5,
    "ogx_mmlux_sk-medical_genetics": 5,
    "ogx_mmlux_sk-miscellaneous": 5,
    "ogx_mmlux_sk-moral_disputes": 5,
    "ogx_mmlux_sk-moral_scenarios": 5,
    "ogx_mmlux_sk-nutrition": 5,
    "ogx_mmlux_sk-philosophy": 5,
    "ogx_mmlux_sk-prehistory": 5,
    "ogx_mmlux_sk-professional_accounting": 5,
    "ogx_mmlux_sk-professional_law": 5,
    "ogx_mmlux_sk-professional_medicine": 5,
    "ogx_mmlux_sk-professional_psychology": 5,
    "ogx_mmlux_sk-public_relations": 5,
    "ogx_mmlux_sk-security_studies": 5,
    "ogx_mmlux_sk-sociology": 5,
    "ogx_mmlux_sk-us_foreign_policy": 5,
    "ogx_mmlux_sk-virology": 5,
    "ogx_mmlux_sk-world_religions": 5,
    "ogx_mmlux_sl-abstract_algebra": 5,
    "ogx_mmlux_sl-anatomy": 5,
    "ogx_mmlux_sl-astronomy": 5,
    "ogx_mmlux_sl-business_ethics": 5,
    "ogx_mmlux_sl-clinical_knowledge": 5,
    "ogx_mmlux_sl-college_biology": 5,
    "ogx_mmlux_sl-college_chemistry": 5,
    "ogx_mmlux_sl-college_computer_science": 5,
    "ogx_mmlux_sl-college_mathematics": 5,
    "ogx_mmlux_sl-college_medicine": 5,
    "ogx_mmlux_sl-college_physics": 5,
    "ogx_mmlux_sl-computer_security": 5,
    "ogx_mmlux_sl-conceptual_physics": 5,
    "ogx_mmlux_sl-econometrics": 5,
    "ogx_mmlux_sl-electrical_engineering": 5,
    "ogx_mmlux_sl-elementary_mathematics": 5,
    "ogx_mmlux_sl-formal_logic": 5,
    "ogx_mmlux_sl-global_facts": 5,
    "ogx_mmlux_sl-high_school_biology": 5,
    "ogx_mmlux_sl-high_school_chemistry": 5,
    "ogx_mmlux_sl-high_school_computer_science": 5,
    "ogx_mmlux_sl-high_school_european_history": 5,
    "ogx_mmlux_sl-high_school_geography": 5,
    "ogx_mmlux_sl-high_school_government_and_politics": 5,
    "ogx_mmlux_sl-high_school_macroeconomics": 5,
    "ogx_mmlux_sl-high_school_mathematics": 5,
    "ogx_mmlux_sl-high_school_microeconomics": 5,
    "ogx_mmlux_sl-high_school_physics": 5,
    "ogx_mmlux_sl-high_school_psychology": 5,
    "ogx_mmlux_sl-high_school_statistics": 5,
    "ogx_mmlux_sl-high_school_us_history": 5,
    "ogx_mmlux_sl-high_school_world_history": 5,
    "ogx_mmlux_sl-human_aging": 5,
    "ogx_mmlux_sl-human_sexuality": 5,
    "ogx_mmlux_sl-international_law": 5,
    "ogx_mmlux_sl-jurisprudence": 5,
    "ogx_mmlux_sl-logical_fallacies": 5,
    "ogx_mmlux_sl-machine_learning": 5,
    "ogx_mmlux_sl-management": 5,
    "ogx_mmlux_sl-marketing": 5,
    "ogx_mmlux_sl-medical_genetics": 5,
    "ogx_mmlux_sl-miscellaneous": 5,
    "ogx_mmlux_sl-moral_disputes": 5,
    "ogx_mmlux_sl-moral_scenarios": 5,
    "ogx_mmlux_sl-nutrition": 5,
    "ogx_mmlux_sl-philosophy": 5,
    "ogx_mmlux_sl-prehistory": 5,
    "ogx_mmlux_sl-professional_accounting": 5,
    "ogx_mmlux_sl-professional_law": 5,
    "ogx_mmlux_sl-professional_medicine": 5,
    "ogx_mmlux_sl-professional_psychology": 5,
    "ogx_mmlux_sl-public_relations": 5,
    "ogx_mmlux_sl-security_studies": 5,
    "ogx_mmlux_sl-sociology": 5,
    "ogx_mmlux_sl-us_foreign_policy": 5,
    "ogx_mmlux_sl-virology": 5,
    "ogx_mmlux_sl-world_religions": 5,
    "ogx_mmlux_sv-abstract_algebra": 5,
    "ogx_mmlux_sv-anatomy": 5,
    "ogx_mmlux_sv-astronomy": 5,
    "ogx_mmlux_sv-business_ethics": 5,
    "ogx_mmlux_sv-clinical_knowledge": 5,
    "ogx_mmlux_sv-college_biology": 5,
    "ogx_mmlux_sv-college_chemistry": 5,
    "ogx_mmlux_sv-college_computer_science": 5,
    "ogx_mmlux_sv-college_mathematics": 5,
    "ogx_mmlux_sv-college_medicine": 5,
    "ogx_mmlux_sv-college_physics": 5,
    "ogx_mmlux_sv-computer_security": 5,
    "ogx_mmlux_sv-conceptual_physics": 5,
    "ogx_mmlux_sv-econometrics": 5,
    "ogx_mmlux_sv-electrical_engineering": 5,
    "ogx_mmlux_sv-elementary_mathematics": 5,
    "ogx_mmlux_sv-formal_logic": 5,
    "ogx_mmlux_sv-global_facts": 5,
    "ogx_mmlux_sv-high_school_biology": 5,
    "ogx_mmlux_sv-high_school_chemistry": 5,
    "ogx_mmlux_sv-high_school_computer_science": 5,
    "ogx_mmlux_sv-high_school_european_history": 5,
    "ogx_mmlux_sv-high_school_geography": 5,
    "ogx_mmlux_sv-high_school_government_and_politics": 5,
    "ogx_mmlux_sv-high_school_macroeconomics": 5,
    "ogx_mmlux_sv-high_school_mathematics": 5,
    "ogx_mmlux_sv-high_school_microeconomics": 5,
    "ogx_mmlux_sv-high_school_physics": 5,
    "ogx_mmlux_sv-high_school_psychology": 5,
    "ogx_mmlux_sv-high_school_statistics": 5,
    "ogx_mmlux_sv-high_school_us_history": 5,
    "ogx_mmlux_sv-high_school_world_history": 5,
    "ogx_mmlux_sv-human_aging": 5,
    "ogx_mmlux_sv-human_sexuality": 5,
    "ogx_mmlux_sv-international_law": 5,
    "ogx_mmlux_sv-jurisprudence": 5,
    "ogx_mmlux_sv-logical_fallacies": 5,
    "ogx_mmlux_sv-machine_learning": 5,
    "ogx_mmlux_sv-management": 5,
    "ogx_mmlux_sv-marketing": 5,
    "ogx_mmlux_sv-medical_genetics": 5,
    "ogx_mmlux_sv-miscellaneous": 5,
    "ogx_mmlux_sv-moral_disputes": 5,
    "ogx_mmlux_sv-moral_scenarios": 5,
    "ogx_mmlux_sv-nutrition": 5,
    "ogx_mmlux_sv-philosophy": 5,
    "ogx_mmlux_sv-prehistory": 5,
    "ogx_mmlux_sv-professional_accounting": 5,
    "ogx_mmlux_sv-professional_law": 5,
    "ogx_mmlux_sv-professional_medicine": 5,
    "ogx_mmlux_sv-professional_psychology": 5,
    "ogx_mmlux_sv-public_relations": 5,
    "ogx_mmlux_sv-security_studies": 5,
    "ogx_mmlux_sv-sociology": 5,
    "ogx_mmlux_sv-us_foreign_policy": 5,
    "ogx_mmlux_sv-virology": 5,
    "ogx_mmlux_sv-world_religions": 5
  },
  "higher_is_better": {
    "ogx_mmlux_bg-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_bg-anatomy": {
      "acc": true
    },
    "ogx_mmlux_bg-astronomy": {
      "acc": true
    },
    "ogx_mmlux_bg-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_bg-college_biology": {
      "acc": true
    },
    "ogx_mmlux_bg-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_bg-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_bg-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_bg-college_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-computer_security": {
      "acc": true
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-econometrics": {
      "acc": true
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_bg-global_facts": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_bg-human_aging": {
      "acc": true
    },
    "ogx_mmlux_bg-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_bg-international_law": {
      "acc": true
    },
    "ogx_mmlux_bg-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_bg-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_bg-management": {
      "acc": true
    },
    "ogx_mmlux_bg-marketing": {
      "acc": true
    },
    "ogx_mmlux_bg-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_bg-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_bg-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_bg-nutrition": {
      "acc": true
    },
    "ogx_mmlux_bg-philosophy": {
      "acc": true
    },
    "ogx_mmlux_bg-prehistory": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_law": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_bg-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_bg-public_relations": {
      "acc": true
    },
    "ogx_mmlux_bg-security_studies": {
      "acc": true
    },
    "ogx_mmlux_bg-sociology": {
      "acc": true
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_bg-virology": {
      "acc": true
    },
    "ogx_mmlux_bg-world_religions": {
      "acc": true
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_cs-anatomy": {
      "acc": true
    },
    "ogx_mmlux_cs-astronomy": {
      "acc": true
    },
    "ogx_mmlux_cs-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_cs-college_biology": {
      "acc": true
    },
    "ogx_mmlux_cs-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_cs-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_cs-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_cs-college_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-computer_security": {
      "acc": true
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-econometrics": {
      "acc": true
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_cs-global_facts": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_cs-human_aging": {
      "acc": true
    },
    "ogx_mmlux_cs-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_cs-international_law": {
      "acc": true
    },
    "ogx_mmlux_cs-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_cs-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_cs-management": {
      "acc": true
    },
    "ogx_mmlux_cs-marketing": {
      "acc": true
    },
    "ogx_mmlux_cs-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_cs-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_cs-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_cs-nutrition": {
      "acc": true
    },
    "ogx_mmlux_cs-philosophy": {
      "acc": true
    },
    "ogx_mmlux_cs-prehistory": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_law": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_cs-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_cs-public_relations": {
      "acc": true
    },
    "ogx_mmlux_cs-security_studies": {
      "acc": true
    },
    "ogx_mmlux_cs-sociology": {
      "acc": true
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_cs-virology": {
      "acc": true
    },
    "ogx_mmlux_cs-world_religions": {
      "acc": true
    },
    "ogx_mmlux_da-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_da-anatomy": {
      "acc": true
    },
    "ogx_mmlux_da-astronomy": {
      "acc": true
    },
    "ogx_mmlux_da-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_da-college_biology": {
      "acc": true
    },
    "ogx_mmlux_da-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_da-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_da-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_da-college_physics": {
      "acc": true
    },
    "ogx_mmlux_da-computer_security": {
      "acc": true
    },
    "ogx_mmlux_da-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_da-econometrics": {
      "acc": true
    },
    "ogx_mmlux_da-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_da-global_facts": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_da-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_da-human_aging": {
      "acc": true
    },
    "ogx_mmlux_da-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_da-international_law": {
      "acc": true
    },
    "ogx_mmlux_da-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_da-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_da-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_da-management": {
      "acc": true
    },
    "ogx_mmlux_da-marketing": {
      "acc": true
    },
    "ogx_mmlux_da-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_da-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_da-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_da-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_da-nutrition": {
      "acc": true
    },
    "ogx_mmlux_da-philosophy": {
      "acc": true
    },
    "ogx_mmlux_da-prehistory": {
      "acc": true
    },
    "ogx_mmlux_da-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_da-professional_law": {
      "acc": true
    },
    "ogx_mmlux_da-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_da-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_da-public_relations": {
      "acc": true
    },
    "ogx_mmlux_da-security_studies": {
      "acc": true
    },
    "ogx_mmlux_da-sociology": {
      "acc": true
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_da-virology": {
      "acc": true
    },
    "ogx_mmlux_da-world_religions": {
      "acc": true
    },
    "ogx_mmlux_de-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_de-anatomy": {
      "acc": true
    },
    "ogx_mmlux_de-astronomy": {
      "acc": true
    },
    "ogx_mmlux_de-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_de-college_biology": {
      "acc": true
    },
    "ogx_mmlux_de-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_de-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_de-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_de-college_physics": {
      "acc": true
    },
    "ogx_mmlux_de-computer_security": {
      "acc": true
    },
    "ogx_mmlux_de-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_de-econometrics": {
      "acc": true
    },
    "ogx_mmlux_de-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_de-global_facts": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_de-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_de-human_aging": {
      "acc": true
    },
    "ogx_mmlux_de-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_de-international_law": {
      "acc": true
    },
    "ogx_mmlux_de-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_de-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_de-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_de-management": {
      "acc": true
    },
    "ogx_mmlux_de-marketing": {
      "acc": true
    },
    "ogx_mmlux_de-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_de-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_de-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_de-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_de-nutrition": {
      "acc": true
    },
    "ogx_mmlux_de-philosophy": {
      "acc": true
    },
    "ogx_mmlux_de-prehistory": {
      "acc": true
    },
    "ogx_mmlux_de-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_de-professional_law": {
      "acc": true
    },
    "ogx_mmlux_de-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_de-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_de-public_relations": {
      "acc": true
    },
    "ogx_mmlux_de-security_studies": {
      "acc": true
    },
    "ogx_mmlux_de-sociology": {
      "acc": true
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_de-virology": {
      "acc": true
    },
    "ogx_mmlux_de-world_religions": {
      "acc": true
    },
    "ogx_mmlux_el-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_el-anatomy": {
      "acc": true
    },
    "ogx_mmlux_el-astronomy": {
      "acc": true
    },
    "ogx_mmlux_el-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_el-college_biology": {
      "acc": true
    },
    "ogx_mmlux_el-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_el-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_el-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_el-college_physics": {
      "acc": true
    },
    "ogx_mmlux_el-computer_security": {
      "acc": true
    },
    "ogx_mmlux_el-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_el-econometrics": {
      "acc": true
    },
    "ogx_mmlux_el-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_el-global_facts": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_el-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_el-human_aging": {
      "acc": true
    },
    "ogx_mmlux_el-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_el-international_law": {
      "acc": true
    },
    "ogx_mmlux_el-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_el-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_el-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_el-management": {
      "acc": true
    },
    "ogx_mmlux_el-marketing": {
      "acc": true
    },
    "ogx_mmlux_el-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_el-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_el-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_el-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_el-nutrition": {
      "acc": true
    },
    "ogx_mmlux_el-philosophy": {
      "acc": true
    },
    "ogx_mmlux_el-prehistory": {
      "acc": true
    },
    "ogx_mmlux_el-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_el-professional_law": {
      "acc": true
    },
    "ogx_mmlux_el-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_el-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_el-public_relations": {
      "acc": true
    },
    "ogx_mmlux_el-security_studies": {
      "acc": true
    },
    "ogx_mmlux_el-sociology": {
      "acc": true
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_el-virology": {
      "acc": true
    },
    "ogx_mmlux_el-world_religions": {
      "acc": true
    },
    "ogx_mmlux_es-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_es-anatomy": {
      "acc": true
    },
    "ogx_mmlux_es-astronomy": {
      "acc": true
    },
    "ogx_mmlux_es-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_es-college_biology": {
      "acc": true
    },
    "ogx_mmlux_es-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_es-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_es-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_es-college_physics": {
      "acc": true
    },
    "ogx_mmlux_es-computer_security": {
      "acc": true
    },
    "ogx_mmlux_es-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_es-econometrics": {
      "acc": true
    },
    "ogx_mmlux_es-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_es-global_facts": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_es-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_es-human_aging": {
      "acc": true
    },
    "ogx_mmlux_es-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_es-international_law": {
      "acc": true
    },
    "ogx_mmlux_es-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_es-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_es-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_es-management": {
      "acc": true
    },
    "ogx_mmlux_es-marketing": {
      "acc": true
    },
    "ogx_mmlux_es-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_es-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_es-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_es-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_es-nutrition": {
      "acc": true
    },
    "ogx_mmlux_es-philosophy": {
      "acc": true
    },
    "ogx_mmlux_es-prehistory": {
      "acc": true
    },
    "ogx_mmlux_es-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_es-professional_law": {
      "acc": true
    },
    "ogx_mmlux_es-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_es-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_es-public_relations": {
      "acc": true
    },
    "ogx_mmlux_es-security_studies": {
      "acc": true
    },
    "ogx_mmlux_es-sociology": {
      "acc": true
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_es-virology": {
      "acc": true
    },
    "ogx_mmlux_es-world_religions": {
      "acc": true
    },
    "ogx_mmlux_et-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_et-anatomy": {
      "acc": true
    },
    "ogx_mmlux_et-astronomy": {
      "acc": true
    },
    "ogx_mmlux_et-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_et-college_biology": {
      "acc": true
    },
    "ogx_mmlux_et-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_et-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_et-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_et-college_physics": {
      "acc": true
    },
    "ogx_mmlux_et-computer_security": {
      "acc": true
    },
    "ogx_mmlux_et-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_et-econometrics": {
      "acc": true
    },
    "ogx_mmlux_et-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_et-global_facts": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_et-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_et-human_aging": {
      "acc": true
    },
    "ogx_mmlux_et-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_et-international_law": {
      "acc": true
    },
    "ogx_mmlux_et-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_et-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_et-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_et-management": {
      "acc": true
    },
    "ogx_mmlux_et-marketing": {
      "acc": true
    },
    "ogx_mmlux_et-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_et-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_et-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_et-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_et-nutrition": {
      "acc": true
    },
    "ogx_mmlux_et-philosophy": {
      "acc": true
    },
    "ogx_mmlux_et-prehistory": {
      "acc": true
    },
    "ogx_mmlux_et-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_et-professional_law": {
      "acc": true
    },
    "ogx_mmlux_et-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_et-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_et-public_relations": {
      "acc": true
    },
    "ogx_mmlux_et-security_studies": {
      "acc": true
    },
    "ogx_mmlux_et-sociology": {
      "acc": true
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_et-virology": {
      "acc": true
    },
    "ogx_mmlux_et-world_religions": {
      "acc": true
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_fi-anatomy": {
      "acc": true
    },
    "ogx_mmlux_fi-astronomy": {
      "acc": true
    },
    "ogx_mmlux_fi-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_fi-college_biology": {
      "acc": true
    },
    "ogx_mmlux_fi-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fi-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fi-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_fi-college_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-computer_security": {
      "acc": true
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-econometrics": {
      "acc": true
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_fi-global_facts": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_fi-human_aging": {
      "acc": true
    },
    "ogx_mmlux_fi-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_fi-international_law": {
      "acc": true
    },
    "ogx_mmlux_fi-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_fi-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_fi-management": {
      "acc": true
    },
    "ogx_mmlux_fi-marketing": {
      "acc": true
    },
    "ogx_mmlux_fi-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_fi-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_fi-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_fi-nutrition": {
      "acc": true
    },
    "ogx_mmlux_fi-philosophy": {
      "acc": true
    },
    "ogx_mmlux_fi-prehistory": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_law": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_fi-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_fi-public_relations": {
      "acc": true
    },
    "ogx_mmlux_fi-security_studies": {
      "acc": true
    },
    "ogx_mmlux_fi-sociology": {
      "acc": true
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_fi-virology": {
      "acc": true
    },
    "ogx_mmlux_fi-world_religions": {
      "acc": true
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_fr-anatomy": {
      "acc": true
    },
    "ogx_mmlux_fr-astronomy": {
      "acc": true
    },
    "ogx_mmlux_fr-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_fr-college_biology": {
      "acc": true
    },
    "ogx_mmlux_fr-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fr-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fr-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_fr-college_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-computer_security": {
      "acc": true
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-econometrics": {
      "acc": true
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_fr-global_facts": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_fr-human_aging": {
      "acc": true
    },
    "ogx_mmlux_fr-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_fr-international_law": {
      "acc": true
    },
    "ogx_mmlux_fr-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_fr-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_fr-management": {
      "acc": true
    },
    "ogx_mmlux_fr-marketing": {
      "acc": true
    },
    "ogx_mmlux_fr-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_fr-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_fr-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_fr-nutrition": {
      "acc": true
    },
    "ogx_mmlux_fr-philosophy": {
      "acc": true
    },
    "ogx_mmlux_fr-prehistory": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_law": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_fr-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_fr-public_relations": {
      "acc": true
    },
    "ogx_mmlux_fr-security_studies": {
      "acc": true
    },
    "ogx_mmlux_fr-sociology": {
      "acc": true
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_fr-virology": {
      "acc": true
    },
    "ogx_mmlux_fr-world_religions": {
      "acc": true
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_hu-anatomy": {
      "acc": true
    },
    "ogx_mmlux_hu-astronomy": {
      "acc": true
    },
    "ogx_mmlux_hu-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_hu-college_biology": {
      "acc": true
    },
    "ogx_mmlux_hu-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_hu-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_hu-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_hu-college_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-computer_security": {
      "acc": true
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-econometrics": {
      "acc": true
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_hu-global_facts": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_hu-human_aging": {
      "acc": true
    },
    "ogx_mmlux_hu-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_hu-international_law": {
      "acc": true
    },
    "ogx_mmlux_hu-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_hu-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_hu-management": {
      "acc": true
    },
    "ogx_mmlux_hu-marketing": {
      "acc": true
    },
    "ogx_mmlux_hu-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_hu-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_hu-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_hu-nutrition": {
      "acc": true
    },
    "ogx_mmlux_hu-philosophy": {
      "acc": true
    },
    "ogx_mmlux_hu-prehistory": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_law": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_hu-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_hu-public_relations": {
      "acc": true
    },
    "ogx_mmlux_hu-security_studies": {
      "acc": true
    },
    "ogx_mmlux_hu-sociology": {
      "acc": true
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_hu-virology": {
      "acc": true
    },
    "ogx_mmlux_hu-world_religions": {
      "acc": true
    },
    "ogx_mmlux_it-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_it-anatomy": {
      "acc": true
    },
    "ogx_mmlux_it-astronomy": {
      "acc": true
    },
    "ogx_mmlux_it-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_it-college_biology": {
      "acc": true
    },
    "ogx_mmlux_it-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_it-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_it-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_it-college_physics": {
      "acc": true
    },
    "ogx_mmlux_it-computer_security": {
      "acc": true
    },
    "ogx_mmlux_it-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_it-econometrics": {
      "acc": true
    },
    "ogx_mmlux_it-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_it-global_facts": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_it-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_it-human_aging": {
      "acc": true
    },
    "ogx_mmlux_it-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_it-international_law": {
      "acc": true
    },
    "ogx_mmlux_it-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_it-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_it-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_it-management": {
      "acc": true
    },
    "ogx_mmlux_it-marketing": {
      "acc": true
    },
    "ogx_mmlux_it-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_it-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_it-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_it-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_it-nutrition": {
      "acc": true
    },
    "ogx_mmlux_it-philosophy": {
      "acc": true
    },
    "ogx_mmlux_it-prehistory": {
      "acc": true
    },
    "ogx_mmlux_it-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_it-professional_law": {
      "acc": true
    },
    "ogx_mmlux_it-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_it-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_it-public_relations": {
      "acc": true
    },
    "ogx_mmlux_it-security_studies": {
      "acc": true
    },
    "ogx_mmlux_it-sociology": {
      "acc": true
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_it-virology": {
      "acc": true
    },
    "ogx_mmlux_it-world_religions": {
      "acc": true
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_lt-anatomy": {
      "acc": true
    },
    "ogx_mmlux_lt-astronomy": {
      "acc": true
    },
    "ogx_mmlux_lt-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_lt-college_biology": {
      "acc": true
    },
    "ogx_mmlux_lt-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lt-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lt-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_lt-college_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-computer_security": {
      "acc": true
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-econometrics": {
      "acc": true
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_lt-global_facts": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_lt-human_aging": {
      "acc": true
    },
    "ogx_mmlux_lt-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_lt-international_law": {
      "acc": true
    },
    "ogx_mmlux_lt-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_lt-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_lt-management": {
      "acc": true
    },
    "ogx_mmlux_lt-marketing": {
      "acc": true
    },
    "ogx_mmlux_lt-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_lt-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_lt-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_lt-nutrition": {
      "acc": true
    },
    "ogx_mmlux_lt-philosophy": {
      "acc": true
    },
    "ogx_mmlux_lt-prehistory": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_law": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_lt-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_lt-public_relations": {
      "acc": true
    },
    "ogx_mmlux_lt-security_studies": {
      "acc": true
    },
    "ogx_mmlux_lt-sociology": {
      "acc": true
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_lt-virology": {
      "acc": true
    },
    "ogx_mmlux_lt-world_religions": {
      "acc": true
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_lv-anatomy": {
      "acc": true
    },
    "ogx_mmlux_lv-astronomy": {
      "acc": true
    },
    "ogx_mmlux_lv-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_lv-college_biology": {
      "acc": true
    },
    "ogx_mmlux_lv-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lv-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lv-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_lv-college_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-computer_security": {
      "acc": true
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-econometrics": {
      "acc": true
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_lv-global_facts": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_lv-human_aging": {
      "acc": true
    },
    "ogx_mmlux_lv-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_lv-international_law": {
      "acc": true
    },
    "ogx_mmlux_lv-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_lv-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_lv-management": {
      "acc": true
    },
    "ogx_mmlux_lv-marketing": {
      "acc": true
    },
    "ogx_mmlux_lv-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_lv-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_lv-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_lv-nutrition": {
      "acc": true
    },
    "ogx_mmlux_lv-philosophy": {
      "acc": true
    },
    "ogx_mmlux_lv-prehistory": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_law": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_lv-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_lv-public_relations": {
      "acc": true
    },
    "ogx_mmlux_lv-security_studies": {
      "acc": true
    },
    "ogx_mmlux_lv-sociology": {
      "acc": true
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_lv-virology": {
      "acc": true
    },
    "ogx_mmlux_lv-world_religions": {
      "acc": true
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_nl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_nl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_nl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_nl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_nl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_nl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_nl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_nl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_nl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_nl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_nl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_nl-international_law": {
      "acc": true
    },
    "ogx_mmlux_nl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_nl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_nl-management": {
      "acc": true
    },
    "ogx_mmlux_nl-marketing": {
      "acc": true
    },
    "ogx_mmlux_nl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_nl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_nl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_nl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_nl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_nl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_nl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_nl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_nl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_nl-sociology": {
      "acc": true
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_nl-virology": {
      "acc": true
    },
    "ogx_mmlux_nl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_pl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_pl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_pl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_pl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_pl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_pl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_pl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_pl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_pl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_pl-international_law": {
      "acc": true
    },
    "ogx_mmlux_pl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_pl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_pl-management": {
      "acc": true
    },
    "ogx_mmlux_pl-marketing": {
      "acc": true
    },
    "ogx_mmlux_pl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_pl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_pl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_pl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_pl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_pl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_pl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_pl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_pl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_pl-sociology": {
      "acc": true
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_pl-virology": {
      "acc": true
    },
    "ogx_mmlux_pl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-international_law": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-management": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-marketing": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-sociology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-virology": {
      "acc": true
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "acc": true
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_ro-anatomy": {
      "acc": true
    },
    "ogx_mmlux_ro-astronomy": {
      "acc": true
    },
    "ogx_mmlux_ro-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_ro-college_biology": {
      "acc": true
    },
    "ogx_mmlux_ro-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_ro-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_ro-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_ro-college_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-computer_security": {
      "acc": true
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-econometrics": {
      "acc": true
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_ro-global_facts": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_ro-human_aging": {
      "acc": true
    },
    "ogx_mmlux_ro-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_ro-international_law": {
      "acc": true
    },
    "ogx_mmlux_ro-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_ro-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_ro-management": {
      "acc": true
    },
    "ogx_mmlux_ro-marketing": {
      "acc": true
    },
    "ogx_mmlux_ro-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_ro-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_ro-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_ro-nutrition": {
      "acc": true
    },
    "ogx_mmlux_ro-philosophy": {
      "acc": true
    },
    "ogx_mmlux_ro-prehistory": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_law": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_ro-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_ro-public_relations": {
      "acc": true
    },
    "ogx_mmlux_ro-security_studies": {
      "acc": true
    },
    "ogx_mmlux_ro-sociology": {
      "acc": true
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_ro-virology": {
      "acc": true
    },
    "ogx_mmlux_ro-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sk-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sk-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sk-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sk-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sk-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sk-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sk-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sk-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sk-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sk-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sk-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sk-international_law": {
      "acc": true
    },
    "ogx_mmlux_sk-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sk-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sk-management": {
      "acc": true
    },
    "ogx_mmlux_sk-marketing": {
      "acc": true
    },
    "ogx_mmlux_sk-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sk-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sk-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sk-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sk-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sk-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sk-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sk-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sk-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sk-sociology": {
      "acc": true
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sk-virology": {
      "acc": true
    },
    "ogx_mmlux_sk-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sl-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sl-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sl-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sl-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sl-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sl-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sl-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sl-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sl-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sl-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sl-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sl-international_law": {
      "acc": true
    },
    "ogx_mmlux_sl-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sl-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sl-management": {
      "acc": true
    },
    "ogx_mmlux_sl-marketing": {
      "acc": true
    },
    "ogx_mmlux_sl-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sl-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sl-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sl-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sl-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sl-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sl-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sl-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sl-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sl-sociology": {
      "acc": true
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sl-virology": {
      "acc": true
    },
    "ogx_mmlux_sl-world_religions": {
      "acc": true
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "acc": true
    },
    "ogx_mmlux_sv-anatomy": {
      "acc": true
    },
    "ogx_mmlux_sv-astronomy": {
      "acc": true
    },
    "ogx_mmlux_sv-business_ethics": {
      "acc": true
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "acc": true
    },
    "ogx_mmlux_sv-college_biology": {
      "acc": true
    },
    "ogx_mmlux_sv-college_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sv-college_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sv-college_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-college_medicine": {
      "acc": true
    },
    "ogx_mmlux_sv-college_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-computer_security": {
      "acc": true
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-econometrics": {
      "acc": true
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "acc": true
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-formal_logic": {
      "acc": true
    },
    "ogx_mmlux_sv-global_facts": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_biology": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_geography": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_physics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "acc": true
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "acc": true
    },
    "ogx_mmlux_sv-human_aging": {
      "acc": true
    },
    "ogx_mmlux_sv-human_sexuality": {
      "acc": true
    },
    "ogx_mmlux_sv-international_law": {
      "acc": true
    },
    "ogx_mmlux_sv-jurisprudence": {
      "acc": true
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "acc": true
    },
    "ogx_mmlux_sv-machine_learning": {
      "acc": true
    },
    "ogx_mmlux_sv-management": {
      "acc": true
    },
    "ogx_mmlux_sv-marketing": {
      "acc": true
    },
    "ogx_mmlux_sv-medical_genetics": {
      "acc": true
    },
    "ogx_mmlux_sv-miscellaneous": {
      "acc": true
    },
    "ogx_mmlux_sv-moral_disputes": {
      "acc": true
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "acc": true
    },
    "ogx_mmlux_sv-nutrition": {
      "acc": true
    },
    "ogx_mmlux_sv-philosophy": {
      "acc": true
    },
    "ogx_mmlux_sv-prehistory": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_accounting": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_law": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_medicine": {
      "acc": true
    },
    "ogx_mmlux_sv-professional_psychology": {
      "acc": true
    },
    "ogx_mmlux_sv-public_relations": {
      "acc": true
    },
    "ogx_mmlux_sv-security_studies": {
      "acc": true
    },
    "ogx_mmlux_sv-sociology": {
      "acc": true
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "acc": true
    },
    "ogx_mmlux_sv-virology": {
      "acc": true
    },
    "ogx_mmlux_sv-world_religions": {
      "acc": true
    }
  },
  "n-samples": {
    "ogx_mmlux_sv-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sv-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sv-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sv-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sv-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sv-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sv-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sv-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sv-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sv-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sv-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sv-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sv-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sv-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sv-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sv-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sv-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sv-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sv-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sv-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sv-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sv-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sv-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sv-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sv-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sv-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sv-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sv-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sv-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sv-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sv-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sv-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sv-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sv-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sv-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sv-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sv-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sv-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sv-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sv-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sv-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sv-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sv-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sv-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sv-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sv-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sv-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sv-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sv-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_sk-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_sk-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_sk-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_sk-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_sk-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_sk-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_sk-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_sk-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_sk-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_sk-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_sk-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_sk-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_sk-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_sk-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_sk-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_sk-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_sk-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_sk-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_sk-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_sk-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_sk-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_sk-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_sk-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_sk-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_sk-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_sk-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_sk-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_sk-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_sk-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_sk-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_sk-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_sk-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_sk-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_sk-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_sk-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_sk-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_sk-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_sk-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_sk-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_sk-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_sk-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_sk-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_sk-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_sk-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_sk-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_sk-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_sk-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_sk-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_ro-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_ro-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_ro-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_ro-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_ro-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_ro-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_ro-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_ro-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_ro-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_ro-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_ro-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_ro-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_ro-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_ro-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_ro-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_ro-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_ro-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_ro-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_ro-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_ro-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_ro-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_ro-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_ro-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_ro-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_ro-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_ro-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_ro-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_ro-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_ro-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_ro-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_ro-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_ro-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_ro-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_ro-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_ro-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_ro-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_ro-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_ro-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_ro-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_ro-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_ro-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_ro-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_ro-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_ro-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_ro-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_ro-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_ro-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_ro-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_pt-pt-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_pt-pt-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_pt-pt-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_pt-pt-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_pt-pt-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_pt-pt-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_pt-pt-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_pt-pt-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_pt-pt-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_pt-pt-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_pt-pt-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_pt-pt-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_pt-pt-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_pt-pt-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_pt-pt-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_pt-pt-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_pt-pt-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_pt-pt-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_pt-pt-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_pt-pt-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_pt-pt-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_pt-pt-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_pt-pt-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_pt-pt-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_pt-pt-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_pt-pt-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_pt-pt-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_pt-pt-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_pt-pt-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_pt-pt-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_pt-pt-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_pt-pt-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_pt-pt-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_pt-pt-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_pt-pt-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_pt-pt-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_pt-pt-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_pt-pt-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_pt-pt-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_pt-pt-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_pt-pt-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_pt-pt-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_pt-pt-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_pt-pt-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_pt-pt-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pt-pt-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_pt-pt-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_pt-pt-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_pl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_pl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_pl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_pl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_pl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_pl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_pl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_pl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_pl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_pl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_pl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_pl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_pl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_pl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_pl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_pl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_pl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_pl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_pl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_pl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_pl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_pl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_pl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_pl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_pl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_pl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_pl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_pl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_pl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_pl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_pl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_pl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_pl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_pl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_pl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_pl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_pl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_pl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_pl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_pl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_pl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_pl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_pl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_pl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_pl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_pl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_pl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_pl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_nl-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_nl-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_nl-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_nl-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_nl-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_nl-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_nl-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_nl-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_nl-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_nl-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_nl-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_nl-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_nl-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_nl-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_nl-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_nl-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_nl-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_nl-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_nl-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_nl-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_nl-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_nl-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_nl-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_nl-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_nl-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_nl-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_nl-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_nl-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_nl-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_nl-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_nl-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_nl-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_nl-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_nl-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_nl-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_nl-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_nl-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_nl-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_nl-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_nl-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_nl-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_nl-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_nl-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_nl-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_nl-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_nl-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_nl-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_nl-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_lv-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_lv-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_lv-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_lv-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_lv-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_lv-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_lv-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_lv-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_lv-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_lv-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_lv-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_lv-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_lv-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_lv-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_lv-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_lv-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_lv-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_lv-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_lv-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_lv-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_lv-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_lv-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_lv-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_lv-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_lv-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_lv-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_lv-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_lv-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_lv-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_lv-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_lv-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_lv-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_lv-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_lv-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_lv-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_lv-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_lv-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_lv-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_lv-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_lv-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_lv-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_lv-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_lv-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_lv-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_lv-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lv-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_lv-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_lv-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_lt-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_lt-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_lt-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_lt-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_lt-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_lt-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_lt-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_lt-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_lt-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_lt-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_lt-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_lt-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_lt-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_lt-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_lt-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_lt-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_lt-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_lt-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_lt-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_lt-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_lt-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_lt-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_lt-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_lt-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_lt-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_lt-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_lt-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_lt-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_lt-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_lt-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_lt-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_lt-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_lt-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_lt-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_lt-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_lt-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_lt-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_lt-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_lt-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_lt-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_lt-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_lt-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_lt-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_lt-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_lt-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_lt-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_lt-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_lt-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_it-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_it-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_it-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_it-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_it-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_it-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_it-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_it-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_it-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_it-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_it-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_it-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_it-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_it-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_it-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_it-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_it-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_it-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_it-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_it-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_it-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_it-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_it-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_it-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_it-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_it-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_it-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_it-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_it-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_it-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_it-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_it-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_it-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_it-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_it-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_it-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_it-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_it-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_it-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_it-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_it-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_it-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_it-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_it-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_it-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_it-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_it-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_it-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_hu-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_hu-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_hu-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_hu-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_hu-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_hu-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_hu-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_hu-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_hu-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_hu-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_hu-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_hu-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_hu-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_hu-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_hu-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_hu-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_hu-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_hu-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_hu-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_hu-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_hu-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_hu-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_hu-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_hu-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_hu-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_hu-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_hu-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_hu-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_hu-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_hu-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_hu-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_hu-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_hu-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_hu-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_hu-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_hu-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_hu-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_hu-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_hu-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_hu-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_hu-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_hu-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_hu-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_hu-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_hu-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_hu-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_hu-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_hu-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_fr-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_fr-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_fr-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_fr-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_fr-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_fr-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_fr-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_fr-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_fr-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_fr-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_fr-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_fr-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_fr-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_fr-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_fr-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_fr-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_fr-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_fr-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_fr-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_fr-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_fr-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_fr-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_fr-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_fr-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_fr-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_fr-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_fr-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_fr-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_fr-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_fr-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_fr-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_fr-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_fr-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_fr-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_fr-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_fr-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_fr-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_fr-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_fr-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_fr-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_fr-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_fr-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_fr-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_fr-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_fr-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fr-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_fr-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_fr-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_fi-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_fi-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_fi-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_fi-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_fi-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_fi-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_fi-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_fi-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_fi-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_fi-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_fi-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_fi-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_fi-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_fi-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_fi-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_fi-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_fi-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_fi-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_fi-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_fi-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_fi-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_fi-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_fi-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_fi-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_fi-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_fi-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_fi-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_fi-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_fi-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_fi-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_fi-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_fi-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_fi-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_fi-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_fi-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_fi-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_fi-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_fi-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_fi-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_fi-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_fi-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_fi-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_fi-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_fi-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_fi-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_fi-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_fi-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_fi-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_et-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_et-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_et-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_et-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_et-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_et-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_et-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_et-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_et-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_et-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_et-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_et-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_et-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_et-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_et-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_et-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_et-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_et-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_et-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_et-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_et-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_et-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_et-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_et-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_et-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_et-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_et-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_et-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_et-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_et-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_et-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_et-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_et-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_et-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_et-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_et-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_et-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_et-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_et-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_et-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_et-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_et-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_et-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_et-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_et-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_et-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_et-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_et-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_es-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_es-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_es-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_es-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_es-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_es-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_es-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_es-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_es-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_es-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_es-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_es-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_es-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_es-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_es-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_es-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_es-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_es-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_es-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_es-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_es-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_es-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_es-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_es-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_es-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_es-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_es-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_es-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_es-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_es-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_es-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_es-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_es-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_es-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_es-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_es-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_es-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_es-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_es-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_es-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_es-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_es-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_es-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_es-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_es-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_es-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_es-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_es-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_el-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_el-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_el-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_el-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_el-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_el-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_el-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_el-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_el-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_el-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_el-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_el-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_el-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_el-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_el-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_el-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_el-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_el-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_el-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_el-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_el-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_el-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_el-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_el-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_el-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_el-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_el-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_el-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_el-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_el-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_el-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_el-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_el-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_el-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_el-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_el-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_el-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_el-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_el-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_el-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_el-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_el-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_el-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_el-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_el-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_el-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_el-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_el-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_de-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_de-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_de-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_de-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_de-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_de-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_de-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_de-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_de-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_de-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_de-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_de-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_de-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_de-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_de-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_de-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_de-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_de-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_de-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_de-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_de-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_de-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_de-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_de-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_de-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_de-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_de-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_de-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_de-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_de-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_de-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_de-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_de-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_de-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_de-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_de-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_de-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_de-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_de-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_de-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_de-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_de-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_de-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_de-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_de-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_de-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_de-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_de-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_da-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_da-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_da-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_da-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_da-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_da-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_da-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_da-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_da-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_da-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_da-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_da-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_da-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_da-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_da-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_da-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_da-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_da-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_da-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_da-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_da-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_da-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_da-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_da-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_da-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_da-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_da-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_da-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_da-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_da-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_da-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_da-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_da-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_da-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_da-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_da-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_da-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_da-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_da-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_da-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_da-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_da-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_da-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_da-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_da-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_da-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_da-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_da-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_cs-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_cs-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_cs-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_cs-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_cs-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_cs-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_cs-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_cs-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_cs-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_cs-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_cs-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_cs-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_cs-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_cs-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_cs-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_cs-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_cs-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_cs-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_cs-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_cs-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_cs-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_cs-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_cs-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_cs-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_cs-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_cs-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_cs-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_cs-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_cs-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_cs-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_cs-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_cs-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_cs-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_cs-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_cs-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_cs-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_cs-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_cs-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_cs-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_cs-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_cs-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_cs-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_cs-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_cs-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_cs-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_cs-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_cs-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_cs-abstract_algebra": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-world_religions": {
      "original": 171,
      "effective": 171
    },
    "ogx_mmlux_bg-virology": {
      "original": 166,
      "effective": 166
    },
    "ogx_mmlux_bg-us_foreign_policy": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-sociology": {
      "original": 201,
      "effective": 201
    },
    "ogx_mmlux_bg-security_studies": {
      "original": 245,
      "effective": 245
    },
    "ogx_mmlux_bg-public_relations": {
      "original": 110,
      "effective": 110
    },
    "ogx_mmlux_bg-professional_psychology": {
      "original": 612,
      "effective": 612
    },
    "ogx_mmlux_bg-professional_medicine": {
      "original": 272,
      "effective": 272
    },
    "ogx_mmlux_bg-professional_law": {
      "original": 1534,
      "effective": 1534
    },
    "ogx_mmlux_bg-professional_accounting": {
      "original": 282,
      "effective": 282
    },
    "ogx_mmlux_bg-prehistory": {
      "original": 324,
      "effective": 324
    },
    "ogx_mmlux_bg-philosophy": {
      "original": 311,
      "effective": 311
    },
    "ogx_mmlux_bg-nutrition": {
      "original": 306,
      "effective": 306
    },
    "ogx_mmlux_bg-moral_scenarios": {
      "original": 895,
      "effective": 895
    },
    "ogx_mmlux_bg-moral_disputes": {
      "original": 346,
      "effective": 346
    },
    "ogx_mmlux_bg-miscellaneous": {
      "original": 783,
      "effective": 783
    },
    "ogx_mmlux_bg-medical_genetics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-marketing": {
      "original": 234,
      "effective": 234
    },
    "ogx_mmlux_bg-management": {
      "original": 103,
      "effective": 103
    },
    "ogx_mmlux_bg-machine_learning": {
      "original": 112,
      "effective": 112
    },
    "ogx_mmlux_bg-logical_fallacies": {
      "original": 163,
      "effective": 163
    },
    "ogx_mmlux_bg-jurisprudence": {
      "original": 108,
      "effective": 108
    },
    "ogx_mmlux_bg-international_law": {
      "original": 121,
      "effective": 121
    },
    "ogx_mmlux_bg-human_sexuality": {
      "original": 131,
      "effective": 131
    },
    "ogx_mmlux_bg-human_aging": {
      "original": 223,
      "effective": 223
    },
    "ogx_mmlux_bg-high_school_world_history": {
      "original": 237,
      "effective": 237
    },
    "ogx_mmlux_bg-high_school_us_history": {
      "original": 204,
      "effective": 204
    },
    "ogx_mmlux_bg-high_school_statistics": {
      "original": 216,
      "effective": 216
    },
    "ogx_mmlux_bg-high_school_psychology": {
      "original": 545,
      "effective": 545
    },
    "ogx_mmlux_bg-high_school_physics": {
      "original": 151,
      "effective": 151
    },
    "ogx_mmlux_bg-high_school_microeconomics": {
      "original": 238,
      "effective": 238
    },
    "ogx_mmlux_bg-high_school_mathematics": {
      "original": 270,
      "effective": 270
    },
    "ogx_mmlux_bg-high_school_macroeconomics": {
      "original": 390,
      "effective": 390
    },
    "ogx_mmlux_bg-high_school_government_and_politics": {
      "original": 193,
      "effective": 193
    },
    "ogx_mmlux_bg-high_school_geography": {
      "original": 198,
      "effective": 198
    },
    "ogx_mmlux_bg-high_school_european_history": {
      "original": 165,
      "effective": 165
    },
    "ogx_mmlux_bg-high_school_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-high_school_chemistry": {
      "original": 203,
      "effective": 203
    },
    "ogx_mmlux_bg-high_school_biology": {
      "original": 310,
      "effective": 310
    },
    "ogx_mmlux_bg-global_facts": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-formal_logic": {
      "original": 126,
      "effective": 126
    },
    "ogx_mmlux_bg-elementary_mathematics": {
      "original": 378,
      "effective": 378
    },
    "ogx_mmlux_bg-electrical_engineering": {
      "original": 145,
      "effective": 145
    },
    "ogx_mmlux_bg-econometrics": {
      "original": 114,
      "effective": 114
    },
    "ogx_mmlux_bg-conceptual_physics": {
      "original": 235,
      "effective": 235
    },
    "ogx_mmlux_bg-computer_security": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_physics": {
      "original": 102,
      "effective": 102
    },
    "ogx_mmlux_bg-college_medicine": {
      "original": 173,
      "effective": 173
    },
    "ogx_mmlux_bg-college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-college_biology": {
      "original": 144,
      "effective": 144
    },
    "ogx_mmlux_bg-clinical_knowledge": {
      "original": 265,
      "effective": 265
    },
    "ogx_mmlux_bg-business_ethics": {
      "original": 100,
      "effective": 100
    },
    "ogx_mmlux_bg-astronomy": {
      "original": 152,
      "effective": 152
    },
    "ogx_mmlux_bg-anatomy": {
      "original": 135,
      "effective": 135
    },
    "ogx_mmlux_bg-abstract_algebra": {
      "original": 100,
      "effective": 100
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=meta-llama/Llama-3.1-8B,dtype=bfloat16,trust_remote_code=True,nccl_timeout=3600,trust_remote_code=True",
    "model_num_parameters": 8030261248,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "d04e592bb4f6aa9cfee91e2e20afa771667e1d4b",
    "batch_size": "auto",
    "batch_sizes": [
      8
    ],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "43468b99",
  "date": 1740644404.0810516,
  "pretty_env_info": "PyTorch version: 2.5.1\nIs debug build: False\nCUDA used to build PyTorch: 12.1\nROCM used to build PyTorch: N/A\n\nOS: Red Hat Enterprise Linux release 8.10 (Ootpa) (x86_64)\nGCC version: (GCC) 8.5.0 20210514 (Red Hat 8.5.0-23)\nClang version: Could not collect\nCMake version: version 3.26.5\nLibc version: glibc-2.28\n\nPython version: 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0] (64-bit runtime)\nPython platform: Linux-4.18.0-553.el8_10.x86_64-x86_64-with-glibc2.28\nIs CUDA available: True\nCUDA runtime version: 12.1.105\nCUDA_MODULE_LOADING set to: LAZY\nGPU models and configuration: \nGPU 0: NVIDIA A100-SXM4-80GB\nGPU 1: NVIDIA A100-SXM4-80GB\nGPU 2: NVIDIA A100-SXM4-80GB\nGPU 3: NVIDIA A100-SXM4-80GB\n\nNvidia driver version: 560.35.05\ncuDNN version: Could not collect\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nArchitecture:        x86_64\nCPU op-mode(s):      32-bit, 64-bit\nByte Order:          Little Endian\nCPU(s):              144\nOn-line CPU(s) list: 0-143\nThread(s) per core:  2\nCore(s) per socket:  36\nSocket(s):           2\nNUMA node(s):        2\nVendor ID:           GenuineIntel\nCPU family:          6\nModel:               106\nModel name:          Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz\nStepping:            6\nCPU MHz:             818.028\nBogoMIPS:            4800.00\nVirtualization:      VT-x\nL1d cache:           48K\nL1i cache:           32K\nL2 cache:            1280K\nL3 cache:            55296K\nNUMA node0 CPU(s):   0-35,72-107\nNUMA node1 CPU(s):   36-71,108-143\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 invpcid_single intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb intel_pt avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local split_lock_detect wbnoinvd dtherm ida arat pln pts hwp_epp avx512vbmi umip pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq rdpid fsrm md_clear pconfig flush_l1d arch_capabilities\n\nVersions of relevant libraries:\n[pip3] numpy==2.0.1\n[pip3] torch==2.5.1\n[pip3] torchaudio==2.5.1\n[pip3] torchvision==0.20.1\n[pip3] triton==3.1.0\n[conda] blas                      1.0                         mkl  \n[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch\n[conda] libjpeg-turbo             2.0.0                h9bf148f_0    pytorch\n[conda] mkl                       2023.1.0         h213fc3f_46344  \n[conda] mkl-service               2.4.0           py310h5eee18b_1  \n[conda] mkl_fft                   1.3.11          py310h5eee18b_0  \n[conda] mkl_random                1.2.8           py310h1128e8f_0  \n[conda] numpy                     2.0.1           py310h5f9d8c6_1  \n[conda] numpy-base                2.0.1           py310hb5e798b_1  \n[conda] pytorch                   2.5.1           py3.10_cuda12.1_cudnn9.1.0_0    pytorch\n[conda] pytorch-cuda              12.1                 ha16c6d3_6    pytorch\n[conda] pytorch-mutex             1.0                        cuda    pytorch\n[conda] torchaudio                2.5.1               py310_cu121    pytorch\n[conda] torchtriton               3.1.0                     py310    pytorch\n[conda] torchvision               0.20.1              py310_cu121    pytorch",
  "transformers_version": "4.49.0",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<|end_of_text|>",
    128001
  ],
  "tokenizer_eos_token": [
    "<|end_of_text|>",
    128001
  ],
  "tokenizer_bos_token": [
    "<|begin_of_text|>",
    128000
  ],
  "eot_token_id": 128001,
  "max_length": 131072,
  "task_hashes": {},
  "model_source": "hf",
  "model_name": "meta-llama/Llama-3.1-8B",
  "model_name_sanitized": "meta-llama__Llama-3.1-8B",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": false,
  "chat_template": null,
  "chat_template_sha": null,
  "start_time": 4291689.984883482,
  "end_time": 4303756.785997513,
  "total_evaluation_time_seconds": "12066.801114031114"
}